<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>Laser Holography</title>
      <link href="/2020/05/03/Projects/Laser-holography/"/>
      <url>/2020/05/03/Projects/Laser-holography/</url>
      
        <content type="html"><![CDATA[<p>This is the my final report for Semiconductor Laser Holography experiement in physics experiment course.</p><p>waiting for upload~</p><!--<div class="row">    <embed src="/pdf_files/半导体激光全息实验总结.pdf" width="100%" height="550" type="application/pdf"></div><p>--&gt;</p>]]></content>
      
      
      <categories>
          
          <category> Projects </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>Optomechanical Structural Design</title>
      <link href="/2020/05/03/Projects/Optomechanical-Structural-Design/"/>
      <url>/2020/05/03/Projects/Optomechanical-Structural-Design/</url>
      
        <content type="html"><![CDATA[<p>This is the major assignment for our optomechanical structural design course. Thanks a lot for Xiaowen Wang, Longxun Cao and Hanmo Mei. That week we all had little time for sleep and we finally made a really big guy! Although that period was very hard , I really cherish it.</p><p>I will make it more detailed when I have time.</p><h3 id="工程图汇总">工程图汇总</h3><div class="row">    <embed src="/pdf_files/钢铁侠手臂台灯-工程图汇总.pdf" width="100%" height="550" type="application/pdf"></div><h3 id="设计文件">设计文件</h3><div class="row">    <embed src="/pdf_files/钢铁侠手臂台灯项目设计文件.pdf" width="100%" height="550" type="application/pdf"></div><h3 id="展示ppt">展示PPT</h3><p>waiting~</p>]]></content>
      
      
      <categories>
          
          <category> Projects </category>
          
          <category> Optics </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>NA-Notes</title>
      <link href="/2020/05/03/Notes-byhand/NA-notes/"/>
      <url>/2020/05/03/Notes-byhand/NA-notes/</url>
      
        <content type="html"><![CDATA[<p>This is my class notes for Numerical Analysis. Hopefully one day I can organize it into an electronic version.</p><p>Waiting for upload~</p><!--<div class="row">    <embed src="/pdf_files/数值分析方法.pdf" width="100%" height="550" type="application/pdf"></div><p>--&gt;</p>]]></content>
      
      
      <categories>
          
          <category> notes </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>PDE-Notes</title>
      <link href="/2020/05/03/Notes-byhand/pde-notes/"/>
      <url>/2020/05/03/Notes-byhand/pde-notes/</url>
      
        <content type="html"><![CDATA[<p>This is my class notes for PDE (partial differential equations ) course.</p><p>...</p><p>Due to the capacity limit, I cannot upload it (200+MB), will find a solution when I have time~</p>]]></content>
      
      
      <categories>
          
          <category> notes </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>Optical Combination Experiment</title>
      <link href="/2020/05/03/Projects/Optical-combination-experiment/"/>
      <url>/2020/05/03/Projects/Optical-combination-experiment/</url>
      
        <content type="html"><![CDATA[<p>This is the optical combination experiment report I’ve done in the Aplied Optical Experiment course.</p><p>Waiting for upload ~</p><!--<div class="row">    <embed src="/pdf_files/光学组合实验实验报告.pdf" width="100%" height="550" type="application/pdf"></div><p>--&gt;</p>]]></content>
      
      
      <categories>
          
          <category> Projects </category>
          
          <category> Optics </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>iPhone Focal Length Measurement</title>
      <link href="/2020/05/03/Projects/iPhone-focal-length-measurement/"/>
      <url>/2020/05/03/Projects/iPhone-focal-length-measurement/</url>
      
        <content type="html"><![CDATA[<p>This is the mobile phone focal length measurement experiment report I’ve done in the Aplied Optical Experiment course.</p><p>Waiting for upload~</p><!--<div class="row">    <embed src="/pdf_files/手机焦距测量实验报告.pdf" width="100%" height="550" type="application/pdf"></div><p>--&gt;</p>]]></content>
      
      
      <categories>
          
          <category> Projects </category>
          
          <category> Optics </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>2020-ICM</title>
      <link href="/2020/05/02/Projects/2020-ICM/"/>
      <url>/2020/05/02/Projects/2020-ICM/</url>
      
        <content type="html"><![CDATA[<p>This work is mainly about the football game team strategy based on big data and is our final paper for the D problem of 2020 Interdisciplinary Contest in Modelling (ICM 2020), contributed collaboratively and equally by R.C. Luo, Y.Z. Zhang and me.</p><p>Thanks cordially to the combined efforts of whole group, we fortunately won an M-prize. Due to privacy and copyright, the control number in our paper is erased.</p><div class="row">    <embed src="/pdf_files/2020_ICM.pdf" width="100%" height="550" type="application/pdf"></div>]]></content>
      
      
      <categories>
          
          <category> Projects </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>Matlab学习</title>
      <link href="/2020/03/03/Computer-Sciencs/Matlab%E5%AD%A6%E4%B9%A0/"/>
      <url>/2020/03/03/Computer-Sciencs/Matlab%E5%AD%A6%E4%B9%A0/</url>
      
        <content type="html"><![CDATA[<h2 id="matlab-学习笔记">Matlab 学习笔记</h2><ul><li><p>函数必须以end结尾。将其保存为.m 文件，即可在其他程 序中以文件名（注意不是函数名，文件名和函数名可以不同）调用该函数。</p></li><li><p>关系运算</p><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs matlab">a~=b<span class="hljs-comment">%不等于</span><br>a&gt;=b<span class="hljs-comment">%大于等于</span><br>a&lt;=b<span class="hljs-comment">%小于等于</span><br></code></pre></td></tr></table></figure></li><li><p>复数</p><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs matlab">a=<span class="hljs-number">1</span>+<span class="hljs-number">2</span><span class="hljs-built_in">i</span><br>z=<span class="hljs-built_in">real</span>(a)<span class="hljs-comment">%实部</span><br>z=<span class="hljs-built_in">imag</span>(a)<span class="hljs-comment">%虚部</span><br>z=<span class="hljs-built_in">angle</span>(a)<span class="hljs-comment">%辐角</span><br>z=<span class="hljs-built_in">abs</span>(a)<span class="hljs-comment">%模</span><br>z=<span class="hljs-built_in">conj</span>(a)<span class="hljs-comment">%共轭</span><br></code></pre></td></tr></table></figure></li><li><p>向量操作</p><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs matlab">a=<span class="hljs-built_in">rand</span>(<span class="hljs-number">1</span>,<span class="hljs-number">3</span>)<br>b=<span class="hljs-built_in">rand</span>(<span class="hljs-number">1</span>,<span class="hljs-number">3</span>)<br>c=<span class="hljs-built_in">dot</span>(a,b)<span class="hljs-comment">%内积</span><br>d=<span class="hljs-built_in">cross</span>(a,b)<span class="hljs-comment">%叉乘</span><br>l=<span class="hljs-built_in">length</span>(a)<span class="hljs-comment">%向量长度</span><br>median(a)<span class="hljs-comment">%中位数</span><br>std(a)<span class="hljs-comment">%标准差</span><br>s=<span class="hljs-built_in">sort</span>(a)<span class="hljs-comment">%排序</span><br><span class="hljs-comment">%还有 min max 等</span><br></code></pre></td></tr></table></figure></li><li><p>矩阵操作</p></li></ul><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs matlab">a=<span class="hljs-built_in">rand</span>(<span class="hljs-number">5</span>,<span class="hljs-number">3</span>)<br>b=<span class="hljs-built_in">rand</span>(<span class="hljs-number">5</span>,<span class="hljs-number">3</span>)<br>b=b'<span class="hljs-comment">%转置</span><br>c=a*b<span class="hljs-comment">%矩阵乘法</span><br>d=a.*b<span class="hljs-comment">%逐元素相乘</span><br>m=b^<span class="hljs-number">3</span><span class="hljs-comment">%幂</span><br>m=b.^<span class="hljs-number">3</span><span class="hljs-comment">%点幂</span><br><span class="hljs-built_in">size</span>(b)<span class="hljs-comment">%矩阵大小</span><br>b=<span class="hljs-built_in">reshape</span>(<span class="hljs-number">1</span>,<span class="hljs-number">15</span>)<br>b=<span class="hljs-built_in">flipud</span>(b)<span class="hljs-comment">%上下翻转 up and down</span><br>b=<span class="hljs-built_in">fliplr</span>(b)<span class="hljs-comment">%左右翻转 left and right</span><br>e=<span class="hljs-built_in">diag</span>(b)<span class="hljs-comment">%取出b的对角元素</span><br><br>left_division=a/b<span class="hljs-comment">% b*inv(a)</span><br>right_division=a\b<span class="hljs-comment">% inv(a)*b</span><br><span class="hljs-comment">%X=A\B是方程A*X=B的解，X=A\B是方程X*A=B的解 </span><br><span class="hljs-comment">%记忆：朝向哪 逆在哪</span><br></code></pre></td></tr></table></figure><ul><li><p>绘图</p><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs matlab">x=<span class="hljs-built_in">linspace</span>(<span class="hljs-number">1</span>,<span class="hljs-number">10</span>,<span class="hljs-number">100</span>)<br>y1=<span class="hljs-built_in">sin</span>(x)<br>y2=<span class="hljs-built_in">cos</span>(x)<br>y3=<span class="hljs-built_in">tan</span>(x)<br><span class="hljs-built_in">plot</span>(x,y1,<span class="hljs-string">'blue'</span>,x,y2,<span class="hljs-string">'LineWidth'</span>,<span class="hljs-number">2</span>,<span class="hljs-string">'color'</span>,<span class="hljs-string">'red'</span>)<br><span class="hljs-comment">%要在同一图中画出多条曲线，只需将坐标依次放入plot函数即可</span><br>axis([<span class="hljs-number">0</span> <span class="hljs-number">4</span>*<span class="hljs-built_in">pi</span> <span class="hljs-number">-1.2</span> <span class="hljs-number">1.2</span>])<span class="hljs-comment">%设置坐标轴范围</span><br>xlim([<span class="hljs-number">1</span> <span class="hljs-number">2</span>])<span class="hljs-comment">%单独控制</span><br>xlabel(<span class="hljs-string">'x'</span>); ylabel(<span class="hljs-string">'y'</span>);<br><span class="hljs-built_in">legend</span>(<span class="hljs-string">'sin(x)'</span>,<span class="hljs-string">'cos(x)'</span>);<br>title(<span class="hljs-string">'Sine and Cosine Functions'</span>);<br><span class="hljs-comment">%title里可以使用latex语法</span><br><span class="hljs-comment">%如 ：title('$y_1=\sin(4\pi t+\pi /3)$','interpreter','latex')</span><br><span class="hljs-comment">% 注明解释器为latex即可</span><br><br><span class="hljs-comment">%绘制子图</span><br>subplot(<span class="hljs-number">2</span>,<span class="hljs-number">2</span>,<span class="hljs-number">1</span>); <span class="hljs-built_in">plot</span>(x,y1);<br>subplot(<span class="hljs-number">2</span>,<span class="hljs-number">2</span>,<span class="hljs-number">2</span>); <span class="hljs-built_in">plot</span>(x,y2);<br>subplot(<span class="hljs-number">2</span>,<span class="hljs-number">2</span>,<span class="hljs-number">3</span>); <span class="hljs-built_in">plot</span>(x,y3);<br></code></pre></td></tr></table></figure></li><li><p>信号处理</p><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs matlab"><span class="hljs-comment">%噪声</span><br>snr=<span class="hljs-number">10</span>; <span class="hljs-comment">%Signal‐to‐noise ratio in dB.</span><br>yn=awgn(y,snr,<span class="hljs-string">'measured'</span>); <span class="hljs-comment">% Add white Gaussian noise. 白噪声</span><br><br><span class="hljs-comment">%函数</span><br>k1=<span class="hljs-number">-3</span>; k2=<span class="hljs-number">3</span>; k=k1:k2; n=<span class="hljs-number">0</span>;<br>step=stepfun(t,t0)<span class="hljs-comment">%t是向量形式的变量,t0表示延迟 阶跃函数</span><br>delta=+(k==n) <span class="hljs-comment">% 冲激函数</span><br>stem(k,delta,<span class="hljs-string">'filled'</span>)<span class="hljs-comment">% 离散函数绘制 stem为绘制杆状图</span><br><br><span class="hljs-comment">%rectpuls和tripuls函数产生指定宽度和高度的矩形和三角脉冲。</span><br></code></pre></td></tr></table></figure></li><li><p>其他技巧</p><ul><li>nargin, nargout 的使用</li></ul></li></ul>]]></content>
      
      
      <categories>
          
          <category> Computer Science </category>
          
          <category> Language Learning </category>
          
          <category> Matlab </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>应用光学</title>
      <link href="/2020/03/02/Physics/%E5%BA%94%E7%94%A8%E5%85%89%E5%AD%A6/"/>
      <url>/2020/03/02/Physics/%E5%BA%94%E7%94%A8%E5%85%89%E5%AD%A6/</url>
      
        <content type="html"><![CDATA[<h1 id="应用光学-整理">应用光学 整理</h1><h2 id="几何光学基础">1. 几何光学基础</h2><ul><li><p>全反射 <span class="math display">\[I=\arcsin{\frac{n_2}{n_1}}\]</span></p></li><li><p>矢量形式的折射定律 <span class="math display">\[\vec A&#39;=\vec A+P\vec N\\\]</span> 其中： <span class="math display">\[\begin{aligned}P&amp;=(\vec A&#39;-\vec A)\cdot \vec N\\&amp;=n&#39;\cos I&#39;-n\cos I\\&amp;=\sqrt{n&#39;^2-n^2\sin ^2 I}-n\cos I\end{aligned}\]</span> 且 <span class="math inline">\(\vec A,\vec A’\)</span> 均为单位向量</p></li><li><p>矢量形式的反射定律 <span class="math display">\[\vec A&#39;=\vec A-2(\vec N\cdot \vec A)\vec N\]</span></p></li><li><p>光程</p><p>​ 光在介质中所经过的几何路径与该介质折射率的乘积。相当于光在介质中走过路程的时间内，在真空中所走的几何路程。 <span class="math display">\[\notag s=nl=ct\]</span></p></li><li><p>完善成像</p><p>​ 等光程上完善成像的物理条件。</p></li></ul><h2 id="球面与球面系统">2. 球面与球面系统</h2><h3 id="单个球面镜成像">单个球面镜成像</h3><ul><li><p>基本公式 <span class="math display">\[\begin{aligned}&amp;\frac{n&#39;}{l&#39;}-\frac{n}{l}=\frac{n&#39;-n}{r}\\&amp;n&#39;u&#39;-nu=\frac{n&#39;-n}{r}h\end{aligned}\]</span></p></li><li><p>光焦度 <span class="math display">\[\phi=\frac{n&#39;-n}{r}=\frac{n&#39;}{f&#39;}=\frac{n}{f}\]</span></p></li><li><p>放大率</p><ul><li><p>横向 <span class="math display">\[\beta=\frac{y&#39;}{y}=\frac{l&#39;-r}{l-r}=\frac{nl&#39;}{n&#39;l}\]</span></p><p><span class="math inline">\(\beta&gt;0\)</span> : 虚实不同；<span class="math inline">\(\beta&lt;0\)</span> : 虚实相同。</p></li><li><p>轴向 <span class="math display">\[\alpha=\frac{dl&#39;}{dl}=\frac{nl&#39;^2}{nl^2}\]</span> 反应像与物的沿轴移动量之比。</p></li><li><p>角度 <span class="math display">\[\gamma=\frac{u&#39;}{u}=\frac{l}{l&#39;}=\frac{n}{n&#39;}\frac{1}{\beta}\]</span></p></li></ul></li><li><p>关系 <span class="math display">\[  \alpha\gamma=\beta  \]</span></p></li><li><p>不变量</p><ul><li><p>阿贝不变量 <span class="math display">\[Q=n(\frac{1}{l}-\frac{1}{r})=n&#39;(\frac{1}{l&#39;}-\frac{1}{r&#39;})\]</span> 阿贝不变量表征界面对某物点发出光线的偏折能力.</p></li><li><p>拉赫不变量</p></li></ul><p><span class="math display">\[J=nyu=n&#39;y&#39;u&#39;\]</span> ​ 推导： <span class="math display">\[\notag\beta=\frac{y&#39;}{y}=\frac{nl&#39;}{n&#39;l}=\frac{nu}{n&#39;u&#39;}\implies nyu=n&#39;y&#39;u&#39;\]</span></p><p>​ <span class="math inline">\(J\)</span> 大，成像范围大，成像孔径角大，传输光能多。</p><p>​ 拉赫不变量表征光学系统的成像能力.</p></li></ul><h3 id="反射球面球面镜">反射球面（球面镜）</h3><ul><li><span class="math inline">\(n’=-n\)</span></li></ul><h2 id="平面和平面系统">3. 平面和平面系统</h2><h3 id="平面镜">平面镜</h3><ul><li>奇次反射成镜像，偶次反射成一致像</li><li>若反射光线不动，平面镜转 <span class="math inline">\(\alpha\)</span> 角，则反射光线转 <span class="math inline">\(2\alpha\)</span> 角</li></ul><h3 id="双平面镜">双平面镜</h3><ul><li>夹角为 <span class="math inline">\(\alpha\)</span> 的双平面镜系统，物与二次反射后所成像的夹角为 <span class="math inline">\(2\alpha\)</span> .</li><li>入射光线与反射光线的夹角为 <span class="math inline">\(2\alpha\)</span> .</li></ul><h3 id="平行平板">平行平板</h3><ul><li><p>近轴横向位移公式 <span class="math display">\[\Delta l&#39;=d(1-\frac{1}{n})\]</span></p></li><li><p>近轴纵向位移公式 <span class="math display">\[\Delta t&#39;=di(1-\frac{1}{n})\]</span> <span class="math inline">\(i\)</span> 为入射角 .</p></li></ul><h3 id="反射棱镜">反射棱镜</h3><ul><li><p>结构常数</p><p>​ 光轴在棱镜中的长度与棱镜通光口径之比 <span class="math display">\[K=\frac{d}{D}\]</span></p></li><li><p>五角棱镜 <span class="math display">\[K=2+\sqrt{2}\notag\]</span></p></li><li><p>达夫棱镜 <span class="math display">\[K=\frac{1}{\sin(45^{\circ}-i)}\notag\]</span></p><p>达夫棱镜的重要性质在于当它绕平行于反射面的轴转 <span class="math inline">\(\alpha\)</span> 角时，物体的反射像将转过 <span class="math inline">\(2\alpha\)</span> 角。</p></li><li><p>屋脊棱镜</p><p>可以增加一次反射，改变像坐标系的左右旋向。</p></li><li>由物坐标求像坐标<ul><li>光轴方向 <span class="math inline">\(z’\)</span> 不变</li><li>垂直于主截面的坐标 <span class="math inline">\(x’\)</span> 视屋脊个数而定：奇数个倒转，偶数个不变。 或者：沿方向画一画确定</li><li><span class="math inline">\(y’\)</span> 坐标根据总反射次数而定：奇数次变左手系。</li></ul></li><li><p>角锥棱镜</p><ul><li><p>从底面以任意方向入射的光线，经三个反射面顺序反射后，以与入射光线相反的方向从底面射出。</p></li><li>当棱镜角以角顶为中心向任意方向偏转时，出射光线方向不变。</li><li>用</li><li><p>矢量形式的反射定律证明</p></li></ul></li></ul><h3 id="折射棱镜">折射棱镜</h3><p><img src="https://tva1.sinaimg.cn/large/00831rSTly1gcv1smbisuj30ad06t0sr.jpg" style="zoom: 67%;" /></p><ul><li><p>偏角公式 <span class="math display">\[\sin(\frac{\alpha+\delta_{min}}{2})=n\sin\frac{\alpha}{2}\]</span> 此时 <span class="math inline">\(I_1=-I_2’, I’_1=-I_2\)</span> .</p></li><li><p>近轴简化：入射角有一定大小，折射角 <span class="math inline">\(\alpha\)</span> 很小 <span class="math display">\[\delta=\alpha\big(n\frac{\cos I&#39;_1}{\cos I_1}-1\big)\]</span></p></li><li><p>近轴简化：入射角很小，折射角很小 <span class="math display">\[\delta=(n-1)\alpha\]</span></p></li></ul><h2 id="理想光学系统">4. 理想光学系统</h2><figure><img src="https://tva1.sinaimg.cn/large/00831rSTly1gd5cgjb5nej32720rstdm.jpg" alt="image-20200324211216424" /><figcaption>image-20200324211216424</figcaption></figure><p>​ 理想光学系统，就是能对任意宽空间内的点以任意宽的光束成完善像的光学系统。</p><h3 id="基本概念">（1）基本概念</h3><ul><li>主点、主平面</li><li>节点</li><li>基点</li><li>焦物距、焦像距</li><li>光焦度：折合焦距的倒数</li><li>视觉放大率</li><li>物距<span class="math inline">\(\ell\)</span> : 主点到物点到距离，像距<span class="math inline">\(\ell&#39;\)</span> : 主点到像点到距离</li></ul><h3 id="作图技巧">（2）作图技巧</h3><ul><li><p>辅助光线：</p><ul><li>平行光轴入射</li><li>过物方焦点入射</li><li>过节点入射</li></ul></li><li><p>依据：</p><ul><li><p>倾斜光轴入射的平行光束过系统后会聚雨像方焦平面</p></li><li><p>物方焦平面上一点发出的光束经系统后相互平行</p></li><li><p>光线与物方、像方主面 的交点，其高度相等</p></li></ul></li></ul><h3 id="公式荟萃">（3）公式荟萃</h3><h4 id="焦距">焦距</h4><p>单个光组： <span class="math display">\[\begin{aligned}(基本)\quad &amp;f&#39;=\frac{h}{u&#39;},\quad f=\frac{h}{u}\\(牛顿公式)\quad &amp; xx&#39;=ff&#39;\\(高斯公式)\quad &amp;\frac{f&#39;}{l&#39;}+\frac{f}{l}=1\\&amp;\beta=-\frac{f}{x}=-\frac{x&#39;}{f&#39;}\\&amp;\frac{f&#39;}{f}=-\frac{n&#39;}{n}\\&amp; \varphi=\frac{n&#39;}{f&#39;}=-\frac{n}{f}\end{aligned}\]</span> 两个光组： <span class="math display">\[\begin{aligned}(牛顿公式)\quad &amp;x_F&#39;=\frac{f_2 f_2&#39;}{\Delta},x_F=\frac{f_1 f_1&#39;}{\Delta} \\(三角形相似)\quad &amp; f&#39;=-\frac{f_1&#39; f_2&#39;}{\Delta},f=\frac{f_1 f_2}{\Delta}\\ &amp;\Delta=d-f_1&#39;-f_2&#39;\end{aligned}\]</span></p><p>多个光组（<span class="math inline">\(k\)</span> 个）： <span class="math display">\[\begin{aligned}&amp;f&#39;=\frac{h_1}{u_k&#39;}\\(截距计算法) \quad &amp;f&#39;=\frac{l_1&#39;l_2&#39;\cdots l_l&#39;}{l_2l_3\cdots l_k}\\\end{aligned}\]</span></p><p>​ 截距计算法：令 <span class="math inline">\(l_1=-\infty\)</span> , 对每一个光组重复应用高斯公式求得物距像距，最后可推出总焦距。</p><p>望远镜系统： 将第二系统的焦距扩大到 <span class="math inline">\(\Gamma\)</span> 倍。（把远处物体拉近到感觉，张角变大了）</p><h4 id="焦物距焦像距">焦物距/焦像距</h4><p>牛顿公式、截距计算法。</p><p>单个光组： <span class="math display">\[\begin{aligned}&amp;xx&#39;=ff&#39;\\&amp;\beta=-\frac{x&#39;}{f&#39;}=-\frac{f}{x}\\(焦距-焦物距-物距)\quad &amp;x=l-f,x&#39;=l&#39;-f&#39;\end{aligned}\]</span></p><p>两个光组：</p><p>​ 对第一光组，焦像距 <span class="math inline">\(x&#39;=\Delta\)</span>, 对第一光组，焦物距 <span class="math inline">\(x=-\Delta\)</span> <span class="math display">\[x_F&#39;=-\frac{f_2f_2&#39;}{\Delta},x_F=\frac{f_1f_1&#39;}{\Delta}\notag\]</span></p><h4 id="放大率">放大率</h4><p>$$ \begin{aligned} &amp;==-=-\ (轴向放大率)&amp; =-\ &amp;=\ (两个光组) &amp; =-=\ (重要，常用) &amp;= l=</p><p>\end{aligned} $$</p><h4 id="光焦度">光焦度</h4><p><span class="math display">\[\begin{aligned}(定义)\quad &amp;\phi=\frac{n&#39;}{f&#39;}=-\frac{n}{f}\\(空气中,双光组)\quad &amp;\phi=\phi_1+\phi_2-d\phi_1\phi_2\\(空气中，多光组)\quad &amp;\phi=\frac{1}{h_1}\sum_{i=1}^k h_i\phi_i\end{aligned}\]</span></p><h4 id="正切计算法">正切计算法</h4><p><img src="https://tva1.sinaimg.cn/large/00831rSTly1gd5bun7wn4j329a0rsjvx.jpg" alt="image-20200324211447349" style="zoom: 25%;" /></p><p><img src="https://tva1.sinaimg.cn/large/00831rSTly1gd5bp3fc1kj31xe0rsn21.jpg" alt="image-20200324210927813" style="zoom:25%;" /></p><p>顺着光路走下去。关键是一步一步地求 <span class="math inline">\(h\)</span> 和 <span class="math inline">\(u\)</span> . $$ \begin{aligned} &amp;-=u_1'-u_1=,u_2'-u_2=,, u'<em>k-u</em>{k}=\ &amp;u_i=u'<em>{i-1}\ &amp;l_i=l'</em>{i-1}-d_i h_i=h_{i-1}-d_{i-1}u'_{i-1}\</p><p>\end{aligned} $$</p><h3 id="透镜">（4）透镜</h3><h2 id="光束限制">5. 光束限制</h2><h3 id="孔径光阑">孔径光阑</h3><h3 id="视场光阑">视场光阑</h3><h3 id="渐晕光阑">渐晕光阑</h3><h3 id="景深">景深</h3><h2 id="光度学基础">6. 光度学基础</h2><h3 id="基本术语">基本术语</h3><ul><li>以电磁辐射形式发射、传输或接收的能量：辐射能 <span class="math inline">\(Q_e\)</span></li><li><p>单位时间内发射、传输或接收的辐射能：辐射通量 / 辐射功率 <span class="math inline">\(\Phi_e\)</span></p></li><li><p>辐射通量中人眼能感受到的部分：光通量 <span class="math inline">\(\Phi_v\)</span> （单位为流明 lm ）</p></li><li>某一方向上单位立体角的光通量：发光强度 <span class="math inline">\(I_v\)</span> （单位为坎德拉 cd ）</li><li>（垂直方向）单位面积接受的光通量：光照度 <span class="math inline">\(E_v\)</span> (单位为勒克斯 lx )</li><li>（垂直方向）单位面积发出的光通量：光出射度 <span class="math inline">\(M_v\)</span></li><li><p>光源发光投影到某一方向上单位面积的发光强度：光亮度 <span class="math inline">\(L_v\)</span> （单位为尼特 nt ）</p></li></ul><p>理解：光照度表征表面接受的光的性质；光亮度表征光源的发光性质，用立体角度量，而且是单位面积，是一个比光出射度更好的光源发光性质描述。</p><h3 id="辅助量和联系量">辅助量和联系量</h3><ul><li>立体角<ul><li><span class="math inline">\(\Omega=\displaystyle\frac{S}{r^2}\)</span></li><li><span class="math inline">\(d \Omega=\sin i \cdot di\cdot d\phi\)</span></li><li><span class="math inline">\(\Omega=\displaystyle\iint_S \sin i did\phi=(\phi_{\max}-\phi_{\min})(\cos i_{\min}-\cos i_{\max})\)</span></li><li>平面孔径角 <span class="math inline">\(U\)</span>, <span class="math inline">\(\Omega=\displaystyle\int_0^{2\pi}d\phi\int_0^U\sin i di=4\pi \sin^2\left(\frac U 2\right)\approx \pi u^2\)</span></li></ul></li><li><p>光谱光视效率 / 视见函数 <span class="math inline">\(V(\lambda)\)</span></p><p>​ 反映人眼的光谱灵敏度，表示人眼对不同波长辐射对敏感度差异。</p><p>​ 和辐射通量直接的换算： <span class="math inline">\(1W\)</span>（辐射通量）<span class="math inline">\(=683\cdot V(\lambda)\)</span> lm</p></li><li><p>发光效率 <span class="math inline">\(\eta\)</span></p><p>​ 辐射体发出的总光通量与该光源的耗电功率之比。</p><p>​ <span class="math inline">\(\eta=\displaystyle\frac{\Phi_v}{P}\)</span></p></li></ul><h3 id="重要关系">重要关系</h3><ul><li><p>光亮度 : <span class="math inline">\(L_v=\displaystyle\frac{I_v}{dA\cos i}=\frac{d\Phi_v}{d\Omega dA\cos i}\)</span></p></li><li><p>朗伯辐射体且面积为 <span class="math inline">\(A\)</span> : <span class="math inline">\(I_N=L_vA\)</span></p></li><li><p>朗伯辐射体已知光出射度或二次辐射源 : <span class="math display">\[L_v=\frac{M_v}{\pi}=\frac{\rho E_v}{\pi}\]</span></p></li></ul><h3 id="基本定律">基本定律</h3><h4 id="朗伯定律">朗伯定律</h4><p>一个光亮度再各个方向上均相等的发光面源（朗伯辐射体），在某一方向上的发光强度等于该面元法线方向上的发光强度与方向角余弦之积。 <span class="math display">\[I_i=I_N\cos i\]</span></p><ul><li><p>朗伯辐射体在孔径角 <span class="math inline">\(U\)</span> 范围内发出的光通量 <span class="math display">\[\begin{align}d\Phi_v&amp;=L_v\cos i dAd\Omega\notag \\\implies \Phi_v&amp;=\int_0^{2\pi}d\phi\int_0^UL_v\sin i\cos idA di\notag \\&amp;=\pi L_v\sin^2 U dA\\&amp;=\pi I\sin^2 U(?)\end{align}\]</span></p></li><li><p>孔径角为 <span class="math inline">\(\displaystyle \frac \pi 2\)</span> 时（平面），<span class="math inline">\(L_v=\displaystyle \frac{\Phi_v }{\pi dA}=\frac{M_v}{\pi}\)</span></p></li></ul><h4 id="距离平方反比定律">距离平方反比定律</h4><p>点光源直接照射表面时，受照面光照度为 <span class="math display">\[E_v=\frac{I_v}{r^2}\]</span> #### 照度余弦定则</p><p>光源不垂直于照明面元时的光照度为 <span class="math display">\[E_v=\frac{I_0\cos i}{r^2}=E_v\cos i\]</span></p><h3 id="光束光亮度的传递">光束光亮度的传递</h3><ul><li><p>面光源照射时受照表面的光照度 <span class="math display">\[E_v=\frac{L_v d S_1\cos i_1\cos i_2}{r^2}\]</span> <span class="math inline">\(i_1,i_2\)</span> 分别为两面法线与距离 <span class="math inline">\(\vec r\)</span> 直接的夹角。</p></li><li><p>光在无损介质中传播时，各截面上的光亮度相等。</p></li><li><p>不同介质分界面上光束的传递 : $$ <span class="math display">\[\begin{align}\rho&amp;\approx\left(\frac{n&#39;-n}{n&#39;+n}\right)^2,\tau=1-\rho\\L_r&amp;=\rho L_i\\L_t&amp;=\left(\frac{n&#39;}{n}\right)^2\tau L_i\end{align}\]</span> $$</p></li></ul><h3 id="光学成像系统的像面照度">光学成像系统的像面照度</h3><h4 id="轴上像点">轴上像点</h4><p><span class="math display">\[\begin{align}E_0&#39;&amp;=\frac{\Phi_v&#39;}{dS&#39;}=\tau \frac{\pi L_v \sin^2 U dS}{dS&#39;}\\&amp;=\frac{1}{\beta^2}\tau \pi L_v\sin^2 U &amp;\text{(物空间)}\\&amp;=\left(\frac{n&#39;}{n}\right)^2\tau\pi L_v\sin^2 U&#39; &amp;\text{(像空间)}\\\end{align}\]</span> 其中用到正弦关系：<span class="math inline">\(ny\sin U=n’y’\sin U&#39;\)</span></p><h4 id="轴外像点">轴外像点</h4><p>设轴外像点 <span class="math inline">\(B’\)</span> 的像方视场角（对出瞳的张角）为 <span class="math inline">\(\omega&#39;\)</span> $$ <span class="math display">\[\begin{align}\sin U_B&#39;&amp;\approx \sin U&#39;\cos ^2\omega\\E_B&#39;&amp;=E_0\cos^4\omega&#39;\end{align}\]</span> $$</p><h1 id="应用光学实验">应用光学实验</h1><h2 id="手机摄像头焦距测量">手机摄像头焦距测量</h2><h3 id="通用知识手机">通用知识（手机）</h3><ul><li><p>手机摄像头近似认为是薄透镜</p></li><li><p>视场光阑：CMOS光敏面最外面一圈</p></li><li><p>一般手机数值孔径：广角～1.8，数值越小难度越大；长焦～2.4，大的到2.8</p></li><li><p>一般手机焦距： 4～6mm</p></li><li><p>等效焦距</p><ul><li><p>同样焦距的镜头，在不同尺寸的感光元件上，成像视角不同，仅以镜头的物理焦距，无法比较不同相机的成像范围（视场角）。</p></li><li><p>为了便于比较，人们习惯将不同尺寸感光元件上成像的视角，转化为 <em>36 x 24 mm 全画幅感光元件上同样成像视角所对应的镜头焦距</em>，这个转化后的焦距就是等效焦距</p></li><li><p>物理焦距 <span class="math inline">\(\times\)</span> 转换系数 <span class="math inline">\(=\)</span> 等效焦距，</p><p>其中 转换系数 <span class="math inline">\(=\)</span> 43.27 ( 全画幅对角线长) <span class="math inline">\(/\)</span> 传感器光面对角线长</p></li><li><p>手机的等效焦距有个坑，1英寸手机厂商这里是 16 mm ，而不是 25.4 mm</p></li></ul></li></ul><h3 id="iphone-x-实验手机">iPhone X (实验手机)</h3><ul><li><p>iPhone X 后置摄像头</p><ul><li>主摄：广角 $F/1.8 $</li><li>副摄：长焦 <span class="math inline">\(F/2.4\)</span></li></ul></li><li><p>CMOS : IMX385 1.22 µm</p></li><li><p>正常拍照模式下一倍变焦用的是广角镜头，二倍变焦用的长焦镜头，人像模式下是两个镜头同时使用，后台计算像场和景深。另外，<strong>长焦镜头使用了更小的光圈，因此需要更多的光线</strong>，苹果让 iPhone 自己来判定光线是否足够，从而启动长焦镜头。</p></li><li><p>物方视场角 FOV：视场角分物方视场角和像方视场角。一般光学设备的使用者关心的是物方视场角。</p><p>对于大多数光学仪器,视场角的度量都是以成像物的直径作为视场角计算的。</p></li><li><p>光瞳直径 <span class="math inline">\(=\)</span> 焦距 <span class="math inline">\(/\)</span> 光圈数 <span class="math inline">\(F\)</span></p></li></ul><h3 id="实验方法">实验方法</h3><ul><li><p>找一张白纸，用直尺画上一条直线，我画的是 150 mm <span class="math inline">\(\implies l=-150\)</span></p></li><li><p>直线一端直立放一把尺子，另一端放手机</p></li><li><p>一倍正常拍摄一张，用的是主（广角）镜头；二倍数字变焦放大拍摄一张，用的是副（长焦）镜头</p></li><li><p>隔空投送到电脑上，用 PhotoShop 寻找尺子 1cm～2cm 的像素距离。</p><p>具体方法为：Ctrl+R 出现横纵坐标轴，在坐标轴上右键选像素，变成像素坐标。在 1cm～2cm 画一个矩形，记录像素距离</p></li><li><p>查找 CMOS 传感器的 unit cell （比如 IMX363 2.4 µm 一个像素点）, 计算实际像高</p></li><li><p>由 <span class="math inline">\(\displaystyle \beta=\frac{y’}{y}=\frac{l’}{l}\)</span> 得到像距 <span class="math inline">\(l’\)</span> ，有了 <span class="math inline">\(l’\)</span> 其他的都可以算了</p></li><li><p>焦距 <span class="math inline">\(f’=\displaystyle\frac{1}{1/l’-1/l}\)</span> （高斯公式）</p></li><li><p>光瞳直径 <span class="math inline">\(\displaystyle D=\frac{f’}{F}\)</span> ，<span class="math inline">\(F\)</span> 为光圈数</p></li><li><p>物方视场角 <span class="math inline">\(\displaystyle FOV=2\arctan\left(\frac{d/2}{l&#39;}\right)\)</span> 其中 <span class="math inline">\(d\)</span> 为传感器对角线长</p></li></ul><h3 id="实验代码">实验代码</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><br><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">get_l1</span><span class="hljs-params">(px, unit, y=<span class="hljs-number">10</span>)</span>:</span><br>        <span class="hljs-comment"># 计算像高y1,像距l1</span><br>    l = <span class="hljs-number">150</span><br>    y1 = px * unit / <span class="hljs-number">1000</span><br>    beta = y1 / y<br>    l1 = beta * l<br>    <span class="hljs-keyword">return</span> y1, l1<br><br><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">get_f</span><span class="hljs-params">(l1, l)</span>:</span><br>        <span class="hljs-comment"># 计算焦距</span><br>    <span class="hljs-keyword">return</span> <span class="hljs-number">1</span> / (<span class="hljs-number">1</span> / l1 + <span class="hljs-number">1</span> / l)<br><br><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">get_diaglen</span><span class="hljs-params">(x, y)</span>:</span><br>        <span class="hljs-comment"># 获得对角线长度</span><br>    <span class="hljs-keyword">return</span> np.sqrt(x**<span class="hljs-number">2</span> + y**<span class="hljs-number">2</span>)<br><br><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">get_FOV</span><span class="hljs-params">(diag, l1)</span>:</span><br>        <span class="hljs-comment"># 计算物方视场角</span><br>    <span class="hljs-keyword">return</span> <span class="hljs-number">2</span> * np.arctan(diag / <span class="hljs-number">2</span> / l1) * <span class="hljs-number">180</span> / np.pi<br><br><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">get_D</span><span class="hljs-params">(f, F)</span>:</span><br>        <span class="hljs-comment"># 获得光瞳直径</span><br>    <span class="hljs-keyword">return</span> f / F<br><br><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">r</span><span class="hljs-params">(x, N=<span class="hljs-number">4</span>)</span>:</span><br>        <span class="hljs-comment"># 保留四位小数</span><br>    <span class="hljs-keyword">return</span> round(x, N)<br><br><br>px1 = <span class="hljs-number">237</span><br>px2 = <span class="hljs-number">432</span><br>F1 = <span class="hljs-number">1.8</span><br>F2 = <span class="hljs-number">2.4</span><br>unit = <span class="hljs-number">1.22</span><br>l = <span class="hljs-number">150</span><br>diag = <span class="hljs-number">6.15</span><br>trans = <span class="hljs-number">43.27</span> / diag<br><br>y1, l1 = get_l1(px1, unit)<br>y2, l2 = get_l1(px2, unit)<br>f1 = get_f(l1, l)<br>f2 = get_f(l2, l)<br>D1 = get_D(f1, F1)<br>D2 = get_D(f2, F2)<br>FOV1 = get_FOV(diag, l1)<br>FOV2 = get_FOV(diag, l2)<br><span class="hljs-comment"># diag = get_diaglen(5.21, 6.29)</span><br><br><span class="hljs-comment"># print('传感器对角线长：', round(diag, 4))</span><br><br>print(<span class="hljs-string">'--广角--'</span>)<br>print(<span class="hljs-string">'焦距：'</span>, r(f1))<br>print(<span class="hljs-string">'等效焦距'</span>, r(trans * f1))<br>print(<span class="hljs-string">'物方视场角：'</span>, r(FOV1))<br>print(<span class="hljs-string">'光瞳直径: '</span>, r(D1))<br>print()<br>print(<span class="hljs-string">'--长焦--'</span>)<br>print(<span class="hljs-string">'焦距：'</span>, r(f2))<br>print(<span class="hljs-string">'等效焦距'</span>, r(trans * f2))<br>print(<span class="hljs-string">'物方视场角：'</span>, r(FOV2))<br>print(<span class="hljs-string">'光瞳直径: '</span>, r(D2))<br><br><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">get_err</span><span class="hljs-params">(y1)</span>:</span><br>    l0 = <span class="hljs-number">1</span> / (<span class="hljs-number">1</span> / <span class="hljs-number">4</span> - <span class="hljs-number">1</span> / <span class="hljs-number">150</span>)<br>    y0 = <span class="hljs-number">10</span> * l0 / <span class="hljs-number">150</span>  <span class="hljs-comment"># 10mm原像,150物距</span><br>    <span class="hljs-keyword">return</span> np.abs(y0 - y1) / y0<br><br><br>print()<br>print(<span class="hljs-string">'--误差计算--'</span>)<br><br>err_y = get_err(y1)<br>print(<span class="hljs-string">'像高误差-主镜头:'</span>, r(err_y) * <span class="hljs-number">100</span>, <span class="hljs-string">'%'</span>)<br>print(<span class="hljs-string">'焦距误差-主镜头'</span>, r(np.abs((f1 - <span class="hljs-number">4.0</span>)) / <span class="hljs-number">4.0</span>) * <span class="hljs-number">100</span>, <span class="hljs-string">'%'</span>)<br>beta1 = l1 / l<br>print()<br>print(<span class="hljs-string">'--放大倍率计算--'</span>)<br>print(<span class="hljs-string">'横向放大倍率'</span>, r(beta1))<br>print(<span class="hljs-string">'显示图像放大倍率'</span>, r(<span class="hljs-number">143.6</span> / (beta1 * <span class="hljs-number">10</span>)))<br></code></pre></td></tr></table></figure><h5 id="结果">结果</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs python">--广角--<br>焦距： <span class="hljs-number">4.2152</span><br>等效焦距 <span class="hljs-number">29.6573</span><br>物方视场角： <span class="hljs-number">70.6732</span><br>光瞳直径:  <span class="hljs-number">2.3418</span><br><br>--长焦--<br>焦距： <span class="hljs-number">7.5098</span><br>等效焦距 <span class="hljs-number">52.8373</span><br>物方视场角： <span class="hljs-number">42.5086</span><br>光瞳直径:  <span class="hljs-number">3.1291</span><br><br>--误差计算--<br>像高误差-主镜头: <span class="hljs-number">5.54</span> %<br>焦距误差-主镜头 <span class="hljs-number">5.38</span> %<br><br>--放大倍率计算--<br>横向放大倍率 <span class="hljs-number">0.0289</span><br>显示图像放大倍率 <span class="hljs-number">496.6452</span><br></code></pre></td></tr></table></figure><h2 id="光学组合实验">光学组合实验</h2><p>200px</p><p>1.22</p>]]></content>
      
      
      <categories>
          
          <category> Physics </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>Leecode</title>
      <link href="/2020/03/02/Computer-Sciencs/Leecode/"/>
      <url>/2020/03/02/Computer-Sciencs/Leecode/</url>
      
        <content type="html"><![CDATA[<h1 id="leecode-题目整理">Leecode 题目整理</h1><h3 id="三数之和">三数之和</h3><p>排序+<strong>双指针</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs python">nums.sort()<br><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> range(n):<br>  <span class="hljs-keyword">if</span> i&gt;<span class="hljs-number">0</span> <span class="hljs-keyword">and</span> nums[i] == nums[i - <span class="hljs-number">1</span>]:<span class="hljs-keyword">continue</span><br>  l = i + <span class="hljs-number">1</span><br>  r = n - <span class="hljs-number">1</span><br>  <span class="hljs-keyword">while</span>(l &lt; r):<br>    <span class="hljs-keyword">if</span> nums[i] + nums[l] + nums[r] == <span class="hljs-number">0</span>:<br>      ans.append([nums[i], nums[l], nums[r]])<br>      <span class="hljs-keyword">while</span> l&lt;r <span class="hljs-keyword">and</span> nums[r]==nums[r<span class="hljs-number">-1</span>]:r=r<span class="hljs-number">-1</span><br>      <span class="hljs-keyword">while</span> l&lt;r <span class="hljs-keyword">and</span> nums[l]==nums[l+<span class="hljs-number">1</span>]:l=l+<span class="hljs-number">1</span><br>      r=r<span class="hljs-number">-1</span><br>      l=l+<span class="hljs-number">1</span><br>    <span class="hljs-keyword">elif</span> nums[i] + nums[l] + nums[r] &gt; <span class="hljs-number">0</span>:r = r - <span class="hljs-number">1</span><br>    <span class="hljs-keyword">else</span>: l = l + <span class="hljs-number">1</span><br></code></pre></td></tr></table></figure><h3 id="两数之和">两数之和</h3><p><strong>carry</strong> 用得很妙, 模拟进位</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">addTwoNumbers</span><span class="hljs-params">(self, l1: ListNode, l2: ListNode)</span> -&gt; ListNode:</span><br>  ans=ListNode(<span class="hljs-number">0</span>)<br>  head=ans<br>  carry=<span class="hljs-number">0</span><br>  <span class="hljs-keyword">while</span> l1 <span class="hljs-keyword">or</span> l2:<br>  x=l1.val <span class="hljs-keyword">if</span> l1 <span class="hljs-keyword">else</span> <span class="hljs-number">0</span><br>  y=l2.val <span class="hljs-keyword">if</span> l2 <span class="hljs-keyword">else</span> <span class="hljs-number">0</span><br>  s=x+y+carry<br>  carry=s//<span class="hljs-number">10</span><br>  ans.next=ListNode(s%<span class="hljs-number">10</span>)<br>  ans=ans.next<br>  <span class="hljs-keyword">if</span> l1:<br>  l1=l1.next<br>  <span class="hljs-keyword">if</span> l2:<br>  l2=l2.next<br>  <span class="hljs-keyword">if</span> carry:<br>  ans.next=ListNode(carry)<br>  <span class="hljs-keyword">return</span> head.next<br></code></pre></td></tr></table></figure><h2 id="队列">队列</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment">#简易版本</span><br>queue=[]<br>queue.append(data) <span class="hljs-comment">#入队</span><br>queue.pop(<span class="hljs-number">0</span>)<span class="hljs-comment">#出队</span><br><br><span class="hljs-comment">#双向队列</span><br><span class="hljs-keyword">import</span> collections<br>que=collectione.deque()<br>que.append() <br>que.appendleft()<br>que.insert(i,x)<span class="hljs-comment">#在第i个位置插入x</span><br>que.popleft()<br>que.pop()<br>que.remove(val)<span class="hljs-comment">#移除查找到的第一个val</span><br>que.count(x)<span class="hljs-comment">#计算que中元素等于x的个数</span><br>que.rotate(n)<span class="hljs-comment">#向右循环移动n步 </span><br>que.clear()<br></code></pre></td></tr></table></figure><h3 id="墙与门">墙与门</h3><p>BFS</p><p>满足条件=&gt;处理=&gt;放入队列</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">used=[]<span class="hljs-comment">#走过的标记不再走</span><br>rooms[tmpk][tmpt] = rooms[i][j] + <span class="hljs-number">1</span> <span class="hljs-comment">#step是上一个的加1</span><br></code></pre></td></tr></table></figure><h3 id="岛屿数量">岛屿数量</h3><p>BFS ：</p><p>写个bfs函数，注意每到一个点要mark。</p><p>对所有可遍历点bfs（同步更新可遍历点）, 每使用一次就找到了一个模块, cnt++。</p><p><strong>并查集（未）</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">bfs</span><span class="hljs-params">(i, j)</span>:</span><br> queue = deque()<br> queue.appendleft((i, j))<br> grid[i][j] = <span class="hljs-string">"0"</span><br> <span class="hljs-keyword">while</span> queue:<br>   i, j = queue.pop()<br>   <span class="hljs-keyword">for</span> x, y <span class="hljs-keyword">in</span> [[<span class="hljs-number">-1</span>, <span class="hljs-number">0</span>], [<span class="hljs-number">1</span>, <span class="hljs-number">0</span>], [<span class="hljs-number">0</span>, <span class="hljs-number">-1</span>], [<span class="hljs-number">0</span>, <span class="hljs-number">1</span>]]:<br>    tmp_i = i + x<br>    tmp_j = j + y<br>   <span class="hljs-keyword">if</span> <span class="hljs-number">0</span> &lt;= tmp_i &lt; row <span class="hljs-keyword">and</span> <span class="hljs-number">0</span> &lt;= tmp_j &lt; col <span class="hljs-keyword">and</span> grid[tmp_i][tmp_j] == <span class="hljs-string">"1"</span>:<br>   grid[tmp_i][tmp_j] = <span class="hljs-string">"0"</span><br>    queue.appendleft((tmp_i, tmp_j))<br><br> <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> range(row):<br>   <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> range(col):<br>     <span class="hljs-keyword">if</span> grid[i][j] == <span class="hljs-string">"1"</span>:<br>       bfs(i, j)<br>       cnt += <span class="hljs-number">1</span><br></code></pre></td></tr></table></figure><h3 id="打开转盘锁">打开转盘锁</h3><p>yield 的使用</p><h2 id="栈">栈</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python">stack=[]<br>stack.append()<br>stack.pop()<br>stack[<span class="hljs-number">-1</span>]<span class="hljs-comment">#取出栈顶元素</span><br></code></pre></td></tr></table></figure><h3 id="最小栈">最小栈</h3><p>使用两个栈，一个作为<strong>辅助栈</strong>。</p>]]></content>
      
      
      <categories>
          
          <category> Computer Science </category>
          
          <category> Practice </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>Linear Algebra</title>
      <link href="/2020/02/28/Mathematics/Linear-Algebra/"/>
      <url>/2020/02/28/Mathematics/Linear-Algebra/</url>
      
        <content type="html"><![CDATA[<h1 id="线性代数学习笔记">线性代数学习笔记</h1><p>不加入例题</p><p>主要是例题中用到的基本性质和定理的证明</p><p>推荐网站：<a href="https://ccjou.wordpress.com/" target="_blank" rel="noopener">线代启示录</a></p><h2 id="线性空间">1. 线性空间</h2><h3 id="基的可扩充性">基的可扩充性</h3><p><span class="math inline">\(V^n\)</span> 的任意一组线性无关的向量都可扩充为一组基。</p><p>证明：</p><p>​ 对于一个有 <span class="math inline">\(m\)</span> 个向量的线性无关组，若 <span class="math inline">\(m&lt;n\)</span> ，则 <span class="math inline">\(V\)</span> 中肯定<strong>存在向量 <span class="math inline">\(x\)</span> 不能被他们表示</strong>。</p><p>​ 可以证明 <span class="math inline">\(x\)</span> 与他们线性无关，把 <span class="math inline">\(x\)</span> 添进去，构成新的线性无关组。</p><p>​ 这样一直添，最后可以扩充为一组基。</p><h3 id="维数公式">维数公式</h3><p><span class="math display">\[dim\ W_1+dim\ W_2=dim(W_1+W_2)+dim(W_1\cap W_2)\notag\]</span></p><p>证明：</p><p>​ 取 <span class="math inline">\(W_1\cap W_2\)</span> 的一组基，分别扩充为 <span class="math inline">\(W_1\)</span> 和 <span class="math inline">\(W_2\)</span> 的基，</p><p>​ 则它们组合起来组成的向量组可以张成 <span class="math inline">\(W_1+W_2\)</span> 。</p><p>​ 接下来只需证明它们线性无关。 <span class="math display">\[\begin{aligned}W_1\cap W_2&amp;=\mathcal{L}(\alpha_1,\cdots,\alpha_r)\\W_1&amp;=\mathcal{L}(\alpha_1,\cdots,\alpha_r,\beta_1,\cdots,\beta_s)\\W_2&amp;=\mathcal{L}(\alpha_1,\cdots,\alpha_r,\gamma_1,\cdots,\gamma_t)\\\implies W_1+W_2&amp;=\mathcal{L}(\alpha_1,\cdots,\alpha_r,\beta_1,\cdots,\beta_s,\gamma_1,\cdots,\gamma_t)\end{aligned}\]</span></p><p>​ 按线性无关定义写出式子，把 <span class="math inline">\(\gamma\)</span> 项移到等式右边，</p><p>​ 利用 <span class="math inline">\(W_1\cap W_2\)</span> 可以把两边都表示成 <span class="math inline">\(\alpha\)</span> 项的线性组合，</p><p>​ 依次利用移项后是 <span class="math inline">\(W_2\)</span> 和 $ W_1 $ 的基，最后得到全是 <span class="math inline">\(0\)</span>。</p><h3 id="直和">直和</h3><p>设 <span class="math inline">\(U_1,\cdots,U_m\)</span> 都是 <span class="math inline">\(V\)</span> 的子空间，则:</p><ul><li>（定义）<span class="math inline">\(U_1+\cdots+U_m\)</span> 是直和，如果 <span class="math inline">\(U_1+\cdots+U_m\)</span> 中的每个元素都可以唯一的表示成 <span class="math inline">\(u_1+\cdots+u_m\)</span> ，其中每个 <span class="math inline">\(u_j\in U_j\)</span>。</li><li><p><span class="math inline">\(\iff\)</span> <span class="math inline">\(0\)</span> 唯一分解成 <span class="math inline">\(0+\cdots+0\)</span></p></li><li><p>对于两个子空间的直和，<span class="math inline">\(U+W=U\oplus W\iff U\cap W=\{0\}\)</span></p></li></ul><h5 id="常用结论">常用结论：</h5><ul><li><span class="math inline">\(\dim V&lt;\infty\)</span> ，若 <span class="math inline">\(T\in \mathcal{L}[V]\)</span> 是幂等变换，则 <span class="math inline">\(V=N(T)\oplus R(T)\)</span> .</li><li><span class="math inline">\(T\in\mathcal{L}[V],\dim V=n\implies V=R(T^n)\oplus N(T^n)\)</span></li></ul><h2 id="线性映射">2. 线性映射</h2><h3 id="线性映射的维数定理">线性映射的维数定理</h3><p><span class="math inline">\(T:V\to W&#39;\)</span>, <span class="math inline">\(dim\ N(T)+dim\ R(T)=dim\ V\)</span></p><p>即：<span class="math inline">\(dim\ Ker(T)+dim\ Im(T)=dim\ V\)</span></p><p>证明1：</p><p>​ 去证 <strong><span class="math inline">\(\overline T:\overline V\to W\)</span>, <span class="math inline">\(\overline v\mapsto T(v)\)</span> 是线性映射且为双射</strong>, <span class="math inline">\(\overline T\)</span> 是由 <span class="math inline">\(T\)</span> 诱导出来的线性映射。</p><p>​ 其中 <span class="math inline">\(W=Im(T)\)</span>, <span class="math inline">\(\overline V=V/ker(T)\)</span>。 从而 <span class="math inline">\(V/ker(T)\cong Im(T)\)</span>。</p><ol type="1"><li><p><span class="math inline">\(\overline T\)</span> 的<strong>定义是合理的</strong>：<span class="math inline">\(\overline T(\overline v)=T(v), \forall k\in Ker(T),\overline v=v+k\)</span></p><p>这需要证明对 <span class="math inline">\(\overline v=v+k_1\)</span> 和 <span class="math inline">\(\overline {v+k_2}=\overline v=v+k_2\)</span>, <span class="math inline">\(\overline T(\overline {v+k_1})=\overline T(\overline {v+k_2})=T(v)\)</span>.</p><p>即 <span class="math inline">\(\overline T(\overline v)=T(v)\)</span> 的成立不依赖于 $v’v=v+Ker(T) $ 的选取</p><p>这是由于 <span class="math inline">\(\forall k\in Ker(T),\overline T(\overline {v+k})=T(v+k)=T(v)+T(k)=T(v)\)</span></p></li><li><p><span class="math inline">\(\overline T\)</span> <strong>是线性映射</strong>：</p><ul><li><p>加法：</p><p><span class="math inline">\(\overline T(\overline {v_1+v_2})=T(v_1+v_2)=T(v_1)+T(v_2)=\overline T(\overline v_1)+\overline T(\overline v_2)\)</span></p></li><li><p>数乘：</p><p><span class="math inline">\(\overline T(\lambda \overline {v})=\overline T(\overline {\lambda v})=T(\lambda v)=\lambda T(v)=\lambda\overline T(\overline v)\)</span></p></li></ul></li><li><p><span class="math inline">\(\overline T\)</span> <strong>是双射</strong>：</p><ul><li><p>单射：</p><p><span class="math inline">\(\overline T(\overline v)=0=&gt;T(v)=0=&gt;v\in Ker(T)=&gt;\overline v=0\\ =&gt;Ker(\overline T)=0\)</span></p></li><li><p>满射：</p><p><span class="math inline">\(\forall w\in W=Im(T),\exist v\in V,s.t.\quad T(v)=w\\ =&gt;\exist\overline v, \overline T(\overline v)=T(v)=w\)</span></p></li></ul></li></ol><p>证明2:</p><p>​ 取 $ N(T)$ 的一组基 <span class="math inline">\((v_1,\cdots,v_s)\)</span> ，将其扩充为 <span class="math inline">\(V\)</span> 的一组基 <span class="math inline">\((v_1,\cdots,v_s,v_{s+1},\cdots,v_n)\)</span></p><p>​ 则 <span class="math inline">\(R(T)=\mathcal{L}\big[T(v_1),\cdots,T(v_n)\big]=\mathcal{L}\big[T(v_{s+1}),\cdots,T(v_n)\big]\)</span></p><p>​ 因此 <span class="math inline">\(T(v_{s+1}),\cdots,T(v_{n})\)</span> 可张成 <span class="math inline">\(R(T)\)</span> ，只需证明它们线性无关。</p><p>​ 如果 <span class="math inline">\(a_1 T(v_{s+1})+\cdots +a_{n-s}T(v_{n})=0\)</span></p><p>​ 则 <span class="math inline">\(T(a_1v_{s+1}+\cdots+a_{n-s}v_n)=0\)</span></p><p>​ <span class="math inline">\(=&gt; a_1v_{s+1}+\cdots+a_{n-s}v_n\in N(T)\)</span></p><p>​ 故 <span class="math inline">\(\exist v_1,\cdots,v_s, \quad a_1v_{s+1}+\cdots+a_{n-s}v_n=b_1v_1+\cdots b_sv_s\)</span></p><p>​ 全部移到左边，由于 <span class="math inline">\(v_1,\cdots,v_n\)</span> 是 <span class="math inline">\(V\)</span> 的基，全部系数为 <span class="math inline">\(0\)</span>.</p><h3 id="线性映射的一些定理">线性映射的一些定理</h3><ul><li><p>到更大维数向量空间的线性映射不是满的</p><p>一定有东西会表示不出来</p></li><li><p>到更小维数向量空间的线性映射不是单的</p></li></ul><h3 id="线性映射的矩阵表示">线性映射的矩阵表示</h3><p>(搞晕了很久 现在终于弄明白了)</p><h4 id="对基">（1）对基</h4><p><span class="math display">\[T(e_1,\cdots,e_n)=(f_1,\cdots,f_m)M(T)\\Te_k=M(T)第k列\notag\]</span></p><p>​ 其中，<span class="math inline">\(e\)</span> 是原空间的基， <span class="math inline">\(f\)</span> 是像空间的基。</p><h4 id="对向量">（2）对向量</h4><p>​ 设 <span class="math inline">\(X=(x_1,\cdots,x_n)^T\)</span> 为向量 <span class="math inline">\(\xi\)</span> 在基 <span class="math inline">\(e=(e_1,\cdots,e_n)\)</span> 下的坐标。 <span class="math display">\[\xi=(e_1,\cdots,e_n)X\notag\]</span> ​ <span class="math inline">\(T\)</span> 作用后的向量为： <span class="math display">\[\begin{aligned}T(\xi)&amp;=T(e_1,\cdots,e_n)X\\&amp;=(f_1,\cdots,f_m)M(T)X\end{aligned}\]</span> ​ <span class="math inline">\(T\)</span> 作用后得到的向量的坐标是 <span class="math inline">\(M(T)X\)</span>.</p><p>(美妙的证明)</p><h4 id="线性映射在不同基下表示表示矩阵的关系">（3）线性映射在不同基下表示表示矩阵的关系</h4><p>相似。 <span class="math display">\[\begin{aligned}T[(e_1,\cdots,e_n)]&amp;=T[(f_1,\cdots,f_m)A]\\&amp;=T[(f_1,\cdots,f_m)]A\\&amp;=(f_1,\cdots,f_m)M_fA\\&amp;=(e_1,\cdots,e_n)A^{-1}M_fA\end{aligned}\]</span> 所以，<span class="math inline">\(M_e=A^{-1}M_fA\)</span>, <span class="math inline">\(A\)</span> 为基的过渡矩阵，<span class="math inline">\(M_e,M_f\)</span> 为线性映射在不同基下的矩阵表示。</p><h4 id="同一个向量在不同基下的坐标关系">（4）同一个向量在不同基下的坐标关系</h4><p><span class="math inline">\(T:V\to W\)</span></p><p><span class="math inline">\(\xi=(v_1,\cdots,v_n)A=(w_1,\cdots,w_m)B\)</span></p><p>其中 <span class="math inline">\(A=(a_1,\cdots,a_n)^T\)</span>, <span class="math inline">\(B=(b_1,\cdots,b_m)^T\)</span> (注意有转置，<strong>基是行向量，坐标是列向量</strong>)</p><p>是 <span class="math inline">\(\xi\)</span> 在不同基下的坐标</p><p>则 ： <span class="math display">\[B=M(T)^{-1}A\notag\]</span></p><h4 id="总结">（5）总结</h4><p>由此可见，线性映射对应的矩阵：</p><ul><li>对基的变换是右乘作用，对基的 <span class="math inline">\(k\)</span> 分量变换后的结果为矩阵的第 <span class="math inline">\(k\)</span> 列</li><li>对向量的坐标的变换为左乘</li><li>在不同基下的表示矩阵相似</li></ul><h3 id="线性方程组">线性方程组</h3><p>设矩阵 <span class="math inline">\(A\in M_{m\times n}(\mathbf{F})\)</span>, 若 <span class="math inline">\(r(A)=r\)</span>, 则齐次线性方程组 <span class="math inline">\(AX=0\)</span> 的解空间 <span class="math inline">\(N(A)\)</span> 是一个 <span class="math inline">\(n-r\)</span> 维子空间。</p><p>证明：</p><p>​ <span class="math inline">\(A\)</span> 与一个线性映射 <span class="math inline">\(\sigma\in L(V_1,V_2)\)</span> 对应, <span class="math inline">\(\dim V_1=n, \dim V_2=m\)</span> .</p><p>​ <span class="math inline">\(AX=0\)</span> 解空间中的基是 <span class="math inline">\(\sigma\)</span> 核空间的基关于 <span class="math inline">\(V_1\)</span> 的坐标, 解空间的基和 <span class="math inline">\(N(\sigma)\)</span> 的基一一对应 .</p><p>简单证明：</p><p>​ 把 <span class="math inline">\(A\)</span> 看作线性变换， <span class="math inline">\(rank(A)=Range(A)\)</span> , <span class="math inline">\(A\)</span> 的核 <span class="math inline">\(N(A)\)</span> 就是方程组的解空间。</p><p><strong>注</strong>：矩阵的秩：矩阵列向量中极大线性无关组的元素个数，等于矩阵作为线性变换对应矩阵的像空间维数。</p><h3 id="幂等变换的性质">幂等变换的性质</h3><p>幂等变换: <span class="math inline">\(T:V\to W,\quad T^2=T\)</span></p><ul><li><p><span class="math inline">\(N(T)=\{v-T(v)\mid v\in V \}\)</span></p></li><li><span class="math inline">\(N(T)\cap R(T)=0\)</span></li><li><p><span class="math inline">\(V=N(T)\oplus R(T)\)</span></p></li></ul><p>证明：</p><p>​ 对第二条，只需证明核空间与像空间的交是 <span class="math inline">\(0\)</span></p><p>​ 如果 <span class="math inline">\(w\in N(T)\cap R(T)\)</span>, 则：</p><p>​ 由于 <span class="math inline">\(w\in N(T)\)</span>, <span class="math inline">\(T(w)=0\)</span></p><p>​ 由于 <span class="math inline">\(w\in R(T)\)</span>, <span class="math inline">\(\exist v\in V,w=T(v)\)</span>, <strong>两边再作用一下 <span class="math inline">\(T\)</span></strong>, 得到：<span class="math inline">\(0=T(w)=T^2(v)=T(v)=w\)</span></p><p>​</p><p>​ 对第一条，</p><p>​ 这是由于 $vV,T^2(v)=T(v)=&gt;T[T(v)-v]=0=&gt;T(v)-vN(T)=&gt;{v-T(v)}N(T)\ vN(T),v=v-T(v)=&gt;{v-T(v)}N(T) $</p><h3 id="算子">算子</h3><p>算子：向量空间到自身的线性映射</p><p>对有限为空间的算子 <span class="math inline">\(T\)</span>：<span class="math inline">\(T\)</span> 可逆<span class="math inline">\(\iff\)</span> <span class="math inline">\(T\)</span> 单 <span class="math inline">\(\iff T\)</span> 满</p><h3 id="对偶">对偶</h3><h2 id="内积空间">3. 内积空间</h2><p>带有内积的向量空间。</p><p>内积：对第一个分量成线性，对第二个分量成共轭线性，有共轭对称性。</p><h3 id="线性映射的内积表示">线性映射的内积表示</h3><p><span class="math display">\[\begin{align}T((v_1,\dots,v_n)&amp;=(v_1,\dots,v_n)A\notag \\T(v_i)&amp;=\sum_{j=1}^n v_j a_{ji}\notag \\\therefore \quad a_{ij}&amp;=\langle Tv_j,v_i\rangle\end{align}\]</span></p><h3 id="柯西-施瓦茨不等式">柯西-施瓦茨不等式</h3><p><span class="math display">\[|\langle u,v \rangle|\leq\|u\|\|v\|\]</span></p><p>证明：</p><p>将 <span class="math inline">\(u\)</span> 正交分解: <span class="math display">\[u=\frac{\langle u,v\rangle}{\|v^2\|}v + w\]</span> 则 <span class="math display">\[\begin{aligned}\|u\|^2&amp;=\bigg\|\frac{\langle u,v\rangle}{\|v^2\|}v\bigg\|^2+\|w\|^2\\&amp;\geq \bigg\|\frac{\langle u,v\rangle}{\|v^2\|}v\bigg\|^2=\frac{|\langle u,v\rangle|^2}{\|v\|^2}\end{aligned}\]</span> 乘过去即得。</p><h3 id="shcmidt-正交化">Shcmidt 正交化</h3><p>设 <span class="math inline">\(v_1,\dots,v_m\)</span> 是 <span class="math inline">\(V\)</span> 中的线性无关向量组，设 <span class="math inline">\(e_1=v_1/\|v_1\|\)</span>. <span class="math display">\[e_j=\frac{v_j-\langle v_j,e_1\rangle e_1-\cdots-\langle v_j,e_{j-1}\rangle e_{j-1}}{\|v_j-\langle v_j,e_1\rangle e_1-\cdots-\langle v_j,e_{j-1}\rangle e_{j-1}\|}\]</span> <span class="math inline">\(\{e_1,\dots,e_m\}\)</span> 是 <span class="math inline">\(V\)</span> 中的规范正交组。</p><h3 id="舒尔定理">舒尔定理</h3><p>设 <span class="math inline">\(V\)</span> 是有限维的复向量空间且 <span class="math inline">\(T\in \mathcal{L}(V,\mathbf{F})\)</span> ，则 <span class="math inline">\(T\)</span> 关于 <span class="math inline">\(V\)</span> 的某个规范正交基具有上三角矩阵。</p><p>证明：</p><p>​ 设 <span class="math inline">\(V=span\{v_1,\dots,v_n\}\)</span> , <span class="math inline">\(\{e_1,\dots,e_n\}\)</span> 为其规范正交基。</p><p>​ 则 <span class="math inline">\(span\{e_1,\dots,e_n\}=span\{v_1,\dots,v_n\}\)</span></p><p>​ 由于存在 <span class="math inline">\(T\)</span> ,其关于 <span class="math inline">\(\{v_1,\dots,v_n\}\)</span> 具有上三角矩阵，则对于每个 <span class="math inline">\(j=1,\dots,n\)</span></p><p>​ $ span{v_1,,v_j}$在 <span class="math inline">\(T\)</span> 作用下不变</p><p>​ 故 <span class="math inline">\(span\{e_1,\dots,e_j\}=span\{v_1,\dots,v_j\}\)</span> 在 <span class="math inline">\(T\)</span> 作用下不变</p><p>​ 所以 <span class="math inline">\(T\)</span> 关于 <span class="math inline">\(\{e_1,\dots,e_n\}\)</span> 具有上三角矩阵。</p><h5 id="关于上三角矩阵">关于上三角矩阵</h5><p>设 <span class="math inline">\(T\in\mathcal{L}[V]\)</span>，<span class="math inline">\((v_1,\dots,v_n)\)</span> 是 <span class="math inline">\(V\)</span> 的基。</p><p>TFAE：</p><ul><li><span class="math inline">\(T\)</span> 关于 <span class="math inline">\(v_1,\dots,v_n\)</span> 的矩阵是上三角的</li><li><span class="math inline">\(Tv_j\in span\{v_1,\dots,v_j\}\)</span></li><li><span class="math inline">\(span\{v_1,\dots,v_j\}\)</span> 在 <span class="math inline">\(T\)</span> 作用下不变</li></ul><h3 id="对偶空间">对偶空间</h3><h4 id="符号说明">符号说明</h4><ul><li><span class="math inline">\(\mathcal{L}(V,W)\)</span> 表示从 <span class="math inline">\(V\)</span> 到 <span class="math inline">\(W\)</span> 的全部线性映射</li><li><span class="math inline">\(\mathbf{F}^{m,n}\triangleq \mathbf{F}^m\times\mathbf{F}^n\)</span> 可看作所有 <span class="math inline">\(m\times n\)</span> 矩阵</li><li>线性泛函：从 <span class="math inline">\(V\)</span> 到 <span class="math inline">\(\mathbf{F}\)</span> 的线性映射，即为 <span class="math inline">\(\mathcal{L}(V,\mathbf{F})\)</span> 中的元素</li><li><p>对偶空间 <span class="math inline">\(V’\)</span>：<span class="math inline">\(V\)</span> 上所有线性泛函构成的向量空间</p></li><li>对偶基 <span class="math inline">\(\{\varphi_1,\dots,\varphi_n\}\)</span>： <span class="math inline">\(\varphi_j(e_k)=\delta_{jk}\)</span></li><li>对偶映射 <span class="math inline">\(T’\)</span>：<span class="math inline">\(T’(\varphi)=\varphi\circ T ,\quad T’\in\mathcal{L}(V’,W’), \varphi\in W’,T’\in V&#39;\)</span></li><li><p>零化子 <span class="math inline">\(U^0\)</span>：<span class="math inline">\(U^0=\{\varphi\in V’:\varphi(u)=0,\forall u\in U\},U\subset V\)</span></p></li></ul><h4 id="重要结论">重要结论</h4><ul><li><p><span class="math inline">\(\mathcal{M}(T)\)</span> 为 <span class="math inline">\(T\in\mathcal{L}(V,W)\)</span> 的矩阵表示 , 其实是一个从 <span class="math inline">\(\mathcal{L}(V,W)\to\mathbf{F}^{m,n}\)</span> 的同构。</p></li><li>对偶映射的代数性质：<span class="math inline">\((aS+bT)’=aS’+bT’\)</span>, <span class="math inline">\((ST)’=T’S&#39;\)</span></li><li><span class="math inline">\(T’\)</span> 的矩阵是 <span class="math inline">\(T\)</span> 的矩阵的转置</li><li><span class="math inline">\(\dim V’=\dim V\)</span></li><li><span class="math inline">\(\dim U+\dim U^0=\dim V\)</span></li><li><span class="math inline">\(T 满\iff T’单, N(T’)=R(T)^0\)</span></li><li><p>$ T单T’满,R(T’)=N(T)^0$</p></li><li><p><span class="math inline">\(\dim R(T)=\dim R(T&#39;)\)</span></p></li></ul><h3 id="里斯表示定理">里斯表示定理</h3><p>设 <span class="math inline">\(V\)</span> 是有限维的且 <span class="math inline">\(\varphi\)</span> 是 <span class="math inline">\(V\)</span> 上的线性泛函，则存在唯一的向量 <span class="math inline">\(u\in V\)</span> 使得对每个 <span class="math inline">\(v\in V\)</span> 均有 <span class="math inline">\(\varphi(v)=\langle v,u\rangle\)</span>.</p><h2 id="多项式">4. 多项式</h2><h3 id="带余除法">带余除法</h3><p>设 <span class="math inline">\(p,s\in \mathcal{P}(\mathbb{F})\)</span> 且 <span class="math inline">\(s\neq 0\)</span>, 则存在唯一多项式 <span class="math inline">\(q,r\in\mathcal{P}(\mathbb{F})\)</span> 使得 <span class="math display">\[p=sq+r\notag\]</span> 且 <span class="math inline">\(\deg\ r&lt;\deg\ s\)</span> .</p><p>证明：</p><p>​ 记 <span class="math inline">\(n=\deg p,m =\deg s\)</span></p><p>​ <span class="math inline">\(n&gt;m\)</span> 时： <span class="math display">\[\begin{aligned}&amp;\because T:\mathcal{P_{n-m}}\times\mathcal{P_{m-1}}\to\mathcal{P_{n}},\quad (q,r)\mapsto sq+r \quad 是线性双射\\&amp;\therefore\{(q,r)\mid q\in \mathcal{P_{n-m}},r\in\mathcal{P_{m-1}}\}\cong\{sq+r\mid q\in \mathcal{P_{n-m}},r\in\mathcal{P_{m-1}}\}\\&amp;\because \dim \mathcal{P_{n-m}}\times\mathcal{P_{m-1}}=(n-m+1)+(m-1+1)=n+1\\&amp;\therefore \dim R(T)=n+1=\dim \mathcal{P_n}\\&amp;\therefore \{sq+r\mid q\in \mathcal{P_{n-m}},r\in\mathcal{P_{m-1}}\}\cong \mathcal{P_n(\mathbb{F})}\end{aligned}\]</span></p><h3 id="代数基本定理">代数基本定理</h3><p>任何一个次数大于 <span class="math inline">\(0\)</span> 的复多项式都至少有一个复数根。</p><p>证明：</p><p>​ 若 <span class="math inline">\(p\in \mathbf{C}[x]\)</span> 没有根，则 <span class="math inline">\(\displaystyle\frac 1 p\)</span> 为全平面有界的解析函数。由刘维尔定理知其必为常数。</p><h3 id="拉格朗日多项式">拉格朗日多项式</h3><p><span class="math display">\[f_i (x)=\prod_{\substack{s=1\\s\neq i}}^n \frac{x-c_s}{c_i-c_s}\]</span></p><p><span class="math inline">\(\{f_0,f_1,\dots,f_n\}\)</span> 构成了 $[x]_{n} $ 的一组代入意义下的单位正交基（ <span class="math inline">\(f_i(c_j)=\delta_{ij}\)</span>）</p><p>拉格朗日插值公式： $g(x)=b_i f_i $ 满足： <span class="math inline">\(g(c_i)=b_i\)</span> .</p><h2 id="矩阵">5. 矩阵</h2><h3 id="秩">秩</h3><ul><li>定义与意义</li></ul><p>矩阵的列向量的极大线性无关组的元素个数。</p><p><span class="math inline">\(A:m\times n\iff \sigma:\mathbb{R}^n\to\mathbb{R}^m\)</span></p><p>由于： <span class="math display">\[R(A)=\left(\begin{matrix}a_{11}x_1+a_{12}x_2+\cdots+a_{1n}x_n\\a_{21}x_1+a_{22}x_2+\cdots+a_{2n}x_n\\\vdots\\a_{m1}x_1+a_{m2}x_2+\cdots+a_{mn}x_n\end{matrix}\right)=\mathscr{L}\left\{ \left(\begin{aligned}a_{11}\\a_{21}\\ \vdots \\ a_{m1}\end{aligned}\right),\left(\begin{aligned}a_{12}\\a_{22}\\ \vdots \\ a_{m2}\end{aligned}\right),\cdots,\left(\begin{aligned}a_{1n}\\a_{2n}\\ \vdots \\ a_{mn}\end{aligned}\right)\right\}\]</span> <span class="math inline">\(A\)</span> 的列秩等于 <span class="math inline">\(A\)</span> 的列空间维数，也是对应线性映射的像空间维数 <span class="math inline">\(\dim R(A)\)</span>。</p><ul><li>行秩 <span class="math inline">\(=\)</span> 列秩</li></ul><h3 id="行列式">行列式</h3><ul><li><span class="math inline">\(\det (A)=\det(A^T)\)</span> 证：初等矩阵转置行列式不变，将矩阵 <span class="math inline">\(A\)</span> 进行初等矩阵分解</li></ul><h2 id="特征值理论">6. 特征值理论</h2><h3 id="特征向量线性无关">特征向量线性无关</h3><p>相应于不同特征值的特征向量线性无关。</p><p>证明：</p><p>​ 设 <span class="math inline">\(T\in \mathcal{L}(V)\)</span> ，设 <span class="math inline">\(\lambda_1,\dots,\lambda_m\)</span> 是 <span class="math inline">\(T\)</span> 对互不相同的特征值， <span class="math inline">\(v_1,\dots,v_m\)</span> 是相应的特征向量，则 <span class="math inline">\(v_1,\dots,v_m\)</span> 是线性无关的。</p><p>​ 设 <span class="math inline">\(k\)</span> 是使得 <span class="math inline">\(v_k=span\{v_1,\dots,v_{k-1}\}\)</span> 成立的<strong>最小</strong>正整数。 <span class="math display">\[\begin{aligned}v_k&amp;=a_1v_1+\cdots+a_{k-1}v_{k-1}\\T(v_k)=\lambda_k v_k&amp;=a_1\lambda_1v_1+\cdots+a_{k-1}\lambda_{k-1}v_{k-1}\\\lambda_k v_k&amp;=a_1\lambda_k v_1+\cdots+a_{k-1}\lambda_{k}v_{k-1}\\\\\implies &amp;a_1(\lambda_1-\lambda_k)v_1+\cdots+a_{k-1}(\lambda_{k-1}-\lambda_{k})v_{k-1}=0\\\implies &amp;a_1=\cdots=a_{k-1}=0\end{aligned}\]</span> ​ 矛盾，故不存在这样的 <span class="math inline">\(k\)</span> ， 特征向量线性无关。</p><h3 id="特征子空间">特征子空间</h3><p>特征子空间是不变子空间。</p><p>特征子空间的和是直和。</p><p><span class="math inline">\(i.e.\)</span> <span class="math display">\[W=E_{\lambda_1}+\cdots + E_{\lambda_m}=E_{\lambda_1}\oplus \cdots \oplus E_{\lambda_m}\notag\]</span> 证明：</p><p>设<span class="math inline">\(\lambda_j\)</span> 和 <span class="math inline">\(E_{\lambda_j}\)</span> 是 <span class="math inline">\(n\)</span> 维线性空间 <span class="math inline">\(V\)</span> 的线性变换 <span class="math inline">\(T\)</span> 的 <span class="math inline">\(m\)</span> 个互不相同的特征值及相应的特征子空间，则只需证明<strong>零向量</strong>在 <span class="math inline">\(W\)</span> 中的<strong>分解唯一</strong>。</p><p>即证： <span class="math inline">\(\xi_1+\cdots \xi_m=0\implies \xi_i=0,\quad \xi_i\in E_{\lambda_i}\)</span></p><p>注意 <span class="math inline">\(\xi_i\)</span> 是特征子空间 <span class="math inline">\(E_{\lambda_i}\)</span> 中的向量，由属于 <span class="math inline">\(\lambda_i\)</span> 的特征向量线性组合而成，仍有 <span class="math inline">\(T(\xi_i)=\lambda_i\xi_i\)</span></p><p><strong>归纳</strong>证明： $$ \begin{aligned} m=2: _1+_2=0 &amp;T(_1+_2)=_1_1+_2_2=0\ &amp;(_1-_2)_2=0\ &amp;_1=_2=0\</p><p>\end{aligned} <span class="math display">\[设对 $m-1$ 结论成立，考虑 $m$ :\]</span> \begin{aligned} &amp; _1++_m=0\ &amp;T(_1++_m)=_1_1++_m_m=0\ &amp;(_1-_m)<em>1++(</em>{m-1}-<em>m)</em>{m-1}=0\ &amp; <em>1==</em>{m-1}=0_m=0 \end{aligned} $$</p><p>由此也可以得到属于不同特征值的特征向量线性无关，因为 <span class="math inline">\(E_{\lambda_i}\cap E_{\lambda_j}={\vec 0}\)</span></p><h3 id="可对角化的条件">可对角化的条件</h3><p><span class="math inline">\(n\)</span> 维线性空间 <span class="math inline">\(V\)</span> 上的线性变换 <span class="math inline">\(T\)</span> 的表示矩阵 <span class="math inline">\(M(T)\)</span> 可对角化：</p><p>$ $ <span class="math inline">\(T\)</span> 有 <span class="math inline">\(n\)</span> 个(线性无关的)特征向量 or <span class="math inline">\(V\)</span> 有由 <span class="math inline">\(T\)</span> 的特征向量构成的基</p><p><span class="math inline">\(\iff\)</span> $V=E_{<em>1}E</em>{_m} $ (已经知道和是直和，接下来只需证明和就是 <span class="math inline">\(V\)</span> ,由有由特征向量构成的基即得)</p><p><span class="math inline">\(\iff\)</span> <span class="math inline">\(T\)</span> 的每个特征值的重数等于其特征子空间的维数 ( 代数重数 <span class="math inline">\(=\)</span> 几何重数 ）, 且不同特征值的重数之和等 于 <span class="math inline">\(n\)</span></p><p>注：一般情况下，代数重数大于等于几何重数，证明先放一放。</p><h3 id="矩阵的秩维数与特征值">矩阵的秩、维数与特征值</h3><p>特征值个数等于矩阵的维数。其中，不等于 <span class="math inline">\(0\)</span> 且<strong>不同</strong>的特征值个数为矩阵的秩。</p><p>也就是说，矩阵的秩是特征子空间的种类数，如何理解和证明？</p><h3 id="广义特征向量">广义特征向量</h3><h4 id="零空间的停止增长">零空间的停止增长</h4><h4 id="广义特征向量线性无关性">广义特征向量线性无关性</h4><h4 id="广义特征空间">广义特征空间</h4><h5 id="刻画">刻画</h5><h2 id="算子理论">7. 算子理论</h2><h3 id="不变子空间">不变子空间</h3><p>待整理</p><h3 id="正交投影">正交投影</h3><p>待整理</p><h3 id="自伴算子">自伴算子</h3><p><span class="math inline">\(T=T^*\)</span>.</p><p>类比：<span class="math inline">\(z\)</span> 是实数</p><h4 id="性质">性质</h4><ul><li><p><span class="math inline">\(\langle Tv,w\rangle=\langle v,Tw\rangle\)</span></p></li><li><p>特征值都是实数</p><p>证：<span class="math inline">\(\lambda\|v\|^2=\langle \lambda v,v\rangle=\langle Tv,v\rangle=\langle v,Tv\rangle=\langle v,\lambda v\rangle=\overline\lambda \|v\|^2\)</span></p></li><li><p>在 <span class="math inline">\(\mathbf{C}\)</span>, 只有零算子才能使 <span class="math inline">\(Tv\)</span> 总正交于 <span class="math inline">\(v\)</span> : <span class="math inline">\(\forall v\in V ,\langle Tv,v\rangle=0\implies T\equiv 0\)</span></p><p>证： <span class="math display">\[\begin{aligned}\forall u,w\in V\\\langle Tu,w \rangle=&amp;\frac{\left\langle T(u+w),u+w\right\rangle-\left\langle T(u-w),u-w\right\rangle}{4}\\&amp;+\frac{\left\langle T(u+iw),u+iw\right\rangle-\left\langle T(u-iw),u-iw\right\rangle}{4}\end{aligned}\]</span></p></li><li><p>在 <span class="math inline">\(\mathbf{C}\)</span>, $vV,Tv,v $ (充要)</p><p>证： <span class="math inline">\(\langle Tv,v\rangle-\overline{\langle Tv,v\rangle}=0\)</span></p></li><li><p>相应于不同特征值的特征向量正交</p></li></ul><h3 id="正规算子">正规算子</h3><p>和伴随可交换：<span class="math inline">\(TT^*=T^*T\)</span></p><p>类比：复数 <span class="math inline">\(z\)</span> : 显然 <span class="math inline">\(zz^*=z^*z\)</span></p><h4 id="性质-1">性质</h4><ul><li><p><span class="math inline">\(\|Tv\|=\|T^* v\|\)</span> (充要)</p><p>证： <span class="math inline">\(TT^*-T^*T=0\iff \forall v\in V, \langle (TT^*-T^*T)v,v\rangle=0\iff \|T^*v\|^2=\|Tv\|^2\)</span></p></li><li><p><span class="math inline">\(T\)</span> 和 <span class="math inline">\(T^*\)</span> 有相同的特征向量 （是充分的吗？）</p><p>具体：<span class="math inline">\(v\)</span> 是 <span class="math inline">\(T\)</span> 的相应于特征值 <span class="math inline">\(\lambda\)</span> 的特征向量，则 <span class="math inline">\(v\)</span> 也是 <span class="math inline">\(T^*\)</span> 的相应于 <span class="math inline">\(\overline\lambda\)</span> 的特征向量</p><p>证：<span class="math inline">\(0=\|(T-\lambda I)v\|=\|(T-\lambda I)^*v\|=\|(T^*-\overline\lambda I)v\|\)</span></p></li><li><p>相应于不同特征值的特征向量正交</p><p>证：<span class="math inline">\((\lambda-\mu)\langle v,w\rangle=\langle \lambda v,w\rangle-\langle v,\overline\mu w\rangle=\langle Tv,w\rangle-\langle v,T^*w\rangle=0\)</span></p><p>注：<span class="math inline">\(\lambda\)</span> 是 <span class="math inline">\(T\)</span> 的特征值当且仅当 <span class="math inline">\(\overline\lambda\)</span> 是 <span class="math inline">\(T^*\)</span> 的特征值。 （ <span class="math inline">\(\det (T-\lambda I)=0\iff \det (T^*-\overline \lambda I)=0\)</span> ）</p></li></ul><h3 id="幂零算子">幂零算子</h3><h3 id="谱分解">谱分解</h3><h4 id="复谱定理">复谱定理</h4><h4 id="实谱定理">实谱定理</h4><h4 id="谱分解定理">谱分解定理</h4><h3 id="奇异值分解">奇异值分解</h3><h4 id="正算子">正算子</h4><h5 id="刻画-1">刻画</h5><h4 id="等距同构">等距同构</h4><h5 id="刻画-2">刻画</h5><h4 id="极分解">极分解</h4><h4 id="奇异值分解-1">奇异值分解</h4><h5 id="奇异值">奇异值</h5><h5 id="线性变换奇异值定理">线性变换奇异值定理</h5><h5 id="矩阵的奇异值分解">矩阵的奇异值分解</h5>]]></content>
      
      
      <categories>
          
          <category> Mathematics </category>
          
          <category> Algebra </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>L2-Net</title>
      <link href="/2020/02/23/Computer-Sciencs/Deep%20learning/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-L2-Net/"/>
      <url>/2020/02/23/Computer-Sciencs/Deep%20learning/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-L2-Net/</url>
      
        <content type="html"><![CDATA[<p>论文链接：http://www.nlpr.ia.ac.cn/fanbin/pub/L2-Net_CVPR17.pdf</p><p>代码链接：https://github.com/yuruntian/L2-Net</p><p>研读次数：1</p><h2 id="提出的好方法">提出的好方法</h2><ul><li><p>a progressive sampling strategy 渐进采样策略，可使网络在有限次数内获得大量样本</p></li><li><p>Discriminative Intermediate Feature map (DIF) 在中间的特征层施加了额外的监督</p></li><li><p>Loss function that takes three important error aspects into account:</p><ul><li>descriptor similarity 未完全理解</li><li>descriptor compactness : ‘An interesting finding is that the degree of overfitting is directly related to the degree of correlation among descriptor dimensions’</li><li>intermediate feature maps 未完全理解</li></ul></li></ul><h3 id="须了解的相关知识">须了解的相关知识</h3><ul><li>SIFT descriptor</li><li>NNS (nearest neighbor search)</li><li>MatchNet (a typical Siamese network)</li></ul><h3 id="应用">应用</h3><ul><li>实现 <em>特征匹配</em> 的神经网络的训练</li></ul>]]></content>
      
      
      <categories>
          
          <category> Computer Science </category>
          
          <category> Deep Learning </category>
          
          <category> Paper Notes </category>
          
      </categories>
      
      
        <tags>
            
            <tag> notes </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>SOS-Net</title>
      <link href="/2020/02/23/Computer-Sciencs/Deep%20learning/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-SOS-Net/"/>
      <url>/2020/02/23/Computer-Sciencs/Deep%20learning/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-SOS-Net/</url>
      
        <content type="html"><![CDATA[<p>代码链接：https://github.com/scape-research/SOSNet</p><p>研读次数：1</p><p>对 L2-Net 和超越L2的 Hard-Net 的超越。</p><h2 id="待学的东西">待学的东西</h2><ul><li>Von Mises-Fisher distribution</li><li>BOLD</li><li>Hard-Net</li><li>First Order Similarity (FOS)</li><li><span class="math inline">\(K\)</span> Nearest Neighbors (KNN)</li></ul>]]></content>
      
      
      <categories>
          
          <category> Computer Science </category>
          
          <category> Deep Learning </category>
          
          <category> Paper Notes </category>
          
      </categories>
      
      
        <tags>
            
            <tag> notes </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>数理方法</title>
      <link href="/2020/02/19/Physics/%E6%95%B0%E7%90%86%E6%96%B9%E6%B3%95/"/>
      <url>/2020/02/19/Physics/%E6%95%B0%E7%90%86%E6%96%B9%E6%B3%95/</url>
      
        <content type="html"><![CDATA[<h1 id="数理方法整理">数理方法整理</h1><center>作者：黄隆钤 混合1801</center><h2 id="一-数学物理定解问题">一 数学物理定解问题</h2><h3 id="定解问题的导出">1.1 定解问题的导出</h3><h4 id="振动方程">（1）振动方程</h4><p><span class="math display">\[u_{tt}-a^2u_{xx}=f(x,t)\\u_{tt}-a^2\Delta u =f(\mathbf{x},t) \qquad (high\ dim)\]</span></p><ul><li><p>弦的横振动</p><p><img src="https://tva1.sinaimg.cn/large/0082zybply1gc1rytn6i6j313l0lcabz.jpg" style="zoom:50%;" /></p></li></ul><p>$ \ $ <a id="more"></a></p><ul><li>杆的纵振动</li></ul><p><img src="https://tva1.sinaimg.cn/large/0082zybply1gc1t5r8oilj30u30jaq4k.jpg" style="zoom: 50%;" /></p><ul><li><p>均匀薄膜的微小横振动</p><p><img src="https://tva1.sinaimg.cn/large/0082zybply1gc1sn6p2ppj30xk0u0am9.jpg" style="zoom: 50%;" /></p></li><li><p>电磁波方程</p></li></ul><p><span class="math display">\[\begin{array}\vec E_{tt}-a^2 \Delta _3 \vec E=0\\\vec H_{tt}-a^2\Delta_3 H=0,&amp;\qquad a^2=1/\mu_o\varepsilon_0 = c^2\end{array}\notag\]</span></p><h4 id="输运方程">（2）输运方程</h4><p><span class="math display">\[u_t-a^2 u_{xx}=f(x,t)\\u_t-a^2\Delta u=f(\mathbf{x},t)\qquad(high \ dim)\]</span></p><ul><li><p>扩散方程</p><p><img src="https://tva1.sinaimg.cn/large/0082zybply1gc2n18scxhj317s0rujvs.jpg" style="zoom: 50%;" /></p></li><li><p>热传导方程</p><p><span class="math display">\[(\Gamma|_x-\Gamma|_{x+dx})dSdt=c(\rho dSdx)du\\=&gt;u_t-a^2u_{xx}=0,\quad a^2=k/c\rho\notag\]</span></p></li><li><p>传输线方程</p></li></ul><p><img src="https://tva1.sinaimg.cn/large/0082zybply1gc2nchm8ifj30u00w2424.jpg" style="zoom: 50%;" /></p><h4 id="泊松方程">（3）泊松方程</h4><p><span class="math display">\[\Delta u=f\]</span></p><ul><li><p>稳定温度分布 <span class="math display">\[c\rho u_t-k\Delta u=F(x,y,z,t),\quad u_t=0\\\implies k\Delta u=-F\notag\]</span></p></li><li><p>静电场方程 <span class="math display">\[\oiint \vec E \ dS=\int_V\nabla\cdot \vec E \ dV=\frac{1}{\varepsilon_0}\int_V \rho \ dV\\\implies\nabla\cdot\vec E=\rho/\varepsilon_0,\qquad \vec E=-\nabla V\\\implies \nabla\cdot\nabla V=-\rho / \varepsilon_0\\ i.e.\quad \Delta V=-\rho / \varepsilon_0\notag\]</span></p></li><li><p>不可压缩流体的无旋定常流动</p></li></ul><p><img src="https://tva1.sinaimg.cn/large/0082zybply1gc2owe4xd5j30u00xu777.jpg" style="zoom: 50%;" /></p><h4 id="其他知识">（4）其他知识</h4><ul><li>冲击函数的物理意义</li></ul><h3 id="定解条件的确定">1.2 定解条件的确定</h3><h4 id="初始条件">（1）初始条件</h4><p>整个系统的初始状态 : <span class="math inline">\(u|_{t=0}\)</span></p><h4 id="边界条件">（2）边界条件</h4><ul><li><p>固定：<span class="math inline">\(u|_{x=x_0}=0\)</span></p></li><li><p>自由: 不受外力。以杆为例：<span class="math inline">\(YS\ u_x|_{x=x_0}=0=&gt;u_x|_{x=x_0}=0\)</span></p></li><li><p>第三类边界条件：</p><ul><li><p>自由冷却：遵循牛顿冷却定律。单位时间单位面积散失的热量与温度差成正比。 <span class="math display">\[\Gamma |_{x=x_0}=h(u|_{x=x_0}-u_0),\quad \Gamma =-k u_x \\i.e. \quad (u_x+\frac{h}{k}u)|_{x=x_0}=\frac{u_0}{k}\notag\]</span></p></li><li><p>弹性连接：杆中的弹性力 <span class="math inline">\(=\)</span> 弹性连接物中的弹性恢复力 <span class="math display">\[YS\ u_x|_{x=x_0}=-ku|_{x=x_0}\\ i.e. \quad (u_x+\frac{k}{YS}u)|_{x=x_0}=0\notag\]</span></p></li></ul></li><li><p>其他：e.g. 杆连接在屋顶的墙上，下端悬挂重物。（方程列出的是弹性力把重物的重力平衡后的式子） <span class="math display">\[-YS\ u_x|_{x=l}=mu_{tt}|_{x=l}\\i.e.\quad (u_x+\frac{m}{YS}u_{tt})=0\notag\]</span></p></li></ul><h4 id="衔接条件">（3）衔接条件</h4><p><img src="https://tva1.sinaimg.cn/large/0082zybply1gc2pmm9gyoj30a00a2q2x.jpg" style="zoom: 50%;" /> <span class="math display">\[\notag\begin{cases}  u_{I}|_{X=x_0}=u_{II}|_{x=x_0}\\T(-u_{Ix}|_{x=x_0})+Tu_{IIx}|_{x=x_0}=F(t)\end{cases}\]</span></p><h3 id="定解问题的求解">1.3 定解问题的求解</h3><ul><li>行波法</li><li>分离变量法</li><li>级数解法</li></ul><h2 id="二-行波法和分离变量法">二 行波法和分离变量法</h2><h3 id="行波法">2.1 行波法</h3><h4 id="达朗贝尔公式">（1）达朗贝尔公式</h4><p><span class="math display">\[\begin{cases}u_{tt}-a^2 u_{xx}=0, \qquad -\infty&lt;x&lt;\infty,t&gt;0  \\u|_{t=0}=\varphi(x),\ u_t|_{t=0}=\psi (x)\end{cases}\notag\]</span></p><p><span class="math display">\[\implies u(x,t)=\frac{1}{2}[\varphi(x+at)+\varphi(x-at)]+\frac{1}{2a}\int_{x-at}^{x+at} \psi(\alpha)d\alpha\]</span></p><h4 id="半无界边界条件不齐次">（2）半无界+边界条件不齐次</h4><p><span class="math inline">\(x&gt;at\)</span> ：可认为端点的影响不能传到，直接按原达朗贝尔公式求出</p><p><span class="math inline">\(x\leq at\)</span> ：待定系数延拓：令 <span class="math display">\[\Psi(x)= \begin{cases}\psi(x),\quad x\geq0\\\psi_1(x),\quad x&lt;0\end{cases}\qquad \Phi(x)=\begin{cases}\varphi(x),\quad x\geq0\\\varphi_1(x),\quad x&lt;0\end{cases}\notag\]</span> 带入边界条件，取合适的 <span class="math inline">\(\psi_1(x)\)</span> 和 <span class="math inline">\(\varphi_1(x)\)</span> 使之成立</p><h3 id="分离变量法">2.2 分离变量法</h3><h4 id="齐次方程-齐次边界">（1）齐次方程-齐次边界</h4><p><span class="math display">\[\begin{cases}u_{tt}-a^2 u_{xx}=0,\quad 0\leq x \leq l,\  t\geq 0&amp; \qquad (I) \\u|_{x=0}=0,\ u|_{x=l}=0 ,\quad t\geq 0&amp;\qquad (II)\\u|_{t=0}=\varphi(x),\ u_t|_{t=0}=\psi(x), \quad 0\leq x \leq l&amp; \qquad (III)\end{cases}\notag\]</span></p><p><span class="math display">\[Let\quad u(x,t)=X(x)T(t)\implies \frac{X&#39;&#39;}{X}=\frac{T&#39;&#39;}{a^2 T}\triangleq -\lambda\\Put \ into \ (I) \ and \ (II) \implies\begin{cases}X&#39;&#39;+\lambda X=0\\ X(0)=X(l)=0\end{cases},\quad T&#39;&#39;+a^2\lambda \ T=0 \\\implies\cdots=&gt;\lambda&gt;0\\\implies\lambda_n=\frac{n^2\pi^2}{l^2},\quad X_n=c_n \sin(\frac{n\pi}{l}x),\\T_n=a_n\cos(\frac{n\pi}{l}t)+b_n\sin(\frac{n\pi}{l}t)\notag\]</span></p><p><span class="math display">\[u(x,t)=\sum\limits_{n=0}^{\infty}X_nT_n=\sum\limits_{n=0}^\infty [A_n \cos(\frac{n\pi}{l}t)+B_n\sin(\frac{n\pi}{l}t)]\sin(\frac{n\pi}{l}x)\\put \ into \ (III)\implies A_n\sin(\frac{n\pi}{l}x)=\varphi(x)\\=&gt;A_n=\frac{\int_0^l\varphi(x)\sin(\frac{n\pi}{l}x)dx}{\int_0^l \sin(\frac{n\pi}{l}x)dx}=\frac{2}{l}\int_0^l\varphi(x)\sin(\frac{n\pi}{l}x)dx\\B_n=\frac{2}{n\pi}\int_0^l\psi(x)\sin(\frac{n\pi}{l}x)dx\notag\]</span></p><p><span class="math display">\[=&gt;u(x,t)=\sum\limits_{n=0}^\infty [A_n \cos(\frac{n\pi}{l}t)+B_n\sin(\frac{n\pi}{l}t)]\sin(\frac{n\pi}{l}x),\qquad A_n,B_n \ are \ as \ above.\]</span></p><h4 id="非齐次边界">（2）非齐次边界</h4><p>首先将边界条件齐次化。再回到2.1。</p><h4 id="非齐次方程">（3）非齐次方程</h4><p>边界条件齐次化之后，可能会转化为齐次化边界的非齐次方程: <span class="math display">\[\begin{cases}u_{tt}-a^2 u_{xx}=f(x,t),\quad 0\leq x \leq l,\  t\geq 0&amp; \qquad (I) \\u|_{x=0}=0,\ u|_{x=l}=0 ,\quad t\geq 0&amp;\qquad (II)\\u|_{t=0}=\varphi(x),\ u_t|_{t=0}=\psi(x), \quad 0\leq x \leq l&amp; \qquad (III)\end{cases}\notag\]</span></p><h5 id="解法一">解法一</h5><p>设 <span class="math inline">\(u=X(x)\cdot T(t)\)</span> 为 <em>齐次方程</em> 的解</p><p>可得 <span class="math inline">\(\displaystyle X_n=c_n \sin(\frac{n\pi}{l}x)\)</span></p><p>以 <span class="math inline">\(\displaystyle \sin(\frac{n\pi}{l}x)\)</span> 为基，对 <span class="math inline">\(u\)</span> 作傅立叶展开:</p><p><strong>设</strong> <span class="math display">\[u=\sum\limits_{n=1}^\infty T_n(t)\cdot \sin\frac{n\pi}{l}x\]</span></p><p>带入 <span class="math inline">\(I\)</span> : <span class="math display">\[\sum\limits_{n=1}^\infty (T_n&#39;&#39;+\frac{a^2 n^2\pi^2}{l^2}T_n)\sin\frac{n\pi}{l}x=f(x,t)\\\implies\quad  T_n&#39;&#39;+\frac{a^2 n^2\pi^2}{l^2}T_n=\frac{2}{l}\int_0^\pi f(x,t)\sin\frac{n\pi}{l}xdx\notag\]</span> 解<span class="math inline">\(ODE\)</span>： <span class="math display">\[T_n=Y_n+Y_n^*\\=&gt;u=\sum\limits_{n=1}^\infty[Y_n+Y_n^*]\cdot\sin\frac{n\pi}{l}x\notag\]</span></p><h5 id="解法二">解法二</h5><p>原式 <span class="math inline">\(\iff\)</span> <span class="math display">\[(I)\begin{cases}u_{tt}-a^2 u_{xx}=0,\\u|_{x=0}=0,\ u|_{x=l}=0 ,\qquad \\u|_{t=0}=\varphi(x),\ u_t|_{t=0}=\psi(x),\end{cases}and \qquad (II)\begin{cases}u_{tt}-a^2 u_{xx}=f(x,t),\\u|_{x=0}=0,\ u|_{x=l}=0 ,\qquad \\u|_{t=0}=0,\ u_t|_{t=0}=0,\end{cases}\]</span></p><p>解 （<span class="math inline">\(I\)</span>）可得 <span class="math inline">\(u_I\)</span></p><p>解（<span class="math inline">\(II\)</span>）： <span class="math display">\[u_{II}=\int_0^tw(x,\tau)d\tau,\quad w\ satisfy:\\(III)\quad\begin{cases}w_{tt}-a^2w_{xx}=0\\w|_{x=0}=w|_{x=l}=0\\w|_{t=\tau}=0,\ w|_{t=\tau}=f(x,\tau)\end{cases}\notag\]</span> 令 <span class="math inline">\(t’=t-\tau\)</span>, 同 <span class="math inline">\(I\)</span> 方法解 <span class="math inline">\((III)\)</span> 即可. <span class="math display">\[=&gt;u=u_I+u_{II}\notag\]</span></p><h2 id="三-球坐标系与柱坐标系">三 球坐标系与柱坐标系</h2><h3 id="拉普拉斯方程">3.1 拉普拉斯方程</h3><p>注：拉普拉斯算子 <span class="math inline">\(\Delta\)</span> 定义为<strong>梯度的散度</strong> <span class="math inline">\(\quad i.e.\quad \Delta f=\nabla\cdot\nabla f\)</span></p><h4 id="极坐标系">(1) 极坐标系</h4><p><span class="math display">\[\Delta u=0\iff u_{rr}+\frac{1}{r}u_r+\frac{1}{r^2}u_{\theta\theta}=0\]</span></p><p><strong>推导：</strong></p><ol type="1"><li>极坐标系下，梯度算子定义为：（径向变化的单位长+角向变化的单位长）</li></ol><p><span class="math display">\[\nabla\triangleq\vec e_r\frac{\partial}{\partial r}+\vec e_\theta\frac{\partial}{r\partial \theta}\]</span></p><ol start="2" type="1"><li>由此推出拉普拉斯算子的公式：</li></ol><p><span class="math display">\[\begin{aligned}\Delta&amp;=\nabla\cdot \nabla  \\&amp;=(\vec e_r\frac{\partial}{\partial r}+\vec e_\theta\frac{\partial}{r\partial \theta})\cdot (\vec e_r\frac{\partial}{\partial r}+\vec e_\theta\frac{\partial}{r\partial \theta})\\&amp;=\frac{\partial^2}{\partial r^2}+\frac{1}{r}\frac{\partial}{\partial r}+\frac{1}{r^2}\frac{\partial^2}{\partial \theta^2}\end{aligned}\notag\]</span></p><ol start="3" type="1"><li>过程中用到： <span class="math display">\[\frac{\partial\vec e_\theta}{\partial\theta}=-\vec e_r,\quad \frac{\partial\vec e_r}{\partial\theta}=\vec e_\theta\\\frac{\partial\vec e_\theta}{\partial r}=0,\quad \frac{\partial\vec e_r}{\partial r}=0\\\]</span></li></ol><h4 id="柱坐标系">(2) 柱坐标系</h4><p><span class="math display">\[\Delta u=0\iff u_{rr}+\frac{1}{r}u_r+\frac{1}{r^2}u_{\varphi\varphi}+u_{zz}=0\]</span></p><ol type="1"><li>推导中用到梯度算子在柱坐标系中的定义：</li></ol><p><span class="math display">\[\nabla\triangleq\vec e_r\frac{\partial}{\partial r}+\vec e_\varphi\frac{\partial}{r\partial \varphi}+\vec e_z\frac{\partial }{\partial z}\notag\]</span></p><ol start="2" type="1"><li><p>直接分离变量，令 <span class="math inline">\(u=R(r)\Phi(\varphi)Z(z)\)</span>, 代入后可得到 关于 <span class="math inline">\(r\)</span> 的<strong>贝塞尔方程</strong></p><p>过程：</p><p>​ 分离出 $$ ，设出 <span class="math inline">\(\lambda\)</span></p><p>=&gt; 由周期条件解出 <span class="math inline">\(\Phi\)</span>, 得到 <span class="math inline">\(\lambda=m^2\)</span> ,回代</p><p>=&gt; 分离出 $ R,Z$ ,设出 <span class="math inline">\(\mu\)</span></p><p>=&gt; 讨论 <span class="math inline">\(\mu\)</span>: <span class="math inline">\(\mu=0\)</span> 为欧拉型ODE;</p><p>​ <span class="math inline">\(\mu&gt;0\)</span> ，令 <span class="math inline">\(x\equiv\sqrt {u}\rho\)</span>, 为 <span class="math inline">\(m\)</span> 阶贝塞尔方程： <span class="math display">\[x^2\frac{d^2R}{dr^2}+x\frac{dR}{dx}+(x^2-m^2)R=0\]</span></p><p>​ <span class="math inline">\(\mu&lt;0\)</span> ，令 <span class="math inline">\(x\equiv\sqrt {-\mu}\rho\)</span>,为虚宗量贝赛尔方程： <span class="math display">\[x^2\frac{d^2R}{dr^2}+x\frac{dR}{dx}-(x^2+m^2)R=0\]</span></p></li></ol><h4 id="球坐标系">(3) 球坐标系</h4><p><span class="math display">\[\Delta u=0\iff \frac{1}{r^2}\frac{\partial }{\partial r}(r^2\frac{\partial u}{\partial r})+\frac{1}{r^2 \sin \theta}\frac{\partial }{\partial\theta}(\sin\theta\frac{\partial u}{\partial\theta})+\frac{1}{r^2\sin^2\theta}\frac{\partial^2 u}{\partial\varphi^2}=0\]</span></p><ol type="1"><li><p>推导中用到：</p><p><img src="https://tva1.sinaimg.cn/large/0082zybply1gc3566n5rrj30aq09jq31.jpg" style="zoom: 67%;" /> <span class="math display">\[\nabla\triangleq\vec e_r\frac{\partial}{\partial r}+\vec e_\theta\frac{\partial}{r\partial \theta}+\vec e_\varphi\frac{\partial }{r\sin\theta\ \partial \varphi}\notag\]</span></p></li><li><p>单位向量之间的关系： <span class="math display">\[\vec e_r\cdot\vec e_\theta=\vec e_r\cdot\vec e_\varphi=\vec e_\theta\cdot\vec e_\varphi=0, \ \vec e_\varphi=\vec e_r\times\vec e_\theta  \notag\]</span></p></li><li><p>微分关系：</p></li></ol><p><span class="math display">\[\frac{\partial\vec e_r}{\partial r}=\frac{\partial\vec e_r}{\partial \theta}=\frac{\partial\vec e_\varphi}{\partial r}=0.\\\frac{\partial\vec e_r}{\partial \theta}=\vec e_\theta,\ \frac{\partial\vec e_\theta}{\partial \theta}=-\vec e_r,\ \frac{\partial\vec e_\varphi}{\partial \theta}=0.\\\frac{\partial\vec e_r}{\partial \varphi}=\vec e_\varphi \sin\theta,\ \frac{\partial\vec e_\theta}{\partial \varphi}=\vec e_\varphi \cos\theta(未理解,求解答),\\ \frac{\partial\vec e_\varphi}{\partial \varphi}=\frac{\partial(\vec e_r\times\vec e_\theta)}{\partial \varphi}=-\vec e_r\sin\theta-\vec e_\theta\cos\theta.\]</span></p><p><strong>推导拉普拉斯方程在球坐标下的表达式，并分离变量</strong>：</p><ol type="1"><li>推导</li></ol><p><span class="math display">\[\begin{aligned}\Delta &amp;=(\vec e_r\frac{\partial}{\partial r}+\vec e_\theta\frac{\partial}{r\partial \theta}+\vec e_\varphi\frac{\partial}{r\sin\theta\ \partial \varphi})\cdot(\vec e_r\frac{\partial}{\partial r}+\vec e_\theta\frac{\partial}{r\partial \theta}+\vec e_\varphi\frac{\partial }{r\sin\theta\ \partial \varphi})\\&amp;=\vec e_r\cdot [0+\vec e_r\frac{\partial^2}{\partial r^2}+0+0+0+0]+\frac{1}{r}\vec e_\theta[\vec e_\theta\frac{\partial}{\partial r}+0+0+\vec e_\theta\frac{\partial^2}{r\partial \theta^2}+0+0]\\&amp;+\frac{1}{r\sin\theta}\vec e_\varphi[\vec e_\varphi\sin\theta\frac{\partial}{\partial r}+0+\vec e_\varphi\cos\theta\frac{\partial}{r\partial\theta}+0+0+\vec e_\varphi\frac{\partial^2}{r\sin\theta\partial\varphi^2}]\\&amp;=\frac{\partial^2}{\partial r^2}+\frac{1}{r}\frac{\partial}{\partial r}+\frac{1}{r^2}\frac{\partial^2}{\partial \theta^2}+\frac{1}{r}\frac{\partial}{\partial r}+\frac{\cos\theta}{r^2\sin\theta}\frac{\partial}{\partial \theta}+\frac{1}{r^2\sin^2\theta}\frac{\partial^2}{\partial \varphi^2}\\&amp;=\frac{1}{r^2}\frac{\partial }{\partial r}(r^2\frac{\partial }{\partial r})+\frac{1}{r^2 \sin \theta}\frac{\partial }{\partial\theta}(\sin\theta\frac{\partial }{\partial\theta})+\frac{1}{r^2\sin^2\theta}\frac{\partial^2 }{\partial\varphi^2}\end{aligned}\]</span></p><p><span class="math display">\[\therefore \Delta u=0\iff \frac{1}{r^2}\frac{\partial }{\partial r}(r^2\frac{\partial u}{\partial r})+\frac{1}{r^2 \sin \theta}\frac{\partial }{\partial\theta}(\sin\theta\frac{\partial u}{\partial\theta})+\frac{1}{r^2\sin^2\theta}\frac{\partial^2 u}{\partial\varphi^2}=0\notag\]</span></p><ol start="2" type="1"><li><p><strong>分离变量</strong></p><p>设 <span class="math inline">\(u(r,\theta,\varphi)=R(r)\cdot Y(\theta,\varphi)\)</span> ，带入 Laplace方程，得： <span class="math display">\[\begin{align}&amp;Y\frac{d}{dr}(r^2\frac{dR}{dr})+R\frac{1}{\sin\theta}\frac{d}{d\theta}(\sin\theta\frac{dY}{d\theta})+R\frac{1}{\sin^2\theta}\frac{d^2 Y}{d\varphi^2}=0\notag \\\implies&amp;\frac{1}{R}\frac{d}{dr}(r^2\frac{dR}{dr})=-\frac{1}{Y}\bigg(\frac{1}{\sin\theta}\frac{d}{d\theta}(\sin\theta\frac{dY}{d\theta})+\frac{1}{\sin^2\theta}\frac{d^2 Y}{d\varphi^2}\bigg)\triangleq l(l+1)\notag \\\implies&amp; \quad r^2 R&#39;&#39;+2rR&#39;-l(l+1) R=0, \label{EulerODE}&amp;\\&amp;\quad \frac{1}{\sin\theta}\frac{d}{d\theta}(\sin\theta\frac{dY}{d\theta})+\frac{1}{\sin^2\theta}\frac{d^2 Y}{d\varphi^2}+l(l+1)Y=0\label{ballfunc}\end{align}\]</span></p><p><span class="math inline">\((\ref{EulerODE})\)</span> 为欧拉型 ODE，解为 <span class="math inline">\(\displaystyle R(r)=Cr^l+D\frac{1}{r^{l+1}}\)</span></p><p>$ ()$为 <strong>球函数方程</strong>， 现进一步分离变量，设 <span class="math inline">\(Y(\theta,\varphi)=H(\theta)\cdot\Phi(\varphi)\)</span> , 代入得 : $$ \begin{aligned}&amp;()+H+l(l+1)H=0\ &amp; ()+l(l+1)^2=-\ &amp;''+=0 ,()+H=0</p><p>\end{aligned} $$</p><p>关于 <span class="math inline">\(\Phi\)</span> 的方程再加上<em>自然周期条件</em> <span class="math inline">\(\Phi(\varphi)=\Phi(\varphi+2\pi)\)</span>, 可得： <span class="math display">\[\lambda=m^2,\quad m=0,1,2,3,\cdots\\\Phi(\varphi)=A\cos m\varphi+B\sin m\varphi\notag\]</span> 将 <span class="math inline">\(\lambda=m^2\)</span> 代入关于 <span class="math inline">\(H\)</span> 的方程, 并记 <span class="math inline">\(x\equiv \cos\theta\)</span>： <span class="math display">\[(1-x^2)\frac{d^2 H}{dx^2}-2x\frac{d H}{dx}+\big[l(l+1)-\frac{m^2}{1-x^2}\big]H=0\label{l-Legendre}\]</span> <span class="math inline">\((\ref{l-Legendre})\)</span> 为 <span class="math inline">\(l\)</span> 阶 <strong>连带勒让德方程</strong></p></li></ol><h4 id="总结">总结</h4><ul><li><p>直角坐标拉普拉斯算子 <span class="math display">\[\Delta=\frac{\partial^2}{\partial x^2}+\frac{\partial^2}{\partial y^2}+\frac{\partial^2}{\partial z^2}\]</span></p></li><li><p>极坐标拉普拉斯算子 <span class="math display">\[\Delta=\frac 1 r\frac{\partial}{\partial r}\left(r\frac{\partial}{\partial r}\right)+\frac{1}{r^2}\frac{\partial^2}{\partial \theta^2}\]</span></p></li><li><p>柱坐标拉普拉斯算子 <span class="math display">\[\Delta=\frac 1 r\frac{\partial}{\partial r}\left(r\frac{\partial}{\partial r}\right)+\frac{1}{r^2}\frac{\partial^2}{\partial \varphi^2}+\frac{\partial^2}{\partial z^2}\]</span></p></li><li><p>球坐标拉普拉斯算子 <span class="math display">\[\Delta=\frac 1 {r^2}\frac{\partial}{\partial r}\left(r^2\frac{\partial}{\partial r}\right)+\frac{1}{r^2\sin\theta}\frac{\partial}{\partial \theta}\left(\sin\theta\frac{\partial}{\partial \theta}\right)+\frac{1}{r^2\sin^2\theta}\frac{\partial^2}{\partial \varphi^2}\]</span></p></li></ul><h3 id="亥姆霍兹方程">3.2 亥姆霍兹方程</h3><p><span class="math display">\[\Delta v+k^2v=0\]</span></p><p>波动方程 <span class="math inline">\(u_{tt}-a^2\Delta u=0\)</span> 或者输运方程 <span class="math inline">\(u_t-a^2\Delta u=0\)</span> 分离时间和空间变量 (令 <span class="math inline">\(u(\vec r,t)=T(t)R(\vec r)\)</span>)后将得到亥姆霍兹方程。</p><h4 id="柱坐标系-1">（1）柱坐标系</h4><p>$$ \begin{aligned} &amp;v+k^2 v=0\ &amp;v_{rr}+v_r+v_{}+v_{zz}+k^2 v=0\</p><p>\end{aligned} $$</p><p>设 <span class="math inline">\(v(r,\varphi,z)\triangleq R(r)\Phi(\varphi)Z(z)\)</span></p><p>先分离 <span class="math inline">\(\Phi\)</span> : <span class="math display">\[\frac{r^2 R&#39;&#39;Z+r R&#39;Z+r^2Z&#39;&#39;+k^2r^2 R Z}{RZ}=-\frac{\Phi&#39;&#39;}{\Phi}\triangleq\lambda\notag\]</span></p><p><span class="math inline">\(\implies\)</span> $ =m^2 $ , <span class="math inline">\(\Phi(\varphi)=A\cos m\varphi+\sin m\varphi\)</span></p><p>再分离 <span class="math inline">\(Z\)</span> ： <span class="math display">\[\frac{r^2 R&#39;&#39;+r R&#39;+(k^2r^2-m^2) R}{r^2 R}=-\frac{Z&#39;&#39;}{Z}\triangleq\nu^2\notag\]</span></p><p>=&gt; <span class="math display">\[\notag Z’’+\nu^2Z=0,\\R&#39;&#39;+\frac{1}{r}R&#39;+(\mu&#39;-\frac{m^2}{r^2})R=0,\qquad \mu&#39;\equiv k^2-\nu^2\]</span> 令 <span class="math inline">\(x=\sqrt {\mu’}r\)</span>， 得： <span class="math display">\[\frac{d^2R}{dx^2}+\frac{1}{x}\frac{dR}{dx}+(1-\frac{m^2}{x^2})R=0\]</span></p><p><span class="math inline">\(m\)</span> 阶贝塞尔方程。</p><h4 id="球坐标系-1">（2）球坐标系</h4><p><span class="math display">\[\frac{1}{r^2}\frac{\partial }{\partial r}(r^2\frac{\partial v}{\partial r})+\frac{1}{r^2 \sin \theta}\frac{\partial }{\partial\theta}(\sin\theta\frac{\partial v}{\partial\theta})+\frac{1}{r^2\sin^2\theta}\frac{\partial^2 v}{\partial\varphi^2}+k^2 v=0\notag\]</span></p><p>设 $v=R(r)Y(,) $ =&gt; <span class="math display">\[\frac{1}{R}\frac{\partial }{\partial r}(r^2\frac{\partial R}{\partial r})+k^2 r^2 =-\bigg[\frac{1}{Y\sin \theta}\frac{\partial }{\partial\theta}(\sin\theta\frac{\partial Y}{\partial\theta})+\frac{1}{Y\sin^2\theta}\frac{\partial^2 Y}{\partial\varphi^2}\bigg]\triangleq l(l+1)\notag\]</span> 得到： <span class="math display">\[\frac{1}{\sin \theta}\frac{d}{d\theta}(\sin\theta\frac{d Y}{d\theta})+\frac{1}{\sin^2\theta}\frac{d^2 Y}{d\varphi^2}+l(l+1)Y=0\\\frac{d}{d r}(r^2\frac{d R}{d r})+\big[k^2 r^2-l(l+1)\big]R=0\notag\]</span></p><p>分别是球函数方程（可进一步分离成连带勒让德方程）和 <span class="math inline">\(l\)</span> 阶球贝塞尔方程。</p><h3 id="矢量波动方程">3.3 矢量波动方程</h3><p><span class="math display">\[\Delta \vec E +k^2 \vec E=0\]</span></p><p>关键：<span class="math inline">\(\vec E=E_r \vec e_r+E_\theta\vec e_\theta+E_z\vec e_z\)</span></p><p>​ <span class="math inline">\(\vec E=E_r \vec e_r+E_\theta\vec e_\theta+E_\varphi\vec e_\varphi\)</span></p><p><img src="https://tva1.sinaimg.cn/large/0082zybply1gc3upwrq71j30u0107tdb.jpg" style="zoom: 50%;" /></p><p><img src="https://tva1.sinaimg.cn/large/0082zybply1gc3uqaat5qj30u012mtd1.jpg" style="zoom: 50%;" /></p><p><img src="https://tva1.sinaimg.cn/large/0082zybply1gc3uqk4nxjj30u00xmq6w.jpg" style="zoom: 50%;" /></p><p><img src="https://tva1.sinaimg.cn/large/0082zybply1gc3ur101aij30xx0u0n16.jpg" style="zoom: 50%;" /></p><h2 id="四-级数解法和本征值问题">四 级数解法和本征值问题</h2><h3 id="常点邻域的级数解法">4.1 常点邻域的级数解法</h3><p>可获得勒让德方程的级数解。</p><p>线性二阶常微分方程： <span class="math display">\[w&#39;&#39;+p(z)w&#39;+q(z)w=0\\w(z_0)=C_0,\ w&#39;(z_0)=C_1\]</span> 其中 <span class="math inline">\(p(z),\ q(z)\)</span> 为点 <span class="math inline">\(z_0\)</span> 的邻域 <span class="math inline">\(|z-z_0|&lt;R\)</span> 上的解析函数。</p><p>令 <span class="math inline">\(w(z)=\displaystyle \sum\limits_{k=0}^\infty a_k(z-z_0)^k\)</span>， 代入方程合并同幂项，对应系数分别为零。</p><h4 id="求解勒让德方程">求解勒让德方程</h4><p>在 <span class="math inline">\(x_0=0\)</span> 的邻域上求解 <span class="math inline">\(l\)</span> 阶勒让德方程 <span class="math display">\[(1-x^2)y&#39;&#39;-2xy&#39;+l(l+1)y=0\notag\]</span> 设 <span class="math inline">\(y=\sum\limits_{n=0}^\infty a_n x^n\)</span> =&gt; <span class="math display">\[a_{k+2}=\frac{(k-l)(k+l+1)}{(k+2)(k+1)}a_k\notag\]</span> =&gt; <span class="math display">\[y=a_0y_0 (x)+a_1 y_1(x)\notag\]</span></p><h3 id="正则奇点邻域的级数解法">4.2 正则奇点邻域的级数解法</h3><p>正则奇点：在方程 <span class="math inline">\((18)\)</span> 的奇点邻域上，两个线性无关解全都有有限个负幂项。</p><p>如： <span class="math inline">\(p(z)\)</span> 以 <span class="math inline">\(z_0\)</span> 为不高于一阶的极点，且 <span class="math inline">\(q(z)\)</span> 以 <span class="math inline">\(z_0\)</span> 为不高于二阶的极点。 <span class="math display">\[i.e.\qquad p(z)=\sum\limits_{k=-1}^\infty p_k(z-z_0)^k ,\ q(z)=\sum\limits_{k=-2}^\infty q_k(z-z_0)^k \notag\]</span></p><h4 id="基本求解步骤">（1）基本求解步骤</h4><ol type="1"><li><p>设 <span class="math inline">\(y=\displaystyle\sum_{n=0}^\infty a_n(z-z_0)^{s+n}\)</span></p></li><li><p>求出 <span class="math inline">\(s_1,\ s_2\)</span></p></li><li><p>若 <span class="math inline">\(s_1-s_2\neq 整数\)</span>， 则 <span class="math inline">\(y(z)=c_1y_1(z)+c_2y_2(z)\)</span></p></li><li><p>若 <span class="math inline">\(s_1-s_2=整数\)</span>， 则两解线性相关，求出一解 <span class="math inline">\(y_1\)</span> ，需另设: <span class="math display">\[y_2(z)=Ay_1(z)\ln (z-z_0)+\sum_{n=0}^\infty b_n (z-z_0)^{s_2+k}\]</span> <span class="math inline">\(y(z)=c_1y_1(z)+c_2y_2(z)\)</span>.</p></li></ol><h4 id="求解-阶贝塞尔方程">（2）求解 $ $ 阶贝塞尔方程</h4><p><span class="math display">\[x^2 y&#39;&#39;+xy&#39;+(x^2-\nu^2)y=0\notag\]</span></p><p>其中 <span class="math inline">\(\nu\)</span> 不为整数或半奇数。</p><p>设 <span class="math inline">\(y=\displaystyle\sum\limits_{n=0}^\infty a_n x^{s+n}, a_0\neq 0\)</span> , 带入： <span class="math display">\[x^2 y&#39;&#39;=\sum_{i=0}^\infty (s+i)(s+i-1)a_i x^{i+s},\quad xy&#39;=\sum_{i=0}^\infty (s+i)a_i x^{i+s}\\x^2 y=\sum_{i=2}^\infty a_{i-2}x^{i+s},\quad -\nu^2y=\nu^2 \sum_{i=0}^\infty a_i x^{i+s}\notag\]</span> 合并同幂项： <span class="math display">\[\begin{aligned}&amp;[s^2-\nu^2]a_0=0 ,\\ &amp;[(s+1)^2-\nu^2]a_1=0\\ &amp;[(s+k)^2-\nu^2]a_k+a_{k-2}=0\end{aligned}\]</span></p><p><span class="math display">\[\implies \quad s_1=\nu,\ s_2=-\nu ,\ a_1=0,\\a_k=\frac{-1}{(s+k)^2-\nu^2}a_{k-2}\notag\]</span></p><p>取 <span class="math inline">\(s=s_1\)</span> : <span class="math display">\[y_1=a_0x^\nu\bigg[1-\frac{1}{1!(\nu+1)}\big(\frac{x}{2}\big)^2+\cdots+(-1)^k\frac{1}{k!(\nu+1)(\nu+2)\cdots(\nu+k)}\big(\frac{x}{2}\big)^{2k}+\cdots\bigg]\notag\]</span> 收敛半径 : <span class="math display">\[R^2=\lim_{k\to\infty}\frac{a_{k-2}}{a_k}=\lim_{k\to\infty}k(2\nu+k)=\infty.\notag\]</span></p><p>通常取 <span class="math display">\[a_0=\frac{1}{2}\Gamma(\nu+1)\notag\]</span> 代入得到 <span class="math inline">\(\nu\)</span> 阶 <strong>贝塞尔函数</strong> ： <span class="math display">\[J_\nu(x)=\sum_{k=0}^\infty (-1)^k\frac{1}{k!\Gamma(\nu+k+1)}\big(\frac{x}{2}\big)^{\nu+2k}\]</span> 取 <span class="math inline">\(s=s_2\)</span> :</p><p>得到 <span class="math inline">\(-\nu\)</span> 阶 贝塞尔函数： <span class="math display">\[J_{-\nu}(x)=\sum_{k=0}^\infty (-1)^k\frac{1}{k!\Gamma(-\nu+k+1)}\big(\frac{x}{2}\big)^{-\nu+2k}\]</span></p><p><span class="math inline">\(\nu\)</span> 阶贝塞尔方程的通解为： <span class="math display">\[y(x)=C_1J_\nu(x)+C_2J_{-\nu}(x)\]</span></p><p>取 <span class="math inline">\(C_1=\cot \nu\pi,\ C_2=-\csc\nu\pi\)</span> 代入得到一个特解 <span class="math inline">\(\nu\)</span> 阶<strong>诺伊曼函数</strong>，以此作为 <span class="math inline">\(\nu\)</span> 阶贝塞尔方程的第二个线性独立的解： <span class="math display">\[N_\nu(x)=\frac{J_v(x)\cos\nu\pi-J_{-\nu}(x)}{\sin\nu\pi}\]</span></p><h4 id="求解半奇数阶贝塞尔方程">（3）求解半奇数阶贝塞尔方程</h4><p><span class="math display">\[x^2 y&#39;&#39;+xy&#39;+[x^2-(l+\frac{1}{2})^2]y=0\notag\]</span></p><p><span class="math inline">\(x_0=0\)</span> 为方程的正则奇点。</p><p><span class="math inline">\(l=0\)</span> 时： <span class="math display">\[\begin{aligned}y_1(x)=J_{\frac{1}{2}}(x)&amp;=\sum_{k=0}^\infty(-1)^k \frac{1}{k!\Gamma(k+\frac{3}{2})}\big(\frac{x}{2}\big)^{2k+\frac{1}{2}}\\&amp;=\sum_{k=0}^\infty\frac{(-1)^k}{k!(k+\frac{1}{2})\cdots \frac{1}{2}\Gamma(\frac{1}{2})}\big(\frac{x}{2}\big)^{2k+\frac{1}{2}}\\&amp;=\sum_{k=0}^\infty\frac{(-1)^k}{k!(k+\frac{1}{2})\cdots \frac{1}{2}\sqrt \pi\cdot 2^{k+1}\cdot2^k}x^{2k+\frac{1}{2}}\cdot(\frac{1}{2})^{-\frac{1}{2}}\\&amp;=\sqrt{\frac{2x}{\pi}}\sum_{k=0}^\infty(-1)^k\frac{x^{2k}}{(2k+1)!}\\&amp;=\sqrt{\frac{2}{\pi x}}\sin x.\end{aligned}\]</span> （同理可得：<span class="math inline">\(\displaystyle J_{-\frac{1}{2}}=\sqrt{\frac{2}{\pi x}}\cos x\)</span> )</p><p>由于 <span class="math inline">\(s_1-s_2=整数\)</span>，设： <span class="math display">\[y_2(x)=AJ_{\frac{1}{2}}(x)\ln x+\sum_{k=-1/2}^\infty b_k x^k\notag\]</span> 仔细代入贝塞尔方程，得到： <span class="math display">\[\begin{aligned}&amp;A\bigg[x^2J_{\frac{1}{2}}&#39;&#39;(x)+xJ_{\frac{1}{2}}&#39;(x)+\big(x^2-\frac{1}{4}\big)J_{\frac{1}{2}}(x)\bigg]\ln x+\\&amp;2AxJ_{\frac{1}{2}}&#39;(x)+\sum_{k=1/2}^\infty k(k-1)b_k x^k+\sum_{k=1/2}^\infty k b_k x^k+\sum_{k=1/2}^\infty b_k x^{k+2}-\sum_{k=1/2}^\infty \frac{1}{4}b_k x^k=0\end{aligned}\]</span> 由于 <span class="math inline">\(J_{\frac{1}{2}}(x)\)</span> 是 <span class="math inline">\(1/2\)</span> 阶贝塞尔方程的解，<span class="math inline">\([\quad \cdot\quad ]\)</span> 里的东西为 <span class="math inline">\(0\)</span> .</p><p>对剩下的合并同幂次项，最后可得：<span class="math inline">\(A=0\)</span>.</p><p>进而可以解得： <span class="math display">\[y(x)=C_1J_{\frac{1}{2}}(x)+C_2J_{-\frac{1}{2}}(x)\notag\]</span> 同样的过程可求得 <span class="math inline">\(\displaystyle l+\frac{1}{2}\)</span> 阶贝塞尔函数的解： <span class="math display">\[y(x)=C_1J_{l+\frac{1}{2}}(x)+C_2J_{-l+\frac{1}{2}}(x)\]</span></p><h4 id="整数-m-阶贝塞尔方程">（4）整数 <span class="math inline">\(m\)</span> 阶贝塞尔方程</h4><p>通解为： <span class="math display">\[y(x)=C_1 J_m(x)+C_2 N_m (x)\]</span></p><p>诺伊曼函数的边界性质： <span class="math display">\[\lim_{x\to 0}N_\nu (x)=\pm \infty,\ \lim_{x\to 0}N_m(x)=-\infty\]</span></p><h4 id="nu-阶虚宗量贝塞尔方程">（5）<span class="math inline">\(\nu\)</span> 阶虚宗量贝塞尔方程</h4><p>可作变换 <span class="math inline">\(\xi=ix\)</span>, 进而求解.</p><p>记 <span class="math display">\[\begin{aligned}&amp;I_v(x)=i^{-\nu}J_\nu (ix)=\sum_{k=0}^\infty\frac{1}{k!\Gamma(\nu+k+1)}\big(\frac{x}{2}\big)^{\nu+2k}\\&amp;I_{-v}(x)=i^{\nu}J_{-\nu} (ix)=\sum_{k=0}^\infty\frac{1}{k!\Gamma(-\nu+k+1)}\big(\frac{x}{2}\big)^{-\nu+2k}\end{aligned}\]</span> <span class="math inline">\(\nu\)</span> 阶虚宗量贝塞尔方程的一般解为： <span class="math display">\[y(x)=C_1I_{\nu}(x)+C_2I_{-\nu}(x).\]</span></p><h5 id="整数-m-阶虚宗量贝塞尔方程">整数 <span class="math inline">\(m\)</span> 阶虚宗量贝塞尔方程</h5><p>整数 <span class="math inline">\(m\)</span> 阶虚宗量贝塞尔方程的一般解：将来学完整理。</p><h3 id="s-l本征值问题">4.3 S-L本征值问题</h3><h4 id="s-l-型方程">（1）S-L 型方程</h4><p><span class="math display">\[\frac{d}{dx}\bigg[k(x)\frac{dy}{dx}\bigg]-q(x)y+\lambda\rho (x)y=0,\quad a\leq x\leq b\]</span></p><h4 id="一般二阶-ode-转化为-s-l-型方程">（2）一般二阶 ODE 转化为 S-L 型方程</h4><p><span class="math display">\[y&#39;&#39;+a(x)y&#39;+b(x)y+\lambda c(x)y=0\notag\]</span> 两边同时乘 <span class="math inline">\(e^{\int a(x)dx}\)</span> : <span class="math display">\[\frac{d}{dx}\bigg[e^{\int a(x)dx}\frac{dy}{dx} \bigg]+b(x)e^{\int a(x)dx}y+\lambda c(x)e^{\int a(x)dx}y=0\]</span></p><p><span class="math display">\[\therefore k(x)=e^{\int a(x)dx},\ q(x)=-b(x)e^{\int a(x)dx},\ \rho(x)=c(x)e^{\int a(x)dx}\]</span></p><h4 id="s-l本征值问题的共同性质">（3）S-L​本征值问题的共同性质</h4><ul><li><p>若 <span class="math inline">\(k(x),k’(x)\)</span> 连续，<span class="math inline">\(q(x)\)</span> 连续或最多以 <span class="math inline">\(x=a\)</span> 或 <span class="math inline">\(x=b\)</span> 为一阶极点，则存在无限多个本征值，相应地有无限多个本征函数。本征函数族是完备的。</p></li><li><p>所有本征值 <span class="math inline">\(\lambda_n\geq 0\)</span></p><p>证明：</p><p>本征值和相应地本征函数满足： <span class="math display">\[-\frac{d}{dx}\bigg[k(x)\frac{dy_n}{dx}\bigg]+q(x)y_n=\lambda_n\rho (x)y_n\notag\]</span> <strong>用 <span class="math inline">\(y_n\)</span> 遍乘各项</strong>，并<strong>逐项从 <span class="math inline">\(a\)</span> 到 <span class="math inline">\(b\)</span> 积分</strong>，得： <span class="math display">\[\begin{aligned}\lambda_n \int_a^b \rho(x)y_n^2&amp;=-\int_a^by_n (x)\frac{d}{dx}\bigg[k(x)\frac{dy_n}{dx}\bigg]dx+\int_a^b q(x)y_n^2(x)dx\\&amp;=(ky_ny_n&#39;)\bigg|_{x=a}-(ky_ny_n&#39;)\bigg|_{x=b}+\int_a^bqy_n^2dx\\\end{aligned}\]</span> 在前三类边界条件 <span class="math display">\[y_n(a)=y_n(b)=0,\quad or \quad y&#39;_n(a)=y&#39;_n(b)=0\\or\quad (y_n-hy&#39;_n)\bigg|_{x=a}=(y_n+hy&#39;_n)\bigg|_{x=b}=0\notag\]</span> 的情况下，右边 <span class="math inline">\(\geq0\)</span>, 故 <span class="math inline">\(\lambda_n\geq0\)</span>.</p></li><li><p>相应于不同本征值 <span class="math inline">\(\lambda_n\)</span> 和 <span class="math inline">\(\lambda_m\)</span> 的本征函数 <span class="math inline">\(y_n(x)\)</span> 和 <span class="math inline">\(y_m(x)\)</span> 在区间 <span class="math inline">\([a,b]\)</span> 带权重 <span class="math inline">\(\rho(x)\)</span> 正交。</p></li></ul><p><span class="math display">\[i.e\quad \int_a^b y_m(x)y_n(x)\rho(x)dx=0\quad (n\neq m)\]</span></p><p>​ 证明：</p><p>​ <span class="math inline">\(y_n,y_m\)</span> 分别满足： <span class="math display">\[\begin{aligned}&amp;\frac{d}{dx}\big(ky&#39;_n\big)-qy_n+\lambda_n\rho y_n=0&amp; (*)\\&amp;\frac{d}{dx}\big(ky&#39;_m\big)-qy_m+\lambda_m\rho y_m=0&amp; (**)\\\end{aligned}\]</span> ​ <span class="math inline">\(\implies\displaystyle \int_a^b\big[(*)\cdot y_m-(**)\cdot y_n\big]dx\)</span> : <span class="math display">\[\begin{aligned}\quad \quad 0&amp;=\int_a^b\bigg[y_m d(ky_n&#39;)-y_nd(ky_m&#39;)\bigg]+(\lambda_n-\lambda_m)\int_a^b y_ny_m\rho dx\\&amp;=(ky_my_n&#39;)\bigg|_a^b-(ky_ny_m&#39;)\bigg|_a^b+\int_a^b \big[(ky_n&#39;y_m&#39;)-(ky_n&#39;y_m&#39;)\big]dx+(\lambda_n-\lambda_m)\int_a^b y_ny_m\rho dx\\&amp;=(\lambda_n-\lambda_m)\int_a^b y_ny_m\rho dx\end{aligned}\]</span> ​ 故 : <span class="math display">\[\int_a^b y_ny_m\rho dx=0\qquad (n\neq m)\notag\]</span></p><h2 id="五-球函数">五 球函数</h2><p>球坐标拉普拉斯方程 : <span class="math display">\[\frac{1}{r^2}\frac{\partial }{\partial r}(r^2\frac{\partial u}{\partial r})+\frac{1}{r^2 \sin \theta}\frac{\partial }{\partial\theta}(\sin\theta\frac{\partial u}{\partial\theta})+\frac{1}{r^2\sin^2\theta}\frac{\partial^2 u}{\partial\varphi^2}=0\notag\]</span> 分离变量可得： <span class="math display">\[R=Cr^l+\frac{D}{r^{l+1}}\\\frac{1}{\sin\theta}\frac{d}{d\theta}(\sin\theta\frac{dY}{d\theta})+\frac{1}{\sin^2\theta}\frac{d^2 Y}{d\varphi^2}+l(l+1)Y=0\notag\]</span></p><p>第二个方程为球函数方程，再次分离变量： <span class="math display">\[\begin{align}&amp;\Phi_m(\varphi)=A_m\cos m\varphi+B_m\sin m\varphi \notag \\&amp;(1-x^2)\frac{d^2 H}{dx^2}-2x\frac{d H}{dx}+\big[l(l+1)-\frac{m^2}{1-x^2}\big]H=0\qquad \label{associated-Legendre}\end{align}\]</span> 就得到了连带勒让德方程 <span class="math inline">\((\ref{associated-Legendre})\)</span>.</p><h3 id="轴对称球函数">5.1 轴对称球函数</h3><p><span class="math inline">\(m=0\)</span> 时的情况。</p><h4 id="勒让德多项式的表达式">（1）勒让德多项式的表达式</h4><p>勒让德方程若和边界条件构成定解问题，一般有自然边界条件（边界处有界），则方程须退化为多项式，此时 <span class="math inline">\(l\)</span> 为整数。将退化的多项式乘以适当的常数，得到 <span class="math inline">\(l\)</span> 阶勒让德多项式。因为 <span class="math inline">\(m=0\)</span> 时 <span class="math inline">\(\Phi(\varphi)\)</span> 为常数，轴对称球函数 <span class="math inline">\(Y\)</span> 简化为勒让德多项式 <span class="math inline">\(P_l(x)\)</span> 。 <span class="math display">\[a_l=\frac{(2l)!}{2^l (l!)^2}\\a_{k+2}=\frac{k(k+1)-l(l+1)}{(k+2)(k+1)}a_k=\frac{(k-l)(k+1-l)}{(k+2)(k+1)}a_k\notag\]</span> 勒让德多项式： <span class="math display">\[P_l(x)=\sum_{k=0}^{[l/2]}(-1)^k\frac{(2l-2k)!}{2^l k! (l-k)!(l-2k)!}x^{l-2k}\]</span></p><p>常用： <span class="math display">\[\begin{aligned}&amp; P_0(x)=1\\&amp;P_1(x)=x\\&amp;P_2(x)=\frac{1}{2}(3x^2-1)\\&amp;P_3(x)=\frac{1}{2}(5x^3-3x)\\&amp;P_4(x)=\frac{1}{8}(35x^4-30x^2+3)\\&amp;------------\\&amp;P_1^1(x)\\&amp;------------\\&amp;P_l(1)=1\\&amp;P_l(-1)=(-1)^l\\&amp; P_{2n}(0)=(-1)^{n}\frac{(2l-1)!!}{(2l)!!}\\&amp; P_{2n+1}(0)=0\end{aligned}\]</span></p><h4 id="勒让德函数的相关性质">（2）勒让德函数的相关性质</h4><ul><li><p>微分表示—罗德里格斯公式 <span class="math display">\[P_l(x)=\frac{1}{2^l l!}\frac{d^l}{dx^{l}}(x^2-1)^l\]</span></p></li><li><p>环路积分表示—施列夫利积分 <span class="math display">\[P_l(x)=\frac{1}{2\pi i}\frac{1}{2^l}\oint\frac{(z^2-1)^l}{(z-x)^{l+1}}dz\]</span></p></li><li><p>定积分表示—拉普拉斯积分 <span class="math display">\[\begin{aligned}take\quad z&amp;=x+\sqrt {x^2-1}e^{i\psi}\\\implies P_l(x)&amp;=\frac{1}{\pi}\int_{0}^{\pi}\big[x+i\sqrt{1-x^2}\cos \psi\big]^l d\psi\\&amp;=\frac{1}{\pi}\int_0^{\pi}\big[\cos \theta+i\sin \theta\cos \psi]^l d\psi\end{aligned}\]</span></p></li><li><p>模 <span class="math display">\[N_l=\sqrt{\frac{2}{2l+1}}\]</span></p><p>推导过程中用到不断地分部积分。</p></li><li><p>正交关系和广义傅里叶级数 <span class="math display">\[\begin{aligned}&amp;f(x)=\sum_{l=0}^\infty f_lP_l(x)\\&amp;f_l=\frac{2l+1}{2}\int_{-1}^{1}f(x)P_l(x)dx\\or: &amp;f_l=\frac{2l+1}{2}\int_{-\pi}^{\pi}f(\theta)P_l(\cos\theta)\sin\theta d\theta\end{aligned}\]</span></p></li><li><p>生成函数（母函数） <span class="math display">\[\frac{1}{\sqrt{1-2r\cos\theta+r^2}}=\begin{cases}\sum\limits_{l=0}^\infty r^l P_l(\cos\theta)\quad(r&lt;1)\\\sum\limits_{l=0}^\infty \frac{1}{r^{l+1}}P_l(\cos\theta)\quad(r&gt;1)\end{cases}\notag\]</span></p><p>一般情况： <span class="math display">\[\frac{1}{\sqrt{R^2-2Rr\cos\theta+r^2}}=\begin{cases}\sum\limits_{l=0}^\infty \frac{r^l}{R^{l+1}} P_l(\cos\theta)\quad (r&lt;R)\\\sum\limits_{l=0}^\infty \frac{R^l}{r^{l+1}}P_l(\cos\theta)\quad(r&gt;R)\end{cases}\]</span> 或： <span class="math display">\[\frac{1}{\sqrt{R^2-2Rrx+r^2}}=\begin{cases}\sum\limits_{l=0}^\infty \frac{r^l}{R^{l+1}} P_l(x)\quad (r&lt;R)\\\sum\limits_{l=0}^\infty \frac{R^l}{r^{l+1}}P_l(x)\quad(r&gt;R)\end{cases}\]</span></p></li><li><p>递推关系</p><p>生成函数两边对 <span class="math inline">\(r\)</span> 求导，比较 <span class="math inline">\(r^k\)</span> 系数，可得： <span class="math display">\[(k+1)P_{k+1}(x)=(2k+1)xP_k(x)-kP_{k-1}(x)\]</span></p></li></ul><p>​ 生成函数两边对 <span class="math inline">\(x\)</span> 求导，比较 <span class="math inline">\(r^k\)</span> 系数，可得： <span class="math display">\[P_k(x)=P&#39;_{k+1}(x)-2xP&#39;_k(x)+P&#39;_{k-1}(x)\notag\]</span></p><h4 id="勒让德方程的一般解">（3）勒让德方程的一般解</h4><ul><li><p>第二类勒让德函数</p></li><li><p>勒让德方程的一般解</p></li></ul><h4 id="拉普拉斯方程的轴对称定解问题">（4）拉普拉斯方程的轴对称定解问题</h4><ul><li>半球的稳定温度分布</li><li>均匀介质球的静电场分布</li></ul><h3 id="连带勒让德函数">5.2 连带勒让德函数</h3><ul><li><p>来源：连带勒让德方程 <span class="math display">\[(1-x^2)y&#39;&#39;-2xy&#39;+\left[l(l+1)-\frac {m^2} {1-x^2}\right]y=0\notag\]</span></p></li><li><p>表达式</p></li></ul><p><span class="math display">\[P_l^m(x)=(1-x^2)^{\frac{m}{2}}P_l^{[m]}(x)\]</span></p><ul><li><p>常见 <span class="math display">\[\begin{aligned}&amp;P_1^1(\cos\theta)=\sin\theta\\&amp;P_2^2(\cos\theta)=3\sin^2\theta\end{aligned}\]</span></p></li><li><p>微分表示—罗德里格斯公式 <span class="math display">\[P_l^m (x)=\frac{(1-x^2)^{\frac{m}{2}}}{2^l l!}\frac{d^{l+m}}{dx^{l+m}}(x^2-1)^l\]</span></p></li><li></li></ul><p><span class="math display">\[P_l^{m}(x)=(-1)^m\frac{(l+m)!}{(l-m)!}P_l^{-m}(x)\]</span></p><ul><li><p>环路积分表示—施列夫利积分</p></li><li><p>定积分表示—拉普拉斯积分</p></li><li><p>模 <span class="math display">\[N_l^m=\sqrt{\frac{(l+m)!}{(l-m)!}\frac{2}{2l+1}}\]</span></p></li><li><p>递推关系</p></li><li><p>正交关系和广义傅里叶级数 <span class="math display">\[\begin{aligned}&amp;f(x)=\sum_{l=m}^\infty  f_l P_l^m (x)\\&amp;f_l=\frac{(l-m)!}{(l+m)!}\frac {2l+1}{2}\int_{-1}^1 f(x)P_l^m (x)dx\end{aligned}\]</span></p></li></ul><h3 id="一般的球函数">5.3 一般的球函数</h3><h4 id="球函数方程">（1）球函数方程</h4><p>​ 拉普拉斯方程的角度部分。 <span class="math display">\[\frac{1}{\sin\theta}\frac{\partial}{\partial\theta}\left(\sin\theta\frac{\partial Y}{\partial\theta}\right)+\frac{1}{\sin^2\theta}\frac{\partial^2 Y}{\partial \varphi^2}+l(l+1)Y=0\]</span></p><h4 id="球函数基本性质">（2）球函数基本性质</h4><ul><li><p>球函数表达式 <span class="math display">\[Y(\theta,\varphi)=P_l^m(\cos \theta)\left\{\begin{aligned}\cos m\varphi\\\sin m\varphi\end{aligned}\right\}\]</span> 其中大括号表示任选其一， <span class="math inline">\(m=0,\dots,l;\quad l=0,1,2,\dots\)</span></p><p>复数形式 <span class="math display">\[Y(\theta,\varphi)=P_l^{|m|}(\cos \theta)e^{im\varphi}\notag\]</span> 其中 <span class="math inline">\(m=-l,\dots,l;\quad l=0,1,2,\dots 。\)</span></p></li><li><p>球函数的模 <span class="math display">\[N_l^m=\sqrt{\frac{2\pi\delta_m }{2l+1}\frac{(l+m)!}{(l-m)!}}\]</span></p><p>其中，<span class="math inline">\(\delta_m=\begin{cases}2,m=0\\1,m\neq0\end{cases}\)</span> .</p><p>复数形式的模： <span class="math display">\[N_l^m=\sqrt{\frac{4\pi }{2l+1}\frac{(l+|m|)!}{(l-|m|)!}}\notag\]</span></p></li><li><p>球函数正交关系与球面上函数的广义傅里叶级数 <span class="math display">\[\begin{aligned}&amp; f(\theta,\varphi)=\sum_{l=m}^\infty\sum_{m=0}^\infty \left[A_l^m\cos m\varphi+B_l^m\sin m\varphi\right]P_l^m(\cos \theta)\\&amp; A_l^m = \frac{2l+1}{2\pi\delta_m}\frac{(l-m)!}{(l+m)!}\int_0^{\pi}\int_0 ^{2\pi} f(\theta,\varphi)P_l^m(\cos \theta)\cos m\varphi \sin\theta \ d\theta d\varphi\\&amp; B_l^m = \frac{2l+1}{2\pi}\frac{(l-m)!}{(l+m)!}\int_0^{\pi}\int_0 ^{2\pi} f(\theta,\varphi)P_l^m(\cos \theta)\sin m\varphi \sin\theta \ d\theta d\varphi\end{aligned}\]</span> 对简单函数的展开方法：</p><p>​ 首先按照 <span class="math inline">\(m\)</span> 分类对 <span class="math inline">\(\varphi\)</span> 展开，然后对每一项前面的系数 <span class="math inline">\(f(\theta)\)</span> 用 <span class="math inline">\(P_l^m\)</span> （这时 <span class="math inline">\(m\)</span> 已经是确定的数）展开。</p></li><li><p>正交归一化的球函数</p><p>​ 物理常用，这个以及球函数的复数形式、加法公式等考完试再用到时专门整理。</p></li></ul><h4 id="球函数的应用">（3）球函数的应用</h4><p><strong>拉普拉斯方程的非轴对称定解问题</strong></p><p>​ 拉普拉斯方程在非轴对称情况下的一般解为: <span class="math display">\[\begin{align}u(r,\theta,\varphi)=\sum_{l=m}^\infty &amp;\sum_{m=0}^\infty  r^l \left[A_l^m\cos m\varphi+B_l^m\sin m\varphi\right]P_l^m(\cos \theta)+\notag\\ &amp;\sum_{l=m}^\infty\sum_{m=0}^\infty\frac 1 {r^{l+1}} \left[C_l^m\cos m\varphi+D_l^m\sin m\varphi\right]P_l^m(\cos \theta)\end{align}\]</span></p><h2 id="六-柱函数">六 柱函数</h2><h3 id="柱函数的导出">6.1 柱函数的导出</h3><h4 id="柱坐标拉普拉斯方程">柱坐标拉普拉斯方程</h4><p><span class="math display">\[\begin{aligned}&amp;\Delta u=0\\\\\implies&amp; \begin{cases}\Phi&#39;&#39;+m^2\Phi=0,\\Z&#39;&#39;-\mu Z=0,\\\rho^2 R&#39;&#39;+\rho R+(\mu\rho^2-m^2)R=0\end{cases}\end{aligned}\\\]</span></p>$$ \begin{aligned} &amp;=0: u={<span class="math display">\[\begin{aligned}1\\z\end{aligned}\]</span>}{\begin{aligned}&amp;1\ &amp;\end{aligned}}+{<span class="math display">\[\begin{aligned}1\\z\end{aligned}\]</span>}{<span class="math display">\[\begin{aligned}\cos m\varphi\\ \sin m\varphi \end{aligned}\]</span><p>}{\begin{aligned}&amp;^m\ &amp;1/^{m}\end{aligned}}</p>\ \ &amp;&gt;0: u={<span class="math display">\[\begin{aligned}e^{\sqrt\mu z}\\e^{-\sqrt\mu z}\end{aligned}\]</span>}{<span class="math display">\[\begin{aligned}\cos m\varphi\\ \sin m\varphi \end{aligned}\]</span>}{\begin{aligned}J_m()\N_m()\\end{aligned}}\ \ &amp;&lt;0: 虚宗量 \ &amp;u={<span class="math display">\[\begin{aligned}\cos\sqrt{-\mu} z\\\sin\sqrt{-\mu} z\end{aligned}\]</span>}{<span class="math display">\[\begin{aligned}\cos m\varphi\\ \sin m\varphi \end{aligned}\]</span><p>}{\begin{aligned}J_m( )\N_m( )\\end{aligned}}\</p><p>\end{aligned} $$</p><h4 id="球坐标亥姆霍兹方程">球坐标亥姆霍兹方程</h4><p>球贝塞尔方程。</p><h4 id="柱坐标亥姆霍兹方程">柱坐标亥姆霍兹方程</h4><p><span class="math display">\[\begin{aligned}&amp;\Delta v+k^2v=0\\\\\implies&amp; \begin{cases}\Phi&#39;&#39;+m^2\Phi=0,\\Z&#39;&#39;+\nu^2 Z=0,\\\displaystyle R&#39;&#39;+\frac{1}{\rho} R+(k^2-\nu^2-\frac{m^2}{\rho^2})R=0\end{cases}\end{aligned}\\\]</span></p><p>注意， <span class="math inline">\(z\)</span> 轴的齐次边界条件保证了 <span class="math inline">\(\nu^2\)</span> 一定是大于 <span class="math inline">\(0\)</span> 的，否则 <span class="math inline">\(Z\)</span> 为 <span class="math inline">\(e\)</span> 指数形式，不可能为 <span class="math inline">\(0\)</span> .</p><p>令 <span class="math inline">\(\mu’\equiv k^2-\nu^2\)</span>, 则 <span class="math inline">\(\rho\)</span> 方向的齐次边界条件保证了 <span class="math inline">\(\mu’\)</span> 是大于等于 <span class="math inline">\(0\)</span> 的（贝塞尔函数的正零点）.</p><p>另外，<span class="math inline">\(\mu’\)</span> 作为贝塞尔函数的零点可以得到具体值， <span class="math inline">\(\nu\)</span> 作为 <span class="math inline">\(Z\)</span> 的本征值可以由边界条件确定。</p><p>而 <span class="math inline">\(k^2\)</span> 是最先设的本征值，可由 <span class="math inline">\(k^2=\mu’+\nu^2\)</span> 得到。</p><p><span class="math display">\[\begin{aligned}&amp;\mu&#39;=0 : u=\left\{\begin{aligned}\cos\nu z\\ \sin\nu z\end{aligned}\right\}\left\{\begin{aligned}1\\ \ln\rho\end{aligned}\right\}+\left\{\begin{aligned}\cos\nu z\\ \sin\nu z\end{aligned}\right\}\left\{\begin{aligned}\cos m\varphi\\ \sin m\varphi\end{aligned}\right\}\left\{\begin{aligned}\rho^m \\ \rho^{-m}\end{aligned}\right\}\\\\&amp;\mu&#39;\neq 0:u=\left\{\begin{aligned}\cos\nu z\\ \sin\nu z\end{aligned}\right\}\left\{\begin{aligned}\cos m\varphi\\ \sin m\varphi\end{aligned}\right\}\left\{\begin{aligned}J_m(\sqrt{\mu&#39;}\rho)\\N_m(\sqrt{\mu&#39;}\rho) \end{aligned}\right\}\\&amp;(if\quad \nu=0,\quad then\quad Z=\left\{\begin{aligned}1\\ z\end{aligned}\right\})\end{aligned}\]</span></p><h3 id="柱函数的性质">6.2 柱函数的性质</h3><h4 id="贝塞尔函数">(1) 贝塞尔函数</h4><ul><li><p>公式</p><p><span class="math display">\[J_\nu(x)=\sum_{k=0}^\infty \frac{(-1)^k}{k!\Gamma(\nu+k+1)}\left(\frac x 2 \right)^{2k+\nu}\]</span></p></li><li><p>递推关系 <span class="math display">\[\begin{aligned}&amp;\frac{d}{dx}\left[x^\nu Z_\nu(x)\right]=x^{\nu}Z_{\nu-1}(x)\\&amp;\frac{d}{dx}\left[\frac{Z_\nu(x)}{x^\nu} \right]=-\frac{Z_{\nu}(x)}{x^{\nu+1}}\\&amp;-------------\\(展开)\quad &amp; Z_\nu&#39;(x) +\frac{\nu}{x}Z_\nu(x)=Z_{\nu-1}(x)\\&amp;Z_\nu&#39;(x) -\frac{\nu}{x}Z_\nu(x)=-Z_{\nu+1}(x)\\&amp;-------------\\&amp;Z&#39;_\nu(x)=\frac{1}{2}\left[Z_{\nu+1}(x)-Z_{\nu-1}(x)\right]\\&amp; Z_{\nu+1}(x)-2\frac{\nu}{x}Z_\nu(x)+Z_{\nu-1}(x)=0\end{aligned}\]</span></p></li><li><p>生成函数 <span class="math display">\[\begin{aligned}&amp; e^{\frac 1 2 x(z-\frac 1 z)}=\sum_{m=-\infty}^\infty J_m(x)z^m\\take \ z=e^{i\theta}:\quad &amp;e^{ix\sin\theta}=\sum_{m=-\infty}^\infty J_m(x) e^{im\theta}\end{aligned}\]</span></p></li></ul><p>​ 求 <span class="math inline">\(m\)</span> 次导数，然后令 <span class="math inline">\(z=0\)</span> : <span class="math display">\[J_m(x)=\frac{1}{2\pi i}\oint \frac{e^{\frac x 2 (z-\frac 1 z )}}{z^{m+1}}dz\notag\]</span></p><ul><li><p>渐近表示 <span class="math display">\[\lim_{x\to \infty}J_\nu(x)\approx\sqrt{\frac{2}{\pi x}}\cos(x-\frac{\pi}{4}-\frac{\nu}{2}\pi)\]</span></p></li><li><p>常用 <span class="math display">\[\begin{aligned}&amp; J&#39;_0(x)=-J_1(x)\\&amp; J_0(0)=1\\&amp; J_\nu(0)=0\quad (\nu\neq0)\end{aligned}\]</span></p></li><li><p>物理意义 <span class="math display">\[J_m(\sqrt{\mu&#39;}\rho)e^{-ikat}\notag\]</span> 在 <span class="math inline">\(\rho\)</span> 很大时对应驻波。</p></li><li><p>模</p></li><li><p>正交性</p></li></ul><h4 id="诺伊曼函数">(2) 诺伊曼函数</h4><ul><li><p>公式 <span class="math display">\[N_\nu(x)=\frac{J_\nu (x)\cos \nu\pi-J_{-\nu}(x)}{\sin \nu\pi}\]</span></p></li><li><p>渐近表示 <span class="math display">\[\begin{aligned}&amp;\lim_{x\to 0}N_\nu (x)\to \pm\infty \\&amp;\lim_{x\to \infty}N_\nu(x)\approx\sqrt{\frac{2}{\pi x}}\sin(x-\frac{\pi}{4}-\frac{\nu}{2}\pi)\end{aligned}\]</span></p></li><li><p>物理意义 <span class="math display">\[  N_m(\sqrt{\mu&#39;}\rho)e^{-ikat}\notag\]</span> 在 <span class="math inline">\(\rho\)</span> 很大时对应驻波。</p></li></ul><h4 id="汉克尔函数">(3) 汉克尔函数</h4><ul><li>公式 $$ \begin{aligned} &amp;H<sup>{(1)}<em>{} (x)=J</em>(x)+iN_{}(x)\ &amp;H</sup>{(2)}<em>{}(x)=J</em>(x)-iN_(x)</li></ul><p>\end{aligned} $$</p><ul><li>渐近表示</li></ul><p><span class="math display">\[H^{(1,2)}_\nu (x)\approx \sqrt{\frac{2}{\pi x}}e^{\pm i (x-\frac{\pi}{4}-\frac{\nu}{2}\pi)}\notag\]</span></p><ul><li><p>重要物理意义 $$ \begin{aligned} &amp;H_m<sup>{(1)}()e</sup>{-ikat}e<sup>{ i(-kat-m/2-/4)}\ &amp;H_m</sup>{2}()e<sup>{-ikat}e</sup>{- i(+kat-m/2-/4)}</p><p>\end{aligned} $$ 分别表示发散波（<span class="math inline">\(t\)</span> 增大，若要收敛则 <span class="math inline">\(\rho\)</span> 也增大）和会聚波。</p></li><li><p>做题常用渐进表示（待研究） <span class="math display">\[1+i\frac 2 \pi \ln \frac{\omega\rho}{2a}+iC\]</span></p></li></ul><h4 id="虚宗量贝塞尔函数">(4) 虚宗量贝塞尔函数</h4><h4 id="球贝塞尔函数">(5) 球贝塞尔函数</h4><h3 id="柱函数的应用">6.3 柱函数的应用</h3><h2 id="七-格林函数法">七 格林函数法</h2><h2 id="八-积分变换法">八 积分变换法</h2><h3 id="傅立叶变换">8.1 傅立叶变换</h3><h4 id="定义">（1）定义</h4><p><span class="math display">\[\begin{align}F(\omega)&amp;=\int_{-\infty}^\infty f(x)e^{-i\omega x} dx\\f(x)&amp;=\frac 1 {2\pi}\int_{-\infty}^\infty F(\omega)e^{i\omega x}d\omega\end{align}\]</span></p><p>条件：有限个间断点+绝对可积</p><p>表示：为了方便，通常用大写表示变换后的，有时也用冒尖表示，<span class="math inline">\(\omega\)</span> 有时换成 <span class="math inline">\(k\)</span> 或 <span class="math inline">\(\lambda\)</span> , 即 <span class="math inline">\(u(\vec r)\to U(\vec k),F(\omega),\hat f(k),\hat f(\lambda)\)</span> 等等</p><h4 id="重要性质">（2）重要性质</h4><ul><li><p>伸缩 <span class="math display">\[\mathcal{F}\left[f(ax)\right]=\frac 1 {|a|} F\left (\frac \omega a\right)\]</span></p></li><li><p>时移 <span class="math display">\[\mathcal{F}\left[f(x-x_0)\right]=e^{-i\omega x_0}F\left (\omega\right)\]</span></p></li><li><p>频移 <span class="math display">\[\mathcal{F}\left[f(x)e^{i\omega x_0}\right]=F\left (\omega-\omega_0\right)\]</span></p></li><li><p>求导 <span class="math display">\[\mathcal{F}\left[f&#39;(x)\right]=i\omega F\left (\omega \right)\]</span></p></li><li><p>积分</p></li></ul><p><span class="math display">\[\mathcal{F}\left[\int^{x}_{x_0}  f(\xi) d\xi \right]=\frac 1 {i\omega} F\left (\omega \right) \]</span></p><ul><li><p>乘多项式 <span class="math display">\[\mathcal{F}\left[x^k\cdot f(x)\right]=i^k\frac{d^k}{d\omega^k}F(\omega)\]</span></p></li><li><p>卷积 <span class="math display">\[\mathcal{F}\left[f_1(x)*f_2(x)\right]=F_1(\omega)\cdot F_2(\omega)\]</span></p></li><li><p>对称性 <span class="math display">\[\mathcal{F^{-1}}\left[f(x)\right](\omega)=\frac 1 {2\pi}\mathcal{F}\left[f(x)\right](-\omega)\]</span> 例如： $$ \begin{aligned} &amp;=2 {1+^2}\ &amp; (x)=e<sup>{-|x|}\ &amp;(x)=2e</sup>{-|-x|}\ &amp;i.e.()=e^{-|x|}</p><p>\end{aligned} $$</p></li></ul><h4 id="多重傅立叶积分">（3）多重傅立叶积分</h4><p>对每个参数逐个进行变换。 <span class="math display">\[\begin{align}F(k_1,k_2,k_3)&amp;=\iiint_{-\infty}^\infty f(x,y,z)e^{-i(k_1x+k_2y+k_3z)}dxdydz\\&amp;=\int f(\vec r)e^{-i\vec k\cdot \vec r} d\vec k\\f(x,y,z)&amp;=\frac 1 {(2\pi)^3}\iiint_{-\infty}^\infty F(k_1,k_2,k_3)e^{i(k_1x+k_2y+k_3z)}dk_1dk_2dk_3\\&amp;=\frac 1 {(2\pi)^3}\int F(\vec k)e^{i\vec k\cdot \vec r}d\vec r\end{align}\]</span></p><h4 id="常用变换">（4）常用变换</h4><p>$$ <span class="math display">\[\begin{align}\mathcal{F}\left[e^{-x^2}\right]&amp;=\sqrt{\pi}e^{-\frac{\omega^2}{4}}\\\mathcal{F}\left[e^{-a|x|}\right]&amp;=\frac{2a}{a^2+\omega^2}\\\mathcal{F}\left[\frac{a}{a^2+\omega^2}\right]&amp;=\pi e^{-a|x|}\end{align}\]</span> $$</p><h4 id="应用">（5）应用</h4><ul><li><p>证明 Helmholtz 定理</p></li><li><p>求解无界空间定解问题</p></li><li><p>求解半无界定解问题</p><p>​ 作延拓，求解延拓到无界的方程，限制在半空间得到解。</p></li></ul><h3 id="拉普拉斯变换">8.2 拉普拉斯变换</h3><h4 id="定义-1">（1）定义</h4><p><span class="math display">\[\begin{align}\bar f(p)\equiv\mathcal{L}\left[f(x)\right]&amp;=\int_0^\infty f(t)e^{-pt}dt\\f(t)=\mathcal{L}^{-1}\left[\bar f(p)\right]&amp;=\frac{1}{2\pi i}\int_{\sigma-i\infty}^{\sigma+i\infty} \bar f(p)e^{pt}dp\end{align}\]</span></p><h4 id="性质">（2）性质</h4><h4 id="常用变换-1">（3）常用变换</h4><h4 id="黎曼-梅林反演公式">（4）黎曼-梅林反演公式</h4><h4 id="求定解问题">（5）求定解问题</h4><h2 id="九-保角变换法">九 保角变换法</h2><h3 id="分式线型变换">9.1 分式线型变换</h3><p><span class="math display">\[\zeta(z)=k\frac{z-\alpha}{z-\beta}\]</span></p><p>为了方便分析可以选取 <span class="math inline">\(k=1\)</span> 或 <span class="math inline">\(k=-1\)</span> 。</p><p>重要性质：</p><ul><li>广义圆 <span class="math inline">\(\mapsto\)</span> 广义圆</li><li>保持对称性</li></ul><h3 id="儒可夫斯基变换">9.2 儒可夫斯基变换</h3><p><span class="math display">\[\zeta(z)=\frac{C}{2}\left(z+\frac{1}{z}\right)\]</span></p><p>令 <span class="math inline">\(z=\rho_0 e^{i\varphi}\)</span> 可以发现：</p><p><span class="math inline">\(\zeta\)</span> 可以将 <span class="math inline">\(z\)</span> 平面上的圆 <span class="math inline">\(\displaystyle x^2 +y^2 =\rho_0^2\)</span> 变为 <span class="math inline">\(\zeta\)</span> 平面上的椭圆 <span class="math inline">\(\displaystyle\frac{x^2}{a^2}+\frac{y^2}{b^2}=1\)</span>,</p><p>其中 <span class="math inline">\(a=\displaystyle\frac C 2 \left(\rho_0+\frac{1}{\rho_0}\right)\)</span>, <span class="math inline">\(b=\displaystyle\frac C 2 \left(\rho_0-\frac{1}{\rho_0}\right)\)</span></p><p>通常是将椭圆变为圆： <span class="math display">\[z=\frac{C}{2}\left(\zeta+\frac{1}{\zeta}\right)\]</span> 反解出来 <span class="math inline">\(\zeta\)</span> 可以将 <span class="math inline">\(z\)</span> 平面的椭圆 <span class="math inline">\(\displaystyle\frac{x^2}{a^2}+\frac{y^2}{b^2}=1\)</span> 变为 <span class="math inline">\(\zeta\)</span> 平面的圆 <span class="math inline">\(\displaystyle x^2 +y^2 =\rho_0^2\)</span> 。</p><p>确定参数：已知 <span class="math inline">\(a,b\)</span> ，求解 <span class="math inline">\(C,\rho_0\)</span> 即可： <span class="math display">\[\begin{align}C&amp;=\sqrt{a^2-b^2}\\\rho&amp;=\frac{a+b}{C}=\frac{a+b}{\sqrt{a^2-b^2}}\end{align}\]</span></p><h3 id="常见构型">9.3 常见构型</h3><h4 id="角形域">（1）角形域</h4><ul><li><p>利用 <span class="math inline">\(\zeta=e^{i\varphi}\cdot z\)</span> 可将其旋转，使一条边和实轴正半轴重合</p></li><li><p>再利用 <span class="math inline">\(\zeta =z^\alpha\)</span> 将其展平为半平面</p></li></ul><h4 id="上半平面">（2）上半平面</h4><p><span class="math display">\[\zeta(z)=\frac{z-i}{z+i}\notag\]</span></p><p><span class="math inline">\(i\mapsto 0,-i\mapsto \infty\)</span></p><p>原来的两点关于界面对称，新的两点只能关于圆对称，边界必须变成圆。</p><p>将上半平面变换为实心圆柱，代入 <span class="math inline">\(z=0\)</span> 确定半径为 <span class="math inline">\(1\)</span> 。</p><h4 id="平行圆柱或圆柱-直线">（3）平行圆柱或圆柱-直线</h4><p>直线是广义圆。</p><p>不妨把两点放到 <span class="math inline">\(x\)</span> 轴上, 以左边的圆的圆心为原点, 两圆相距 <span class="math inline">\(d\)</span> 。</p><p>寻找两圆的公共对称点 <span class="math inline">\(z=a\)</span> 和 <span class="math inline">\(z=b\)</span> : <span class="math display">\[\begin{aligned}ab&amp;=R_1^2\\(d-a)(d-b)&amp;=R_2^2\end{aligned}\]</span> 可以解出 <span class="math inline">\(a,b\)</span> 。</p><p><span class="math inline">\(a\mapsto 0,b\mapsto \infty\)</span> : <span class="math display">\[\zeta(z)=\frac{z-a}{z-b}\]</span> 可将平行圆变为同心圆。代入 <span class="math inline">\(z\)</span> 平面平行圆的边界点可以确定同心圆的内外径。</p><h4 id="弓形或两圆相交区域">（4）弓形或两圆相交区域</h4><ul><li><p>先找到广义圆的两个交点，用分式线型变换把一个变到 <span class="math inline">\(0\)</span> ，另一个变到 <span class="math inline">\(\infty\)</span></p></li><li><p>由于保角性，交角不变，弓形或者两圆相交区域变为一个角形区域（这是由于 <span class="math inline">\(z\)</span> 平面上的两段广义圆弧变成了 <span class="math inline">\(\zeta\)</span> 平面上的过 <span class="math inline">\(0\)</span> 和 <span class="math inline">\(\infty\)</span> 的广义圆弧，半径为 <span class="math inline">\(\infty\)</span> 只能是两条过原点的射线）</p></li><li><p>再进行（1）和（2）即可</p></li></ul><h3 id="常用电势电容结论">9.4 常用电势电容结论</h3><h4 id="同轴圆柱单位电容">（1）同轴圆柱单位电容</h4><p><span class="math display">\[C=\frac{2\pi \varepsilon_0}{\ln (R_1/R_2)}\]</span></p><p>证明：</p><p>​ 利用 <span class="math inline">\(\zeta(z)=\ln z=\ln|z|+i Argz\)</span> 将同轴圆柱变为平行板电容器</p><p>​ <span class="math inline">\(\displaystyle C\cdot l=\frac{\varepsilon_0A}{d}=\frac{\varepsilon\cdot 2\pi\cdot l}{\ln(R_1/R_2)}\implies C=\frac{2\pi\varepsilon_0}{\ln(R_1/R_2)}\)</span></p><h4 id="接地金属圆柱壳中心细导线电势分布">（2）接地金属圆柱壳+中心细导线电势分布</h4><p>设金属圆柱壳的半径为 <span class="math inline">\(a\)</span> 。 <span class="math display">\[u=\frac{\lambda}{2\pi\varepsilon_0}\ln\left(\frac{a}{|\zeta|} \right)\]</span> 证明：</p><p>​ 由高斯定律 <span class="math inline">\(\displaystyle E\cdot 2\pi rl=\lambda l/\varepsilon_0\implies E=\frac{\lambda}{2\pi\varepsilon_0}\frac 1 r\)</span></p><p>​ <span class="math inline">\(\therefore u(\zeta(z))=\displaystyle\int^\mathcal{O}_{|\zeta|}\vec E\cdot d\vec \ell=\frac{\lambda}{2\pi\varepsilon_0}\ln\left(\frac{a}{|\zeta|} \right)\)</span></p><h4 id="导体圆柱周围电势分布">（3）导体圆柱周围电势分布</h4><p><span class="math display">\[u=c_1\ln|\zeta|+c_2\]</span></p><p>证明：</p><p>​ 由柱坐标拉普拉斯方程 <span class="math inline">\(\displaystyle\Delta u=0\implies\frac {1}{r}\frac{\partial}{\partial r}\left(r\frac{\partial u}{\partial r}\right)=0\)</span></p><p>​ 得到通解为 <span class="math inline">\(u=c_1\ln|\zeta|+c_2\)</span></p><p>​ <span class="math inline">\(c_2\)</span> 和零电势点的选取有关，可以令其为0</p><p>​ <span class="math inline">\(c_1\)</span> 的确定见书 <span class="math inline">\(Page -{308}\)</span></p><p>​ <span class="math inline">\(|\zeta|\to0,|\zeta|\to \infty\)</span> 时导致的发散是由于点电荷和无穷长导线都是理想的物理模型。</p>]]></content>
      
      
      <categories>
          
          <category> Physics </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>Theoretical Mechanics</title>
      <link href="/2020/02/18/Physics/Theoretical-mechanics/"/>
      <url>/2020/02/18/Physics/Theoretical-mechanics/</url>
      
        <content type="html"><![CDATA[<h1 id="理论力学笔记">理论力学笔记</h1><p>ing～</p>]]></content>
      
      
      <categories>
          
          <category> Physics </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>Electromagnetism</title>
      <link href="/2020/02/18/Physics/Electromagnetism/"/>
      <url>/2020/02/18/Physics/Electromagnetism/</url>
      
        <content type="html"><![CDATA[<h1 id="电动力学笔记">电动力学笔记</h1><h2 id="麦克斯韦方程和规范理论概述起源杨振宁">0 麦克斯韦方程和规范理论概述起源（杨振宁）</h2><ul><li><p>Electrotonic state, Faraday<br /><span class="math display">\[H=\nabla \times A\]</span></p></li><li><p>Maxwell <span class="math display">\[Light=EM\ waves\]</span></p></li><li><p>Maxwell : A Dynamical Theory of the Electromagnetic Field <span class="math display">\[energy\;\ density=\frac{1}{8\pi ^2}(E^2+H^2)\]</span></p></li><li><p>Dirac‘s sea</p></li><li><p>Renormalization <span class="math display">\[\alpha=(g-2)/2\]</span></p></li><li>gauge theory 规范理论, non-Abelian gauge theory, 重整化群</li><li><p>Symmetry breaking, Standard Mode</p></li></ul><p><strong>“妙的地方”</strong></p><p>$ \ $ <a id="more"></a></p><h2 id="矢量分析整理">1 矢量分析整理</h2><h3 id="符号约定">符号约定</h3><ul><li><p>Kronecker <span class="math display">\[\delta_{ij}=\begin{cases}1\quad i=j,\\0 \quad i\neq j.\end{cases}\notag\]</span></p></li><li><p>Levi-Civita</p></li></ul><p><span class="math display">\[\varepsilon_{ijk}=\begin{cases}1\quad (ijk)偶排列,\\ -1 \quad (ijk)奇排列, \\0 \quad 下标中有两个相等.\end{cases}\notag\]</span></p><ul><li><p><span class="math display">\[\begin{aligned}&amp;\varepsilon_{ijk}\varepsilon_{lmn}=\left|\begin{array}{cccc}     \delta_{il} &amp; \delta_{im} &amp;  \delta_{in}\\      \delta_{jl}&amp; \delta_{jm}&amp; \delta_{jn}\\     \delta_{kl}&amp; \delta_{km}&amp; \delta_{kn}\end{array}\right|\\&amp;\varepsilon_{ijk}\varepsilon_{lmk}=\delta_{il}-\delta_{jm}\end{aligned}\]</span></p></li><li><p>Einstein 求和约定 <span class="math display">\[A_i\vec e_i\equiv \sum_{i=1}^n A_i\vec e_i=\vec A\notag\]</span></p></li></ul><h3 id="点乘和叉乘">点乘和叉乘</h3><p><span class="math display">\[\begin{aligned}&amp;\vec A\times \vec B=A_iB_j\varepsilon_{ijk}\vec e_k=\left|\begin{array}{cccc}     \vec e_x &amp; \vec e_y &amp; \vec e_z \\     B_x &amp; B_y &amp; B_z\\     C_x &amp; C_y &amp; C_z \end{array}\right|\\&amp;\vec A\cdot (\vec B\times\vec C)=\vec B\cdot (\vec C\times \vec A)=\vec C\cdot (\vec A\times \vec B)=\left|\begin{array}{cccc}     A_x &amp; A_y &amp; A_z \\     B_x &amp; B_y &amp; B_z\\     C_x &amp; C_y &amp; C_z \end{array}\right| \\&amp; \vec A\times (\vec B\times\vec C)=(\vec A\cdot \vec C)\vec B-(\vec A\cdot \vec B)\vec C\\&amp; (\vec A\times \vec B)\times \vec C=(\vec A\cdot \vec C)\vec B-(\vec B\cdot\vec C)\vec A\end{aligned}\]</span></p><h3 id="多元微分">多元微分</h3><h4 id="理解">1. 理解</h4><p>（1）多元标量函数求导：梯度</p><p>（2）矢量函数求导可以看成有两种：散度、旋度</p><p>（3）标量函数可以求梯度，但无法求散度和旋度</p><p>（4）矢量函数可以求散度和旋度，但无法求梯度</p><h4 id="积规则">2. 积规则</h4><h4 id="梯度">（1）梯度</h4><ul><li><p>乘积 <span class="math display">\[\nabla(fg)=f\nabla g+g\nabla f\notag\]</span></p></li><li></li></ul><p><span class="math display">\[\nabla(\frac{f}{g})=\frac{g\nabla f-f\nabla g}{g^2}\notag\]</span></p><ul><li>复合</li></ul><p><span class="math display">\[\nabla [f(g)]=\nabla f\odot \nabla g\notag\]</span></p><ul><li>点乘</li></ul><p><span class="math display">\[\nabla(\vec A\cdot \vec B)=\vec A\times(\nabla \times\vec B)+\vec B\times(\nabla\times\vec A)+(\vec A \cdot \nabla)\vec B+(\vec B\cdot \nabla )\vec A\notag\]</span></p><p>​</p><p>注意梯度算符同时具有矢量性和微分性。</p><h4 id="散度">（2）散度</h4><ul><li><p><span class="math display">\[\nabla \cdot (f\vec A)=(\nabla f)\cdot\vec A+f (\nabla \cdot \vec A)\notag\]</span></p></li><li><p><span class="math display">\[\nabla\cdot(\frac{\vec A}{g})=\frac{(\nabla\cdot \vec A)g-(\nabla g)\cdot \vec A}{g^2}\notag\]</span></p></li><li><p><span class="math display">\[\nabla \cdot (\vec A\times \vec B)=\vec B\cdot (\nabla \times\vec A)-\vec A\cdot (\nabla\times \vec B)\notag\]</span></p></li></ul><h4 id="旋度">（3）旋度</h4><ul><li><p><span class="math display">\[\nabla\times(f\vec A)=(\nabla f)\times \vec A+f(\nabla\times \vec A)\notag\]</span></p></li><li><p><span class="math display">\[\nabla\times(\frac{\vec A}{g})=\frac{(\nabla\times\vec A)g-(\nabla g)\times\vec A}{g^2}\notag\]</span></p></li><li><p><span class="math display">\[\nabla\times(\vec A\times \vec B)=(\nabla\cdot \vec B)\vec A-(\nabla\cdot \vec A)\vec B+(\vec B\cdot \nabla)\vec A-(\vec A\cdot \nabla)\vec B\notag\]</span></p></li></ul><h4 id="二阶微分">（4）二阶微分</h4><ul><li><p>Laplace <span class="math display">\[\Delta T\triangleq\nabla\cdot \nabla T\notag\]</span></p></li><li><p>梯度的旋度为零 <span class="math display">\[\nabla\times(\nabla T)=0\notag\]</span></p></li><li><p>旋度的旋度 <span class="math display">\[\nabla\times(\nabla\times\vec A)=\nabla(\nabla\cdot \vec A)-\nabla^2 \vec A\notag\]</span></p></li></ul><h4 id="波常用">3. 波常用</h4><ul><li><p><span class="math display">\[\begin{align}\nabla e^{i\vec k\cdot \vec r}&amp;=i\vec k e^{i\vec k\cdot \vec r}\\\nabla^2e^{i\vec k\cdot \vec r}&amp;=\nabla\cdot(\nabla e^{i\vec k\cdot \vec r})\notag\\&amp;=i(\nabla\cdot\vec k)e^{i\vec k\cdot \vec r}+i(\nabla e^{i\vec k\cdot\vec r})\cdot\vec k\notag\\&amp;=-k^2 e^{i\vec k\cdot \vec r}\end{align}\]</span></p></li><li><p>平面波 $ E=E_0 e^{ikr}$ <span class="math display">\[\begin{align}\nabla\cdot\vec E&amp;=i\vec k \cdot \vec E\\\nabla\times\vec E&amp;=i\vec k\times\vec E\\\end{align}\]</span></p></li></ul><h3 id="多元积分">多元积分</h3><h4 id="总广义stokes定理">1. 总：广义Stokes​定理</h4><p><span class="math display">\[\int_V dw=\int_{\partial V}w\]</span></p><h4 id="理解-1">2. 理解</h4><p>（1）两边的矢量性/标量性要一致</p><p>（2）分两类，一类是两边都是标量，一类是两边都是矢量</p><h4 id="积分公式">3. 积分公式</h4><p>可以通过同时点乘或叉乘常矢量 <span class="math inline">\(\vec c\)</span> ，然后使用积规则（类似分布积分）证明出。</p><h4 id="梯度-1">（1）梯度</h4><ul><li>梯度的线积分不依赖于路径</li></ul><p><span class="math display">\[\int _a^b (\nabla T)\cdot d\vec \ell=T(b)-T(a)\notag\]</span></p><ul><li><span class="math display">\[\int_V (\nabla T)d\tau=\int_{\partial V}Td\vec\sigma\notag\]</span></li></ul><h4 id="散度-1">（2）散度</h4><ul><li><p><span class="math display">\[(Gauss)\qquad \int_V(\nabla\cdot \vec A) d\tau=\int_{\partial V}\vec A\cdot d\vec \sigma\notag\]</span></p></li><li><p><span class="math display">\[\int_S (\nabla\cdot \vec A)d\vec\sigma=\int_{\partial S}\vec A\times d\vec \ell\notag\]</span></p></li></ul><h4 id="旋度-1">（3）旋度</h4><ul><li><span class="math display">\[\int _V(\nabla \times \vec A)d\tau=\int_{\partial V} d\vec \sigma\times\vec A=-\int_{\partial V}\vec A\times d\vec \sigma\notag\]</span></li></ul><p>​ 注意 <span class="math inline">\(\vec A\)</span> 始终要在叉乘符号的右边</p><ul><li><p><span class="math display">\[(Stokes)\qquad \int_S(\nabla\times\vec A)\cdot d\vec\sigma=\int_{\partial S}\vec A\cdot d\vec \ell\notag\]</span></p></li><li><p><span class="math display">\[\int_S (\nabla T)\times d\vec \sigma=-\int_{\partial S}Td\vec \ell\notag\]</span></p></li></ul><p>​ 注意左边是旋度积分而且两边都是矢量性的，如果右边积分变量写正常，多个负号</p><h3 id="狄拉克函数">狄拉克函数</h3><ul><li>考虑一个正交的曲线坐标系，它由三个参数 <span class="math inline">\(u,v,w\)</span> 来确定（<span class="math inline">\(u=const,v=const,w=const\)</span> 的面互相垂直）。沿着三个相互垂直的方向的无穷小线元的长度分别是 <span class="math inline">\(du/U,dv/V,dw/W\)</span> 。则：</li></ul><p><span class="math display">\[\delta^{(3)}(\vec x-\vec x&#39;)=\delta(u-u&#39;)\delta(v-v&#39;)\delta(w-w&#39;)UVW\]</span></p><ul><li><span class="math display">\[-\nabla^2\frac{1}{|\vec r-\vec r&#39;|^2}=\nabla \cdot (\frac{\vec r - \vec r&#39;}{|\vec r-\vec r&#39;|^3})=4\pi\delta^3(\vec r-\vec r&#39;)\notag\]</span></li></ul><h3 id="位置矢量-vec-r-相关">位置矢量 <span class="math inline">\(\vec r\)</span> 相关</h3><ul><li>定义</li></ul><p><span class="math display">\[\vec r=x\vec e_x+y\vec e_y+z\vec e_z\\r=\sqrt{x^2+y^2+z^2}\notag\]</span></p><ul><li><p><span class="math inline">\(r\)</span> <span class="math display">\[\begin{aligned}\nabla r=\frac{\vec r}{|r|}=\vec e_r\end{aligned}\]</span></p></li><li><p><span class="math inline">\(\vec r\)</span></p></li></ul><p><span class="math display">\[\begin{aligned}\nabla\cdot \vec r=3\\\nabla\times \vec r=0\end{aligned}\]</span></p><ul><li><span class="math inline">\(\displaystyle\frac{1}{r}\)</span></li></ul><p><span class="math display">\[\nabla(\frac{1}{r})=-\frac{\nabla r}{r^2}=-\frac{\vec e_r}{r^2}=-\frac{\vec r}{r^3}\notag\]</span></p><p><span class="math display">\[\nabla^2 \frac{1}{r}=-4\pi\delta(r)\notag\]</span></p><ul><li><p><span class="math inline">\(\vec e_r\)</span> <span class="math display">\[\nabla \cdot \vec e_r=\frac{2}{r}\notag\]</span></p></li><li><p><span class="math inline">\(\displaystyle \frac{\vec e_r}{r^2}\)</span> <span class="math display">\[\notag\nabla\cdot \frac{\vec e_r}{r^2}=0\\\nabla\frac{\vec e_r}{r^2}=\frac{\nabla \vec r r^3-(\nabla r^3)\vec r}{r^6}=\frac{\overleftrightarrow I-3\vec e_r\vec e_r}{r^3}\]</span></p></li></ul><p>以上对 <span class="math inline">\(\vec r-\vec r’\)</span> 同样适用。</p><h3 id="张量相关">张量相关</h3><p><span class="math display">\[\begin{aligned}&amp;\iint \vec e_r d\Omega =0\\&amp;\iint \vec e_r\vec e_r d\Omega=\frac {4\pi}{3}\overleftrightarrow I\end{aligned}\]</span></p><h2 id="电磁学公式">2 电磁学公式</h2><h3 id="高斯定律">高斯定律</h3><p><span class="math display">\[\nabla\cdot \vec E(\vec r)=\frac{\rho(r)}{\varepsilon_0}\]</span></p><h3 id="电流密度">电流密度</h3><p><span class="math display">\[\vec j=\rho_{+}\vec v_++\rho_-\vec v_-\]</span></p><h3 id="电荷的连续性方程">电荷的连续性方程</h3><p><span class="math display">\[\frac{\partial\rho}{\partial t}+\nabla\cdot \vec j=0\]</span></p><h3 id="毕奥萨伐尔定律">毕奥—萨伐尔定律</h3><p><span class="math display">\[\begin{aligned}&amp;d\vec B(\vec r)=\frac{\mu_0}{4\pi}\frac{\vec j(\vec r&#39;)\times \vec e(\vec r-\vec r&#39;)}{|\vec r-\vec r&#39;|^2}d\tau&#39;\\&amp;\vec B(\vec r)=\frac{\mu_0}{4\pi}\int_V\frac{\vec j(\vec r&#39;)\times \vec e(\vec r-\vec r&#39;)}{|\vec r-\vec r&#39;|^2}d\tau&#39;=\nabla\times\vec A\\&amp;\vec A=\frac{\mu_0}{4\pi}\int_V\frac{j(\vec r&#39;)}{|\vec r -\vec r&#39;|}d\tau&#39;\end{aligned}\]</span></p><h3 id="安培定律">安培定律</h3><p><span class="math display">\[\oint \vec B\cdot d\vec \ell=\mu_0\sum I\]</span></p><h3 id="磁场对电流的力密度">磁场对电流的力密度</h3><p>施加在单位体积内在流体上的力。 <span class="math display">\[f=j\times B\]</span></p><h3 id="法拉第电磁感应定律">法拉第电磁感应定律</h3><p><span class="math display">\[\mathcal{E}=-\frac{d\Phi}{dt}=\oint \vec E\cdot d\vec \ell ,\quad \Phi=\int_S\vec B\cdot d\vec \sigma\]</span></p><h2 id="麦克斯韦方程组">3 麦克斯韦方程组</h2><h3 id="原始形式">原始形式</h3><p><span class="math display">\[\begin{aligned}\nabla\cdot \vec E&amp;=\frac{\rho}{\varepsilon_0}\\\nabla\times \vec E&amp;=-\frac{d\vec  B}{dt}\\\nabla \cdot\vec  B&amp;=0\\\nabla\times\vec  B&amp;=\mu_0 \vec j+\varepsilon_0\mu_0\frac{\partial \vec E}{\partial t}\end{aligned}\]</span></p><h3 id="介质形式">介质形式</h3><p><span class="math display">\[\begin{aligned}\nabla\cdot \vec D&amp;=\rho\\\nabla\times \vec E&amp;=-\frac{d \vec B}{dt}\\\nabla \cdot \vec B&amp;=0\\\nabla\times \vec H&amp;=\vec  j+\frac{\partial\vec  D}{\partial t}\end{aligned}\]</span></p><p>其中： <span class="math display">\[\begin{aligned}\vec D&amp;=\varepsilon_0\vec E+\vec P\\\vec H&amp;=\frac{1}{\mu_0}\vec B-\vec M\end{aligned}\]</span> 其中：</p><p><span class="math inline">\(\vec P=\rho_p\vec \ell\)</span> 为极化强度，是单位体积内分子的总偶极矩。</p><p><span class="math inline">\(\vec M\)</span> 为单位体积内的磁矩。</p><p>这一部分需要再细细整理。</p><h3 id="边界条件">边界条件</h3><p>$$ \begin{aligned} D^{}_1-D_2^&amp;=_f\ E_1<sup>{}-E</sup>{}_2&amp;=0 \ H_1<sup>{}-H_2</sup>{}&amp;=K_fn\ B_1<sup>-B_2</sup>&amp;=0</p><p>\end{aligned} $$</p><h2 id="电磁场能动量">4 电磁场能动量</h2><h3 id="能量">能量</h3><p>能流密度： <span class="math display">\[\vec S=\frac{1}{\mu_0}\vec E\times \vec B\\\]</span> 电磁场能量密度： <span class="math display">\[w=\frac{1}{2}(\varepsilon_0 E^2+\frac{1}{\mu_0}B^2                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             )\]</span></p><h3 id="麦克斯韦应力张量">麦克斯韦应力张量</h3><p>$$ \begin{aligned} f&amp;=E+vB=E+jB\ &amp;=-_0_0</p><p>\end{aligned} $$</p><p>其中，麦克斯韦应力张量： <span class="math display">\[\overleftrightarrow{\mathcal{T}}=\varepsilon_0\vec E\vec E+\frac{1}{\mu_0}\vec B\vec B-\frac{1}{2}\big(\varepsilon_0\vec E^2+\frac{1}{\mu_0}\vec B^2\big)\overleftrightarrow I\]</span> 分量形式为： <span class="math display">\[T_{ij}=\varepsilon_0(E_iE_j-\frac 1 2 \delta_{ij}E^2)+\frac 1 \mu_0 (B_iB_j-\frac 1 2 \delta_{ij}B^2)\]</span></p><p>空间 <span class="math inline">\(V\)</span> 内电荷所受合力为： <span class="math display">\[\vec F=\int_V\vec f d\tau=\int_S\overleftrightarrow{\mathcal{T}}\cdot d\vec \sigma-\varepsilon_0\mu_o\frac{d}{dt}\int_V \vec S d\tau\]</span></p><h3 id="动量">动量</h3><p><span class="math display">\[\begin{aligned}&amp;\vec f=\frac{d\vec p_{mech}}{dt}=-\frac{d}{dt}(\varepsilon_0\mu_0\vec S)+\nabla\cdot\overleftrightarrow {\mathcal{T}}\\\iff &amp;\frac{d}{dt}\bigg(\vec p_{mech}+\vec g\bigg)=-\nabla\cdot\overleftrightarrow{\Tau}\end{aligned}\]</span></p><p>其中 <span class="math inline">\(\vec p_{mech}\)</span> 为机械动量密度， <span class="math inline">\(\vec g\equiv\vec p_{em}\)</span> 为电磁动量密度，<span class="math inline">\(\overleftrightarrow \Tau=-\overleftrightarrow{\mathcal{T}}\)</span> 为动量流密度。</p><p>电磁场动量密度 <span class="math display">\[\vec g=\varepsilon_0\mu_0\vec S=\frac{1}{c^2}\vec S\]</span> 动量流密度 <span class="math display">\[\overleftrightarrow\Tau=\frac{1}{2}\big(\varepsilon_0\vec E^2+\frac{1}{\mu_0}\vec B^2\big)\overleftrightarrow I-\varepsilon_0\vec E\vec E-\frac{1}{\mu_0}\vec B\vec B\]</span></p><h3 id="角动量">角动量</h3><p>电磁场角动量密度 <span class="math display">\[\vec \ell_{em}=\vec r\times\vec g=\varepsilon_0\big[\vec r\times\vec E\times \vec B\big]\]</span></p><h3 id="电磁辐射压强">电磁辐射压强</h3><p><span class="math display">\[\mathcal{P}=\frac{\Delta F}{\Delta A}=\frac{g\Delta V}{\Delta t\Delta A}=\frac{g\Delta \ell}{\Delta t}=cg\]</span></p><p>这是完全吸收时的辐射压强，其中 <span class="math inline">\(c\)</span> 为光速。</p><p>不完全吸收时, <span class="math inline">\(\mathcal{P}=cg(1+r)\)</span> , 其中 <span class="math inline">\(r\)</span> 为反射系数。</p><h2 id="静电问题">6 静电问题</h2><h3 id="电势">电势</h3><p><span class="math display">\[\begin{aligned}V(\vec r)&amp;\equiv -\int _{\mathcal{O}}^ r\vec E\cdot d\vec \ell\\&amp;=\int_r^\infty \vec E\cdot d\vec \ell\end{aligned}\]</span></p><h3 id="多极展开">多极展开</h3><h4 id="原理">原理</h4><ul><li><p>泰勒定理</p><p>若函数 <span class="math inline">\(f\)</span> 在点 <span class="math inline">\(P_0(x_0,y_0)\)</span> 点邻域 <span class="math inline">\(U(P_0)\)</span> 上有直到 <span class="math inline">\(n+1\)</span> 阶的连续偏导数，则对 <span class="math inline">\(U({_0})\)</span> 内任一点 <span class="math inline">\((x_0+h,y_0+k)\)</span> ，存在相应的 <span class="math inline">\(\theta\in(0,1)\)</span> ，使得 <span class="math display">\[\begin{aligned}f(x_0+h,y_0+k)=&amp;f(x_0,y_0)+\bigg(h\frac{\partial}{\partial x}+k\frac{\partial}{\partial y}\bigg)f(x_0,y_0)\\&amp;+\frac{1}{2!}\bigg(h\frac{\partial}{\partial x}+k\frac{\partial}{\partial y}\bigg)^2f(x_0,y_0)+\cdots\\&amp;+\frac{1}{n!}\bigg(h\frac{\partial}{\partial x}+k\frac{\partial}{\partial y}\bigg)^n f(x_0,y_0)\\&amp;+\frac{1}{(n+1)!}\bigg(h\frac{\partial}{\partial x}+k\frac{\partial}{\partial y}\bigg)^{n+1}f(x_0+\theta h,y_0+\theta k)\end{aligned}\]</span></p></li><li><p>场量的泰勒展开：对 <span class="math inline">\(f(\vec x-\vec x’)\)</span> 在 <span class="math inline">\(\vec x’=0\)</span> 附近展开</p></li></ul><p><span class="math display">\[\begin{aligned}f(\vec x-\vec x&#39;)&amp;=f(\vec x)-\sum_{i=1}^3 x_i\frac{\partial f}{\partial x_i}+\frac{1}{2!}\sum_{i,j}x_i x_j \frac{\partial^2 f}{\partial x_i\partial x_j}+\cdots\\&amp;=f(\vec x)-\vec x&#39;\cdot \nabla f(\vec x)+\frac{1}{2}\vec x&#39;\vec x&#39;\colon \nabla\nabla f(\vec x)+\cdots\end{aligned}\]</span></p><p>$$ \begin{aligned} &amp;()=-=- \ &amp;()=-=</p><p>\end{aligned} $$</p><ul><li><p>常用展开：把 <span class="math inline">\(\displaystyle \frac{1}{|\vec r- \vec r|}\)</span> 在 <span class="math inline">\(\vec r’=0\)</span> 附近作泰勒展开 <span class="math display">\[\frac{1}{|\vec r-\vec r&#39;|}=\frac{1}{r}+\frac{\vec r&#39;\cdot\vec e_r}{r^2}+\frac{(3\vec r&#39;\vec r&#39;-r&#39;^2\overleftrightarrow I):\vec e_r\vec e_r}{2r^3}+\cdots\notag\]</span></p></li><li><p>更方便地展开：把 <span class="math inline">\(\displaystyle \frac{1}{|\vec r- \vec r|}\)</span> 展开成勒让德多项式 ( <span class="math inline">\(r\)</span> 很大时) <span class="math display">\[\begin{aligned}\frac{1}{|\vec r-\vec r&#39;|}&amp;=\frac{1}{\sqrt{r^2+r&#39;^2-2rr&#39;\cos\theta&#39;}}\\&amp;=\sum_{n=0}^\infty \frac{(r&#39;)^n}{r^{n+1}}P_n(\cos\theta&#39;)\\&amp;=\frac{1}{r}+\frac{r&#39;}{r^2}\cos\theta&#39;+\frac{r&#39;^2}{r^3}[\frac{1}{2}(3\cos^2\theta&#39;-1)]+\cdots\\&amp;=\frac{1}{r}+\frac{\vec r&#39;\cdot\vec e_r}{r^2}+\frac{(r&#39;)^2(3\cos^2\theta&#39;-1)}{2r^3}+\cdots\end{aligned}\]</span></p></li></ul><h4 id="静电场的多极展开">静电场的多极展开</h4><h4 id="单极">单极</h4><p><span class="math display">\[\varphi_1=\frac{1}{4\pi\epsilon_0}\frac{Q}{r}\notag\]</span></p><h4 id="偶极">偶极</h4><p><span class="math display">\[\varphi_2=\frac{1}{4\pi\epsilon_0}\frac{\vec p\cdot \vec e_r}{r^2}\notag\]</span></p><ul><li>电偶极矩 <span class="math display">\[\vec p=\int_V\vec r\cdot\rho(\vec r) d\tau\notag\]</span> <span class="math inline">\(\vec r\)</span> 为每个电荷的位置矢量</li></ul><h4 id="四极">四极</h4><p><span class="math display">\[\varphi_3=\frac{1}{4\pi\epsilon_0}\frac{\overleftrightarrow{\mathcal{D}}\colon(3\vec e_r\vec e_r-\overleftrightarrow I)}{2r^3}=\frac{1}{4\pi\epsilon_0}\frac{\overleftrightarrow {D}\colon \vec e_r\vec e_r}{2r^3}\]</span></p><ul><li><p>二级矩 <span class="math display">\[\overleftrightarrow{\mathcal{D}}=\sum_n q_n\vec r_n\vec r_n\\\overleftrightarrow{\mathcal{D}}=\int_V \rho(\vec r)\cdot \vec r\vec r d\tau\\\notag\]</span></p></li><li><p>四极矩</p></li></ul><p><span class="math display">\[\overleftrightarrow D=3\overleftrightarrow{\mathcal{D}}-tr(\overleftrightarrow{\mathcal{D}})\overleftrightarrow{I}\notag\]</span></p><ul><li><p>四极矩的性质</p><ul><li>对称性：<span class="math inline">\(D_{ij}=D_{ji}\)</span></li><li>无迹性： <span class="math inline">\(tr(\overleftrightarrow D)=0\)</span></li></ul></li></ul><h3 id="电偶极子在电场中的受力">电偶极子在电场中的受力</h3><h4 id="位能与受力">位能与受力</h4><p><span class="math display">\[\begin{aligned}U&amp;=-\vec p\cdot\vec E\\\vec F&amp;=-\nabla U=\nabla(\vec p\cdot \vec E)\end{aligned}\]</span></p><h4 id="力矩">力矩</h4><p><span class="math display">\[\vec \tau=\vec p\times \vec E\notag\]</span></p><h3 id="唯一性定理">唯一性定理</h3><ul><li>若边界上的电势或者电势的法向变化率已知</li><li>除导体外， <span class="math inline">\(V\)</span> 内电荷分布一致，表面有已知的第一类或第二类边界条件。若导体表面电势已知</li><li>若导体所带的总电量已知</li></ul><p>满足一点，则区域 <span class="math inline">\(V\)</span> 内的电势分布有唯一解。</p><h3 id="电像法">电像法</h3><p>对球类电场，可以添加镜像电荷使球面电势为 <span class="math inline">\(0\)</span>, 若导体球带电荷 <span class="math inline">\(Q\)</span> ，再于球心放置一个电荷量为 <span class="math inline">\(Q\)</span> 的等效电荷。</p><p>球半径为 <span class="math inline">\(R\)</span> , 原电荷在距球心 <span class="math inline">\(a\)</span> 处，电荷量为 <span class="math inline">\(q\)</span> , 则镜像电荷放置到距球心 <span class="math inline">\(\displaystyle\frac{R^2}{a}\)</span> 处，电荷量为 <span class="math inline">\(\displaystyle-\frac{R}{a} q\)</span> .</p><h3 id="格林函数法">格林函数法</h3><ul><li>格林函数 <span class="math inline">\(G\)</span> ：</li></ul><p><span class="math display">\[\Delta G=\delta^{(3)}(\vec x-\vec x&#39;)\notag\]</span></p><ul><li><p>各种解：</p></li><li><p>应用：</p></li></ul><h2 id="静磁问题">7 静磁问题</h2><h3 id="电流">电流</h3><p>电流由库仑每秒来量度， <span class="math inline">\(1A=1C/s\)</span></p><ul><li><p>线电流 : $I=v=I d$</p></li><li>面电流密度 : <span class="math inline">\(\displaystyle\vec K\equiv\frac{d\vec I}{dl_{\perp}}=\sigma\vec v\)</span> （电流带带上的电流除以带宽度） <span class="math inline">\(I=\displaystyle\int_\ell \vec K\cdot d\vec \ell\)</span></li><li><p>体电流密度 : <span class="math inline">\(\displaystyle\vec J\equiv\frac{d\vec I}{da_{\perp}}=\rho \vec v\)</span> （垂直于电流方向上单位面积流过的电流） <span class="math inline">\(I=\displaystyle\int_S \vec J\cdot d\vec \sigma\)</span></p></li></ul><p>注： <span class="math display">\[\begin{aligned}\vec jd\tau&amp;=C\delta(r-a)\delta(\theta-\frac\pi 2)d\varphi \vec e_\varphi\\Id\vec \ell&amp;=Iad\varphi\vec e_\varphi\\&amp;=\int_{d\ell}\vec j(\vec r)d\tau=\vec e_\varphi\int _{d\varphi}C\delta(r-a)\delta(\theta-\frac\pi 2)r^2\sin\theta \, dr d\theta d \varphi\\&amp;=Ca^2d\varphi\vec e_\varphi\\\implies C&amp;=\frac{I}{a}\\\therefore\int \vec j(\vec r)d\tau&amp;=\int\vec e_\varphi \frac I a\delta(r-a)\delta(\theta-\frac\pi 2)r^2\sin\theta\, drd\theta d\varphi \\&amp;=I\int\vec e_\varphi a\,d\varphi=I\int d\vec \ell\end{aligned}\]</span> <strong>相关公式</strong></p><ul><li>表面电流密度 <span class="math inline">\(\vec K=\vec M\cdot \hat n\)</span></li><li><p>内部体电流密度 <span class="math inline">\(\vec J=\nabla\times \vec M\)</span></p></li><li><p>磁感应强度 <span class="math inline">\(\vec B=\mu_0 \vec K\)</span></p></li></ul><h3 id="受力">受力</h3><h4 id="一段载流导线">一段载流导线</h4><p><span class="math display">\[\begin{aligned}\vec F&amp;=\int (\vec v\times \vec B)dq=\int (\vec v\times\vec B)\lambda d l=\int (\vec I\times \vec B)dl\\&amp;=I\int \vec d\ell\times\vec B\end{aligned}\]</span></p><h4 id="磁偶极子">磁偶极子</h4><p><span class="math display">\[\begin{aligned}U&amp;=-\vec m\cdot \vec B\\\vec F&amp;=\nabla(\vec m\cdot \vec B)\\\vec \tau&amp;=\vec m\times\vec B\end{aligned}\]</span></p><h3 id="源起">源起</h3><p>静磁场满足的微分方程： <span class="math display">\[\begin{aligned}&amp;\nabla\cdot \vec B=0\\&amp; \nabla\times \vec B=\mu_0\vec j\\&amp;\nabla\cdot \vec j=0\end{aligned}\]</span></p><h3 id="磁矢势">磁矢势</h3><p><span class="math inline">\(\nabla\times\vec A=0\)</span> 在库仑规范 <span class="math inline">\(\nabla\cdot \vec A=0\)</span> 下得到矢量泊松方程 <span class="math inline">\(\nabla^2\vec A=-\mu_0\vec j\)</span></p><p>磁库仑解为： <span class="math display">\[\vec A=\frac{\mu_0}{4\pi}\int_全 \frac{\vec j(\vec r&#39;)}{|\vec r-\vec r&#39;|}d\tau&#39;\notag\]</span> 具体： <span class="math display">\[\begin{aligned}\vec A&amp;=\frac{\mu_0}{4\pi}\int_V \frac{\vec J(\vec r&#39;)}{|\vec r-\vec r&#39;|}d\tau&#39;（体电流产生的磁矢势）\\&amp;=\frac{\mu_0}{4\pi}\int_S \frac{\vec K(\vec r&#39;)}{|\vec r-\vec r&#39;|}da&#39;（面电流产生的磁矢势）\\&amp;=\frac{\mu_0}{4\pi}\int_l \frac{\vec I(\vec r&#39;)}{|\vec r-\vec r&#39;|}dl&#39;=\frac{\mu_0 I}{4\pi}\int_l \frac{1}{|\vec r-\vec r&#39;|}d\vec \ell（线电流产生的磁矢势）\end{aligned}\]</span></p><p>由此可得到毕奥-萨伐尔定律： <span class="math display">\[\begin{aligned}\vec B&amp;=\nabla\times \vec A=\frac{\mu_0}{4\pi}\int_全 \nabla\times\bigg(\frac{\vec j(\vec r&#39;)}{|\vec r-\vec r&#39;|}\bigg)d\tau&#39;\\&amp;=\frac{\mu_0}{4\pi}\vec e_k\int_全 \varepsilon_{ijk}\partial_i \bigg(\frac{\vec j_j(\vec r&#39;)}{|\vec r-\vec r&#39;|}\bigg)d\tau&#39; \\&amp;=\frac{\mu_0}{4\pi}\vec e_k\int_全\varepsilon_{ijk}\frac{-(x_i-x_i&#39;)}{|\vec r-\vec r&#39;|^3}j_j(\vec r&#39;)d\tau&#39;\\&amp;=\frac{\mu_0}{4\pi}\int _全 \vec j(\vec r&#39;)\times\frac{\vec r-\vec r&#39;}{|\vec r-\vec r&#39;|^3}d\tau&#39;\\&amp;=\frac{\mu_0}{4\pi}\int_全 \frac{\vec j(\vec r&#39;)\times e(\vec r-\vec r&#39;)}{|\vec r-\vec r&#39;|^2 }d\tau&#39;\\&amp;=\frac{\mu_0}{4\pi}I\int_l \frac{\vec d\ell&#39;\times e(\vec r-\vec r&#39;)}{|\vec r-\vec r&#39;|^2}（线电流）\\&amp;=\frac{\mu_0}{4\pi}\int_S \frac{\vec K(\vec r&#39;)\times e(\vec r-\vec r&#39;)}{|\vec r-\vec r&#39;|^2}da&#39; （面电流）\\&amp;=\frac{\mu_0}{4\pi}\int_V \frac{\vec J(\vec r&#39;)\times e(\vec r-\vec r&#39;)}{|\vec r-\vec r&#39;|^2 }d\tau&#39;（体电流）\end{aligned}\]</span></p><p>一般地，磁矢势的方向和电流方向一致。</p><p>对称性好的情况下，已知磁感应强度利用磁通量求磁矢势（类似安培定理）： <span class="math display">\[\begin{aligned}\oint\vec A\cdot d\vec \ell=\int_S(\nabla\times\vec A) \cdot da=\int_S \vec B\cdot d\vec a=\Phi\end{aligned}\]</span></p><h3 id="磁矢势多极展开">磁矢势多极展开</h3><p><span class="math display">\[\begin{aligned}\vec A&amp;=\frac{\mu_0}{4\pi}\int\frac{\vec j(\vec r&#39;)}{|\vec r-\vec r&#39;|}d\tau&#39;\\&amp;=\frac{\mu_0}{4\pi}\sum_{n=0}^\infty \frac{1}{r^{n+1}}\int\vec j(\vec r&#39;)\big[(r&#39;)^n P_n(\cos\theta&#39;)\big]d\tau&#39;\\&amp;=\frac{\mu_0}{4\pi}\int\vec j(\vec r&#39;)\big[\frac 1 r+\frac {r&#39;\cos\theta&#39;}{r^2}+\frac{r&#39;^2(3\cos^2\theta&#39;-1)}{2r^3}+\cdots\big]d\tau&#39;\\\\\vec A_{偶极}&amp;=\frac{\mu_0}{4\pi}\int\vec j(\vec r&#39;)\frac{\vec r&#39;\cdot \vec e_r}{r^2}d\tau&#39;\\&amp;\equiv\frac{\mu_0}{4\pi}\frac{\vec m \times\vec e_r}{r^2}\\\\\vec B_{偶极}&amp;=\frac {\mu_0}{4\pi}\frac{1}{r^3}\left[3(\vec m\cdot\vec e_r)\vec e_r-\vec m\right]\end{aligned}\]</span></p><ul><li>磁偶极矩 <span class="math inline">\(\vec m\)</span> :</li></ul><p><span class="math display">\[\begin{aligned}\vec m&amp;\equiv\frac 1 2\int\vec r&#39;\times\vec j(\vec r&#39;)d\tau&#39;\end{aligned}\]</span></p><p>​ 其中<span class="math inline">\(\vec j\)</span> 为电流密度。</p><ul><li><p>环形电流圈（半径为 <span class="math inline">\(a\)</span> ）： <span class="math display">\[\begin{aligned}\vec m&amp;=\frac1 2 I\oint \vec r&#39;\times d\vec \ell=\frac 1 2 Ia\cdot2\pi a\vec e_k=I\vec S\\m&amp;=\frac {dq}{dt}S=\frac{q_e}{2\pi a/v}\pi a^2=\frac 1 2q_e v r\\\vec A_{偶}&amp;=\frac{\mu_0 I}{4\pi}\frac{\vec S\times \vec e_r}{r^2}\\\vec B_{偶}&amp;=\nabla\times\vec A_{偶}=\frac{\mu_0}{4\pi}\frac{\vec m}{r^3}\cdot (3\vec e_r\vec e_r-\overleftrightarrow I)\\&amp;=\frac{\mu_0}{4\pi}\frac{1}{r^3}[3(\vec m\cdot \vec e_r)\vec e_r-\vec m]\end{aligned}\]</span></p><p>对指向 <span class="math inline">\(z\)</span> 轴的 $m $ : <span class="math display">\[\vec B_{偶}=\frac{\mu_0}{4\pi}\frac{m}{r^3}\left(2\cos\theta\vec e_r+\sin\theta\vec e_\theta\right)\]</span></p></li></ul><h3 id="常用磁场">常用磁场</h3><p>长直导线 <span class="math display">\[\vec B=\frac{\mu_0 I}{4\pi d}\left(\sin\theta_1-\sin\theta_2\right)\]</span></p><h3 id="磁标势">磁标势</h3><p>已知磁化强度 <span class="math inline">\(\vec M\)</span>, 以及静磁方程： <span class="math display">\[\begin{aligned}&amp;\nabla\cdot\vec B=0\\&amp;\nabla\times\vec H=\vec j\\&amp;\vec B=\mu_0(\vec H+\vec M)\end{aligned}\]</span></p><p>对于没有传导电流的<em>单连通区域</em> <span class="math inline">\(V\)</span> : <span class="math inline">\(\nabla\times \vec H=0\)</span></p><p>所以存在磁标势 <span class="math inline">\(\varphi_m\)</span> : <span class="math inline">\(\vec H=-\nabla\varphi_m\)</span></p><p>由静磁方程推出：<span class="math inline">\(\nabla^2\varphi_m=\nabla\cdot \vec M\)</span></p><h2 id="电磁波的传播">8 电磁波的传播</h2><h3 id="能量-1">能量</h3><p><span class="math display">\[\begin{aligned}&amp;u=\frac 1 2 \varepsilon E^2+\frac{1}{2\mu}B^2=\varepsilon E^2=\frac{1}{\mu}B^2\\&amp;\vec S=\frac{1}{\mu}\vec E\times\vec B=cu\hat k\\&amp;\vec g=\frac 1 {c^2}\vec S=\frac 1 c u\hat k\end{aligned}\]</span></p><p>周期平均值： $$ \begin{aligned} fg&amp;=1 2 Re(fg ^*)\ u&amp;=1 2 E^2\ S&amp;=cu\</p><p>\end{aligned} <span class="math display">\[强度与辐射压强：\]</span> \begin{aligned} I&amp;S\ P&amp;=cg== \end{aligned} $$</p><h3 id="偏振">偏振</h3><h3 id="在线性介质中的传播">在线性介质中的传播</h3><p>由相位在边界上相等可以得到折射定律和反射定律，利用边界条件进一步分析可得到菲涅尔定律等。</p><h4 id="折射定律和反射定律的导出">折射定律和反射定律的导出</h4><p>$$ Ae<sup>{i(k_ir-t)}+Be</sup>{i(k_rr-t)}=Ce^{i(k_tr-t)}\</p><p>\begin{cases} <em>i=<em>r=<em>t=kc\ k_ir=k_rr=k_tr|</em>{z=0} \end{cases}\ \begin{aligned} &amp;k</em>{i_x}=k</em>{r_x}=k_{t_x}\ &amp;k_i_i=k_r_r=k_t_t \end{aligned} $$</p><p>进而可以推出折射定律和反射定律。</p><h4 id="菲涅尔定律">菲涅尔定律</h4><p>不抄了，利用边界条件推导即可，没必要记。</p><h4 id="布儒斯特角">布儒斯特角</h4><p>偏振方向平行界面入射的波以这角入射时反射波完全消失。 <span class="math display">\[\theta_B=\arctan \frac{n&#39;}{n}\]</span></p><h3 id="在导电介质中的传播">在导电介质中的传播</h3><h4 id="麦克斯韦方程">麦克斯韦方程</h4><p><span class="math display">\[\begin{aligned}\nabla\cdot \vec E&amp;=0\\\nabla\cdot \vec B&amp;=0\\\nabla\times\vec E&amp;=-\frac{\partial\vec B}{\partial t}\\\nabla\times\vec B&amp;=\mu\varepsilon \frac{\partial \vec E}{\partial t}+\mu\sigma\vec E\end{aligned}\]</span></p><p>良导体。差别在磁场的旋度中多了一项。</p><h4 id="平面波解">平面波解</h4><p><span class="math display">\[\widetilde E(z,t)=\widetilde E_0e^{-\kappa z}e^{i(kz-\omega t)}\\\widetilde B(z,t)=\widetilde B_0e^{-\kappa z}e^{i(kz-\omega t)}\\\notag\]</span></p><p>注意电场与磁场不再同相，振幅的倍数也不再是 <span class="math inline">\(c\)</span> : <span class="math display">\[\begin{aligned}&amp;\widetilde B_0=\frac{\widetilde k}{\omega}\widetilde  E_0=\frac{Ke^{i\phi}}{\omega}\widetilde  E_0 \\&amp;\frac{B_0}{E_0}=\frac{K}{\omega}=\sqrt{\varepsilon\mu\sqrt{1+\left(\frac{\sigma}{\varepsilon\omega}\right)^2}}\end{aligned}\]</span></p><h4 id="折射定律和反射定律">折射定律和反射定律</h4><p>仍然成立。</p><h3 id="波导">波导</h3><h4 id="边界条件-1">边界条件</h4><p><span class="math display">\[\begin{cases}\vec E^{\parallel}=0\\\vec B^\perp=0\end{cases}\notag\]</span></p><p>磁场和电场不同的边界条件导致 <span class="math inline">\(TE\)</span> 和 <span class="math inline">\(TM\)</span> 波的不同。</p><h4 id="重要方程">重要方程</h4><p>由于导体的影响，波导内的波一般不再是横波。推导中引入了纵向分量: <span class="math display">\[\widetilde E_0=E_x\hat x+E_y \hat y +E_z\hat z\\\widetilde B_0=B_x\hat x+B_y \hat y +B_z\hat z\notag\]</span> 代入麦克斯韦方程组可以写出各分量方程。</p><p>最后得到独立的 <span class="math inline">\(E_z\)</span> 和 <span class="math inline">\(B_z\)</span> 的方程： <span class="math display">\[\left[\frac{\partial^2}{\partial x^2}+\frac{\partial^2}{\partial y^2}+\left(\frac{\omega}{c}\right)^2-k^2\right]E_z=0\\\left[\frac{\partial^2}{\partial x^2}+\frac{\partial^2}{\partial y^2}+\left(\frac{\omega}{c}\right)^2-k^2\right]B_z=0\]</span></p><h4 id="重要结论">重要结论</h4><p>中空波导中 <span class="math inline">\(TEM\)</span> 波不能发生。</p><h4 id="矩形波导">矩形波导</h4><h5 id="te-波"><span class="math inline">\(TE\)</span> 波</h5><p><span class="math inline">\(E_z=0\)</span>, 分离变量求解得： <span class="math display">\[B_z=B_0\cos(\frac{m\pi}{a}x)\cos(\frac{n\pi}{b}y)\notag\]</span></p><h5 id="tm-波"><span class="math inline">\(TM\)</span> 波</h5><p><span class="math inline">\(B_z=0\)</span>. <span class="math display">\[E_z=E_0\sin(\frac{m\pi}{a}x)\sin(\frac{n\pi}{b}y)\notag\]</span></p><h5 id="相关物理量">相关物理量</h5><p><span class="math display">\[\begin{aligned}&amp;k_x=\frac{m\pi}{a},k_y=\frac{n\pi}{b}\\&amp;\omega_{mn}\equiv c\sqrt{k_x^2+k_y^2}=c\pi\sqrt{\left(\frac{m}{a}\right)^2+\left(\frac{n}{b}\right)^2}(\text{截断频率})\\&amp;k=\sqrt{\left(\frac{\omega}{c}\right)^2-k_x^2-k_y^2}=\frac{1}{c}\sqrt{\omega^2-\omega_{mn}^2}\end{aligned}\]</span></p><h5 id="波速与群速度">波速与群速度</h5><p><span class="math display">\[\begin{aligned}&amp;v=\frac \omega k=\frac{c}{\sqrt{1-(\omega/\omega_{mn})^2}}\\&amp;v_g=\frac{1}{dk/d\omega}=c \sqrt{1-(\omega/\omega_{mn})^2}\end{aligned}\]</span></p><h2 id="电磁波的激发">9 电磁波的激发</h2><h3 id="麦克斯韦方程组的探讨">麦克斯韦方程组的探讨</h3><p><span class="math display">\[\begin{align}\nabla\cdot \vec E&amp;=-\frac {\rho(\vec r,t)}{\varepsilon}\label{E-divergence}\\\nabla\times\vec E&amp;=-\frac{\partial \vec B}{\partial t}\label{E-curl}\\\nabla\cdot\vec B&amp;=0\label{B-divergence}\\\nabla \times\vec B&amp;=\mu\vec J+\varepsilon\mu\frac{\partial\vec E}{\partial t}\label{B-curl}\end{align}\]</span></p><p><span class="math inline">\(\vec J\)</span> 是电流密度。</p><p>由标势和矢势可以确定电场和磁场：</p><p>由 <span class="math inline">\((\ref{B-divergence})\)</span> 可得 <span class="math display">\[\vec B=\nabla\times\vec A\label{B}\]</span> 这将确定磁场。</p><p>由 <span class="math inline">\((\ref{E-curl})\)</span> 可得 <span class="math display">\[\begin{align}&amp;\nabla\times\left (\vec E+\frac{\partial \vec A}{\partial t}\right)=0\notag \\\implies &amp;\vec E=-\nabla \varphi-\frac{\partial \vec A}{\partial t}\label{E}\end{align}\]</span> 这将确定电场。</p><p>由 <span class="math inline">\((\ref{E-divergence})\)</span> 和 <span class="math inline">\((\ref{B-curl})\)</span> 可以确定电荷分布和电流分布： <span class="math display">\[\begin{align}-\frac{\rho} \varepsilon&amp;=\nabla^2\varphi+\frac{\partial}{\partial t}(\nabla\cdot \vec A)\\-\mu \vec J&amp;=\nabla^2\vec A-\varepsilon\mu\frac{\partial^2 }{\partial t^2}\vec A-\nabla\left(\nabla\cdot \vec A+\varepsilon\mu \frac{\partial}{\partial t }\varphi \right)\end{align}\]</span></p><p>麦克斯韦方程组本来有六个变量 <span class="math inline">\(E_x,E_y,E_z,B_x,B_y,B_z\)</span> ，利用矢势和标势将其浓缩为四个变量 <span class="math inline">\(A_x,A_y,A_z,V\)</span> ，留下两个自由度可以用来做规范变换。</p><h3 id="规范变换">规范变换</h3><h4 id="一般规范">一般规范</h4><p><span class="math display">\[\begin{aligned}&amp;\varphi\mapsto  \varphi&#39;=\varphi+\alpha(\vec r,t)\\&amp;\vec A\mapsto  \vec A&#39;=\vec A+\vec \beta(\vec r,t)\end{aligned}\]</span></p><p>代入 <span class="math inline">\((\ref{B})\)</span> <span class="math inline">\(\vec B\)</span> 应保持不变，得到 <span class="math inline">\(\nabla\times\vec \beta=0\)</span></p><p>再代入 <span class="math inline">\((\ref{E})\)</span> <span class="math inline">\(\vec E\)</span> 也应保持不变，得到 <span class="math inline">\(\nabla \alpha+\displaystyle\frac{\partial\vec \beta}{\partial t}=0\)</span></p><p><span class="math inline">\(\implies\)</span> <span class="math display">\[\begin{align}&amp;\varphi\mapsto  \varphi&#39;=\varphi-\frac{\partial}{\partial t}\lambda \\&amp;\vec A\mapsto  \vec A&#39;=\vec A+\nabla\lambda\end{align}\]</span></p><h4 id="库仑规范">库仑规范</h4><p>选取 <span class="math inline">\(\lambda\)</span> 使 <span class="math display">\[\nabla\cdot \vec A=0\notag\]</span></p><h4 id="洛伦兹规范">洛伦兹规范</h4><p>选取 <span class="math inline">\(\lambda\)</span> 使 <span class="math display">\[\nabla\cdot \vec A+\epsilon\mu\frac{\partial}{\partial t}\varphi=0\]</span></p><h3 id="推迟势">推迟势</h3><p><span class="math display">\[\begin{align}\varphi&amp;=\frac{1}{4\pi\varepsilon_0}\int \frac{\rho(\vec r&#39;,t_r)}{|\vec r-\vec r&#39;| }d\tau&#39;\\\vec A&amp;=\frac {\mu_0}{4\pi}\int \frac{\vec J(\vec r&#39;,t_r)}{|\vec r-\vec r&#39;|}d\tau&#39;\\t_r&amp;=t-\frac{|\vec r-\vec r&#39;|}{c}\end{align}\]</span></p><p>非静止状态下，信息不是源现在的状态，而是较早时间 <span class="math inline">\(t_r\)</span> 时信息离开当时的源时的状态。</p><p><strong>证明</strong>：</p><p>洛伦兹规范下，得到（真空中） <span class="math display">\[\begin{cases}\displaystyle\nabla^2 \vec A-\frac 1 {c^2}\frac {\partial^2}{\partial t^2}\vec A=-\mu_0\vec J\\\displaystyle\nabla^2 \varphi-\frac 1 {c^2}\frac{\partial^2}{\partial t^2}\varphi=-\frac{\rho}{\varepsilon_0}\end{cases}\notag\]</span> 考虑 <span class="math display">\[\nabla^2 \psi-\frac 1 {c^2}\frac{\partial^2}{\partial t^2}\psi=-4\pi f(\vec r,t)\notag\]</span> 将 <span class="math inline">\(f\)</span> 写成点源形式 <span class="math display">\[f(\vec r,t)=\int f(\vec r&#39;,t)\delta(\vec r-\vec r&#39;)d\tau&#39;\notag\]</span> 将 <span class="math inline">\(\psi\)</span> 也写成如此形式 <span class="math display">\[\psi=\int G(\vec r-\vec r&#39;,t)d\tau&#39;\notag\]</span> 可以得到 <span class="math display">\[\nabla^2 G-\frac 1 {c^2}\frac{\partial^2}{\partial t^2}G=-4\pi f(\vec r&#39;,t)\delta(\vec r-\vec r&#39;)\notag\]</span> 可以固定这时的 <span class="math inline">\(\vec r’\)</span> 为源点，利用球坐标拉普拉斯算子得到 <span class="math display">\[\frac 1{r^2}\frac{\partial}{\partial r}\left(r^2\frac{\partial}{\partial r}G\right)-\frac 1 {c^2}\frac{\partial^2}{\partial t^2}G=0\qquad(\vec r\neq \vec 0)\notag\]</span> 令 <span class="math inline">\(R(\vec r,t)=r G(\vec r,t)\)</span>, 得到 <span class="math display">\[\left(\frac{\partial}{\partial r}-\frac 1 c \frac{\partial}{\partial t}\right)\left(\frac{\partial}{\partial r}+\frac 1 c \frac{\partial}{\partial t}\right)R=0\notag\]</span> 引入光锥坐标 <span class="math display">\[\begin{align}u=r-ct\\v=r+ct\end{align}\]</span> 可得 <span class="math display">\[\begin{aligned}&amp;4\frac{\partial^2}{\partial u \partial v}R=0\\\implies\quad &amp;R(u,v)=g_1(k_1u)+g_2(k_2 v)\end{aligned}\]</span> 取 <span class="math inline">\(\displaystyle k_1=-\frac{1}{c},k_2=\frac 1 c\)</span> ，并舍去超前时间，最终得到 <span class="math display">\[G=\frac 1 r g_1(t-\frac r c)\notag\]</span></p><p><span class="math inline">\(\vec r\to \vec 0\)</span> 时，对时间的偏导相对梯度都可以略去，有 <span class="math display">\[\begin{aligned}\nabla^2 G(\vec r,t)&amp;=-4\pi f(\vec 0,t)\delta(\vec r)\\\implies \lim_{\vec r\to\vec 0} G&amp;=\frac{f(\vec 0,t) }r\end{aligned}\]</span> 对比非零处可以得到 <span class="math display">\[g_1(t-\frac r c)=f(\vec 0,t-\frac r c)\notag\]</span></p><p>$$ \begin{aligned} G(r,t)&amp;=&amp; r'=0\ G(r-r',t)&amp;=&amp; r'0\ (r,t)&amp;=G(r-r',t)d'</p><p>\end{aligned} $$</p><h3 id="李纳-维谢尔势">李纳-维谢尔势</h3><p>特定轨迹 <span class="math inline">\(\vec w(t)\)</span> 的运动点电荷产生的势（推迟势）。 $$ <span class="math display">\[\begin{align}\phi(\vec r,t)&amp;=\frac{1}{4\pi\varepsilon_0}\frac{q}{|\vec r-\vec w(t_r)|}\cdot \frac{1}{\displaystyle 1-\frac{\vec v(t_r)}{c}\cdot\frac{\vec r-\vec w(t_r)}{|\vec r-\vec w(t_r)|}}\\&amp;=\frac{1}{4\pi\varepsilon_0}\frac{q}{|\vec R|}\cdot \frac{1}{\displaystyle1-\frac{\vec v(t_r)}{c}\cdot \hat R}\\\vec A(\vec r,t)&amp;=\frac{\vec v(t_r)}{c^2}\varphi(\vec r,t)\end{align}\]</span> $$</p><p>注意这里面最终的时间都是推迟时间。</p><p>其中，有一些重要的量和关系经常用到： $$ <span class="math display">\[\begin{align}\vec R&amp;=\vec r-\vec w(t_r)\\t_r&amp;=t-\frac{|\vec r-\vec w(t_r)|}{c}=t-\frac{|\vec R|}{c}\\\vec v(t)&amp;=\vec w&#39;(t)=\frac{d}{dt}\vec w(t)\\\vec v(t_r)&amp;=\vec w &#39;(t_r)=\frac{d}{d t_r}\vec w(t_r)\\(&amp;=\frac {d}{dt}\vec w(t)\biggm|_{t=t_r}=\frac {d}{d t_r}\vec w(t)\cdot\frac{d t_r}{dt})\notag\\\end{align}\]</span> $$</p><p>比较神奇的是，因子 <span class="math inline">\(\displaystyle\frac{1}{\displaystyle 1-\frac{\vec v(t_r)}{c}\cdot \hat R}\)</span> 恰好是 推迟时间对时间的导数： <span class="math display">\[\begin{align}&amp;c(t-t_r)= |\vec R|\\\implies &amp;c(1-\partial_t t_r)=\partial_t R=\partial_{t_r}R\cdot \partial_t t_r\notag\\\implies &amp;\partial_t t_r=\frac{1}{1-\displaystyle\frac 1 c\partial_{t_r}R}\notag\\\notag \\\because\quad \partial_{t_r}R&amp;\overset{技巧}{=}\frac{\partial\sqrt{\vec R\cdot \vec R}}{\partial t_r}\notag \\&amp;=\frac{\vec R}{R}\frac{\partial\vec R}{\partial t_r}\notag \\&amp;=\vec w&#39;(t_r)\cdot \hat {R}=\vec v\cdot \hat{R}\notag\\\therefore\quad \partial_t t_r&amp;=\displaystyle\frac{1}{\displaystyle 1-\frac{\vec v(t_r)}{c}\cdot \hat R}\end{align}\]</span></p><h3 id="运动电荷的场">运动电荷的场</h3><h4 id="一般运动电荷的场">一般运动电荷的场</h4><p>艰难链式法则求导。 $$ <span class="math display">\[\begin{align}\vec E&amp;=\frac q {4\pi\varepsilon_0}\frac{R}{(\vec R\cdot\vec u)^3}\left[(c^2-v^2)\vec u+\vec R\times (\vec u\times \vec a)\right]\\\vec B&amp;=\frac 1 c \hat R\times\vec E\\ \notag \\t_r&amp;=t-\frac{R}{c}\quad (or: c(t-t_r)=R)\label{t_r}\\\vec R&amp;=\vec r-\vec w(t_r),\label{r-w(t_r)}\\ \vec u&amp;=c\hat R-\vec v,\\\vec v&amp;=\vec v(t_r)=\partial_{t_r}w(t_r),=w&#39;(t_r)\notag\\ \vec a&amp;=w&#39;&#39;(t_r)\notag\end{align}\]</span> $$ 其中 ，<span class="math inline">\(\vec E\)</span> 的第一项为广义库仑场, 第二项为辐射场。由 <span class="math inline">\((\ref{t_r})\)</span> 和 <span class="math inline">\((\ref{r-w(t_r)})\)</span> 可以解出 <span class="math inline">\(t_r\)</span> 。</p><h4 id="匀速运动电荷的场">匀速运动电荷的场</h4><p><span class="math inline">\(\vec a=0,\vec w(t)=\vec v t\)</span>。 <span class="math display">\[\begin{align}\vec E(\vec r,t)&amp;=\frac{q}{4\pi\varepsilon_0}\frac{1-v^2/c^2}{\left(1-v^2\sin^2\theta/c^2\right)^{\frac 3 2}}\frac{\vec r-\vec v t}{|\vec r -\vec v t|^3}\\\vec B&amp;=\frac 1 c \hat R\times \vec E=\frac 1 {c^2}(\vec v\times \vec E)\end{align}\]</span></p><p><img src="https://tva1.sinaimg.cn/large/007S8ZIlly1gebpwaba5qj30wa0rsjsw.jpg" style="zoom:25%;" /></p><p>运动垂直方向上： <span class="math display">\[\vec E=\frac{q}{4\pi\varepsilon_0}\frac{1}{\rho^2}\frac{1}{\sqrt{1-v^2/c^2}}\vec e_\rho\]</span> 运动水平方向上： <span class="math display">\[\vec E=\frac{1}{4\pi\varepsilon_0}\frac 1 {\rho^2}\cdot(1-v^2/c^2)\vec e_\rho\]</span></p><h2 id="习题">习题</h2><h3 id="高斯定律-1">高斯定律</h3><p>Three isolated infinite metal (i.e. conducting) slabs have their normals along the <em>z</em> axis, so the slabs are parallel to each other. The top slab has total charge <em>Q</em>, while the bottom slab has total charge <em>q</em>. Find the charge on the top surfaces of each slab and on the bottom surfaces of each slab. (<a href="chrome-extension://ohfgljdgelakfkefopgklcohadegdpjf/https://web.pa.msu.edu/people/duxbury/courses/phy481/Fall2009/MidtermIBSolutions-2009.pdf">Solusion</a>)</p>]]></content>
      
      
      <categories>
          
          <category> Physics </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>2020</title>
      <link href="/2020/02/11/Other%20Things/2020/"/>
      <url>/2020/02/11/Other%20Things/2020/</url>
      
        <content type="html"><![CDATA[<h2 id="section">2020</h2><ul><li><p>大二冬学期期末 1.1～1.17</p></li><li><p>搞博客，研究hexo 1.17～1.20</p></li><li><p><a href="%5Bhttps://github.com/Pratitya/wuhan2020-timeline/blob/master/%E6%97%B6%E9%97%B4%E7%BA%BFTIMELINE.md%5D(https://github.com/Pratitya/wuhan2020-timeline/blob/master/时间线TIMELINE.md)">新冠病毒</a></p><p>$ \ $ <a id="more"></a></p><ul><li>2019.12.1 第一位武汉市民有不明原因症状</li><li>2019.12.8 第一例武汉不明原因肺炎病人发病</li><li>2019.12.31 武汉卫健委公开通报出现“不明原因肺炎” 27人</li><li>1.3 武汉市卫健委通，称未发现“人传人”证据。44人</li><li>1.5 56人疑似。</li><li>1.8 中国国家卫健委称，“新型冠状病毒”为<em>疫情病原</em>，多名医护人员陆续感染</li><li>1.9 第一例死亡病例。</li><li>1.16 日本出现。湖北“两会“闭幕。</li><li>1.18 通报新增4例，武汉百步亭“万家宴”</li><li>1.20 通报确诊136例，北京和深圳出现首次疫情报告，钟南山确认“人传人”</li><li>美国、台湾出现。湖北省委书记、省长等出席春节团拜、观看演出。</li><li>香港、澳门出现。</li><li>1.23 武汉、黄冈等封城。 湖北省确诊444人，8人死亡。浙江、广东、湖南启动一级应急响应。</li><li>1.24 除夕，前线医护人员求助物资不足。湖北、北京、上海、安徽、重庆、天津、四川、云南、贵州、山东、福建启动一级响应。“火神山医院” 七日紧急搭建开始。红十字会医院很多遗体处理不过来。国际上英国专家警告，至少4000人，武汉最坏情况为，近万人染病。</li><li>1.25 春晚。白岩松：“我们在这过年，你们在帮我们过关。”武汉准备半个月内再建一所“雷神山医院”。</li><li>1.26 美国关闭武汉领事馆并撤侨。</li><li>1.27 中国大陆确诊4515人。</li><li>1.29 3554人。寿光向武汉捐350吨蔬菜。被低价出售。</li><li>1.30 7771人。WHO宣布疫情构成“国际突发公共卫生事件”。西藏确诊首例病例，疫情已蔓延至中国所有省份。黑十字会。</li><li>2.1 突破10000人。澳大利亚政府拒绝所有来自或途径中国对非澳大利亚公民入境。抢双黄连风波。德国种族歧视袭击。</li><li>2.2 湖北对所有疑似病例进行集中隔离，开始搭建方舱医院。火神山医院交付。</li><li>2.3 上证综指暴跌7%。中国多家媒体收到关于疫情的报道禁令。</li><li>2.4 晋江毒王。</li><li>2.6/7 李文亮医生去世。</li><li>2.8 元宵节。36000人。超过800人死亡。</li><li>武软的强盗行为。</li><li>2.11 42744人。</li><li>2.12 48206人。</li><li>2.14 51986人。</li><li>2.15 66492人。</li><li>2.19 74185人。</li><li>“钻石公主”号 移动的病毒库</li><li>2.21 济宁任城监狱 200+人</li><li>2.26 韩国疫情日益严重</li><li>3.7 福建泉州欣佳快捷酒店坍塌 是医学观察点</li><li>3.7 下午 方舱医院患者清零 东西湖方舱明日起休舱</li><li>3.10 美股熔断</li><li>3.11 美股高开，大V反弹。意大利疫情加重，监狱暴动；在过去的24小时，塔利班在阿富汗15省发动了32次袭击。俄罗斯通过宪法修正案草案。洛杉矶万人马拉松开跑。（“说起马拉松，想必不少网友会想起那场将意大利拖入绝境的马拉松。正是因为有一名超级传染者夹杂在了比赛中，这才使得近5万人成为了疑似病例。眼下意大利确诊人数已经突破了6000人，总理宣布将北方地区封锁。”）</li><li>3.13 英国准备拖延疫情，“等百分之六十人感染”，“获得群体免疫”。根据流行病学的研究，不知道会如何。</li><li>3.15 塞尔维亚宣布进入紧急状态，塞尔维亚总统几度哽咽请求中国援助。“我们请求中国提供一切帮助”。加油，都加油，努力，再努力。</li><li>3.23 意大利新增新冠肺炎5560例，累计确诊59138例；美国共报告新冠肺炎确诊32717例。</li><li>3.24 过去24小时，西班牙新增新冠肺炎确诊病例6584例，累计确诊39673例。新增死亡病例514例，累计死亡2696例。</li><li>美国新冠肺炎确诊病例达53268例，新增确诊病例达10054例。</li><li>3.27 英国首相鲍里斯·约翰逊确诊肺炎。这两天每天美国单日增13000+。德国累计确诊新冠肺炎49039例，单日新增近6000例。</li><li>3.28 美国单日新增超两万。法国向中国订购10亿只口罩，通过56次来回完成交运工作。特朗普签署台北法案。</li><li>4.2 一百万。 全球新冠肺炎确诊病例达1002159例，死亡病例为51485例。美国新冠肺炎确诊病例升至236339例，是目前确诊病例最多的国家，其死亡病例为5648例；意大利死亡病例达13915例，是目前死亡病例最多的国，其确诊病例为115242例；西班牙确诊病例达110238例，死亡病例为10096例。</li><li>4.4 全国默哀，全网黑白。纳入疗养院数据后，法国确诊病例跳跃性增至83029例。西班牙在过去24小时新增7026例，累计确诊124736例。</li><li>2020.4.7 山东援鄂护师张静静因抢救无效离世。英国首相约翰逊被转进重症监护室。法国单日死亡833人居欧洲首位，医院累计确诊74390例，养老院累计23620例。美国新增确诊病例27235例，新增死亡1127例，累计确诊362759例。</li><li>4.15 加油，意大利。意大利新增确诊2972例，新增死亡602例，为3月14日以来最低增幅。</li><li>4.16 两百万。全球确诊病例已超过200万例，达2000984例。累计死亡病例达128011例。哈尔滨聚集性疫情，传染链出现“跨省”传播，1传43。</li><li>4.18 非洲。过去一周非洲病例增加51%。</li><li>4.20 印度新冠肺炎确诊病例已升至16116例。其中死亡519例，治愈出院2302例。在过去24小时内，印度共新增1324例确诊病例。 美国累计确诊755533例，死亡40461例。新增确诊病例28888例，新增死亡2523例。</li><li>4.26 美国共有新冠病毒感染病例9333050例，新增感染病例42526例，新增死亡病例2374例。</li></ul></li><li><p>日本：山川异域，风月同天。</p></li><li><p>科比遇难 1.27 凌晨四点</p></li><li><p>2.14--2.18 美赛 with l,z.</p></li><li><p>2.24 浙大线上开学</p></li><li><p>2.27 巴基斯坦蝗灾</p></li><li><p>3.30 西昌突发山火。</p></li><li><p>3.31 2020年全国高考延期一个月举行，考试时间为7月7日至8日。</p></li><li><p>4.16 电动力学期中测试，打击与反转</p></li><li><p>4.24 罗志祥、肖战、柯洁</p></li></ul><p>多度paper多度经典文献建立整个学科面貌的认识，培养自己独立的科研兴趣和观点。</p>]]></content>
      
      
      <categories>
          
          <category> Life </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>Movies</title>
      <link href="/2020/02/07/Other%20Things/Movies/"/>
      <url>/2020/02/07/Other%20Things/Movies/</url>
      
        <content type="html"><![CDATA[<h1 id="电影们">电影们</h1><ul><li>小丑</li><li>爱尔兰杀手</li></ul>]]></content>
      
      
      <categories>
          
          <category> life </category>
          
          <category> movie </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>Mathematic Modeling</title>
      <link href="/2020/02/07/Mathematics/Mathematical-Modeling/"/>
      <url>/2020/02/07/Mathematics/Mathematical-Modeling/</url>
      
        <content type="html"><![CDATA[<h1 id="美赛历年题目学习">美赛历年题目学习</h1><h2 id="english">English</h2><ul><li>a schematic diagram</li><li>Attributes 属性</li></ul><h2 id="icm-d">2016 ICM D</h2><h3 id="关键词">1. 关键词</h3><p>信息.</p><h3 id="有用的理论">2. 有用的理论</h3><ul><li>图论<ul><li>Nodes<ul><li>Type : media / person node</li><li>Degree</li><li>State : unknown, known, tired</li></ul></li><li>Edges<ul><li>Start node</li><li>End node</li><li>Time ( ～ communication tools )</li></ul></li></ul></li><li>Pareto Principle<ul><li>帕雷托法则指出，约仅有20%的变因操纵着80%的局面。也就是说：所有变量中，最重要的仅有20%，虽然剩余的80%占了多数，控制的范围却远低于“关键的少数”。</li><li>应用： If the news value meets the Pareto principle, then 20% of the news contains 80% of the total value of all the news in real world.</li></ul></li></ul><p>$ \ $ <a id="more"></a></p><ul><li><p>Indifference Curve 无差异曲线</p><ul><li><p>一条表示当消费者获得同样的效用时的消费组合曲线，其斜率一般为负值，这在经济学中表明在收入与价格既定的条件下，消费者为了获得同样的效用，增加一种商品的消费就必须减少或放弃另一种商品的消费，两种商品在消费者偏好不变的条件下，不能同时减少或增加。</p></li><li><p>应用：构造方程。“This function meets all the typical properties of an Indifference Curve. Thus it can be used to measure information’s inherent value based on its attributes.”</p></li></ul></li><li>Product life-cycle theory ( 产品生命周期理论， PLC )<ul><li>产品生命是指市上的营销生命，产品和人的生命一样，要经历形成，成长，成熟，衰退这样的周期。就产品而言，也就是要经历一个开发，转移，成长，成熟，衰退的阶段。而这个周期在不同的技术水平的国家里，发生的时间和过程是不一样的，期间存在一个相互矛盾的差异和时差，正是这一时差，表现为不同国家在技术上的差距，它反映了同一产品在不同国家市场上的竞争层次的差异，从而决定了国际贸易和国际投资的变化。</li><li>应用：利用产品生命周期理论模拟新通讯网络的诞生和旧通讯网络的衰落</li></ul></li></ul><h3 id="o奖论文结构">3. O奖论文结构</h3><ul><li><p>引言、问题重述、假设、符号规定</p></li><li>利用图论建立通讯网络的拓扑图，微观（个人-个人）/ 宏观（媒体-个人）</li><li>建立信息价值模型 ，定义了信息的三个属性/类别 （极端、娱乐、新闻），利用无差异曲线和二八定律（帕雷托法则）构造出信息价值的方程，给出了评判信息是否为新闻的标准</li><li>建立信息流动的动态模型 ，主要给出了信息流动的过程（绘制了简易流程图）</li><li>利用BBC新闻的信息流动来作为模型检验和应用的例子，进行了信息的流动模拟仿真</li><li>利用产品生命周期理论建立信息网络更新换代的模型，用以预测2050年的信息网络变化。给网络容量下了公式定义，并给出了不同的网络性能量化指标。提出未来的三十年将出现三种新的信息网络，并给出了网络的强度（人们使用的频繁程度），然后用线性函数简化模型，给出了新的信息网络生命周期的线性函数表达式。</li><li>模型进一步扩展，加入了人的选择因素，引入“门槛效应”建立新的信息流动机制</li><li><p>灵敏性分析（不知道图是怎么做出来的）、模型优缺点分析</p></li></ul><h3 id="总结">4. 总结</h3><ul><li>他们的论文解释的很多很详细，但是就是不知道图是怎么出来的，数据怎么得到的。有的地方给出了公式或者文字说了好多就过去了，似乎不用计算。</li><li>灵活地应用了各种经济学的模型</li><li>查阅了详尽资料论文，信息网络有前人的论文可借鉴</li><li>我们的想法：可以引入香农的信息论内容进行分析</li></ul><h2 id="icm-e">2017 ICM E</h2><h3 id="关键词-1">1. 关键词</h3><p>smart growth</p><p>模糊综合评价、层次分析法</p><h3 id="我们的想法">2. 我们的想法</h3><h4 id="smart-growth-的10个原则一级指标">2.1 smart growth 的10个原则（一级指标）</h4><p><span class="math inline">\(U=\{U_i\mid i=1,\cdots,10\}\)</span></p><p>给出一级指标集对应的权重向量 <span class="math inline">\(A=[a_1,\cdots,a_{10}]\)</span></p><h4 id="衡量一座城市的10大指标">2.2 衡量一座城市的10大指标</h4><p><span class="math inline">\(V=\{v_i\mid i=1,\cdots10\}\)</span></p><p>对每个 <span class="math inline">\(U_i\)</span> , 取其中不同的 <span class="math inline">\(s\)</span> 个指标作为评判不同 <span class="math inline">\(U_i\)</span> 的二级指标。</p><p>可以给出 <span class="math inline">\(U_i\)</span> 的指标集对应的权重向量 <span class="math inline">\(A_i=[a_1,\cdots,a_{s}]\)</span></p><h4 id="定义评语集成功度">2.3 定义评语集：成功度</h4><p><span class="math inline">\(S=\{s_i\mid i=1,\cdots,m\}\)</span></p><h4 id="综合评价">2.4 综合评价</h4><ul><li><p>根据成功度对不同的二级指标作出评判，得到 10 个二级指标的 <span class="math inline">\(s\times m\)</span> 评判向量 <span class="math inline">\(R_i\)</span> , $ i=1,,10$</p></li><li><p>第 <span class="math inline">\(i\)</span> 个一级指标的评判结果：<span class="math inline">\(B_i=A_i\cdot R_i\)</span>， 组成综合评判矩阵 <span class="math inline">\(R=[B_1;\cdots;B_{10}]\)</span></p></li><li><p>最终综合评判结果 <span class="math inline">\(B=A\cdot R\)</span> , 根据最大隶属度原则，取 <span class="math inline">\(B\)</span> 中最大值对应的成功度作为城市 smart growth 的成功度</p></li></ul><h2 id="o奖论文学习">3 O奖论文学习</h2><h3 id="english-1">3.1 English</h3><p>propose feasible plan</p><p>To ameliorate this situation</p><p>According to the optimization model aforementioned</p><h3 id="有用的东西可学习的东西">3.2 有用的东西/可学习的东西</h3><ul><li><p>flow chart</p></li><li><p>表格里添加不同浅色背景</p></li><li><p>数据归一化处理方法</p></li><li><p>AHP：层次分析法</p></li><li><p>友好的Latex注记方式：<a href="https://www.latexstudio.net/archives/51620.html" target="_blank" rel="noopener">添加脚注</a></p></li><li><p>Entropy Weight Method 熵权法：确定综合评价的权重</p><p>客观赋权法，仅依赖于数据本身的离散性</p></li><li><p>K-means clustering Algorithm ：K-均值聚类</p><ul><li>把 n 个点（可以是样本的一次观察或一个实例）划分到 k 个聚类中，使得每个点都属于离他最近的均值（此即聚类中心）对应的聚类，以之作为聚类的标准。</li><li>应用：（甚妙）文中利用K均值聚类方法，通过求解非线性规划问题，得到衡量城市“smart growth”不同方面程度的量化值（类似“成功度”）</li></ul></li><li><p><a href="https://zhuanlan.zhihu.com/p/33692660" target="_blank" rel="noopener">SVM 和 SVR</a></p></li><li><p>“ grid search algorithm ” 调整模型参数的算法（其实就是穷举）</p></li><li><p>Time Series Forecasting</p><p>时间序列预测,机器学习的一个重要领域</p></li><li><p>创新地结合SVM和时间序列预测方法（加权移动平均法），提出对未来的预测模型</p></li><li><p>radar diagram 雷达图</p></li></ul><h3 id="o奖论文结构-1">3.3 O奖论文结构</h3><ul><li>引言、模型假设、符号说明</li><li>二级模糊综合评价，完成任务一。权重矩阵由层次分析法、“专家”评估法、熵权法获得；使用K-均值聚类方法获得城市“成功度”的量化值</li><li>使用雷达图、条形图介绍和对比两城市的现有发展规划，完成任务二</li><li>提出基于smart growth的城市发展规划，使用时间序列分析方法和支持向量机给出预测模型，完成任务三</li><li>根据不同城市的水平，提出不同的人口增长模型，在此基础上通过雷达图表现预测结果</li><li><p>用Matlab画了个三维图（参数1，参数2，误差）作为灵敏度分析</p></li><li><p>优缺点分析</p></li></ul><h2 id="icm-d-1">2018 ICM D</h2><h3 id="关键词-2">关键词</h3><p>充电汽车，充电网络</p><h3 id="建模解题">建模解题</h3><h3 id="task-1">Task 1</h3><p>Is Tesla on track to allow a complete switch to all-electric in the US? If everyone switched to all-electric personal passenger vehicles in the US, how many charging stations would be needed, and how should they be distributed between urban, suburban, and rural areas?</p><h4 id="符号说明">符号说明</h4><ul><li><p>充电桩数量：<span class="math inline">\(N_c\)</span></p></li><li><p>汽车拥有量: <span class="math inline">\(N\)</span></p></li><li><p>充电汽车占有率：<span class="math inline">\(\alpha\)</span></p></li><li><p>在用电动汽车总数 ：$N_{EV}=N $</p></li><li><p>每天汽车总加油量 : <span class="math inline">\(G\)</span></p></li><li><p>每天内汽车总里程 <span class="math inline">\(S=S(G)\)</span></p></li><li><p><span class="math inline">\(N_c=f(P,s,\cdots)\)</span></p></li></ul><h4 id="确定充电桩数量">确定充电桩数量</h4><ol type="1"><li>一段时间内总的充电电动汽车数量：</li></ol><ul><li><p>电动汽车蓄电池的充电时间是一个受使用者偏好等随机因素影响的随机变量，根据中心极限定理，可认为电动汽车的平均充电时间服从正态分布 <span class="math inline">\(N(\mu,\sigma)\)</span>，即不同的充电时间 <span class="math inline">\(t\)</span> 发生的概率为 <span class="math inline">\(\phi(t)\)</span>.</p></li><li><p><span class="math inline">\(\mu,\sigma\)</span> 和电动汽车的普及程度 、电动汽车各类型比例、不同类型电动汽车的充电时间有关，可以按两种类型的充电桩分别讨论</p></li><li><p>时间段 <span class="math inline">\(T\)</span> 内，在充电汽车数量： <span class="math display">\[N_{charging}=N_{EV}\int_{T_0}^{T_0+T} \phi(t)dt\]</span></p></li></ul><ol start="2" type="1"><li><p>设置充电桩以不改变客户的出行方式为目的，就是假设确保不改变总里程 <span class="math inline">\(S\)</span>, 每天充电总需求时间 <span class="math inline">\(T_R=T_R(S)\)</span></p></li><li><p>设每天每辆汽车平均充电 <span class="math inline">\(m\)</span> 次，每天充电总供给时间 $T_S=N_{charing}t m $</p></li><li><p>确定 <span class="math inline">\(\mu\)</span>: 推荐加油时常</p></li><li><p>确定 <span class="math inline">\(\sigma\)</span></p></li><li><p>想法二：获得美国充电站数量的历年数据，使用预测方法推出需要的充电站数量。这也可以对上面的模型进行检验。</p></li><li><p>想法三：根据加油站数量等的历史数据，拟合出加油站数量在成长阶段的增长曲线。然后进行常数变异，拟合充电站的增长曲线。同样可以对上面的模型进行检验。</p></li></ol><h4 id="设置充电桩位置">设置充电桩位置</h4><ol type="1"><li><p>要求：距离每个充电桩最近的充电桩在充电后可跑历程范围内 ；同时使用的充电桩消耗的功率不会使电网崩溃</p></li><li><p>具体化：白天任意时段内确保 <span class="math inline">\(k\)</span> km附近有空闲的目的地充电桩；乡镇需要：乡镇内每天有空闲的目的地充电桩；公路需要：沿途在一次充电里程的后半段内有空闲的加压充电桩</p></li><li><p>考虑因素：</p><ul><li>地域<ul><li>城市</li><li>乡村</li><li>城市--乡村过渡带</li></ul></li><li>电动汽车分布</li></ul></li><li><p>想法：</p><ul><li><p>利用层次分析法获得每个州的交通运输度综合评价得分，根据得分（看作权重）分配充电站数量。<span class="math inline">\(N_i=N\times w_i\)</span></p></li><li><p>根据各州的电动汽车保有量和交通运输量，在每个充电站里细分提供的充电桩种类和数量</p></li><li><p>先广覆盖，满足基本需求，再有针对性地根据地域和需求逐步增加数量</p></li><li><p>借鉴加油站的分布</p></li><li><p>由于智能充电引导系统的应用，可以假设驾驶员都可以选择最优的充电桩</p></li><li><p>若有美国电动汽车充电桩的数据，可使用K-means聚类方法确定充电站的位置：“如果我们定位了50个公共充电站，则将应用K-means方法将充电时间窗的位置划分为50个簇，然后将充电站定位在每个集群的质心处。”</p></li><li><p>电动汽车拥有率～所需充电里程数</p></li></ul></li><li><p>The electrification rate, defined as the ratio of miles PHEVs travel in all electric mode over the total driving miles, is adopted to evaluate different location plans。</p></li><li><p>Time series Simulation Model</p></li></ol><h3 id="电动汽车拥有量预测">电动汽车拥有量预测</h3><ul><li>Bass 扩散模型</li></ul><h3 id="o奖论文学习-1">O奖论文学习</h3><h4 id="d82504">D82504</h4><h3 id="english-2">1. English</h3><p>quantify the key factors’ influences</p><p>Redefine the concept of urban, suburban and rural areas</p><p>establish a functional relationship between the charger density and out chosen factors</p><p>in practice</p><p>Empirically 以经验为依据地</p><p>visualized simulation results</p><p>conduct further discussions</p><h3 id="有用的东西">2. 有用的东西</h3><ul><li><p>Markov method</p></li><li><p>Gini coefficient 基尼系数</p><p>判断年收入分配公平程度的指标。在0～1之间。基尼系数越小，年收入分配越平均；基尼系数越大，年收入分配越不平均。</p></li></ul><h3 id="learn">3. Learn</h3><ul><li>‘Related Work’ Section</li><li><p>写得好：“3.1 Tesla’s Objective”</p></li><li>use the completed charging network in Manhattan to estimate <span class="math inline">\(c_u\)</span></li><li><p>divide the urban area to several squares, and consider the distribution of stations in each square.</p></li><li>考虑实际情况，在用K-means聚类方法时使用曼哈顿距离（<span class="math inline">\(L_1\)</span>）代替传统的欧式距离</li><li><p>在对电动汽车市场占有份额建模时，采用逻辑回归模型 Logistic Model</p></li></ul><h4 id="d82794">D82794</h4><h3 id="english-3">English</h3><p>from a macro perspective</p><p>Here we list the symbols and notations used in this paper, as shown in Table 1.</p><p>folk customs 民俗</p><h3 id="d81402">D81402</h3><h4 id="english-4">1. English</h4><h4 id="有用的东西-1">2. 有用的东西</h4><ul><li><p>决策策略：Nash Equilibrium</p></li><li><p>经济学概念：帕累托最优</p></li><li><p>传播理论：Bass diffusion model</p><p>适用于耐用消费品的分析预测。</p></li></ul><h2 id="论文写作">论文写作</h2><h3 id="摘要">摘要</h3><p>优秀的内容提要：对建模方法良好组织的精确的描述、获得的基本结果、你的建议。</p><h3 id="数学模型">数学模型</h3><ul><li>明确了关键假设，说明详实合理，在建模过程中起到了作用</li><li>从数学和文字方面对建模动机和理由进行阐述</li><li>估算和解释模型中的参数值</li><li>重点分析了题目关键点</li><li>用到的结果和数据的调查，以及对用到的相关科学术语很好的解释</li><li>是否利用真是数据验证模型，是否测试了模型的精度和鲁棒性</li><li>如何利用模型来告知决策者并指导他未来的决策</li><li>你是否真正了解你的模型。应讨论模型的优缺点：局限性、假设条件的约束及所用方法的局限性。改善模型的方法。</li></ul><h3 id="信息视觉图表">信息、视觉、图表</h3><p>写作规范、明了、适当使用图表。</p><h3 id="灵敏性分析">灵敏性分析</h3><ul><li><p>对参数添加呈正态分布的随机变量干扰</p></li><li><p>添加高斯噪声</p></li><li><p>交叉验证</p></li></ul>]]></content>
      
      
      <categories>
          
          <category> Mathematics </category>
          
          <category> Mathematics Modeling </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>学习规划</title>
      <link href="/2020/02/06/Other%20Things/%E5%AD%A6%E4%B9%A0%E8%A7%84%E5%88%92/"/>
      <url>/2020/02/06/Other%20Things/%E5%AD%A6%E4%B9%A0%E8%A7%84%E5%88%92/</url>
      
        <content type="html"><![CDATA[<h2 id="大二下">大二下</h2><p>$ \ $ <a id="more"></a></p><p>6.24, 6.26, (6.27) ,6.29, 6.30, 7.2, 7.3</p><ul><li><p>物理的学习</p><ul><li><p>电动力学 6.24 8:00-10:00</p><ul><li><p>课前预习</p></li><li>上课认真做笔记</li><li>上课后Markdown整理</li><li><p>教材未知</p></li></ul></li><li><p>理论力学7.2 10:30--12:30</p><ul><li>课前预习</li><li>上课认真做笔记</li></ul></li><li><p>应用光学 7.3 8:00--10:00</p><ul><li>当天必须解决不明白的</li><li>每周整理</li></ul></li><li><p>数理方法II 4.23 10:30--12:30</p></li></ul></li><li><p>专业课的学习</p><ul><li><p>数电 6.29 8:00-10:00</p><ul><li>上课认真听</li><li>每周整理笔记</li></ul></li><li><p>信号与系统 6.26 14:00-16:00</p></li></ul></li><li><p>数学的学习</p><ul><li>线性代数 6.30--8:00--10:00</li><li>矩阵论十讲</li><li>随机过程 6.27 10:30--12:30 周五345，西1-106</li><li>凸优化</li></ul></li><li><p>计算机的学习</p><ul><li>数字图像处理 自学完成</li><li>机器学习：<strong>CS229</strong></li><li>数据结构</li><li>爬虫</li></ul></li><li><p>硬件软件配置</p><ul><li>配置好 Texpad</li><li>Sublime 的代码自动补全配置</li><li>IPython或jupyter notebook的配置</li></ul></li><li><p>科研与竞赛</p><ul><li>导师的那篇论文 CNN实现<ul><li>可能要去看 <a href="http://cs231n.stanford.edu/syllabus.html" target="_blank" rel="noopener">CS231</a></li></ul></li><li><p>中控杯（须尽快完成）</p></li><li>SRTP</li><li>物理创新竞赛<ul><li>可能要学习 <a href="https://morvanzhou.github.io/tutorials/python-basic/tkinter/" target="_blank" rel="noopener">Tkinter窗口库</a></li></ul></li></ul></li><li><p>课余时间（少）</p><ul><li><p>每天跑步和早起早睡</p></li><li>围棋</li><li>台球</li><li><p>npy？</p></li></ul></li><li><p>GRE（重要） 5.9</p></li><li><p>待完成</p><ul><li>数值分析的整理</li></ul></li></ul><h2 id="大三">大三</h2><ul><li>微分几何</li><li>大数据分析</li><li>概率论</li><li>数理统计</li><li>数据库</li><li>数据结构</li></ul>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>Mathematics Models</title>
      <link href="/2020/02/01/Mathematics/Mathematic-Models/"/>
      <url>/2020/02/01/Mathematics/Mathematic-Models/</url>
      
        <content type="html"><![CDATA[<h1 id="数学建模-模型学习">数学建模 模型学习</h1><h2 id="确定性连续模型">1 确定性连续模型</h2><h2 id="静态优化模型微分法建模">1.1 静态优化模型/微分法建模</h2><h3 id="不允许缺货的存贮模型">1.1.1 不允许缺货的存贮模型</h3><ol type="1"><li><p>模型假设：</p><ul><li>每天存货费用：<span class="math inline">\(c_1\)</span> 元/吨</li><li>每次订货费用：<span class="math inline">\(c_2\)</span> 元</li><li>每天货物需求量：<span class="math inline">\(r\)</span> 吨/天</li><li>任意时刻 <span class="math inline">\(t\)</span> 的货物贮存量：<span class="math inline">\(q(t)\)</span></li><li>订货周期：<span class="math inline">\(T\)</span> 天</li><li>每次订货数量：<span class="math inline">\(Q\)</span> 吨</li></ul></li><li><p>模型假设：</p><p>每次订货后库存量均匀下降： <span class="math display">\[\frac{dq}{dt}=-r,\qquad q(0)=Q \\q(t)=-r\cdot t+Q\]</span></p></li><li><p>模型建立：</p><ul><li>订货数量、订货周期、每日货物需求的关系：</li></ul><p><span class="math display">\[Q=r\cdot T\]</span></p><ul><li>每日平均花费：</li></ul><p><span class="math display">\[Cost(T)=\frac{1}{T}\cdot(c_2+c_1\int_0^Tq(t)dt)=\frac{c_2}{T}+\frac{1}{2}c_1 rT\]</span></p><ul><li>目标：<span class="math inline">\(min[Cost]\)</span></li></ul><p><span class="math display">\[\frac{dCost}{dT}=0\\=&gt; T=\sqrt{\frac{2c_2}{c_1r}},\quad Q=\sqrt{\frac{2c_2r}{c_1}}\]</span></p></li></ol><p>$ \ $ <a id="more"></a></p><h3 id="允许缺货的存贮模型">1.1.2 允许缺货的存贮模型</h3><h2 id="遗传算法-ga">2 遗传算法 GA</h2><h3 id="算法流程">2.1 算法流程</h3><ul><li><p>适应度函数</p><p>目标函数，函数的最优值便是适应度最高（最适合生存）的种群的适应度</p></li><li><p>变异</p><p>产生跳出局部最优解的可能</p></li></ul><h3 id="单目标优化">2.2 单目标优化</h3><p>pass</p><h2 id="综合评价方法">3 综合评价方法</h2><h3 id="层次分析法-ahp">3.1 层次分析法 AHP</h3><p>Analytic Hierarchy Process.</p><p><a href="https://zhuanlan.zhihu.com/p/38207837" target="_blank" rel="noopener">算法流程</a>：</p><ul><li><p>建模，确定各层次因素</p></li><li><p>进行单层次排序（从上往下）</p><ul><li>对于每一个上一层对元素，挨个分析每一层因素的相对重要性，构建成对比较矩阵（使用<strong>1-9标度法</strong>）</li><li>进行一致性检验（传递性），不通过则需要调整相对重要性</li><li>获得归一化的最大特征向量，最为当前层对上一层对权重向量</li></ul></li><li><p>进行层次总排序，获得最下层每个元素对最终目标的归一化权重向量（从下往上）</p></li><li><p>得到决策结果</p></li></ul><p>为什么特征向量可以作为权重？</p><p>可证充分性。<span class="math inline">\(AX\)</span>的列向量的第 <span class="math inline">\(i\)</span> 个元素可以作为第 <span class="math inline">\(i\)</span> 个指标的综合评价（=<span class="math inline">\(\sum_j\)</span>第 <span class="math inline">\(i\)</span> 个元素对第 <span class="math inline">\(j\)</span> 个元素的重要程度<span class="math inline">\(\times\)</span> 第 <span class="math inline">\(j\)</span> 个元素的最终权重），正比于第 <span class="math inline">\(i\)</span> 个元素的最终权重（$AX=X $）</p><h3 id="主成分分析-pca">3.2 主成分分析 PCA</h3><p>Principle Component Analysis.</p><p>应用：</p><ul><li><p>变量较多，需要从数据中挖掘出主要成分。通过正交变换，消除变量之间的相关影响。</p></li><li><p>对多变量的截面数据表进行最佳综合简化。</p></li><li><p>对指标进行客观赋权。（从相关系数矩阵的特征值引出的信息贡献率可作为”新变量“的权重）</p></li></ul><p>算法流程：</p><ul><li>设指标变量为 <span class="math inline">\(\mathbf{x}=[x_1,\cdots,x_n]\)</span></li><li>将变量标准化、去除量纲：<span class="math inline">\(\mathbf{\widetilde x}=\displaystyle\frac{\mathbf{x}-\mu}{\sigma}\)</span></li><li>获得 <span class="math inline">\(\mathbf{\widetilde x}\)</span> 的相关系数矩阵 <span class="math inline">\(R=(r_{ij})_{n\times n }\)</span></li><li>计算 <span class="math inline">\(R\)</span> 的特征值 <span class="math inline">\(\lambda_1\geq\cdots \geq\lambda_n\)</span> 和对应的特征(列)向量 <span class="math inline">\(\mathbf{\mu_1,\cdots\mu_n}\)</span></li><li>设 <span class="math inline">\(\mathbf{\mu_i}=[\mu_{1i},\cdots,\mu_{ni}]^T\)</span>, 得到新的变量：<span class="math inline">\(\mathbf{y_i}=\sum_j \mu_{ji}\cdot\widetilde x_i\)</span></li><li>特征值 <span class="math inline">\(\lambda_i\)</span> 的信息贡献率 <span class="math inline">\(b_i=\lambda_i\big/(\sum_i \lambda_i)\)</span>, 累计贡献率 <span class="math inline">\(\alpha_p=(\sum_{j=1}^p \lambda_j)\big/(\sum_i\lambda_i)\)</span></li><li>根据累计贡献率挑选出主成分</li><li>根据信息贡献率得到基于主成分的综合评价得分：<span class="math inline">\(Z=\sum_{j=1}^p b_j y_j\)</span></li></ul><h3 id="模糊综合评价">3.3 模糊综合评价</h3><p>Fuzzy Comprehension Evaluation.</p><p>应用：评价的人多的时候比较好，比如人事考核，军训打分。</p><h4 id="一级模糊综合评判">（1）一级模糊综合评判</h4><ul><li><p>确定因素集 <span class="math inline">\(U=\{u_1,\cdots,u_n\}\)</span></p></li><li><p>确定各因素权重 <span class="math inline">\(A=[a_1,\cdots,a_n]\)</span></p><ul><li>主成分分析</li><li><a href="https://zhuanlan.zhihu.com/p/28067337" target="_blank" rel="noopener">熵权法</a>（基于多个样本在指标下的离散程度赋权）</li><li>专家评估</li><li>众人打分</li></ul></li><li><p>确定评语集 <span class="math inline">\(V=\{v_1,\cdots,v_m\}\)</span></p></li><li><p>对每个因素 <span class="math inline">\(u_i\)</span> 获得一个对应评语集的评价向量 <span class="math inline">\(R_i=[r_{i1},\cdots,r_{im}]\)</span>, 得到模糊综合判断矩阵 <span class="math inline">\(R=(r_{ij})_{n\times m}\)</span> （<span class="math inline">\(r_{ij}\%\)</span> 的人认为第 <span class="math inline">\(i\)</span> 个因素可以达到评语 <span class="math inline">\(v_j\)</span> ）</p></li><li><p>综合评判 <span class="math inline">\(B=A\cdot R=[b_1,\cdots, b_m]\)</span>, 可取数值最大的评语作为最终结果（最大隶属度原则）</p></li></ul><h4 id="多级模糊综合评判">（2）多级模糊综合评判</h4><p><a href="http://html.rhhz.net/ZGJCYJ/html/2007-03-30.htm" target="_blank" rel="noopener">例子</a></p><h3 id="灰色关联评估">3.4 灰色关联评估</h3><p>灰色系统理论的一个分支，应用于受多种相互关联因素影响的事物和现象的综合评价问题。</p><h3 id="可作为综合题练习">3.5 可作为综合题练习</h3><p>第1辑第3章医疗保健系统评估问题。</p><h2 id="模拟仿真方法">模拟/仿真方法</h2><h3 id="元胞自动机">元胞自动机</h3><p>制定规则，模拟。</p><ul><li><a href="https://blog.csdn.net/Harrytsz/article/details/85094334" target="_blank" rel="noopener">模拟交通流</a></li><li><a href="https://blog.csdn.net/weixin_39590507/article/details/86760958" target="_blank" rel="noopener">模拟游客疏散</a></li><li><a href="https://github.com/chen622/Louvre" target="_blank" rel="noopener">比较全面地模拟游客疏散</a></li><li><a href="https://blog.csdn.net/your_answer/article/details/79287367" target="_blank" rel="noopener">模拟流言传播</a></li></ul><h2 id="模型">模型</h2><ul><li><p>贝叶斯信念网络 （概率图）</p></li><li><p>小世界模型</p></li><li><p>Lotka–Volterra方程（捕食者-被捕食者方程） 可发挥创造性推广至多捕食者多被捕食者的动态网络。</p></li><li>扩散模型<ul><li>扩散方程</li><li>高斯烟流模式：大气污染预测</li><li>技术扩散模型：Bass Diffusion Model</li><li>创新扩散模型：Diffusion of Innovations Theory</li></ul></li><li><p>拓扑网络</p><ul><li>局部中心</li><li>影响度</li><li>Pagerank 佩奇排名算法度量网络节中心性</li></ul></li><li><p>普林斯顿海洋模型（POM） 47、48</p></li><li><p>Forrester 世界模型 51</p></li></ul>]]></content>
      
      
      <categories>
          
          <category> Mathematics </category>
          
          <category> Mathematics Modeling </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>神经网络学习</title>
      <link href="/2020/01/30/Computer-Sciencs/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%AD%A6%E4%B9%A0/"/>
      <url>/2020/01/30/Computer-Sciencs/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%AD%A6%E4%B9%A0/</url>
      
        <content type="html"><![CDATA[<h1 id="神经网络-学习笔记">神经网络 学习笔记</h1><p>学习资源: <a href="">neuralnetworksanddeeplearning.com</a></p><h2 id="chapter-12">Chapter 1、2</h2><h3 id="基本概念">1.1 基本概念</h3><ul><li><p>activation function 激活函数/传递函数 定义了该节点在给定的输入或输入的集合下的输出，比如 sigmoid function</p></li><li><p>perceptron model 感知器：输入 <span class="math inline">\(0,1\)</span> 二值函数，输出 <span class="math inline">\(0,1\)</span> 二值函数</p></li><li><p>sigmoid neurons S 神经元</p><p>​ 中间部分更精细，<span class="math inline">\(\displaystyle\sigma(z)=\frac{1}{1+e^{-z}}\)</span> 输入二值，输出为 <span class="math inline">\([0,1]\)</span> 之间的数，极限性质和感知器一样</p></li><li><p>feedforward neural networks 前馈神经网络</p><p>​ 没有反馈的神经网络，由输入层(input layer)、隐藏层(hidden layer)、输出层(output layer)构成</p></li></ul><p>$ \ $ <a id="more"></a></p><h3 id="stochastic-gradient-descent-随机梯度下降">1.2 stochastic gradient descent 随机梯度下降</h3><h4 id="参数">1.2.1 参数</h4><ul><li><span class="math inline">\(x\)</span> ：输入的训练集（一个矩阵，每一列是一次单独的输入）, <span class="math inline">\(y\)</span> ：最终输出，<span class="math inline">\(y=w\cdot x+b\)</span></li><li><span class="math inline">\(w\)</span>：weights，由矩阵组成的向量。<span class="math inline">\(w_j\)</span> 是一个 <span class="math inline">\(m\times n\)</span> 型矩阵，连接 <span class="math inline">\(j-1\)</span> 层和 <span class="math inline">\(j\)</span> 层，其中 <span class="math inline">\(j-1\)</span> 层有 <span class="math inline">\(n\)</span> 个神经元，$ j $ 层有 <span class="math inline">\(m\)</span> 个神经元</li><li><span class="math inline">\(b\)</span> ：biases，由 $ m1$ 型矩阵组成的向量。 <span class="math inline">\(b_k\)</span> 是一个<span class="math inline">\(m\times 1\)</span> 型矩阵，连接 <span class="math inline">\(j-1\)</span> 层和 <span class="math inline">\(j\)</span> 层，其中第 <span class="math inline">\(j\)</span> 层有 <span class="math inline">\(m\)</span> 个神经元</li><li>Cost function ： $ C(w,b)=<em>x |y(x)-a |^2=</em>{i=1}<sup>{n}[y(x<sup>{(i)})-a</sup>{(i)}]</sup>2 $</li></ul><h4 id="方法">1.2.2 方法</h4><ul><li>对于整个训练集，用随机梯度下降法使损失函数尽可能小</li><li>先将训练集打乱，再按给定的小批训练集大小等间隔取小批训练集（相当于随机取样），每次选择更优的 <span class="math inline">\(w,b\)</span> 使损失函数一步步减小</li></ul><h4 id="保证每次都获得更优的-wb">1.2.3 保证每次都获得更优的 <span class="math inline">\(w,b\)</span>：</h4><ol type="1"><li></li></ol><p><span class="math display">\[\displaystyle \nabla C=(\frac{\partial C}{\partial v_1},\frac{\partial C}{\partial v_2})^T , \quad \vec v_1\equiv v_1\equiv w,\vec v_2\equiv v_2\equiv b\\ \displaystyle\Delta C\approx  \frac{\partial C}{\partial w}\Delta v_1+\frac{\partial C}{\partial b}\Delta v_2=\Delta v\cdot \nabla C \\ =&gt; take\quad \Delta v=(\Delta v_1,\Delta v_2)=-\eta \nabla C,\quad \eta&gt;0\\\begin{aligned}\therefore C&amp;:=C+\Delta C=C-\eta \|\nabla C \|^2\\v_1&amp; :=v_1-\eta\cdot\frac{\partial C}{\partial v_1}\\v_2&amp;:=v_2-\eta\cdot\frac{\partial C}{\partial v_2s}\end{aligned}\]</span></p><ol start="2" type="1"><li>分量式：</li></ol><p><span class="math display">\[\begin{aligned}w_{jk}&amp;:=w_{jk}-\eta\cdot \frac{\partial C}{\partial w_{jk}}=w_{jk}-\eta\cdot \nabla C_{w_{jk}}\approx w_{jk}-\eta\cdot \frac{1}{m}\sum_{i=1}^m \frac{\partial C}{\partial w_{jk}^{(i)}} \\b_{k}&amp;:=b_{ k}-\eta\cdot \frac{\partial C}{\partial b_{k}}=b_{k}-\eta\cdot \nabla C_{b_{k}}\approx b_{k}-\eta\cdot\frac{1}{m}\sum_{i=1}^m \frac{\partial C}{\partial b_{k}^{(i)}}\end{aligned}\]</span></p><h2 id="bp算法反向传播-back-propagate">2 BP算法（反向传播 back propagate ）</h2><p>目的：快速计算 <span class="math inline">\(\displaystyle \frac{\partial C}{\partial w},\frac{\partial C}{\partial b}\)</span> .</p><h3 id="原理">2.1 原理：</h3><p>最终结果产生的偏差是由于每个神经元产生的误差叠加起来造成的。通过前向反馈得到的结果若与正确结果有偏差，则从此偏差反向推导，可得到各层神经元产生的误差。</p><h3 id="符号表示">2.2 符号表示</h3><ul><li><span class="math inline">\(w_{jk}^l\)</span> ：连接第 <span class="math inline">\(l-1\)</span>层第 <span class="math inline">\(k\)</span> 个神经元和第 <span class="math inline">\(l\)</span> 层第 <span class="math inline">\(j\)</span> 个神经元的权重</li><li><span class="math inline">\(w^l\)</span> ：连接第 <span class="math inline">\(l-1\)</span> 和第 <span class="math inline">\(l\)</span> 层网络的权重矩阵</li><li><span class="math inline">\(b_j^l\)</span> ：第 <span class="math inline">\(l\)</span> 层第 <span class="math inline">\(j\)</span> 个神经元的 bias</li><li><span class="math inline">\(z_j^l\)</span> ：第 <span class="math inline">\(l\)</span> 层网络的带权输入 <span class="math inline">\(z_j^l=\displaystyle\sum_k w_{jk}^l a_k^{l-1}+b_j^l\)</span>，<span class="math inline">\(z^l=w^l a^{l-1}+b^l\)</span></li><li><p><span class="math inline">\(\delta_j^l\)</span> ：第 <span class="math inline">\(l\)</span> 层第 <span class="math inline">\(j\)</span> 个神经元产生的误差,，定义 <span class="math inline">\(\displaystyle \delta^l_j \equiv \frac{\partial C}{\partial z^l_j}\)</span></p></li><li><span class="math inline">\(a_j^l\)</span> ：第 <span class="math inline">\(l\)</span> 层网络的第 <span class="math inline">\(j\)</span> 个神经元的激活量，<span class="math inline">\(a_j^l=\sigma(z_j^l)\)</span></li><li><p><span class="math inline">\(C\)</span> ：损失函数，用小批量输入的平均值近似。</p></li></ul><h3 id="重要的关系公式">2.3 重要的关系公式</h3><ol start="0" type="1"><li><p>注：推导中的除法 ''<span class="math inline">\(\bigg /\)</span> ''、乘法 <span class="math inline">\(\odot\)</span> （ Hadamard Product）均为<strong>elementwise</strong></p></li><li><p><span class="math display">\[C=\displaystyle \frac{1}{2n}\sum_x \|y(x)-a^L(x)\|^2=\frac{1}{n}\sum_x ^n C(x)\approx\frac{1}{m}\sum_x^m C(x)\\ C(x)=\frac{1}{2}\|y-a^L(x)\|^2=\frac{1}{2}\sum_i \big(y_i-a_i^L(x)\big)^2\]</span></p></li><li><p><span class="math display">\[a_j^l=\sigma\bigg(\sum_k w_{jk}^l a_k^{l-1}+b_j^l\bigg)\\ a^l=\sigma\bigg(w^l a^{l-1}+b^l\bigg)\]</span></p></li><li><p><span class="math display">\[\delta^l=\frac{\partial C}{\partial b^l}\bigg/ \frac{\partial z^l}{\partial b^l}=\frac{\partial C}{\partial b^l},\qquad \frac{\partial C}{\partial b^l}\triangleq(\frac{\partial C}{\partial b_1^l},\cdots,\frac{\partial C}{\partial b_{N(l)}^l})^T \tag{1}\]</span></p></li><li><p><span class="math display">\[\delta_j^l=\frac{\partial C}{\partial w_{jk}^l}\bigg /\frac{\partial z^l}{\partial w_{jk}^l}=\frac{\partial C}{\partial w_{jk}^l}\big/ a_k^{l-1}\]</span></p></li></ol><p><span class="math display">\[i .e. \qquad \frac{\partial C}{\partial w_{jk}^l}=a_{k}^{l-1}\cdot  \delta_j^l \qquad =&gt;\nabla C_{w^l}=\delta^l\cdot (a^{l-1})^T \tag{2}\]</span></p><ol start="5" type="1"><li><p><span class="math display">\[\delta^L=\frac{\partial C}{\partial a^L}\odot \frac{\partial a^L}{\partial z^L}=\frac{\partial C}{\partial a^L}\odot\sigma&#39;(z^L)=(a^L-y) \odot \sigma&#39;(z^L)\tag{3}\]</span></p></li><li><p><strong>Move error backward:</strong> <span class="math display">\[\begin{eqnarray}z^{l+1}_k = \sum_j w^{l+1}_{kj} a^l_j +b^{l+1}_k = \sum_j w^{l+1}_{kj} \sigma(z^l_j) +b^{l+1}_k=&gt;\frac{\partial z^{l+1}_k}{\partial z^l_j} = w^{l+1}_{kj} \sigma&#39;(z^l_j)\end{eqnarray}\]</span></p><p><span class="math display">\[\delta_j^l=\sum_k \frac{\partial C}{\partial z_k^{l+1}}\cdot \frac{\partial z_k^{l+1}}{\partial z_j^l}=\sum_{k=1}^{N(l)}\delta_k^{l+1}\cdot w_{kj}^{l+1}\cdot \sigma&#39;(z_j^l)\]</span></p><p><span class="math display">\[=&gt; \delta^l=\big((w^{l+1})^T\sigma&#39;(z^l)\big)\odot \delta^{l+1}\tag{4}\]</span></p></li></ol><h3 id="实现步骤">2.4 实现步骤</h3><ol type="1"><li><p>feedforward : 得到 <span class="math inline">\(z^L\)</span> 和相应的 <span class="math inline">\(a^L\)</span> <span class="math display">\[a^{x,l} = \sigma(z^{x,l})\]</span></p></li><li><p>output error : <span class="math display">\[\delta^{x,L} = \nabla_a C_x \odot \sigma&#39;(z^{x,L})\]</span></p></li><li><p>error back propagate :<br /><span class="math display">\[\delta^{x,l} = ((w^{l+1})^T \delta^{x,l+1})  \odot \sigma&#39;(z^{x,l})\]</span></p></li><li><p>update weights and biases : <span class="math display">\[\begin{aligned}w_{jk}&amp;:=w_{jk}-\eta\cdot \nabla C_{w_{jk}}\approx w_{jk}-\eta\cdot \frac{1}{m}\sum_{i=1}^m \frac{\partial C}{\partial w_{jk}^{(x_i)}}=w_{jk}-\eta\cdot\frac{1}{m}\sum_{i=1}^m \big(a_k^{l-1}\delta_j^{l}\big)^{(x_i)}\\b_{k}&amp;:=b_{k}-\eta\cdot \nabla C_{b_{k}}\approx b_{k}-\eta\cdot\frac{1}{m}\sum_{i=1}^m \frac{\partial C}{\partial b_{k}^{(x_i)}}=b_{k}-\eta\cdot\frac{1}{m}\sum_{i=1}^m \big(\delta_k^{l}\big)^{(x_i)}\end{aligned}\]</span></p><p>即： <span class="math display">\[w^l \rightarrow  w^l-\frac{\eta}{m} \sum_x \delta^{x,l} (a^{x,l-1})^T \\b^l \rightarrow b^l-\frac{\eta}{m}  \sum_x \delta^{x,l}\]</span></p></li></ol><h3 id="代码实现">2.5 代码实现</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> random<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><br><br><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Network</span><span class="hljs-params">(object)</span>:</span><br><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span><span class="hljs-params">(self, sizes)</span>:</span><br>        <span class="hljs-comment"># 生成神经网络 </span><br>        self.num_layers = len(sizes)<br>        self.sizes = sizes<br>        self.biases = [np.random.randn(y, <span class="hljs-number">1</span>) <span class="hljs-keyword">for</span> y <span class="hljs-keyword">in</span> sizes[<span class="hljs-number">1</span>:]]<br>        self.weights = [np.random.randn(y, x)<br>                        <span class="hljs-keyword">for</span> x, y <span class="hljs-keyword">in</span> zip(sizes[:<span class="hljs-number">-1</span>], sizes[<span class="hljs-number">1</span>:])]<br><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">feedforward</span><span class="hljs-params">(self, a)</span>:</span><br>        <span class="hljs-comment"># 激活神经元，向后面的层产生反馈</span><br>        <span class="hljs-keyword">for</span> b, w <span class="hljs-keyword">in</span> zip(self.biases, self.weights):<br>            a = sigmoid(np.dot(w, a) + b)<br>        <span class="hljs-keyword">return</span> a<br><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">SGD</span><span class="hljs-params">(self, training_data, epochs, mini_batch_size, eta,<br>            test_data=None)</span>:</span><br>        <span class="hljs-comment"># 随机梯度下降 Stochastic Gradient Descent</span><br>        <span class="hljs-comment"># epochs 训练次数, mini_batch_size 每次选取的小训练集大小, eta 学习率 由自己设定</span><br>        <span class="hljs-keyword">if</span> test_data:<br>            test_data = list(test_data)  <br>            n_test = len(test_data)<br>        training_data = list(training_data)<br>        n = len(training_data)<br>        <br>        <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> range(epochs):<br>            random.shuffle(training_data)<br>            mini_batches = [<br>                training_data[k:k + mini_batch_size]<br>                <span class="hljs-keyword">for</span> k <span class="hljs-keyword">in</span> range(<span class="hljs-number">0</span>, n, mini_batch_size)]  <br>            <span class="hljs-keyword">for</span> mini_batch <span class="hljs-keyword">in</span> mini_batches:<br>                self.update_mini_batch(mini_batch, eta)<br>            <span class="hljs-keyword">if</span> test_data:<br>                print(<span class="hljs-string">"Epoch &#123;0&#125;: &#123;1&#125; / &#123;2&#125;"</span>.format(j,<br>                                                    self.evaluate(test_data), n_test))<br><br>            <span class="hljs-keyword">else</span>:<br>                print(<span class="hljs-string">"Epoch &#123;0&#125; complete"</span>.format(j))<br><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">update_mini_batch</span><span class="hljs-params">(self, mini_batch, eta)</span>:</span><br>        <span class="hljs-comment"># 更新 w 和 b</span><br>        nabla_b = [np.zeros(b.shape) <span class="hljs-keyword">for</span> b <span class="hljs-keyword">in</span> self.biases]<br>        nabla_w = [np.zeros(w.shape) <span class="hljs-keyword">for</span> w <span class="hljs-keyword">in</span> self.weights]<br>        <span class="hljs-keyword">for</span> x, y <span class="hljs-keyword">in</span> mini_batch:<br>            delta_nabla_b, delta_nabla_w = self.backprop(x, y)<br>            nabla_b = [nb + dnb <span class="hljs-keyword">for</span> nb, dnb <span class="hljs-keyword">in</span> zip(nabla_b, delta_nabla_b)]<br>            nabla_w = [nw + dnw <span class="hljs-keyword">for</span> nw, dnw <span class="hljs-keyword">in</span> zip(nabla_w, delta_nabla_w)]<br>        self.weights = [w - (eta / len(mini_batch)) * nw<br>                        <span class="hljs-keyword">for</span> w, nw <span class="hljs-keyword">in</span> zip(self.weights, nabla_w)]<br>        self.biases = [b - (eta / len(mini_batch)) * nb<br>                       <span class="hljs-keyword">for</span> b, nb <span class="hljs-keyword">in</span> zip(self.biases, nabla_b)]<br><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">backprop</span><span class="hljs-params">(self, x, y)</span>:</span><br>        <span class="hljs-comment"># 反向传播算法</span><br>        nabla_b = [np.zeros(b.shape) <span class="hljs-keyword">for</span> b <span class="hljs-keyword">in</span> self.biases]<br>        nabla_w = [np.zeros(w.shape) <span class="hljs-keyword">for</span> w <span class="hljs-keyword">in</span> self.weights]<br>        <span class="hljs-comment"># feedforward</span><br>        activation = x<br>        activations = [x]  <span class="hljs-comment"># list to store all the activations, layer by layer</span><br>        zs = []  <span class="hljs-comment"># list to store all the z vectors, layer by layer</span><br>        <span class="hljs-keyword">for</span> b, w <span class="hljs-keyword">in</span> zip(self.biases, self.weights):<br>            z = np.dot(w, activation) + b<br>            zs.append(z)<br>            activation = sigmoid(z)<br>            activations.append(activation)<br>        <span class="hljs-comment"># backward pass</span><br>        delta = self.cost_derivative(activations[<span class="hljs-number">-1</span>], y) * \<br>            sigmoid_prime(zs[<span class="hljs-number">-1</span>])<span class="hljs-comment"># \delta^L</span><br>        nabla_b[<span class="hljs-number">-1</span>] = delta<br>        nabla_w[<span class="hljs-number">-1</span>] = np.dot(delta, activations[<span class="hljs-number">-2</span>].transpose())<br><br>        <span class="hljs-keyword">for</span> l <span class="hljs-keyword">in</span> range(<span class="hljs-number">2</span>, self.num_layers):<br>            z = zs[-l]<br>            sp = sigmoid_prime(z)<br>            delta = np.dot(self.weights[-l + <span class="hljs-number">1</span>].transpose(), delta) * sp<br>            nabla_b[-l] = delta<br>            nabla_w[-l] = np.dot(delta, activations[-l - <span class="hljs-number">1</span>].transpose())<br>        <span class="hljs-keyword">return</span> (nabla_b, nabla_w)<br><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">evaluate</span><span class="hljs-params">(self, test_data)</span>:</span><br>       <span class="hljs-comment"># 返回输出结果和训练数据集的正确结果相同的个数</span><br>        test_results = [(np.argmax(self.feedforward(x)), y)<br>                        <span class="hljs-keyword">for</span> (x, y) <span class="hljs-keyword">in</span> test_data]<br>        <span class="hljs-keyword">return</span> sum(int(x == y) <span class="hljs-keyword">for</span> (x, y) <span class="hljs-keyword">in</span> test_results) <br><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">cost_derivative</span><span class="hljs-params">(self, output_activations, y)</span>:</span><br>        <span class="hljs-string">"""Return the vector of partial derivatives \partial C_x /<br>        \partial a for the output activations."""</span><br>        <span class="hljs-keyword">return</span> (output_activations - y)<br><br><span class="hljs-comment"># Miscellaneous functions</span><br><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">sigmoid</span><span class="hljs-params">(z)</span>:</span><br>    <span class="hljs-comment"># The sigmoid function.</span><br>    <span class="hljs-keyword">return</span> <span class="hljs-number">1.0</span> / (<span class="hljs-number">1.0</span> + np.exp(-z))<br><br><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">sigmoid_prime</span><span class="hljs-params">(z)</span>:</span><br>    <span class="hljs-comment"># Derivative of the sigmoid function.</span><br>    <span class="hljs-keyword">return</span> sigmoid(z) * (<span class="hljs-number">1</span> - sigmoid(z))<br></code></pre></td></tr></table></figure><h2 id="chapter-3">Chapter 3</h2><h3 id="交叉熵">3.1 交叉熵</h3><p>对错误的乘法力度加大，学习速率更快</p><h3 id="softmax">3.2 Softmax</h3><p>输出转化为概略分布</p><h3 id="其他损失函数">3.3 其他损失函数</h3><h3 id="调整超参数的方法">3.4 调整超参数的方法</h3><h2 id="chapter-4">Chapter 4</h2><p>神经网络可以计算任何函数。</p><h2 id="chapter-5">Chapter 5</h2><ul><li><p>vanishing gradient</p></li><li><p>exploding gradient</p></li></ul><h2 id="chapter-6-cnn">Chapter 6 CNN</h2><h3 id="架构">6.1 架构</h3><ul><li>卷积层<ul><li>共享权重</li><li>提取特征</li></ul></li><li>池化层<ul><li>减少参量</li></ul></li><li>全连层<ul><li>二维压缩成一维，方便输出</li></ul></li><li>Softmax层<ul><li>输出概率分布</li></ul></li></ul><h3 id="代码-with-pytorch">6.2 代码： with pytorch</h3><h4 id="数据载入">6.2.1 数据载入</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><code class="hljs python">train_data = torchvision.datasets.MNIST(<br>    root=<span class="hljs-string">'./'</span>,    <span class="hljs-comment"># 保存或者提取位置</span><br>    train=<span class="hljs-literal">True</span>, <br>    <span class="hljs-comment"># 转换 PIL.Image or numpy.ndarray</span><br>    transform=torchvision.transforms.ToTensor(),<br>    download=DOWNLOAD_MNIST,<br>)<br><span class="hljs-comment"># print(train_data.data.shape)</span><br><span class="hljs-comment">#train_data.data : (60000,28,28)</span><br><span class="hljs-comment"># train_data.targets : (60000)</span><br>test_data = torchvision.datasets.MNIST(root=<span class="hljs-string">'./'</span>, train=<span class="hljs-literal">False</span>)<br><span class="hljs-comment"># test_data 包括：test_data.data 和 test_data.targets</span><br><span class="hljs-comment">#test_data.data : (10000,28,28)</span><br><span class="hljs-comment">#test_data.targets : (10000)</span><br><br><span class="hljs-comment"># 批训练 50samples, 1 channel, 28x28 (50, 1, 28, 28)</span><br>train_batches = Data.DataLoader(<br>    dataset=train_data, batch_size=BATCH_SIZE, shuffle=<span class="hljs-literal">True</span>)<br><span class="hljs-comment"># print(train_batches.dataset.targets.shape</span><br><br><span class="hljs-comment"># 测试前2000个</span><br>test_x = torch.unsqueeze(test_data.data, dim=<span class="hljs-number">1</span>).type(torch.FloatTensor)[<br>    :<span class="hljs-number">2000</span>] / <span class="hljs-number">255.0</span>  <span class="hljs-comment"># shape from (2000, 28, 28) to (2000, 1, 28, 28), value in range(0,1)</span><br>test_y = test_data.targets[:<span class="hljs-number">2000</span>]<br></code></pre></td></tr></table></figure><h4 id="卷积神经网络构建">6.2.2 卷积神经网络构建</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">CNN</span><span class="hljs-params">(nn.Module)</span>:</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span><span class="hljs-params">(self)</span>:</span><br>        super(CNN, self).__init__()<br>        self.conv1 = nn.Sequential(  <span class="hljs-comment"># input shape (1, 28, 28)</span><br>            nn.Conv2d(<br>                in_channels=<span class="hljs-number">1</span>,      <span class="hljs-comment"># input height</span><br>                out_channels=<span class="hljs-number">16</span>,    <span class="hljs-comment"># n_filters i.e. number of features</span><br>                kernel_size=<span class="hljs-number">5</span>,      <span class="hljs-comment"># filter size</span><br>                stride=<span class="hljs-number">1</span>,           <span class="hljs-comment"># filter movement/step</span><br>                <span class="hljs-comment"># 如果想要 con2d 出来的图片长宽没有变化, padding=(kernel_size-1)/2 当 stride=1</span><br>                padding=<span class="hljs-number">2</span>,<br>            ),      <span class="hljs-comment"># -&gt; (16, 28, 28)</span><br>            nn.ReLU(),    <span class="hljs-comment"># activation</span><br>            nn.MaxPool2d(kernel_size=<span class="hljs-number">2</span>),    <span class="hljs-comment"># -&gt; (16, 14, 14)</span><br>        )<br>        self.conv2 = nn.Sequential(  <span class="hljs-comment"># input shape (16, 14, 14)</span><br>            nn.Conv2d(<span class="hljs-number">16</span>, <span class="hljs-number">32</span>, <span class="hljs-number">5</span>, <span class="hljs-number">1</span>, <span class="hljs-number">2</span>),  <span class="hljs-comment"># output shape (32, 14, 14)</span><br>            nn.ReLU(),  <span class="hljs-comment"># activation</span><br>            nn.MaxPool2d(<span class="hljs-number">2</span>),  <span class="hljs-comment"># output shape (32, 7, 7)</span><br>        )<br>        <span class="hljs-comment"># fully connected layer, output 10 classes</span><br>        self.fc1 = nn.Linear(<span class="hljs-number">32</span> * <span class="hljs-number">7</span> * <span class="hljs-number">7</span>, <span class="hljs-number">100</span>)<br>        self.fc2 = nn.Linear(<span class="hljs-number">100</span>, <span class="hljs-number">10</span>)<br><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">forward</span><span class="hljs-params">(self, x)</span>:</span><br>        x = self.conv1(x)<br>        x = self.conv2(x)<br>        x = x.view(x.size(<span class="hljs-number">0</span>), <span class="hljs-number">-1</span>)   <span class="hljs-comment"># 展平多维的卷积图成 (batch_size, 32 * 7 * 7)</span><br>        x = torch.sigmoid(self.fc1(x))<br>        x = self.fc2(x)<br>        <span class="hljs-keyword">return</span> x<br></code></pre></td></tr></table></figure><h4 id="反向传播训练神经网络">6.2.3 反向传播、训练神经网络</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><code class="hljs python">cnn = CNN()<br>optimizer = torch.optim.Adam(cnn.parameters(), lr=LR) <span class="hljs-comment">#adam算法</span><br>loss_func = nn.CrossEntropyLoss()  <span class="hljs-comment"># Softmax–Log–NLLLoss，自动输出log-softmax</span><br><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">train</span><span class="hljs-params">()</span>:</span><br>    <span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> range(epochs):<br>        <span class="hljs-comment"># 分配 batch data, normalize x when iterate train_loader</span><br>        <span class="hljs-keyword">for</span> step, (b_x, b_y) <span class="hljs-keyword">in</span> enumerate(train_batches):  <span class="hljs-comment"># enumerate 添加索引可便历</span><br>            <span class="hljs-comment"># print(b_x.shape)--&gt;(50,1,28,28)</span><br>            <span class="hljs-comment"># print(b_y.shape)--&gt;(50)</span><br>            <span class="hljs-comment"># 1200组</span><br>            output = cnn(b_x)               <span class="hljs-comment"># cnn output</span><br>            loss = loss_func(output, b_y)   <span class="hljs-comment"># cross entropy loss</span><br>            optimizer.zero_grad()           <span class="hljs-comment"># clear gradients for this training step</span><br>            loss.backward()                 <span class="hljs-comment"># backpropagation, compute gradients</span><br>            optimizer.step()                <span class="hljs-comment"># apply gradients</span><br>            <span class="hljs-keyword">if</span> step % <span class="hljs-number">100</span> == <span class="hljs-number">0</span>:<br>                test_output = cnn(test_x)<br>                pred_y = torch.max(test_output, <span class="hljs-number">1</span>)[<br>                    <span class="hljs-number">1</span>].data.numpy()  <span class="hljs-comment"># [0]:一行中的最大值,[1]:最大值的索引</span><br>                accuracy = float((pred_y == test_y.data.numpy()).astype(<br>                    int).sum()) / float(test_y.size(<span class="hljs-number">0</span>))<br>                print(<span class="hljs-string">'Epoch: '</span>, epoch, <span class="hljs-string">'| train loss: %.4f'</span> %<br>                      loss.data.numpy(), <span class="hljs-string">'| test accuracy: %.2f'</span> % accuracy)<br>    torch.save(cnn.state_dict(), <span class="hljs-string">"cnn_net_params.pkl"</span>)<br><br>train()<br></code></pre></td></tr></table></figure><h4 id="参数存储与加载">6.2.4 参数存储与加载</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python">torch.save(cnn.state_dict(), <span class="hljs-string">"cnn_net_params.pkl"</span>)<span class="hljs-comment">#保存训练好的参数</span><br><br><br>cnn = CNN()<br>cnn.load_state_dict(torch.load(<span class="hljs-string">'cnn_net_params.pkl'</span>))<span class="hljs-comment">#加载参数</span><br></code></pre></td></tr></table></figure><p>其他：关于深度学习和图像处理卷积的定义问题：深度学习中conv2d卷积层其实是无所谓是否翻转的，因为所有的weights也就是kernel其实是随机初始化的。那么每次的更新迭代都是为了去寻找一个最合适的kernel，所以是否翻转也变的无关紧要了。</p>]]></content>
      
      
      <categories>
          
          <category> Computer Science </category>
          
          <category> Machine Learning </category>
          
          <category> Neural Networks </category>
          
      </categories>
      
      
        <tags>
            
            <tag> notes </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>数值分析 学习笔记</title>
      <link href="/2020/01/28/Computer-Sciencs/%E6%95%B0%E5%80%BC%E5%88%86%E6%9E%90-%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
      <url>/2020/01/28/Computer-Sciencs/%E6%95%B0%E5%80%BC%E5%88%86%E6%9E%90-%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/</url>
      
        <content type="html"><![CDATA[<h1 id="数值分析-学习笔记">数值分析 学习笔记</h1>]]></content>
      
      
      <categories>
          
          <category> Computer Science </category>
          
          <category> Numerical Analysis </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>Python 学习笔记</title>
      <link href="/2020/01/28/Computer-Sciencs/Python-%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
      <url>/2020/01/28/Computer-Sciencs/Python-%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/</url>
      
        <content type="html"><![CDATA[<h1 id="python-学习笔记">Python 学习笔记</h1><h2 id="pandas-library">pandas library</h2><h3 id="day-1">Day #1</h3><p>df = pd.read_csv(' ')</p><p>df.head(n)</p><p>df.tail(n)</p><p>df.nlargest(n,'name')</p><p>df.nsmallest(n,'name')</p><p>df [Pd['bla bla']=='labalaba']</p><h3 id="day-2">Day #2</h3><p>df.shape</p><p>df.columns.tolist( )</p><p>df['name'].unique( )</p><p>df = df.replace('Orig' , 'New')</p><p>df.isnull( ) // Checks if each value in the dato frame is missing</p><p>Trick: print(df.isnull().sum()) // return the total amount of missing values for each feature(column)</p><p>NaN stands for 'not a number'</p><p><strong>creating columns:</strong></p><p>df['new column name'] = fomula</p><p>e.g. df['% Female'] = df['Female'] / df['Total']</p><p>df.dtypes</p><p>df.select_dtypes(['object'])</p><p><strong>measures of spread or distribution</strong></p><p>df['column name'].mean( )</p><p>df['column name'].median( )</p><p>df['column name'].mode( )</p><p>df.groupby(by='column name').agg('mean')</p><p>// agg stands for 'aggregate'. group the data by the 'column name'</p><p>df['column name'].max( ) — df['column name'].min( )</p><p>df['column name'].std( ) // standard deviation</p><p>df['column name'].var( ) // variance</p><p>df.groupby(by='column name').agg('std')</p><p><strong>correlation coefficient</strong></p><p>df.corr( )</p><p>df.corr( )['x'] ['y']</p><h3 id="day-3">Day #3</h3><h4 id="bar-chart-条形图">Bar Chart 条形图</h4><p>df_top10 = df.nlargest(10,'Total')</p><p>df_top10.plot.bar(x='Major Name', y='Total')</p><h4 id="histograms-直方图">Histograms 直方图</h4><p>df.hist(column = '% Female')</p><h4 id="boxplot-箱形图-超有用">Boxplot 箱形图 超有用</h4><p>df.boxplot(column = '% Female', vert=False)</p><h4 id="scatterplots-散点图">Scatterplots 散点图</h4><p>df.plot.scatter(x='Male', y='Female')</p><p>##. . .</p><h4 id="simulation">Simulation</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> random<br>random.ranint(<span class="hljs-number">1</span>,<span class="hljs-number">10</span>)<br><br><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> range(<span class="hljs-number">1</span>,<span class="hljs-number">100</span>):<br>  print(random.randint(<span class="hljs-number">1</span>,<span class="hljs-number">10</span>))<br></code></pre></td></tr></table></figure><h3 id="day-4">Day #4</h3><ul><li>generate a dataset of random numbers</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> random <span class="hljs-keyword">as</span> rd<br>arr=[]<br><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> range(<span class="hljs-number">100</span>):<br>  value=rd.randint(<span class="hljs-number">1</span>,<span class="hljs-number">10</span>)<br>  arr.append(&#123;<span class="hljs-string">'value'</span>:value&#125;)<br></code></pre></td></tr></table></figure><ul><li><p><strong>Monty Hall Game</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br><span class="hljs-keyword">import</span> random<br><br>results = []<br><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> range(<span class="hljs-number">1000</span>):<br>  prize = random.randint(<span class="hljs-number">1</span>, <span class="hljs-number">3</span>)<br>  choice = random.randint(<span class="hljs-number">1</span>, <span class="hljs-number">3</span>)<br>  print(<span class="hljs-string">"We picked door "</span> + str(choice))<br><br>  <span class="hljs-comment"># Show a door that is not the winning door:</span><br>  <span class="hljs-keyword">if</span> prize != <span class="hljs-number">1</span> <span class="hljs-keyword">and</span> choice != <span class="hljs-number">1</span>: showdoor = <span class="hljs-number">1</span><br>  <span class="hljs-keyword">elif</span> prize != <span class="hljs-number">2</span> <span class="hljs-keyword">and</span> choice != <span class="hljs-number">2</span>: showdoor = <span class="hljs-number">2</span><br>  <span class="hljs-keyword">else</span>: showdoor = <span class="hljs-number">3</span><br>  print(<span class="hljs-string">"We were shown that door "</span> + str(showdoor) + <span class="hljs-string">" was a goat"</span>)<br><br>  <span class="hljs-comment"># We did NOT swap the door:</span><br>  <span class="hljs-keyword">if</span>   choice == <span class="hljs-number">1</span> <span class="hljs-keyword">and</span> showdoor == <span class="hljs-number">2</span>: choice = <span class="hljs-number">3</span><br>  <span class="hljs-keyword">elif</span> choice == <span class="hljs-number">1</span> <span class="hljs-keyword">and</span> showdoor == <span class="hljs-number">3</span>: choice = <span class="hljs-number">2</span><br><br>  <span class="hljs-keyword">elif</span> choice == <span class="hljs-number">2</span> <span class="hljs-keyword">and</span> showdoor == <span class="hljs-number">1</span>: choice = <span class="hljs-number">3</span><br>  <span class="hljs-keyword">elif</span> choice == <span class="hljs-number">2</span> <span class="hljs-keyword">and</span> showdoor == <span class="hljs-number">3</span>: choice = <span class="hljs-number">1</span><br><br>  <span class="hljs-keyword">elif</span> choice == <span class="hljs-number">3</span> <span class="hljs-keyword">and</span> showdoor == <span class="hljs-number">1</span>: choice = <span class="hljs-number">2</span><br>  <span class="hljs-keyword">elif</span> choice == <span class="hljs-number">3</span> <span class="hljs-keyword">and</span> showdoor == <span class="hljs-number">2</span>: choice = <span class="hljs-number">1</span><br>    <br>  print(<span class="hljs-string">"We DID swap doors."</span>)<br><br>  <span class="hljs-comment"># Check if we won:</span><br>  <span class="hljs-keyword">if</span> prize == choice:<br>    print(<span class="hljs-string">"WE WIN!!!!!!!!!!!!!!!"</span>)<br>    results.append( &#123;<span class="hljs-string">"result"</span>: <span class="hljs-number">1</span>&#125; )<br>  <span class="hljs-keyword">else</span>:<br>    print(<span class="hljs-string">" :( "</span>)<br>    results.append( &#123;<span class="hljs-string">"result"</span>: <span class="hljs-number">0</span>&#125; )<br>    <br>df = pd.DataFrame(results)<br></code></pre></td></tr></table></figure></li></ul><h2 id="其他">其他</h2><p>enumerate() 函数用于将一个可遍历的数据对象(如列表、元组或字符串)组合为一个索引序列，同时列出数据和数据下标，一般用在 for 循环当中</p><p>向量范数</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">while</span> sum(i**<span class="hljs-number">2</span> <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> f(x)) &gt;= TOL**<span class="hljs-number">2</span>:<br></code></pre></td></tr></table></figure><p>列表一个溢出error的解决</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python">i = [<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">5</span>, <span class="hljs-number">8</span>, <span class="hljs-number">13</span>]<br>j = [<span class="hljs-literal">None</span>] * len(i)<br><span class="hljs-comment">#j == [None, None, None, None, None, None]</span><br>k = <span class="hljs-number">0</span><br><br><span class="hljs-keyword">for</span> l <span class="hljs-keyword">in</span> i:<br>   j[k] = l<br>   k += <span class="hljs-number">1</span><br></code></pre></td></tr></table></figure><p>Python中初始化一个5 x 3每项为0的数组，最好方法是：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">multilist = [[<span class="hljs-number">0</span> <span class="hljs-keyword">for</span> col <span class="hljs-keyword">in</span> range(<span class="hljs-number">5</span>)] <span class="hljs-keyword">for</span> row <span class="hljs-keyword">in</span> range(<span class="hljs-number">3</span>)]<br></code></pre></td></tr></table></figure><p>np数组索引：</p><p>A[i,j]</p><p>A[i,:i] i的前一个</p><p>A[i,i:] 算上i往后</p><p>函数中的参量似乎不是形参</p><p>if all(abs(x1[i]-x0[i]) &lt; eps for i in range(n))</p><p>[max([abs(m[i][j]) for j in range(n)]) for i in range(n)]</p><p>A.shape[0]和A.shape[1]</p><p>print(...,end=' ')</p><p>新的Python语法，是不支持的代码对齐中，混用TAB和空格的。所以出现上述错误提示了。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">map(func, seq1[, seq2,…])<br></code></pre></td></tr></table></figure><p>第一个参数接受一个函数名，后面的参数接受一个或多个可迭代的序列，返回的是一个集合。 Python函数编程中的map()函数是将func作用于seq中的每一个元素，并将所有的调用的结果作为一个list返回。如果func为None，作用同zip()。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">print(“&#123;:<span class="hljs-number">.3</span>f&#125;<span class="hljs-string">".format())</span><br></code></pre></td></tr></table></figure><p>Matrix product of two arrays:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">numpy.matmul(*x1*, *x2*, */*, *out=<span class="hljs-literal">None</span>*, ***, *casting=<span class="hljs-string">'same_kind'</span>*, *order=<span class="hljs-string">'K'</span>*, *dtype=<span class="hljs-literal">None</span>*, *subok=<span class="hljs-literal">True</span>*[, *signature*, *extobj*]) *= *<br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python">D = np.diag(np.diag(A)) <span class="hljs-comment"># A的对角元构成的矩阵</span><br>L = np.tri(*np.shape(A),<span class="hljs-number">-1</span>) * (-A)  <span class="hljs-comment"># A的下三角元的相反数构成的矩阵L</span><br>U = D - L -A <span class="hljs-comment">#A的上三角元的相反数构成的元素</span><br>M = np.linalg.inv(D-L)  <span class="hljs-comment">#求（D-L）的逆</span><br></code></pre></td></tr></table></figure><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python">numpy.tri(N, M=None, k=0, dtype=&lt;class 'float'&gt;)[source]<br>/*An array with ones at and below the given diagonal and zeros elsewhere.*/<br>/*k : int, optional<br>The sub-diagonal at and below which the array is filled. k = 0 is the main diagonal, while k &lt; 0 is below it, and k &gt; 0 is above. The default is 0.*/<br>np.tri(3, 5, 2, dtype=int)<br>array([[1, 1, 1, 0, 0],<br>       [1, 1, 1, 1, 0],<br>       [1, 1, 1, 1, 1]])<br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">list(enumerate(<span class="hljs-string">'abc'</span>, <span class="hljs-number">1</span>)) <br>[(<span class="hljs-number">1</span>, <span class="hljs-string">'a'</span>), (<span class="hljs-number">2</span>, <span class="hljs-string">'b'</span>), (<span class="hljs-number">3</span>, <span class="hljs-string">'c'</span>)]<br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment">#三元运算</span><br>[on_true] <span class="hljs-keyword">if</span> [expression] <span class="hljs-keyword">else</span> [on_false]<br>x, y = <span class="hljs-number">50</span>, <span class="hljs-number">25</span><br>small = x <span class="hljs-keyword">if</span> x &lt; y <span class="hljs-keyword">else</span> y<br></code></pre></td></tr></table></figure><figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs dockerfile">xk = x.<span class="hljs-keyword">copy</span><span class="bash">()</span><br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python">a = [i/<span class="hljs-number">100.0</span> <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> range(<span class="hljs-number">10</span>, <span class="hljs-number">50</span>)]<br><br>numpy.arange(<span class="hljs-number">0.1</span>, <span class="hljs-number">0.5</span>, <span class="hljs-number">0.01</span>)<br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python">x = np.linspace(<span class="hljs-number">-10</span>,<span class="hljs-number">10</span>,<span class="hljs-number">500</span>)<br>y = f(x)<br>plt.plot(x,y,color=<span class="hljs-string">"orange"</span>,label=<span class="hljs-string">"$x^2 + 10 * sin(x) + 1$"</span>,linewidth=<span class="hljs-number">2</span>)<br></code></pre></td></tr></table></figure><p>获取横纵坐标的简洁写法</p><p>plot里面可以用latex！</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">res = minimize_scalar(f, bounds = (<span class="hljs-number">-5</span>, <span class="hljs-number">0</span>), method = <span class="hljs-string">'bounded'</span>)<br><span class="hljs-keyword">print</span> <span class="hljs-string">"(-5, 0)"</span>, res.x<br></code></pre></td></tr></table></figure><p>获取极值以及对应的坐标</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment">#支持中文显示</span><br><span class="hljs-keyword">from</span> pylab <span class="hljs-keyword">import</span> *<br>mpl.rcParams[<span class="hljs-string">'font.sans-serif'</span>] = [<span class="hljs-string">'SimHei'</span>]<br> <br><span class="hljs-comment">#创建数据</span><br>x = np.linspace(<span class="hljs-number">-5</span>, <span class="hljs-number">5</span>, <span class="hljs-number">100</span>)<br>y1 = np.sin(x)<br>y2 = np.cos(x)<br> <br><span class="hljs-comment">#创建figure窗口</span><br>plt.figure(num=<span class="hljs-number">3</span>, figsize=(<span class="hljs-number">8</span>, <span class="hljs-number">5</span>))<br><span class="hljs-comment">#画曲线1</span><br>plt.plot(x, y1)<br><span class="hljs-comment">#画曲线2</span><br>plt.plot(x, y2, color=<span class="hljs-string">'blue'</span>, linewidth=<span class="hljs-number">5.0</span>, linestyle=<span class="hljs-string">'--'</span>)<br><span class="hljs-comment">#设置坐标轴范围</span><br>plt.xlim((<span class="hljs-number">-5</span>, <span class="hljs-number">5</span>))<br>plt.ylim((<span class="hljs-number">-2</span>, <span class="hljs-number">2</span>))<br><span class="hljs-comment">#设置坐标轴名称</span><br>plt.xlabel(<span class="hljs-string">'xxxxxxxxxxx'</span>)<br>plt.ylabel(<span class="hljs-string">'yyyyyyyyyyy'</span>)<br><span class="hljs-comment">#设置坐标轴刻度</span><br>my_x_ticks = np.arange(<span class="hljs-number">-5</span>, <span class="hljs-number">5</span>, <span class="hljs-number">0.5</span>)<br>my_y_ticks = np.arange(<span class="hljs-number">-2</span>, <span class="hljs-number">2</span>, <span class="hljs-number">0.3</span>)<br>plt.xticks(my_x_ticks)<br>plt.yticks(my_y_ticks)<br> <br><span class="hljs-comment">#显示出所有设置</span><br>plt.show()<br></code></pre></td></tr></table></figure><p>python添加元素</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python">p_arr = np.concatenate((p_arr,[p_])) <span class="hljs-comment"># 先将p_变成list形式进行拼接，注意输入为一个tuple</span><br>p_arr = np.append(p_arr,p_) <span class="hljs-comment">#直接向p_arr里添加p_</span><br><span class="hljs-comment">#注意一定不要忘记用赋值覆盖原p_arr不然不会变</span><br></code></pre></td></tr></table></figure><p>Np.cos 自变量是弧度</p><p>卡西欧计算器cos自变量是角度</p><p>当函数要接受元组或者字典参数时，它分别使用*和**前缀。</p><p>如果使用**前缀，多余的参数会被认为是字典.</p><h2 id="绘制三维图">绘制三维图</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python">fig = plt.figure()<br>ax = Axes3D(fig)<br>X = np.meshgrid(X)<br>Y = np.meshgrid(Y)<br>Z = f(X,Y)<br>ax.plot_surface(X,Y,Z,cmap=plt.get_cmap(<span class="hljs-string">'rainbow'</span>))<br></code></pre></td></tr></table></figure><h2 id="聚类分析">聚类分析</h2><h3 id="k-均值聚类">1. K-均值聚类</h3><p>划分式聚类方法。</p><p>已知要分点聚类数，随机生成类数个质心，从质心出发逐渐分类</p><ul><li>生成 KMeans 类</li><li>使用 KMeans 中的 fit_predict 函数直接得聚类后各点对应的类标签</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> sklearn.datasets <span class="hljs-keyword">import</span> make_blobs<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br><span class="hljs-keyword">from</span> sklearn.cluster <span class="hljs-keyword">import</span> KMeans<br><br><span class="hljs-comment"># 生成n_samples个点对,data[1]是每个成员的整数标签(类别)</span><br>data = make_blobs(n_samples=<span class="hljs-number">500</span>, n_features=<span class="hljs-number">2</span>, centers=<span class="hljs-number">8</span>,<br>                  cluster_std=<span class="hljs-number">1.6</span>, random_state=<span class="hljs-number">50</span>)<br>points = data[<span class="hljs-number">0</span>]<br>fig1 = plt.figure()  <span class="hljs-comment"># 生成画布</span><br>fig1 = plt.scatter(points[:, <span class="hljs-number">0</span>], points[:, <span class="hljs-number">1</span>], c=data[<span class="hljs-number">1</span>],<br>                   cmap=<span class="hljs-string">'viridis'</span>)<br>plt.title(<span class="hljs-string">'before'</span>)<br>plt.xlim(<span class="hljs-number">-15</span>, <span class="hljs-number">15</span>)<br>plt.ylim(<span class="hljs-number">-15</span>, <span class="hljs-number">15</span>)<br><br><span class="hljs-comment"># create kmeans object</span><br>kmeans = KMeans(n_clusters=<span class="hljs-number">8</span>)<br><br><span class="hljs-comment"># print location of clusters learned by kmeans object</span><br><span class="hljs-comment"># print(kmeans.cluster_centers_)</span><br><br>km_res = kmeans.fit_predict(points)<br><br>fig2 = plt.figure()<br>fig2 = plt.scatter(points[:, <span class="hljs-number">0</span>], points[:, <span class="hljs-number">1</span>], c=km_res,<br>                   cmap=<span class="hljs-string">'viridis'</span>)  <span class="hljs-comment"># c:color 按data[1]给每个点对应的颜色</span><br>plt.title(<span class="hljs-string">'after'</span>)<br>plt.xlim(<span class="hljs-number">-15</span>, <span class="hljs-number">15</span>)<br>plt.ylim(<span class="hljs-number">-15</span>, <span class="hljs-number">15</span>)<br>plt.show()<br></code></pre></td></tr></table></figure><h3 id="层次分析聚类">2. 层次分析聚类</h3><p>层次化聚类方法。</p><p>从每个点各为一类开始，“归并”。</p><p>步骤：</p><ul><li>生成距离矩阵：pdist函数</li><li>进行层次聚类，使用ward提出的离差平方和方法效果较好： linkage函数。 注：返回的Z的第一列和第二列代表聚集的两类的序列号，第三列代表第一列和第二列序号所代表的集群在聚集时的距离(与层次聚类图的高度相等)，第四列代表聚集时所包含的原始数据的个数</li><li>绘制树状图 dendrogram 函数</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br><span class="hljs-keyword">import</span> scipy<br><span class="hljs-keyword">import</span> scipy.cluster.hierarchy <span class="hljs-keyword">as</span> sch<br><br><br><span class="hljs-comment"># 生成待聚类的数据点,这里生成了20个点,每个点4维:</span><br>points = scipy.randn(<span class="hljs-number">20</span>, <span class="hljs-number">4</span>)<br><br><span class="hljs-comment"># 生成点与点之间的距离矩阵,这里用的欧氏距离:</span><br>disMat = sch.distance.pdist(points, <span class="hljs-string">'euclidean'</span>)<br><span class="hljs-comment"># 进行层次聚类:</span><br>Z = sch.linkage(disMat, method=<span class="hljs-string">'ward'</span>)<br><span class="hljs-comment"># 将层级聚类结果以树状图表示出来并保存为plot_dendrogram.png</span><br>P = sch.dendrogram(Z)<br>plt.savefig(<span class="hljs-string">'plot_dendrogram.png'</span>)<br><br><span class="hljs-comment"># 根据linkage matrix Z得到聚类结果:</span><br>cluster = sch.fcluster(Z, t=<span class="hljs-number">4</span>, criterion=<span class="hljs-string">'maxclust'</span>)<span class="hljs-comment">#t表示最大聚类簇数</span><br>print(<span class="hljs-string">"Original cluster by hierarchy clustering:\n"</span>, cluster)<br><br>plt.show()<br></code></pre></td></tr></table></figure><h3 id="应用">3. 应用</h3><p>首先使用变量聚类法找出相关度较低的“主变量”（主要指标），删除主变量之外的次变量，然后根据主变量使用样本聚类分析法进行样本分类。</p><h2 id="主成分分析-pca">主成分分析 PCA</h2><p>Principle Component Analysis. 将相关度很高的向量转化为相关度较低的向量。</p><p>Python 实现：</p><p>直接调库：<strong>sklearn.decomposition.PCA</strong> （类）</p><p>参数：</p><ul><li>n_component : 想要将到的维数；或者规定主成分的累计贡献率阀值（percentage）</li><li>whiten: 是否白化，即归一化</li><li>explained_variance_ : 代表降维后的各主成分的方差值。方差值越大，则说明越是重要的主成分。</li><li>explained_variance_ratio_ : 代表降维后的各主成分的方差值占总方差值的比例(累计贡献率)</li><li>Y = fit_transform(X) 利用主成分分析方法对数据降维，返回对X降维后的矩阵: X.shape=(n_samples,n_features); Y.shape=(n_samples,n_components)</li><li>fit(X) 利用主成分分析法对X降维和变换，X已经改变</li><li>transform(X) 返回 n_samples<span class="math inline">\(\times\)</span> n_components 的切掉后面的矩阵</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br><span class="hljs-keyword">from</span> sklearn.decomposition <span class="hljs-keyword">import</span> PCA<br><br>x = np.array([[<span class="hljs-number">1</span>, <span class="hljs-number">2</span>], [<span class="hljs-number">1</span>, <span class="hljs-number">4</span>], [<span class="hljs-number">5</span>, <span class="hljs-number">8</span>]])<br>pca = PCA(n_components=<span class="hljs-number">0.9</span>)<br>y = pca.fit_transform(x)<br>print(<span class="hljs-string">"累计贡献率："</span>, pca.explained_variance_ratio_)<br>print(<span class="hljs-string">"变换后的x"</span>, y)<br><span class="hljs-comment">#or:</span><br><span class="hljs-comment">#pca.fit(x)</span><br><span class="hljs-comment">#y=pca.transform(x)</span><br></code></pre></td></tr></table></figure><p>（numpy练习）</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><br><span class="hljs-comment"># 归一化</span><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">stdData</span><span class="hljs-params">(dataMat)</span>:</span><br>    meanVal = np.mean(dataMat, axis=<span class="hljs-number">0</span>)  <span class="hljs-comment"># 按列求均值，即求各个特征的均值</span><br>    _, n = dataMat.shape<br>    stdval = np.std(dataMat, axis=<span class="hljs-number">0</span>)<br>    newData = (dataMat - meanVal)<br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> range(n):<br>        newData[:, i] /= stdval[i]<br>    <span class="hljs-keyword">return</span> newData<br><br><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">percentage2n</span><span class="hljs-params">(eigVals, percentage)</span>:</span><br>    sortEig = np.sort(eigVals)  <span class="hljs-comment"># 升序</span><br>    sortEig = sortEig[<span class="hljs-number">-1</span>::<span class="hljs-number">-1</span>]  <span class="hljs-comment"># 逆转，即降序</span><br>    arraySum = sum(sortEig)<br>    tmpSum = <span class="hljs-number">0</span><br>    num = <span class="hljs-number">0</span><br>    contribute = []  <span class="hljs-comment"># 信息贡献率</span><br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> sortEig:<br>        contribute.append(i / arraySum)<br>    contribute = np.array(contribute)<br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> sortEig:<br>        tmpSum += i<br>        num += <span class="hljs-number">1</span><br>        <span class="hljs-keyword">if</span> tmpSum &gt;= arraySum * percentage:<br>            <span class="hljs-keyword">return</span> num, contribute<br><br><span class="hljs-comment">#主成分分析</span><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">PCA</span><span class="hljs-params">(dataMat, percentage=<span class="hljs-number">0.9</span>)</span>:</span><br>    newData = stdData(dataMat)<br>    corMat = np.corrcoef(newData, rowvar=<span class="hljs-number">0</span>)<br>    <span class="hljs-comment"># 求特征值和特征向量,特征向量是按列放的，即一列代表一个特征向量</span><br>    eigVals, eigVects = np.linalg.eig(np.mat(corMat))<br>    eigValIndice = np.argsort(eigVals)  <span class="hljs-comment"># 对特征值从小到大排序</span><br>    n, contribute = percentage2n(eigVals, percentage)  <span class="hljs-comment"># 达到累积贡献率百分比的n,默认90%</span><br>    n_eigValIndice = eigValIndice[<span class="hljs-number">-1</span>:-(n + <span class="hljs-number">1</span>):<span class="hljs-number">-1</span>]  <span class="hljs-comment"># 最大的n个特征值的下标</span><br>    n_eigVect = eigVects[:, n_eigValIndice]  <span class="hljs-comment"># 最大的n个特征值对应的特征向量</span><br>    lowDDataMat = newData[:,:n] * n_eigVect  <span class="hljs-comment"># 低维特征空间的数据</span><br>    contribute = contribute[:n]<br>    score = np.float(contribute * lowDDataMat)  <span class="hljs-comment"># 基于主成分分析的综合评价得分</span><br>    <span class="hljs-keyword">return</span> lowDDataMat, score<br><br><br>x = np.array([[<span class="hljs-number">1</span>, <span class="hljs-number">2</span>], [<span class="hljs-number">1</span>, <span class="hljs-number">4</span>], [<span class="hljs-number">5</span>, <span class="hljs-number">8</span>]])<br>print(PCA(x))<br></code></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Computer Science </category>
          
          <category> Language Learning </category>
          
          <category> Python </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>LaTex Tricks</title>
      <link href="/2020/01/25/LaTex/Latex-Tricks/"/>
      <url>/2020/01/25/LaTex/Latex-Tricks/</url>
      
        <content type="html"><![CDATA[<h1 id="latex-tricks">LaTex Tricks</h1><h4 id="字母上面加东西">字母上面加东西：</h4><ul><li><p>$ x$ : x, $ x$ : x , <span class="math inline">\(\hat x\)</span> : x, <span class="math inline">\(\widehat x\)</span> : x</p></li><li><p><span class="math inline">\(\widetilde {x}, \widetilde{ab}\)</span> : *** {x}, </p></li><li><span class="math inline">\(\dot x\)</span> : x, <span class="math inline">\(\ddot x\)</span> : x</li><li><p><span class="math inline">\(\vec{x}\)</span> : x</p></li><li><p>东西上写东西 <span class="math inline">\(\overset{a}{bcd}\)</span> ： </p></li></ul><h4 id="数学常用">数学常用：</h4><ul><li><p>$ <em>{1in}$ : </em>{1in}{1in}</p></li><li><p><span class="math inline">\(\because\)</span> -- , <span class="math inline">\(\therefore\)</span> -- </p></li><li><p><span class="math inline">\(\forall\)</span> : , $ $ : </p></li><li><p><span class="math inline">\(\sqrt[n]{abc}\)</span> : </p><p><a id="more"></a></p></li><li><p><span class="math inline">\(a\biggm| \displaystyle{\frac{n+1}{3}}\)</span> : a<strong>|</strong> ***{}</p></li><li><p><span class="math inline">\(\pm\)</span> : </p></li><li><p><span class="math inline">\(\mp\)</span> : </p></li><li><p>多行对齐：\begin{aligned} &amp; \end{aligned}</p></li><li><p>大括号：<span class="math display">\[\begin{equation} \begin{aligned} \left \ {  \right. \end{aligned}\end{equation}\]</span></p></li><li><p>同构 <span class="math inline">\(\cong\)</span> ：</p></li><li><p>内积 <span class="math inline">\(\langle \rangle\)</span> : </p></li><li><p>等号上写东西 <span class="math inline">\(\xlongequal[abc]{def}\)</span> : </p></li></ul><h4 id="物理常用">物理常用：</h4><ul><li><span class="math inline">\(\nabla\)</span> ：</li></ul>]]></content>
      
      
      <categories>
          
          <category> LaTex </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>Image Processing 学习笔记</title>
      <link href="/2020/01/24/Computer-Sciencs/Image-Processing%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
      <url>/2020/01/24/Computer-Sciencs/Image-Processing%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/</url>
      
        <content type="html"><![CDATA[<h1 id="图像信息处理">图像信息处理</h1><h2 id="灰度变换与空间滤波">1 灰度变换与空间滤波</h2><h3 id="灰度变换str">1.1 灰度变换：<span class="math inline">\(s=T(r)\)</span></h3><ul><li>图像反转：<span class="math inline">\(s=L-1-r\)</span></li><li>对数变换：<span class="math inline">\(s=c\log(1+r)\)</span></li><li>伽马变换：<span class="math inline">\(s=cr^\gamma\)</span></li><li>分段分式线性变换：对比度拉伸、灰度级分层、比特平面分层</li></ul><p>$ \ $ <a id="more"></a></p><h3 id="直方图处理">1.2 直方图处理</h3><p>$ h(r_k)=n_k$ ，<span class="math inline">\(r_k\)</span> 是第 <span class="math inline">\(k\)</span> 级灰度值，<span class="math inline">\(n_k\)</span> 为图像中灰度为 <span class="math inline">\(r_k\)</span> 的像素个数。不妨从 <span class="math inline">\(0\)</span> 开始，令 <span class="math inline">\(r_k=k\)</span></p><p>归一化： <span class="math inline">\(p(r_k)=n_k/MN\)</span></p><h4 id="直方图均衡化">1.2.1 直方图均衡化</h4><ol type="1"><li><span class="math inline">\(p_s(s)=p_r(r)\cdot |\displaystyle\frac{dr}{ds}|=p_r(r) / |T^{&#39;}(r)|\)</span></li><li>选取变换函数 <span class="math inline">\(s=T(r)=(L-1) \displaystyle\int_0 ^r p_r(w)dw\)</span></li><li><span class="math inline">\(=&gt; \quad p_s(s)=\displaystyle\frac{1}{L-1}\)</span></li><li>离散形式：$ s_k=T(r_k)=(L-1)<em>{j=0}^k p_r (r </em> j)=_{j=0}^k n_j $，最后取值四舍五入</li></ol><h4 id="直方图规定化">1.2.2 直方图规定化</h4><h4 id="局部直方图处理">1.2.3 局部直方图处理</h4><p>略～</p><p>$ \ $</p><h2 id="空间滤波">1.2 空间滤波</h2><p>空间滤波器由一个邻域和预定义操作组成。</p><p><span class="math inline">\(g(x,y)=\displaystyle\sum\limits_{s=-a}^b\sum\limits_{t=-b}^b w(s,t)f(x+s,y+t)\)</span></p><h3 id="空间相关与卷积">1.2.1 空间相关与卷积</h3><p>相关上滤波器模版移过图像并计算每个位置乘积之和的处理，卷积的机理类似，但滤波器首先要旋转<span class="math inline">\(180^o\)</span></p><h4 id="平滑空间滤波器">1.2.1.1 平滑空间滤波器</h4><ul><li>均值滤波器：<span class="math inline">\(g(x,y)=\displaystyle\frac{\sum\limits_{s=-a}^a\sum\limits_{s=-b}^b w(s,t)f(x+s,y+t)}{\sum\limits_{s=-a}^a\sum\limits_{s=-b}^b w(s,t)}\)</span></li><li>统计排序滤波器 $e.g. $ 中值滤波器：去除椒盐噪声</li></ul><p>$ \ $</p><h4 id="锐化空间滤波器">1.2.1.2 锐化空间滤波器</h4><p>定义: <span class="math inline">\(\displaystyle\frac{\partial f}{\partial x}=f(x+1)-f(x)\)</span> , <span class="math inline">\(\displaystyle\frac{\partial ^2f}{\partial^2 x}=f(x+1)+f(x-1)-2f(x)\)</span></p><ol type="1"><li>使用拉普拉斯算子</li></ol><p><span class="math inline">\(\nabla^2 f(x,y)=f(x+1,y)+f(x-1,y)+f(x,y+1)+f(x,y-1)-4f(x,y)\)</span></p><p><span class="math inline">\(g(x,y)=f(x,y)+c[\nabla^2 f(x,y)]\)</span></p><p><a href="https://www.cnblogs.com/polly333/p/7269843.html" target="_blank" rel="noopener">比较清楚的介绍</a></p><ol start="2" type="1"><li>非锐化掩蔽</li></ol><ol type="1"><li>模糊原图像 <span class="math inline">\(\overline f (x,y)\)</span></li><li>从原图像中减去模糊图像（产生差值图像，即模版）<span class="math inline">\(g_{mask}(x,y)=f(x,y)-\overline f(x,y)\)</span></li><li>将模版加到原图像上 <span class="math inline">\(g(x,y)=f(x,y)+k\cdot g_{mask}(x,y)\)</span></li></ol><ol start="3" type="1"><li>使用梯度算子</li></ol><p><a href="https://blog.csdn.net/qq_29540745/article/details/51918004" target="_blank" rel="noopener">Soble算子</a>：<span class="math inline">\(M(x,y)=|(z_7+2z_8+z_9)-(z_1+2z_2+z_3)|+|(z_3+2z_6+z_9)-(z_1+2z_4+z_7)\)</span></p><p>$ \ $</p><h3 id="使用模糊技术进行灰度变换和空间滤波">1.2.2 使用模糊技术进行灰度变换和空间滤波</h3><h4 id="模糊集合论">1.2.2.1 模糊集合论</h4><ul><li><p>模糊集合：<span class="math inline">\(\{(z,\mu(z))\}\)</span> 有元素和它的隶属度函数组成的数对组成，<span class="math inline">\(\mu(z)\in[0,1]\)</span></p></li><li><p>模糊逻辑：</p><p>$ A AND B(_A(z),_B(z)),zZ $ ,</p><p><span class="math inline">\(A\ OR\ B\iff \max(\mu_A(z),\mu_B(z)),\quad \forall z\in Z\)</span> ,</p><p>$A=B_A (z)=_B (z),zZ $ ,</p><p>$AB_A(z)_B(z),zZ $ ,</p><p>$AB_A(z)_B(z),zZ $ .</p></li><li><p>应用步骤：</p><ul><li><span class="math inline">\(IF-THEN\)</span> 形式化</li><li>输入输出模糊化：<span class="math inline">\(\mu_i(z),\mu_o(z)\)</span></li><li>既满足 <span class="math inline">\(IF\)</span> 又满足 <span class="math inline">\(THEN\)</span> <span class="math inline">\(=&gt; INPUT\&amp;OUTPUT\)</span> <span class="math inline">\(=&gt; \mu_3(z,v)=\min\{\mu_i(z),\mu_o(v)\}\)</span></li><li>对每一个 <span class="math inline">\(z_0\)</span> ，最终模糊输出 <span class="math inline">\(Q(v)=\mu_3(z_0,v)\)</span> , 对于多个 <span class="math inline">\(Q_i(v)\)</span> ，全部模糊响应应为单个模糊响应的并集，取 <span class="math inline">\(\max\limits_i (Q_i (v))\)</span></li><li>去模糊：计算集合重心：<span class="math inline">\(v_0=\displaystyle\frac{\sum\limits_{v=1}^K vQ(v)}{\sum\limits_{v=1}^K Q(v)}\)</span></li></ul></li></ul><h4 id="利用模糊集合论进行灰度变换">1.2.2.2 利用模糊集合论进行灰度变换</h4><ul><li><p>目的：增强对比度。黑的更黑，白的更白，灰的仍灰</p></li><li><p><span class="math inline">\(IF-THEN\)</span> 形式化：</p><ul><li><p>$IFdark,THEN darker $</p></li><li><p><span class="math inline">\(IF\quad gray ,\quad THEN \quad gray\)</span></p></li><li><p><span class="math inline">\(IF\quad white,\quad THEN \quad whiter\)</span></p></li></ul></li><li><p>输入模糊化：<span class="math inline">\(dark-\mu_{id}(z),\quad gray-\mu_{ig}(z),\quad white-\mu_{iw}(z)\)</span></p><ul><li><span class="math display">\[\mu_{id}(z)=\begin{equation}\left\{\begin{aligned}1 &amp;, &amp;  0\leq z&lt; 80, \\ \displaystyle\frac{1}{47}(127-z)&amp; , &amp; 80\leq z\leq 127,\\ 0&amp;,&amp; 127&lt;z\leq 255\end{aligned}\right.\end{equation} \]</span></li><li><span class="math display">\[\mu_{ig}(z)=\begin{equation}\left\{\begin{aligned}0 &amp;, &amp;  0\leq z&lt; 80, \\ \displaystyle\frac{1}{47}(z-80)&amp; , &amp; 80\leq z\leq 127,\\ \displaystyle\frac{1}{47}(174-z)&amp; , &amp; 127&lt;z\leq 174,\\ 0&amp;,&amp; 174&lt;z\leq 255\end{aligned}\right.\end{equation} \]</span></li><li><span class="math display">\[\mu_{iw}(z)=\begin{equation}\left\{\begin{aligned}0 &amp;, &amp;  0\leq z&lt; 127, \\ \displaystyle\frac{1}{47}(z-127)&amp; , &amp; 127\leq z\leq 174,\\ 1&amp;,&amp; 174&lt;z\leq 255\end{aligned}\right.\end{equation} \]</span></li></ul></li><li>输出模糊化：<span class="math inline">\(datker-\mu_{od}(v),\quad gray-\mu_{og}(v),\quad whiter-\mu_{ow}(v)\)</span><ul><li><span class="math display">\[\mu_{od}(v)=\begin{equation}\left \{\begin{aligned}\infty,&amp;\quad v=v_d\\ 0,&amp;\quad otherwise \end{aligned}\right.\end{equation}\]</span></li><li><span class="math display">\[\mu_{og}(v)=\begin{equation}\left \{\begin{aligned}\infty,&amp;\quad v=v_g\\ 0,&amp;\quad otherwise \end{aligned}\right.\end{equation}\]</span></li><li><span class="math display">\[\mu_{ow}(v)=\begin{equation}\left \{\begin{aligned}\infty,&amp;\quad v=v_w\\ 0,&amp;\quad otherwise \end{aligned}\right.\end{equation}\]</span></li></ul></li><li>输出最终模糊响应：<span class="math inline">\(Q(v)=\max\{Q_d,Q_g,Q_w\}=\max\{\min\limits_{v\in Z}\{\mu_{ik}(z_0),\mu_{ok}(v)\}\}\)</span></li><li><p>去模糊：<span class="math inline">\(v_0=\displaystyle\frac{\mu_{id}(z_0)\cdot v_d+\mu_{ig}(z_0)\cdot v_g+\mu_{iw}(z_0)\cdot v_w}{\mu_{id}(z_0)+\mu_{ig}(z_0)+\mu_{iw}(z_0)}\)</span></p></li></ul><p><strong>Code : </strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 基于模糊集合论的灰度变换 </span><br><span class="hljs-comment"># 增加对比度</span><br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> cv2<br><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">f_id</span><span class="hljs-params">(z)</span>:</span><br><br>    <span class="hljs-keyword">if</span> z &lt; <span class="hljs-number">80</span>:<br>        <span class="hljs-keyword">return</span> <span class="hljs-number">1</span><br>    <span class="hljs-keyword">elif</span> z &gt;= <span class="hljs-number">80</span> <span class="hljs-keyword">and</span> z &lt;= <span class="hljs-number">127</span>:<br>        <span class="hljs-keyword">return</span> <span class="hljs-number">1</span> / <span class="hljs-number">47</span> * (<span class="hljs-number">127</span> - z)<br>    <span class="hljs-keyword">else</span>:<br>        <span class="hljs-keyword">return</span> <span class="hljs-number">0</span><br><br><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">f_ig</span><span class="hljs-params">(z)</span>:</span><br><br>    <span class="hljs-keyword">if</span> z &gt;= <span class="hljs-number">80</span> <span class="hljs-keyword">and</span> z &lt;= <span class="hljs-number">127</span>:<br>        <span class="hljs-keyword">return</span> <span class="hljs-number">1</span> / <span class="hljs-number">47</span> * (z - <span class="hljs-number">80</span>)<br>    <span class="hljs-keyword">elif</span> z &gt; <span class="hljs-number">127</span> <span class="hljs-keyword">and</span> z &lt;= <span class="hljs-number">174</span>:<br>        <span class="hljs-keyword">return</span> <span class="hljs-number">1</span> / <span class="hljs-number">47</span> * (<span class="hljs-number">174</span> - z)<br>    <span class="hljs-keyword">else</span>:<br>        <span class="hljs-keyword">return</span> <span class="hljs-number">0</span><br><br><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">f_iw</span><span class="hljs-params">(z)</span>:</span><br><br>    <span class="hljs-keyword">if</span> z &gt;= <span class="hljs-number">127</span> <span class="hljs-keyword">and</span> z &lt;= <span class="hljs-number">174</span>:<br>        <span class="hljs-keyword">return</span> <span class="hljs-number">1</span> / <span class="hljs-number">47</span> * (z - <span class="hljs-number">127</span>)<br>    <span class="hljs-keyword">elif</span> z &gt; <span class="hljs-number">174</span> <span class="hljs-keyword">and</span> z &lt;= <span class="hljs-number">255</span>:<br>        <span class="hljs-keyword">return</span> <span class="hljs-number">1</span><br>    <span class="hljs-keyword">else</span>:<br>        <span class="hljs-keyword">return</span> <span class="hljs-number">0</span><br><br><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">gray_trans</span><span class="hljs-params">(img)</span>:</span><br>    vd = <span class="hljs-number">0</span><br>    vg = <span class="hljs-number">127</span><br>    vw = <span class="hljs-number">255</span><br>    output_img = np.copy(img)<br>    m, n = img.shape<br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> range(<span class="hljs-number">1</span>, m):<br>        <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> range(<span class="hljs-number">1</span>, n):<br>            tmp1 = f_id(img[i][j]) * vd + f_ig(img[i][j]) * \<br>                vg + f_iw(img[i][j]) * vw<br>            tmp2 = f_id(img[i][j]) + f_ig(img[i][j]) + f_iw(img[i][j])<br>            output_img[i][j] = tmp1 / tmp2<br>    <span class="hljs-keyword">return</span> output_img<br><br><br>img = cv2.imread(<span class="hljs-string">'test.jpg'</span>, <span class="hljs-number">0</span>)<br>img2 = gray_trans(img)<br>cv2.imshow(<span class="hljs-string">'before'</span>, img)<br>cv2.imshow(<span class="hljs-string">'after'</span>, img2)<br>cv2.waitKey(<span class="hljs-number">0</span>)<br>cv2.destroyAllWindows()<br></code></pre></td></tr></table></figure><p><strong>效果：</strong>(before and after)</p><figure><img src="https://tva1.sinaimg.cn/large/006tNbRwly1gbdwm7ycd7j30dm0go0w3.jpg" alt="before" /><figcaption>before</figcaption></figure><figure><img src="https://tva1.sinaimg.cn/large/006tNbRwly1gbdwm89b0zj30dm0goq6v.jpg" alt="after" /><figcaption>after</figcaption></figure><h4 id="利用模糊集合进行空间滤波">1.2.2.3 利用模糊集合进行空间滤波</h4><p>有一种基于模糊集合的边缘提取方法.</p><p>$ \ $</p><h2 id="频率域滤波">2 频率域滤波</h2><h3 id="傅立叶变换基础">2.1 傅立叶变换基础</h3><h4 id="冲激函数相关">2.1.1 冲激函数相关</h4><ol type="1"><li><p>冲激函数 对连续函数取样和对离散函数取样定义有所不同</p></li><li><p>冲激串函数：<span class="math inline">\(\displaystyle s_{\Delta T}(t)=\sum\limits_{n=-\infty}^{\infty}\delta(t-n\Delta T)\)</span> , 以 <span class="math inline">\(\Delta T\)</span> 为间隔取样</p></li></ol><h4 id="傅立叶变换相关">2.1.2 傅立叶变换相关</h4><ol type="1"><li><p>傅立叶级数：<span class="math inline">\(\displaystyle f(t)=\sum\limits_{n=-\infty}^\infty c_ne^{j\frac{2\pi n}{T}t},\quad c_n=\frac{1}{T}\int_{-\frac{T}{2}}^\frac{T}{2}f(t)e^{-j\frac{2\pi n}{T}t}\)</span>, 其中 <span class="math inline">\(f(t)\)</span> 以 <span class="math inline">\(T\)</span> 为周期</p></li><li><p>傅立叶变换：$[f(t)]=_{-}<sup>f(t)e</sup>{-2t} dt $</p></li><li><p>关于原点对称的宽为 <span class="math inline">\(W\)</span> 、高为 <span class="math inline">\(A\)</span> 的带限函数 <span class="math inline">\(W(t)\)</span> 的傅立叶变换： <span class="math inline">\(\mathcal{F}[W(t)]=AWsinc(m)\)</span>, 其中在数字图像处理中，<span class="math inline">\(sinc(x)=\displaystyle\frac{sin(\pi x)}{\pi x}\)</span></p></li><li><p>冲激函数的傅立叶变换：<span class="math inline">\(\mathcal{F}[\delta(t-t_0)]=e^{-j2\pi\mu t_0}=&gt;\mathcal{F}^{-1}[e^{-j2\pi\mu t_0}]=\delta(t-t_0)=&gt;\mathcal{F}[e^{-j2\pi\mu_0 t}]=\delta(-\mu-\mu_0)\)</span></p></li><li><p>冲激串函数的傅立叶变换 ：</p><ul><li>将冲激串函数用傅立叶级数展开（不展开直接变换似乎不一致收敛，就不能交换求和号和积分号）：<span class="math inline">\(\displaystyle s_{\Delta T}(t)=\sum\limits_{n=-\infty}^\infty c_ne^{j\frac{2\pi n}{\Delta T}t},\quad c_n=\frac{1}{\Delta T}\int_{-\frac{\Delta T}{2}}^\frac{\Delta T}{2} s_{\Delta T}(t)e^{-j\frac{2\pi n}{\Delta T}t}=\frac{1}{\Delta T}e^0=\frac{1}{\Delta T}\\=&gt;\displaystyle s_{\Delta T}(t)=\frac{1}{\Delta T}\sum\limits_{n=-\infty}^\infty e^{j\frac{2\pi n}{\Delta T}t}\)</span></li><li><span class="math inline">\(S(\mu)=\displaystyle\mathcal{F}[ s_{\Delta T}(t)]=\frac{1}{\Delta T}\sum\limits_{n=-\infty}^\infty \delta(\mu-\frac{n}{\Delta T})\)</span></li></ul></li><li><p>卷积：</p><p><span class="math inline">\(\begin{aligned} f(t)*g(t)&amp;\iff F(\mu)\cdot G(\mu)\\F(\mu)*G(\mu)&amp;\iff f(t)\cdot g(t)\end{aligned}\)</span></p></li></ol><h4 id="取样">2.1.3 取样</h4><ul><li><p>取样后的函数 <span class="math inline">\(\widetilde f(t)=f(t)\cdot s_{\Delta T}(t)=\displaystyle \sum\limits_{n=-\infty}^{\infty}f(t)\delta(t-n\Delta T)\)</span></p></li><li><p>每个取样值：由加权后的冲激强度给出。 <span class="math inline">\(f_k=\displaystyle\int_{-\infty}^{\infty}f(t)\delta(t-k\Delta T)=f(k\Delta T)\)</span></p></li><li><p>取样后的函数的傅立叶变换：<span class="math inline">\(\displaystyle \widetilde F(\mu)=F(\mu)*S(\mu)=\frac{1}{\Delta T}\sum\limits_{n=-\infty}^{\infty}\int_{-\infty}^{\infty}F(\tau)\delta(\mu-\frac{n}{\Delta T}-\tau)d\tau=\frac{1}{\Delta T}\sum\limits_{n=-\infty}^{\infty}F(\mu-\frac{n}{\Delta T})\)</span></p><p>这是取样前函数<span class="math inline">\(F(\mu)\)</span> 的一个拷贝的无限、周期序列，确切的说是周期为 <span class="math inline">\(\displaystyle\frac{1}{\Delta T}\)</span> 的无限延伸的连续函数。</p></li><li><p>另一方面，直接变换得：<span class="math inline">\(\widetilde F(\mu)=\displaystyle \sum_{n=-\infty}^{\infty}\int_{-\infty}^{\infty}f(t)\delta (t-n\Delta T)e^{-j2\pi \mu t}dt= \sum_{n=-\infty}^{\infty}f(n\Delta T)e^{-j2\pi \mu n\Delta T}\)</span></p></li><li><strong>取样定理</strong>：如果一超过函数最高频率的两倍的取样率来获得样本，连续的带限函数可以完全地从它的样本集来恢复。 <span class="math inline">\(\displaystyle\frac{1}{\Delta T}&gt;2\mu_{max}\)</span></li><li>复原：令 <span class="math inline">\(H(\mu)=\begin{equation}\left\{\begin{aligned} \Delta T,&amp;\quad -\mu_{max}\leqslant\mu\leqslant\mu_{max}\\ 0.&amp;\quad otherwise\end{aligned}\right.\end{equation}\)</span>, <span class="math inline">\(F(\mu)=H(\mu)\cdot \widetilde F(\mu)\)</span>，进而由傅立叶逆变换可复原 <span class="math inline">\(f\)</span></li><li><p>但是，在实践中我们通常要限制函数的持续时间，相当于要乘一个周期内为 <span class="math inline">\(1\)</span> 其他地方为 <span class="math inline">\(0\)</span> 的函数，而这在频率域内相当于用 <span class="math inline">\(sinc(x)\)</span> 作卷积，这就引入了频率域无限周期分量。这样，在频率域截取时总无法截取全部周期，混淆总会产生。</p></li></ul><h3 id="离散傅立叶变换-dft">2.2 离散傅立叶变换 DFT</h3><h4 id="单变量dft">2.2.1 单变量<span class="math inline">\(DFT\)</span></h4><p>对 <span class="math inline">\(\widetilde F(\mu)\)</span> 的一个周期取样是 <span class="math inline">\(DFT\)</span> 的基础。</p><p>记 <span class="math inline">\(f(n\Delta T)\)</span> 为 <span class="math inline">\(f_n\)</span> , <span class="math inline">\(\widetilde F(\mu)=\displaystyle \sum_{n=-\infty}^{\infty}f_ne^{-j2\pi \mu n\Delta T}\)</span></p><p>想在周期 <span class="math inline">\(\mu = 0\)</span> 和 <span class="math inline">\(\mu=\displaystyle\frac{1}{\Delta T}\)</span> 之间得到 <span class="math inline">\(M\)</span> 个等间距的<em>样本</em> ，可令 <span class="math inline">\(\mu=\displaystyle\frac{m}{M\Delta T}\)</span>.</p><p>离散傅立叶变换 <span class="math inline">\(DFT\)</span> 为： <span class="math display">\[F_m=\sum\limits_{n=0}^{M-1}f_ne^{-j2\pi mn/M}\]</span> 离散傅立叶逆变换 <span class="math inline">\(IDFT\)</span> 为： <span class="math display">\[f_n=\frac{1}{M}\sum\limits_{m=0}^{M-1}F_m e^{j2\pi mn/M}\]</span> 为了更方便表示，引入 <span class="math inline">\(u\)</span> 和 <span class="math inline">\(x\)</span> 代替 <span class="math inline">\(m\)</span> 和 <span class="math inline">\(n\)</span> ：</p><p><span class="math inline">\(DFT\)</span>： <span class="math display">\[F(u)=\sum\limits_{x=0}^{M-1}f(x)e^{-j2\pi ux/M}\]</span> <span class="math inline">\(IDFT\)</span>： <span class="math display">\[f(x)=\frac{1}{M}\sum\limits_{u=0}^{M-1}F(u)e^{j2\pi ux/M}\]</span></p><p>（PS：有点小疑问：为什么是 <span class="math inline">\(f(x)\)</span> 而不是 $ f(xT)$ ？）</p><p>傅立叶正变换和逆变换得到的函数都是无限周期的，周期为 <span class="math inline">\(M\)</span>。</p><h3 id="二维dft">2.2.2 二维DFT</h3><p>略</p><h3 id="频率域滤波器">2.2.3 频率域滤波器</h3><p>过程：空间域 <span class="math inline">\(=&gt;\)</span> 傅立叶变换转到频率域 <span class="math inline">\(=&gt;\)</span> 在频率域使用模版处理振幅或者相位 <span class="math inline">\(=&gt;\)</span> 傅立叶逆变换回到空间域</p><ul><li>理想低/高通滤波器</li><li>k阶布特沃斯低/高通滤波器</li><li>高斯低/高通滤波器</li><li>频率域拉普拉斯算子（需归一化）</li><li>同态滤波（未完全理解）</li><li>选择性滤波器：带通滤波器、陷波滤波器（未实现）</li></ul><p><strong>代码实现：</strong></p><p>（1）：低通/高通滤波器</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> cv2<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br><br><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">IPF</span><span class="hljs-params">(img, d0, flag)</span>:</span><br>    <span class="hljs-comment">#  理想滤波器 ideal pass filter，d0 为滤波器半径</span><br>    <span class="hljs-comment"># flag == 1 : low pass filter; flag == 0 : high pass filter</span><br>    m, n = img.shape<br>    ans = np.zeros(img.shape)<br><br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> range(m):<br>        <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> range(n):<br>            <span class="hljs-keyword">if</span> (i - m / <span class="hljs-number">2</span>)**<span class="hljs-number">2</span> + (j - n / <span class="hljs-number">2</span>)**<span class="hljs-number">2</span> &lt; d0**<span class="hljs-number">2</span>:<br>                ans[i][j] = <span class="hljs-number">1</span><br>    <span class="hljs-keyword">if</span> flag == <span class="hljs-number">0</span>:<br>        ans = <span class="hljs-number">1</span> - ans<br><br>    <span class="hljs-keyword">return</span> ans<br><br><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">GPF</span><span class="hljs-params">(img, d0, flag)</span>:</span><br>    <span class="hljs-comment"># 高斯滤波器</span><br>    m, n = img.shape<br>    d0 = d0**<span class="hljs-number">2</span><br>    ans = np.zeros(img.shape)<br><br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> range(m):<br>        <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> range(n):<br>            d = (i - m / <span class="hljs-number">2</span>)**<span class="hljs-number">2</span> + (j - n / <span class="hljs-number">2</span>)**<span class="hljs-number">2</span><br>            <span class="hljs-keyword">if</span> d &lt; d0:<br>                ans[i][j] = np.exp(-d / (<span class="hljs-number">2</span> * d0))<br><br>    <span class="hljs-keyword">if</span> flag == <span class="hljs-number">0</span>:<br>        ans = <span class="hljs-number">1</span> - ans<br><br>    <span class="hljs-keyword">return</span> ans<br><br><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">BPF</span><span class="hljs-params">(img, do, flag, k)</span>:</span><br>    <span class="hljs-comment"># k阶布特沃斯高通滤波器</span><br>    m, n = img.shape<br>    d0 = d0**<span class="hljs-number">2</span><br>    ans = np.zeros(img.shape)<br><br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> range(m):<br>        <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> range(n):<br>            d = (i - m / <span class="hljs-number">2</span>)**<span class="hljs-number">2</span> + (j - n / <span class="hljs-number">2</span>)**<span class="hljs-number">2</span><br>            <span class="hljs-keyword">if</span> d &lt; d0:<br>                ans[i][j] = <span class="hljs-number">1</span> / (<span class="hljs-number">1</span> + (d / d0)**k)<br><br>    <span class="hljs-keyword">if</span> flag == <span class="hljs-number">0</span>:<br>        ans = <span class="hljs-number">1</span> - ans<br><br>    <span class="hljs-keyword">return</span> ans<br><br><br><span class="hljs-comment"># 高通滤波--提取轮廓</span><br><span class="hljs-comment"># 低通滤波--模糊化</span><br>img_man = cv2.imread(<span class="hljs-string">'ch03_5.jpg'</span>, <span class="hljs-number">0</span>)  <span class="hljs-comment"># 直接读为灰度图像</span><br>plt.subplot(<span class="hljs-number">131</span>), plt.imshow(img_man, <span class="hljs-string">'gray'</span>), plt.title(<span class="hljs-string">'before'</span>)<br>plt.xticks([]), plt.yticks([])<br><br><br>rows, cols = img_man.shape<br>mask1 = np.ones(img_man.shape, np.uint8)  <span class="hljs-comment"># 高通</span><br>mask1[int(rows / <span class="hljs-number">2</span>) - <span class="hljs-number">30</span>: int(rows / <span class="hljs-number">2</span>) + <span class="hljs-number">30</span>,<br>      int(cols / <span class="hljs-number">2</span>) - <span class="hljs-number">30</span>:int(cols / <span class="hljs-number">2</span>) + <span class="hljs-number">30</span>] = <span class="hljs-number">0</span><br><br>mask2 = np.zeros(img_man.shape, np.uint8)  <span class="hljs-comment"># 低通</span><br>mask2[int(rows / <span class="hljs-number">2</span>) - <span class="hljs-number">30</span>:int(rows / <span class="hljs-number">2</span>) + <span class="hljs-number">30</span>,<br>      int(cols / <span class="hljs-number">2</span>) - <span class="hljs-number">30</span>:int(cols / <span class="hljs-number">2</span>) + <span class="hljs-number">30</span>] = <span class="hljs-number">1</span><br><br><br>mask31 = np.ones(img_man.shape, np.uint8)<br>mask31[int(rows / <span class="hljs-number">2</span>) - <span class="hljs-number">10</span>:int(rows / <span class="hljs-number">2</span>) + <span class="hljs-number">10</span>,<br>       int(cols / <span class="hljs-number">2</span>) - <span class="hljs-number">10</span>:int(cols / <span class="hljs-number">2</span>) + <span class="hljs-number">10</span>] = <span class="hljs-number">0</span><br>mask32 = np.zeros(img_man.shape, np.uint8)<br>mask32[int(rows / <span class="hljs-number">2</span>) - <span class="hljs-number">80</span>:int(rows / <span class="hljs-number">2</span>) + <span class="hljs-number">80</span>,<br>       int(cols / <span class="hljs-number">2</span>) - <span class="hljs-number">80</span>:int(cols / <span class="hljs-number">2</span>) + <span class="hljs-number">80</span>] = <span class="hljs-number">1</span><br>mask3 = mask31 * mask32  <span class="hljs-comment"># 带通</span><br><br>mask = IPF(img_man, <span class="hljs-number">30</span>, <span class="hljs-number">1</span>)<br><br>f1 = np.fft.fft2(img_man)<br>f1shift = np.fft.fftshift(f1)<br>f1shift = f1shift * mask<br>f2shift = np.fft.ifftshift(f1shift)<br>img_new = np.fft.ifft2(f2shift)<br>img_new = np.abs(img_new)<br><span class="hljs-comment"># 调整大小范围便于显示</span><br><span class="hljs-comment"># img_new = (img_new - np.amin(img_new)) / (np.amax(img_new) - np.amin(img_new))</span><br><br>plt.subplot(<span class="hljs-number">132</span>), plt.imshow(mask, <span class="hljs-string">'gray'</span>), plt.title(<span class="hljs-string">'mask'</span>)<br>plt.xticks([]), plt.yticks([])<br>plt.subplot(<span class="hljs-number">133</span>), plt.imshow(img_new, <span class="hljs-string">'gray'</span>), plt.title(<span class="hljs-string">'after'</span>)<br>plt.xticks([]), plt.yticks([])<br>plt.show()<br></code></pre></td></tr></table></figure><p>（2）：频率域拉普拉斯滤波</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">Laplace</span><span class="hljs-params">(shape)</span>:</span><br>    m, n = shape<br>    ans = np.zeros(shape)<br><br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> range(m):<br>        <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> range(n):<br>            d = (i - m / <span class="hljs-number">2</span>)**<span class="hljs-number">2</span> + (j - n / <span class="hljs-number">2</span>)**<span class="hljs-number">2</span><br>            ans[i][j] = <span class="hljs-number">1</span> + <span class="hljs-number">4</span> * (np.pi**<span class="hljs-number">2</span>) * d / (m * n)<br>            <span class="hljs-comment"># 之前失败是由于没有处以mn</span><br>    <span class="hljs-keyword">return</span> ans<br><br><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">stdimg</span><span class="hljs-params">(img)</span>:</span><br>        <span class="hljs-comment"># 灰度值归一化</span><br>    m, n = img.shape<br>    min_img = np.amin(img)<br>    max_img = np.amax(img)<br>    img = np.float64(img)<br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> range(m):<br>        <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> range(n):<br>            img[i][j] = (img[i][j] - min_img) / (max_img - min_img)<br><br>    <span class="hljs-keyword">return</span> img<br><br><br>img = cv2.imread(<span class="hljs-string">'ch03_3.jpg'</span>, <span class="hljs-number">0</span>)<br>img = stdimg(img)<br>f = np.fft.fft2(img)<br>f = np.fft.fftshift(f)<br>mask = Laplace(img.shape)<br>f *= mask<br>img_back = np.fft.ifftshift(f)<br>img_back = np.fft.ifft2(img_back)<br>img_back = np.abs(img_back)<br>plt.subplot(<span class="hljs-number">131</span>), plt.imshow(img, <span class="hljs-string">'gray'</span>), plt.title(<span class="hljs-string">'before'</span>)<br>plt.xticks([]), plt.yticks([])<br>plt.subplot(<span class="hljs-number">132</span>), plt.imshow(mask, <span class="hljs-string">'gray'</span>), plt.title(<span class="hljs-string">'mask'</span>)<br>plt.xticks([]), plt.yticks([])<br>plt.subplot(<span class="hljs-number">133</span>), plt.imshow(img_back, <span class="hljs-string">'gray'</span>), plt.title(<span class="hljs-string">'after'</span>)<br>plt.xticks([]), plt.yticks([])<br><br>plt.show()<br></code></pre></td></tr></table></figure><h2 id="图像复原与重建">3 图像复原与重建</h2><h2 id="彩色图像处理">4 彩色图像处理</h2>]]></content>
      
      
      <categories>
          
          <category> Computer Science </category>
          
          <category> Image Processing </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>Computer-Sciencs/Git学习笔记</title>
      <link href="/2020/01/24/Computer-Sciencs/Git%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
      <url>/2020/01/24/Computer-Sciencs/Git%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/</url>
      
        <content type="html"><![CDATA[<h2 id="git学习">Git学习</h2><h3 id="创建版本库">创建版本库</h3><p>mkdir dirname // make directory 创建目录 dirname 为目录名</p><p>pwd //print working directory 查看当前工作目录的完整路径</p><p>ls -a // 显示所有文件及目录，包括隐藏档</p><p>git init</p><h3 id="修改与提交">修改与提交</h3><p>git add filename1.txt filename2.txt // 把要提交的所有<em>修改</em> 放到暂存区</p><p>git commit -m &quot;what I did in this commission&quot; // 一次性把暂存区的所有修改提交到分支 -m表示message</p><p>git log // 查看修改日志</p><p>git log --graph // 查看分支合并图</p><p>git log --pretty=oneline // 每次修改在一行简明显示</p><p><a id="more"></a></p><p>git reflog // 查看命令历史</p><p>git reset --hard versionnumber // 彻底回退到某版本</p><p>git status // 查看版本库状态</p><p>cat filename // 查看文件内容</p><p>git diff HEAD -- readme.txt // 查看版本库最新版本和工作区的readme文件的区别</p><p>git restore --staged filename // 撤销提交到暂存区</p><p>rm filename // remove 删除文件</p><p>rmdir dirname // 删除空文件目录</p><p>git rm filename // 从版本库中删除文件</p><p>git checkout -- filename // 误删文件的恢复</p><h3 id="远程仓库">远程仓库</h3><p>git remote add origin git@github.com:longqianh/learngit.git</p><p>git push -u origin master</p><p>git clone git@github.com:longqianh/learngit.git</p><h3 id="分支管理">分支管理</h3><p>git checkout</p><p>git branch // 查看分支</p><p>git branch -d branchname // 删除分支</p><p>git branch branchname // 创建分支</p><p>git checkout branchname 或 git checkout branchname // 切换分支</p><p>git checkout -b branchname 或 git switch -c branchname // 创建并切换分支</p><p>git merge branchname // 合并branch分支到master上</p><p>git merge --no-ff -m &quot;branchname&quot; // 合并branch分支到master上,并产生一条记录</p><p>建议：使用分支完成某个任务，合并后再删掉分支</p><p>git remote // 查看远程库信息</p><p>git branch --set-upstream branchname origin/branchname // 建立本地分支与远程分支的关联</p><p>git pull // 拉取远程分支新提交并合并</p><p>git push branchname // 向远程仓库推送分支</p><p>git tag tagname // 给分支打标签</p><p>git tag -a tagname -m &quot;message&quot; // 给标签加说明</p><p>git tag // 查看所有标签</p><p>git push tagname // 推送一个本地标签到远程</p><p>git push --tag // 推送所有本地标签</p><p>git tag -d tagname // 删除标签</p><p>git push origin :refs/tags/tagname // 删除一个远程标签</p><p>git config --global alias.st status // 配置别名 加--global对当前用户起作用，不加则对当前仓库起作用</p>]]></content>
      
      
      <categories>
          
          <category> Computer Science </category>
          
          <category> Git </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>Abstract Algebra</title>
      <link href="/2020/01/20/Mathematics/Abstract-Algebra/"/>
      <url>/2020/01/20/Mathematics/Abstract-Algebra/</url>
      
        <content type="html"><![CDATA[<h1 id="抽象代数内容整理">抽象代数内容整理</h1><h2 id="群论">1 群论</h2><h3 id="群-group">1.1 群 Group</h3><h4 id="群的定义">1.1.1 群的定义</h4><p>一个<em>群</em> 是带有下列性质的合成法则的集合<span class="math inline">\(G\)</span> :</p><ol type="1"><li>合成法则满足结合律</li><li>包含单位元</li><li>每个元素都有逆元</li></ol><p>=&gt; 消去律</p><p>$ \ $ <a id="more"></a></p><h4 id="子群">1.1.2 子群</h4><h4 id="定义">1.1.2.1 定义</h4><ol type="1"><li>对运算具有封闭性</li><li>包含单位元</li><li>每个元素都有逆元</li></ol><p>$ \ $</p><h4 id="正规子群">1.1.2.2 正规子群</h4><p>$ N G $</p><p>$ $ $ aN,gG gag^{-1}G $ $ \ $</p><p>$ $ $ gNg^{-1}=N $</p><p>$ $ $ gN=Ng $</p><p>$ \ $</p><h4 id="同态">1.1.3 同态</h4><p>两个群中与合成法则相容的映射。</p><p>$: GG', s.t \ a,b G, (ab)=(a)(b) $</p><p><span class="math inline">\(\implies\)</span> <span class="math inline">\(\varphi\)</span> 把单位元映射为单位元，把逆元映射为逆元</p><p><span class="math inline">\(\implies\)</span> $ im G', G$</p><p><span class="math inline">\(\implies\)</span> 群同态基本定理： <span class="math inline">\(G/\ker\varphi \cong im\varphi\)</span></p><p>$ \ $</p><h4 id="同构">1.1.4 同构</h4><p>双射群同态。</p><p><span class="math inline">\(\implies\)</span> 第一同构定理：</p><p>$ $ 是一个满同态， $$ 是典范态射 <span class="math inline">\((canonical)\)</span></p><p>则存在唯一一个同构映射<span class="math inline">\(\overline \varphi : \overline G\to G&#39; \quad s.t. \quad \varphi=\overline\varphi \circ \pi\)</span></p><ul><li><p>验证 <span class="math inline">\(\varphi:G\to G’\)</span> 是同构的方法：</p><p>只需验证 <span class="math inline">\(\ker \varphi=\{1\},im\varphi=G&#39;\)</span></p></li></ul><h4 id="陪集">1.1.5 陪集</h4><p>关于同余关系的等价类。</p><h4 id="左陪集">1.1.5.1 左陪集</h4><p>$ HG, aG, aH={ah|aH }$</p><p><span class="math inline">\(\implies\)</span> <span class="math inline">\(a\in bH \Leftrightarrow aH=bH\)</span></p><p><span class="math inline">\(\implies\)</span> $ |G|=[G:H]|H|$</p><p>$ \ $</p><h4 id="拉格朗日定理">1.1.5.2 拉格朗日定理</h4><p>子群的阶整除群的阶。 <span class="math inline">\(i.e. |H| \biggm| |G|\)</span></p><p><span class="math inline">\(\implies\)</span> 素数阶群是循环群</p><p>$ \ $</p><h4 id="对应定理">1.1.6 对应定理</h4><p>$: GG' $ 是一个满同态.</p><p>$ K=ker, H'G', HK$ .</p><p><span class="math inline">\(\implies\)</span> 若 <span class="math inline">\(H&#39;\)</span> 是正规子群，则 <span class="math inline">\(H\)</span> 也是正规子群。<span class="math inline">\(\varphi\)</span> 是满射，<span class="math inline">\(H\)</span> 是正规子群，则<span class="math inline">\(H&#39;\)</span> 也是正规子群。</p><p><span class="math inline">\(\implies\)</span> <span class="math inline">\(\{G的含有K的子群 \}\longleftrightarrow \{G&#39;的子群\}\)</span></p><p>$ \ $</p><h4 id="积群">1.1.7 积群</h4><p><span class="math inline">\(G\times G&#39;=\{(g,g&#39;) |g\in G, g&#39;\in G&#39;\}\)</span></p><p>$ \ $</p><p><span class="math inline">\(\implies\)</span> <span class="math inline">\(r\)</span>、<span class="math inline">\(s\)</span> 互素，则 <span class="math inline">\(C_{rs}\cong C_r\times C_s\)</span></p><p><span class="math inline">\(\implies\)</span> 命题 <span class="math inline">\(2.11.4\)</span> :</p><p><span class="math inline">\(H,K \leqslant G, let \quad f:H\times K \to G\)</span> 是一个映射，</p><p>$def : f(h,k)=hk. imf=HK={hk|hH,kK } $</p><p><span class="math inline">\(then\)</span> <span class="math inline">\(f\)</span> 是一个同构 i.e $HK HK $</p><p>$ $ $HK={1},HK=G,HG,KG. $</p><p>$ \ $</p><h4 id="商群">1.1.8 商群</h4><p>群<span class="math inline">\(G\)</span>在正规子群<span class="math inline">\(N\)</span>的陪集的集合上定义合成法则，这个运算法则使得正规子群的陪集成为一个群，称为<em>商群</em>。</p><p><span class="math inline">\(\overline G=G/N\triangleq \{ \overline g|\overline g=gN,g\in G \}\)</span></p><p>$ \ $</p><p><span class="math inline">\(\implies\)</span> 典范态射：<span class="math inline">\(\pi : G\to \overline G \quad g\mapsto\overline g\)</span> 这是一个满同态。</p><p>$ \ $</p><h3 id="群作用">1.2 群作用</h3><h4 id="轨道稳定子">1.2.1 轨道、稳定子</h4><h4 id="定义-1">1.2.1.1 定义</h4><p>orbit： <span class="math inline">\(O_s=\{s&#39;\in S | s&#39;=gs,g\in G\}\)</span></p><p>stabilizer：<span class="math inline">\(G_s=\{g\in G|gs=s\}\)</span></p><p>$ \ $</p><h4 id="计数公式">1.2.1.2 计数公式</h4><p><span class="math inline">\(|G|=|G_s|\cdot |O_s|\)</span></p><p>$ \ $</p><p><span class="math inline">\(\implies\)</span> <span class="math inline">\(|O_s|=[G:G_s]\)</span></p><p><span class="math inline">\(\implies\)</span> <span class="math inline">\(|S|=|O_1|+|O_2|+\cdots +|O_k|\)</span></p><p>$ \ $</p><h4 id="对陪集的作用">1.2.2 对陪集的作用</h4><h4 id="诱导表示">1.2.2.1 诱导表示</h4><h4 id="置换表示">1.2.3 置换表示</h4><p>群<span class="math inline">\(G\)</span>的置换表示送从该群到一个对称群的同态.</p><p><span class="math inline">\(\varphi : G\to S_N\)</span></p><p><span class="math inline">\([G在S上的作用]\leftrightarrow[置换表示]\)</span></p><p>$ \ $</p><h4 id="凯莱定理">1.2.3.2 凯莱定理</h4><p>每一个有限群都同构于某个置换群的子群.</p><p>如果<span class="math inline">\(|G|=n\)</span> , 则 <span class="math inline">\(G\hookrightarrow S_n\)</span></p><p>$ \ $</p><h4 id="共轭作用">1.2.4 共轭作用</h4><h4 id="中心化子共轭类">1.2.4.1 中心化子、共轭类</h4><p>中心化子：元素<span class="math inline">\(x\)</span>关于共轭作用的稳定子。</p><p><span class="math inline">\(Z(x)=\{g\in G|gx=xg\}\)</span></p><p>共轭类：<span class="math inline">\(x\)</span>关于共轭作用的轨道。</p><p><span class="math inline">\(C(x)=\{x&#39;\in G|x&#39;=gxg^{-1},g\in G\}\)</span></p><p>$ \ $</p><p><span class="math inline">\(\implies\)</span> <span class="math inline">\(|G|=|Z(x)|\cdot |C(x)|\)</span></p><p>$ \ $</p><h4 id="类方程">1.2.4.1 类方程</h4><p>共轭类划分群<span class="math inline">\(G\)</span>。</p><p>$ |G|=<em>{共轭类C} |C|=|Z|+</em> {xg}|C(x)| $</p><p>$ \ $</p><h4 id="sylow定理">1.2.5 Sylow定理</h4><p>设 <span class="math inline">\(|G|=n=p^e m\)</span> .</p><h4 id="p-群相关命题">1.2.5.1 p-群相关命题</h4><p>p-群：阶是素数 <span class="math inline">\(p\)</span> 的正幂的群。</p><ul><li><p>p-群 <span class="math inline">\(G\)</span> 的中心是非平凡群。</p></li><li><p>（不动点定理）<span class="math inline">\(G\)</span>是p-群，<span class="math inline">\(S\)</span> 是一个有限集合，<span class="math inline">\(G\)</span> 在 <span class="math inline">\(S\)</span> 上面作用。若<span class="math inline">\(p\nmid |S|\)</span> , 则<span class="math inline">\(G\)</span>的作用有个不动点<span class="math inline">\(s\)</span>， 它的稳定子是整个群。</p></li><li><p><span class="math inline">\(p^2\)</span> 阶群是 <span class="math inline">\(Abel\)</span> 群。</p><p>$ \ $</p></li></ul><h4 id="sylow-i">1.2.5.4 Sylow-I</h4><p>阶被素数 <span class="math inline">\(p\)</span> 整除的有限群包含一个 <span class="math inline">\(Sylow-p\)</span> 子群。</p><p>$ \ $</p><p><span class="math inline">\(=&gt;\)</span> 阶被素数 <span class="math inline">\(p\)</span> 整除的有限群包含一个 <span class="math inline">\(p\)</span> 阶的元素。</p><p>$ \ $</p><h4 id="sylow-ii">1.2.5.5 Sylow-II</h4><ol type="a"><li><p><span class="math inline">\(G\)</span> 的 <span class="math inline">\(Sylow-p\)</span> 子群是共轭子群。</p></li><li><p><span class="math inline">\(G\)</span>的每一个p-群的子群都包含在一个 <span class="math inline">\(Sylow-p\)</span> 子群里。</p></li></ol><p>$ \ $</p><p><span class="math inline">\(\implies\)</span> 群 <span class="math inline">\(G\)</span> 只有一个 <span class="math inline">\(Sylow-p\)</span> 子群<span class="math inline">\(\iff\)</span>这个子群是正规子群</p><p>$ \ $</p><h4 id="sylow-iii">1.2.5.6 Sylow-III</h4><p><span class="math inline">\(G\)</span> 的 <span class="math inline">\(Sylow-p\)</span> 子群的个数整除 <span class="math inline">\(m\)</span> 且模 <span class="math inline">\(p\)</span> 余 <span class="math inline">\(1\)</span>.</p><p>$ \ $</p><h3 id="自由群">1.2.6 <a href="https://zh.wikipedia.org/wiki/%E8%87%AA%E7%94%B1%E7%BE%A4" target="_blank" rel="noopener">自由群</a></h3><p>群的元素的一个集合称为是<em>自由的</em>，如果其元素除了群的公理给出的关系外不满足任何别的关系。</p><p>具有自由的生成元的集合的群称为<em>自由群</em>。</p><p>$ \ $</p><h2 id="环论">2 环论</h2><h3 id="环的定义-ring">2.1 环的定义 Ring</h3><p>一个<em>环</em> <span class="math inline">\(R\)</span> 是一个具有两种合成法则<span class="math inline">\(+\)</span>和<span class="math inline">\(\times\)</span> 的集合。</p><p>关于加法为阿贝尔群，关于乘法满足结合律。</p><p>关于加法和乘法满足分配律。</p><p>$ \ $</p><p><strong>整环</strong>（Integral Domain）：不含零因子的环。整环满足消去律。</p><p><strong>诺特环</strong>：一个环是诺特环如果它的每个理想都是有限生成的。</p><p>$ \ $</p><h3 id="环同态">2.2 环同态</h3><p>从一个环到另一个环的映射，与加法和乘法的合成法则相容。</p><p><span class="math inline">\(\varphi (a+b)=\varphi(a)+\varphi(b),\quad \varphi(ab)=\varphi(a)\cdot \varphi(b)\)</span></p><p>若环有乘法单位元，则 <span class="math inline">\(\varphi(1)=1\)</span></p><p>$ \ $</p><h3 id="理想-ideal">2.3 理想 Ideal</h3><ul><li>环<span class="math inline">\(R\)</span>的左理想<span class="math inline">\(I\)</span>是满足下列性质的非空子集：</li></ul><p>（1）关于加法封闭</p><p>（2）<span class="math inline">\(\forall r\in R, s\in I, \quad rs\in I\)</span></p><p>$ \ $</p><ul><li>极大理想：<span class="math inline">\(M&lt; R(M\neq R),\)</span> 若<span class="math inline">\(I\subseteq M,\)</span> 则 <span class="math inline">\(I=M\)</span> 或 <span class="math inline">\(I=R\)</span> 。</li></ul><p>$ \ $</p><p><span class="math inline">\(\implies\)</span> 整数环 <span class="math inline">\(Z\)</span> 的极大理想是有素数生成的主理想。</p><p><span class="math inline">\(\implies\)</span> <span class="math inline">\(F\)</span> 是一个域，<span class="math inline">\(F[x]\)</span> 的极大理想是由既约的首一多项式生成的主理想</p><p>$ \ $</p><h3 id="商环-第一同构定理">2.4 商环, 第一同构定理</h3><p>类似群论。</p><h3 id="对应定理-1">2.5 对应定理</h3><p><span class="math inline">\(\varphi ：R\to R&#39;\)</span> 是满射环同态，则存在一个双射对应：</p><p><span class="math inline">\(\{R的含核 理想\}\leftrightarrow \{R&#39;的理想\}\)</span></p><p>$ \ $</p><h3 id="希尔伯特零点定理">2.6 希尔伯特零点定理</h3><p>多项式环 <span class="math inline">\(\mathbf C[x_1,x_2,\cdots,x_n]\)</span>的极大理想与复<span class="math inline">\(n\)</span>维空间的点一一对应。$^n $ 的一个点<span class="math inline">\(a=(a_1,a_2,\cdots,c_n)\)</span>对应于映 <span class="math inline">\(x_i \rightsquigarrow a_i\)</span>的代入映射 <span class="math inline">\(s_a:\mathbf{C}[x_1,\cdots, x_n]\to\mathbf{C}\)</span>的核<span class="math inline">\(M_a\)</span> . 这个映射的核 <span class="math inline">\(M_a\)</span> 是由 <span class="math inline">\(n\)</span> 个线性多项式 <span class="math inline">\(x_i-a_i\)</span> 生成的理想。</p><p>$ \ $</p><h3 id="因子分解">2.7 因子分解</h3><h4 id="基本概念">2.7.1 基本概念</h4><ul><li>单位 unit ：有乘法逆元</li><li>相伴 associate ：<span class="math inline">\(a\)</span> 和 <span class="math inline">\(b\)</span> 相伴<span class="math inline">\(\iff\)</span><span class="math inline">\((a)=(b)\)</span></li><li>不可约 irreducible : 不是单位且没有真因子，因子为单位或者相伴元</li><li>素元 prime : <span class="math inline">\(p\)</span> 是素元 <span class="math inline">\(\iff\)</span> <span class="math inline">\(p\mid ab=&gt;p\mid a \quad or \quad p\mid b\)</span></li></ul><p>$ \ $</p><h4 id="欧几里得整环-ed">2.7.2 欧几里得整环 ED</h4><ul><li>有尺度函数，可进行带余除法</li><li>常见例子：<span class="math inline">\(\mathbf{Z},F[x],\mathbf{Z}[i]\)</span></li><li><span class="math inline">\(ED\)</span> is <span class="math inline">\(PID\)</span></li></ul><p>$ \ $</p><h4 id="主理想整环-pid">2.7.3 主理想整环 PID</h4><ul><li>所有理想均为主理想</li><li>理想<span class="math inline">\((a,b)=Ra+Rb\)</span> 的生成元 <span class="math inline">\(d\)</span> 是 <span class="math inline">\(a,b\)</span> 的最大公因子</li><li><span class="math inline">\(\exists r,s \in R\quad s.t.\quad d=ra+sb\)</span></li><li><span class="math inline">\(PID\)</span> 中，元素是不可约的当且仅当它是素的</li></ul><p>$ \ $</p><h4 id="唯一分解整环-ufd">2.7.4 唯一分解整环 UFD</h4><ul><li>分解终止，且元素的既约分解唯一</li><li><span class="math inline">\(ED=&gt;PID=&gt;UFD\)</span></li></ul><p>$ \ $</p><h3 id="高斯引理">2.7 高斯引理</h3><ul><li>本原多项式：正次数的正系数多项式，且整数系数 <span class="math inline">\(a_1, a_2,\cdots,a_n\)</span>的最大公因子是<span class="math inline">\(1\)</span>。</li><li><span class="math inline">\(f\)</span> 是本原的<span class="math inline">\(\iff\)</span><span class="math inline">\(f\)</span> 不能被任何素数 $ p $ 整除 <span class="math inline">\(\iff\)</span> <span class="math inline">\(\forall p: prime,\psi_p(f)\neq 0\quad(\psi_p为系数模素数p的同态)\)</span></li><li><span class="math inline">\(Gauss&#39;s\)</span> <span class="math inline">\(Lemma\)</span> : 本原多项式的积是本原的</li><li>每个有理系数的正次数多项式 <span class="math inline">\(f(x)\)</span> 可唯一地写成 <span class="math inline">\(f(x)=cf_0(x)\)</span> ，其中 <span class="math inline">\(c\in \mathbb{Q}\)</span>，<span class="math inline">\(f_0(x)\)</span> 是本原多项式</li><li>多项式环 $ [x]$ 是唯一分解整环。每个不是 <span class="math inline">\(\pm 1\)</span> 的非零多项式 <span class="math inline">\(f(x)\in\mathbf{Z}[x]\)</span> 可以写成积的形式： <span class="math inline">\(f(x)=\pm p_1\cdots p_m q_1(x)\cdots q_n(x)\)</span> ，$p_i $ 是整素数，<span class="math inline">\(q_i\)</span> 是本原的既约多项式。</li></ul><p>$ \ $</p><h3 id="爱森斯坦判别法">2.8 爱森斯坦判别法</h3><p>设 <span class="math inline">\(f(x)=a_nx^n+\cdots+a_0\)</span> 是一个整多项式，并设 <span class="math inline">\(p\)</span> 是一个素整数。若 <span class="math inline">\(f\)</span> 的系数满足：</p><ol type="1"><li><p><span class="math inline">\(p\nmid a_n\)</span></p></li><li><p><span class="math inline">\(p\mid a_{n-1},\dots,p\mid a_0\)</span></p></li><li><p><span class="math inline">\(p^2 \nmid a_0\)</span></p></li></ol><p>则 <span class="math inline">\(f\)</span> 在 <span class="math inline">\(\mathbf{Q}[x]\)</span> 中是既约的。</p><p>$ \ $</p><h3 id="模论环上的线性代数">2.9 模论：环上的线性代数</h3><h4 id="模-module">2.9.1 模 Module</h4><p><span class="math inline">\(R\)</span> 是一个环，<span class="math inline">\(R\)</span>-模 <span class="math inline">\(V\)</span> 包含一个加法阿贝尔群与一个标量乘法 $RVV ,r,vrv $ , 满足一下条件：</p><p><span class="math inline">\(1v=v,\quad (rs)v=r(sv),\quad (r+s)v=rv+sv,\quad r(v+v&#39;)=rv+rv&#39;.\qquad\forall r,s \in R,\quad v,v&#39;\in V\)</span></p><p>$ \ $</p><p><span class="math inline">\(=&gt;\)</span> <span class="math inline">\(\mathbf{Z}\)</span>-模 与 阿贝尔群 是等价的概念，因为一个合成法则记为加法的阿贝尔群有唯一的 方法构成 <span class="math inline">\(\mathbf{Z}\)</span> 上的一个模。</p><p>$ \ $</p><h4 id="子模">2.9.2 子模</h4><p>在加法和标量乘法下封闭的子集。</p><p><span class="math inline">\(=&gt;\)</span> <span class="math inline">\(R\)</span>-模 <span class="math inline">\(R\)</span> 的子模是 <span class="math inline">\(R\)</span> 的理想</p><p>$ \ $</p><h4 id="商模">2.9.3 商模</h4><h4 id="模同态">2.9.3.1 模同态</h4><p><span class="math inline">\(\varphi : V\to W\quad \varphi(v+v&#39;)=\varphi(v)+\varphi(v&#39;),\quad \varphi(rv)=r\varphi(v)\)</span></p><p>同态的像是子模。</p><p>$ \ $</p><h4 id="典范态射">2.9.3.2 典范态射</h4><p>令 $W $ 是 <span class="math inline">\(R\)</span>-模 <span class="math inline">\(V\)</span> 的子模。</p><p><span class="math inline">\(\pi : V\to \overline V\quad v\rightsquigarrow\overline v=[v+W]\)</span></p><p><span class="math inline">\(\pi\)</span> 是一个满同态，<span class="math inline">\(\ker\pi =W\)</span></p><p>$ \ $</p><h4 id="第一同构定理">2.9.3.3 第一同构定理</h4><p><span class="math inline">\(f:V\to V&#39;\)</span> 是模满同态，同态核 <span class="math inline">\(K=W\)</span>. 则 <span class="math inline">\(\overline f:\overline V=V/W\to V&#39;\)</span> 是一个同构。</p><p>$ \ $</p><h4 id="对应定理-2">2.9.3.4 对应定理</h4><p><span class="math inline">\(f:V\to V&#39;\)</span> 是模满同态, 核为 <span class="math inline">\(W\)</span> . 存在一个一一对应：</p><p><span class="math inline">\(\{V的包含W的子模\}\leftrightarrow \{V&#39; 的子模\}\)</span></p><p>$ \ $</p><h4 id="自由模">2.9.4 自由模</h4><p>一个模是自由的当且仅当它有基。</p><p>设 <span class="math inline">\(R\)</span> 是一个非零交换环。</p><p>（1）一个自由模的基变换矩阵是一个可逆矩阵</p><p>（2）<span class="math inline">\(R\)</span> 上同一个自由模的两个基具有同样的元素个数</p><p>$ \ $</p><h4 id="阿贝尔群结构定理">2.9.5 阿贝尔群结构定理</h4><p>有限生成阿贝尔群 <span class="math inline">\(V\)</span> 是循环子群 <span class="math inline">\(C_{d_1},\cdots,C_{d_n}\)</span> 和一个自由阿贝尔群 <span class="math inline">\(L\)</span> 的直和：</p><p><span class="math display">\[V=C_{d_1}\oplus\cdots C_{d_n}\oplus L,\qquad d_i&gt;1,d_i\mid d_{i+1}\]</span></p><p>$ \ $</p><p>进一步分解后：</p><p><span class="math inline">\(=&gt;\)</span> 每一个有限生成阿贝尔群是素数幂阶循环群的直和</p><p>$ \ $</p><h2 id="域论">3 域论</h2><h3 id="域-field">3.1 域 Field</h3><h3 id="域的定义">3.1.1 域的定义</h3><p>域 <span class="math inline">\(F\)</span> 具有加法和乘法两个合成法则，关于加法称为阿贝尔群 <span class="math inline">\(F^+\)</span> ，非零元关于乘法称为阿贝尔群 <span class="math inline">\(F^{\times}\)</span>，关于加法和乘法满足分配律。</p><ul><li>含幺交换环 <span class="math inline">\(+\)</span> 每个元素都有逆元 <span class="math inline">\(=&gt;\)</span> 域</li></ul><p>子域：域的子集，且关于加减乘除封闭</p><p>$ \ $</p><h3 id="代数元和超越元">3.1.2 代数元和超越元</h3><h4 id="基本概念-1">3.1.2.1 基本概念</h4><p>代数元：是一个系数属于 <span class="math inline">\(F\)</span> 的某个首一多项式的根</p><p>超越元：不是任何一个系数属于 <span class="math inline">\(F\)</span> 的某个首一多项式的根</p><p>代数元 <span class="math inline">\(\alpha\)</span> 在 <span class="math inline">\(F\)</span> 上的既约多项式 <span class="math inline">\(f\)</span> : <span class="math inline">\(F[x]\)</span> 上的首一、次数最低、以 <span class="math inline">\(\alpha\)</span> 为根的多项式</p><p><span class="math inline">\(=&gt;\)</span> 由 <span class="math inline">\(f\)</span> 生成的 <span class="math inline">\(F[x]\)</span> 的主理想是一个极大理想</p><p><span class="math inline">\(\alpha\)</span> 在 <span class="math inline">\(F\)</span> 上的次数 : 既约多项式 <span class="math inline">\(f\)</span> 的次数</p><p>扩域 <span class="math inline">\(K/F\)</span> 的次数 <span class="math inline">\([K:F]\)</span>：<span class="math inline">\(K\)</span> 作为 <span class="math inline">\(F\)</span> 向量空间 <span class="math inline">\(_F K\)</span> 的维数</p><p>$ \ $</p><p><strong>次数的乘法性质</strong>：<span class="math inline">\(F\subset K\subset L,\quad [L:F]=[L:K]\cdot [K:F]\)</span></p><p>$ \ $</p><h4 id="相关命题">3.1.2.2 相关命题</h4><ul><li><p>扩域的一个元素 <span class="math inline">\(\alpha\)</span> 是 <span class="math inline">\(F\)</span> 上的代数元 <span class="math inline">\(\iff\)</span> 扩域的次数 <span class="math inline">\([F(\alpha):F]\)</span> 有限</p></li><li><p><span class="math inline">\(K/F\)</span> 为 <span class="math inline">\(n\)</span> 次有限扩域，<span class="math inline">\(\alpha \in K\)</span> <span class="math inline">\(=&gt;\)</span> <span class="math inline">\(\alpha\)</span> 在 <span class="math inline">\(F\)</span> 上是代数的，且其在 <span class="math inline">\(F\)</span> 上的次数为 <span class="math inline">\(n\)</span></p></li><li><p>令 <span class="math inline">\(F\subset F&#39;\subset L\)</span> 是域. 如果 <span class="math inline">\(L\)</span> 中元素 <span class="math inline">\(\alpha\)</span> 是 <span class="math inline">\(F\)</span> 上的代数元，则它也是 <span class="math inline">\(F&#39;\)</span> 上的代数元。如果 <span class="math inline">\(\alpha\)</span> 在 <span class="math inline">\(F\)</span> 上的次数为 <span class="math inline">\(d\)</span> , 则它在 <span class="math inline">\(F&#39;\)</span> 上的次数最多为 <span class="math inline">\(d\)</span>。</p></li><li><p>由有限多个代数元生成的扩域是有限扩域，一个有限扩域由有限多个代数元生成</p></li><li><p>如果 <span class="math inline">\(K\)</span> 是 <span class="math inline">\(F\)</span> 的扩域，则 <span class="math inline">\(K\)</span> 中所有 <span class="math inline">\(F\)</span> 上的代数元的集合构成 <span class="math inline">\(K\)</span> 的子域 （代数元加减乘除还是代数元）</p></li><li><p>设 <span class="math inline">\(K\)</span> 是 <span class="math inline">\(F\)</span> 上的素数 <span class="math inline">\(p\)</span> 次扩域， <span class="math inline">\(\alpha \in K,\alpha\notin F\)</span>, 则 <span class="math inline">\(\alpha\)</span> 在 <span class="math inline">\(F\)</span> 上的次数为 <span class="math inline">\(p\)</span> 且 <span class="math inline">\(K=F(\alpha)\)</span></p><p>$ \ $</p></li></ul><p>令 <span class="math inline">\(\alpha\)</span> 是扩域 <span class="math inline">\(K/F\)</span> 上的元素，<span class="math inline">\(\alpha\)</span> 是 <span class="math inline">\(F\)</span> 上的代数元，令 <span class="math inline">\(f\)</span> 是 <span class="math inline">\(\alpha\)</span> 在 <span class="math inline">\(F\)</span> 上的既约多项式。</p><ul><li><p><span class="math inline">\(F[\alpha]\cong F(\alpha)\)</span> , 更一般：$F[_1,, _n]F(_1,, _n)pf:Bezout $</p></li><li><p><span class="math inline">\([F(\alpha):F]=deg\)</span> <span class="math inline">\(f\)</span></p><p>$ \ $</p></li></ul><h3 id="尺规作图">3.1.3 尺规作图</h3><p>令 <span class="math inline">\(a\)</span> 是一个可构造的实数，则 <span class="math inline">\(a\)</span> 是一个代数数，且它在 <span class="math inline">\(\mathbf{Q}\)</span> 上的次数是 <span class="math inline">\(2\)</span> 的幂。 （“平方根塔”）</p><p>$ \ $</p><h3 id="扩域中的带余除法">3.1.4 扩域中的带余除法</h3><p>设 <span class="math inline">\(f\)</span> 和 <span class="math inline">\(g\)</span> 是系数属于 <span class="math inline">\(F\)</span> 的多项式， <span class="math inline">\(f\neq 0\)</span>，设 <span class="math inline">\(K\)</span> 是 <span class="math inline">\(F\)</span> 的扩域。</p><ul><li>在 <span class="math inline">\(F[x]\)</span> 和 <span class="math inline">\(K[x]\)</span> 中，由 <span class="math inline">\(f\)</span> 对 <span class="math inline">\(g\)</span> 作的带余除法得到相同的答案</li><li>在 <span class="math inline">\(K[x]\)</span> 中 <span class="math inline">\(f\)</span> 整除 <span class="math inline">\(g\)</span> <span class="math inline">\(\iff\)</span> 在 <span class="math inline">\(F[x]\)</span> 中 <span class="math inline">\(f\)</span> 整除 <span class="math inline">\(g\)</span><br /></li><li>如果 <span class="math inline">\(f\)</span> 和 <span class="math inline">\(g\)</span> 在 <span class="math inline">\(K\)</span> 上有公共根，则它们在 <span class="math inline">\(F[x]\)</span> 中不是互素的。如果 <span class="math inline">\(f\)</span> 和 <span class="math inline">\(g\)</span> 在 <span class="math inline">\(K[x]\)</span> 中不是互素的，则存在一个扩域 <span class="math inline">\(L\)</span> ，它们在其中有公共根</li><li>如果 <span class="math inline">\(f\)</span> 在 <span class="math inline">\(F[x]\)</span> 中是既约的且 <span class="math inline">\(f\)</span> 和 <span class="math inline">\(g\)</span> 在 <span class="math inline">\(K\)</span> 中有公共根，则 <span class="math inline">\(f\)</span> 在<span class="math inline">\(F[x]\)</span> 中整除 <span class="math inline">\(g\)</span></li></ul><p>$ \ $</p><h3 id="重根">3.1.5 重根</h3><p>令 <span class="math inline">\(f(x)\)</span> 是一个系数属于 <span class="math inline">\(F\)</span> 的多项式.</p><p>存在 <span class="math inline">\(K/F\)</span> ，在其上 <span class="math inline">\(f(x)\)</span> 有重根<span class="math inline">\(\iff\)</span> <span class="math inline">\(f\)</span> 和 <span class="math inline">\(f&#39;\)</span> 不互素</p><p>$ \ $</p><p><span class="math inline">\(=&gt;\)</span> 若 <span class="math inline">\(f(x)\)</span> 是既约的，且 <span class="math inline">\(char\)</span><span class="math inline">\(F=0\)</span>，则 <span class="math inline">\(f\)</span> 在 <span class="math inline">\(F\)</span> 的任意扩域中没有重根</p><p>$ \ $</p><h3 id="有限域">3.1.6 有限域</h3><p><span class="math inline">\(K\)</span> 是有限域 ，则 <span class="math inline">\(char\)</span> <span class="math inline">\(K\)</span> <span class="math inline">\(= p\)</span>（素数），<span class="math inline">\(|K|=p^r\triangleq q\)</span></p><h4 id="相关命题-1">相关命题</h4><ul><li>$ K $ 的元素是多项式 $x^q-x $ 的根</li><li>在素域 <span class="math inline">\(F=\mathbf{F_p}\)</span> 上的多项式 <span class="math inline">\(x^q-x\)</span> 的既约因子是次数整除 <span class="math inline">\(r\)</span> 的 <span class="math inline">\(F[x]\)</span> 上的既约多项式</li><li>所有的 <span class="math inline">\(q\)</span> 阶域是同构的</li><li>$ K$ 的非零元素的乘法群 <span class="math inline">\(K^{\times}\)</span> 是一个 <span class="math inline">\(q-1\)</span> 阶循环群</li><li><span class="math inline">\(K\)</span> 内含有 <span class="math inline">\(p^k\)</span> 阶子域当且仅当 <span class="math inline">\(k\)</span> 整除 <span class="math inline">\(r\)</span></li><li>多项式 <span class="math inline">\(x^q-x\)</span> 在 <span class="math inline">\(F\)</span> 的任何扩域上没有重根 （导数等于 <span class="math inline">\(-1\)</span> ，与 <span class="math inline">\(x^q-x\)</span> 无公共根）</li><li>在多项式环 <span class="math inline">\(F[x,y]\)</span> 中，<span class="math inline">\((x+y)^q=x^q+y^q\)</span></li></ul><p>$ \ $</p><h2 id="galois-理论-部分">4 Galois​ 理论 （部分）</h2><h3 id="基本概念-2">4.1 基本概念</h3><ul><li>分裂域 (splitting field) ： <span class="math inline">\(F\)</span> 上 <span class="math inline">\(f\)</span> 的分裂域是扩域 <span class="math inline">\(K/F\)</span> ，使得 <span class="math inline">\(f\)</span> 在 <span class="math inline">\(K\)</span> 里完全分裂 <span class="math inline">\(f=(x-\alpha_1)\cdots (x-\alpha_n),\quad \alpha_i\in K\)</span>, 且 <span class="math inline">\(K=F(\alpha_1,\cdots,\alpha_n)\)</span></li><li><span class="math inline">\(F\)</span><span class="math inline">\(-\)</span>同构：令 <span class="math inline">\(K\)</span> 与 <span class="math inline">\(K&#39;\)</span> 是 <span class="math inline">\(F\)</span> 的域扩张，<span class="math inline">\(\sigma : K\to K&#39;\)</span>，为限制在子域 <span class="math inline">\(F\)</span> 上为恒等映射的同构</li><li><span class="math inline">\(Galois\)</span> 群：有限扩张 <span class="math inline">\(K\)</span> 的 <span class="math inline">\(F-\)</span>自同构构成一个群，称为 <span class="math inline">\(K\)</span> 在 <span class="math inline">\(F\)</span> 上的 <span class="math inline">\(Galois\)</span> 群 <span class="math inline">\(Gal(K/F)\)</span></li><li><span class="math inline">\(Galois\)</span>扩张：<span class="math inline">\(|Gal(K/F)|=[K:F]\)</span> 的扩张</li><li>固定域：令 <span class="math inline">\(H\)</span> 是域 <span class="math inline">\(K\)</span> 的自同构群，<span class="math inline">\(H\)</span> 的固定域 <span class="math inline">\(K^H\)</span> 是由 <span class="math inline">\(K\)</span> 的每个群元素固定不动的元素集合：<span class="math inline">\(K^H=\{\alpha \in K|\sigma(\alpha)=\alpha,\sigma\in H \}\)</span></li></ul><h3 id="相关定理">4.2 相关定理</h3><h4 id="galois-扩张的特征性质">4.2.1 Galois​ 扩张的特征性质</h4><p>令 <span class="math inline">\(K/F\)</span> 是有限扩张，设 <span class="math inline">\(G\)</span> 为它的 <span class="math inline">\(Galois\)</span> 群</p><p><span class="math inline">\(K/F\)</span> is <span class="math inline">\(Galois\)</span></p><p><span class="math inline">\(\iff\)</span> <span class="math inline">\(|G|=[K:F]\)</span></p><p><span class="math inline">\(\iff\)</span> 固定域 <span class="math inline">\(K^G\)</span> 等于 <span class="math inline">\(F\)</span></p><p><span class="math inline">\(\iff\)</span> <span class="math inline">\(K\)</span> 是 <span class="math inline">\(F\)</span> 的分裂域</p><h4 id="主要定理-the-main-theorem">4.2.2 主要定理 The Main Theorem</h4><p>令 <span class="math inline">\(K\)</span> 是域 <span class="math inline">\(F\)</span> 的 <span class="math inline">\(Galois\)</span> 扩张，设 <span class="math inline">\(G\)</span> 为它的 <span class="math inline">\(Galois\)</span> 群，则在 <span class="math inline">\(G\)</span> 的子群与中间域之间存在一一对应，这个对应把子群 <span class="math inline">\(H\)</span> 与它的固定域、中间域 <span class="math inline">\(L\)</span> 与 <span class="math inline">\(K\)</span> 在 <span class="math inline">\(L\)</span> 上的 <span class="math inline">\(Galois\)</span> 群结合起来.</p><p><span class="math inline">\(\Phi:H\rightsquigarrow K^H\)</span> 和 $ :LG(K/L)$ 是互逆的。</p><p>即： <span class="math inline">\(\Phi \circ \Psi (L)=L\)</span>, <span class="math inline">\(\Psi\circ\Phi (H)=H\)</span></p><h4 id="应用">4.2.3 应用</h4><p><span class="math inline">\(K/F=F(\alpha)/F\)</span> 上的最小多项式为:</p><p><span class="math inline">\(f(x)=\displaystyle\prod\limits_{\sigma\in Gal(K/F)} (x-\sigma(\alpha))\)</span></p><p>$ \ $</p><p><strong>例：</strong></p><p>Let <span class="math inline">\(N\geqslant 3\)</span> ，<span class="math inline">\(\xi_N\)</span> is a primitive <span class="math inline">\(n\)</span> th root of unit.</p><p>Assume <span class="math inline">\(\sigma(\xi_N)=\xi_N ^a\)</span> where <span class="math inline">\((a,N)=1\)</span></p><p>we have : <span class="math inline">\(\phi: Gal(\mathbb{Q}(\xi_N)/\mathbb{Q})\to (\mathbb{Z}/N\mathbb Z)^{\times}\)</span> is bijective.</p><p>$ $ is injective since <span class="math inline">\(\ker \phi=1\)</span> （identity mapping)</p><p><span class="math inline">\(\phi\)</span> is surjective since <span class="math inline">\(\forall p,(p,N)=1 ,\exists \sigma\in Gal(\mathbb{Q}(\xi_N)/\mathbb{Q}),\quad s.t.\quad \sigma(\xi_N)=\xi_N^p\)</span></p><p><span class="math inline">\(\because \mathbb{Q}(\xi_N)\)</span> is the splitting field of <span class="math inline">\(x^N-1\)</span></p><p><span class="math inline">\(\therefore \mathbb{Q}(\xi_N)/\mathbb{Q}\)</span> is <span class="math inline">\(Galois\)</span></p><p><span class="math inline">\(\therefore [\mathbb{Q}(\xi_N):\mathbb{Q}]=|Gal(\mathbb{Q}(\xi_N)/\mathbb{Q})|=|(\mathbb{Z}/N\mathbb Z)^{\times}|=\varphi(N)\)</span></p><p>And the unit polynomial is :</p><p><span class="math inline">\(f(x)=\displaystyle\prod\limits_{\sigma\in Gal(\mathbb{Q}(\xi_N)/\mathbb{Q})}(x-\sigma(\xi_N))=\displaystyle\prod\limits_{(a,n)=1}(x-\xi_N^a)\)</span></p>]]></content>
      
      
      <categories>
          
          <category> Mathematics </category>
          
          <category> Algebra </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 代数 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>搭建此博客过程中的心得</title>
      <link href="/2020/01/19/Other%20Things/%E6%90%AD%E5%BB%BA%E6%AD%A4%E5%8D%9A%E5%AE%A2%E8%BF%87%E7%A8%8B%E4%B8%AD%E7%9A%84%E5%BF%83%E5%BE%97/"/>
      <url>/2020/01/19/Other%20Things/%E6%90%AD%E5%BB%BA%E6%AD%A4%E5%8D%9A%E5%AE%A2%E8%BF%87%E7%A8%8B%E4%B8%AD%E7%9A%84%E5%BF%83%E5%BE%97/</url>
      
        <content type="html"><![CDATA[<h1 id="搭建此博客过程中的心得">搭建此博客过程中的心得</h1><h2 id="hexo框架">1. <a href="https://zhuanlan.zhihu.com/p/26625249" target="_blank" rel="noopener">Hexo框架</a></h2><p>看到“绑定域名”之前就可以了。</p><p>理解以下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs php+HTML">hexo clean % 清除当前缓存<br>hexo g -d % generate 生成博客<br>hexo d % deploy 将博客部署到GitHub<br>hexo s % hexo server的简写 之后可以在localhost上访问<br>hexo new &quot;bulabula&quot; %生成名为bulabula的md文件（一篇新文章）<br></code></pre></td></tr></table></figure><h2 id="购买域名">2. 购买域名</h2><p>选择了阿里云，发现域名买起来也挺方便的。</p><p><a id="more"></a></p><h2 id="域名与github-page-绑定">3. 域名与GitHub Page 绑定</h2><p>这里踩了不少坑。有的文章跟着走下来却没有效果。最后是跟着<a href="https://cloud.tencent.com/developer/article/1037114" target="_blank" rel="noopener">这篇文章</a>的域名解析和GitHub解析部分完成的。还是要用SSH。只需要做一个A类型和一个CNAME类型两个域名解析。</p><p>需要域名和GitHub Page双向绑定。</p><p>（1）输入longqianh.github.io。由于在setting里的设置，GitHub Page会帮我重定向到我购买的longqianh.com，然后DNS服务器解析域名，将 longqianh.com 解析为我GitHub Page 的IP地址，然后得以访问。<a href="https://blog.csdn.net/gui951753/article/details/83070180" target="_blank" rel="noopener">但是可能是一个IP可能对应多个web地址，直接访问IP地址是不行的</a>。</p><p>（2）输入longqianh.com。DNS服务器解析到GitHub Page的IP地址进行访问。</p><p>我似乎还没有理解在域名解析那里设置CNAME所起的作用。</p><h2 id="主题设置">4. 主题设置</h2><p>我从<a href="https://hexo.io/themes/" target="_blank" rel="noopener">各种hexo的主题</a>里选择了 Ayer 主题， 然后修改.yml文件、一些.ejs文件，然后更换了一些图片。从Google的主题上拿下来了一个钢铁侠的超好看背景图片，然后从一些icon网站下了一些钢铁侠的图标，用PS反相操作一下，把黑色反转成白色以突出，就成了现在的模样。</p><h2 id="一些常见问题">5. 一些常见问题</h2><ul><li><p>hexo g 失败：</p><p>‘YAMLException: can not read a block mapping entry; a multiline key may not be an implicit key at line 6, column 1’</p></li></ul><p>解决：</p><p>title: hexo 注意冒号后面要加空格</p><p>categories 下面的’-’ 号，后面也要加空格再写字</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>监督学习</title>
      <link href="/2020/01/19/Computer-Sciencs/Supvised%20Learning/"/>
      <url>/2020/01/19/Computer-Sciencs/Supvised%20Learning/</url>
      
        <content type="html"><![CDATA[<h1 id="supvised-learning">Supvised Learning</h1><h2 id="linear-regression">1.Linear Regression</h2><p>output hypotheses function: <span class="math display">\[h(x)= \theta^Tx\]</span></p><p><span class="math inline">\(x\)</span> is the input vector: <span class="math display">\[x=(x_1,x_2,\cdots,x_n)^T\]</span></p><p><span class="math inline">\(\theta\)</span> is the parameter vector: <span class="math display">\[\theta=(\theta_1,\theta_2,\cdots,\theta_n)^T\]</span></p><p><span class="math inline">\(y\)</span> is the training output</p><p><span class="math inline">\(X\)</span> is the training input matrix: <span class="math display">\[X= (x^{(1)},x^{(2)},\cdots,x^{(m)})\]</span></p><p><span class="math inline">\(Y\)</span> is the training output matrix: <span class="math display">\[Y=(y^{(1)},y^{(2)},\cdots,y^{(m)})\]</span></p><p>$\ $</p><h3 id="lms-algorithm">LMS algorithm</h3><ul><li>cost function:<br /><span class="math display">\[J(\theta)=\frac{1}{2}\parallel{\theta^T X-Y}\parallel^2\\        or : J(\theta)=\frac{1}{2}\sum\limits_{i=1}^{m}(h(x^{(i)})-y^{(i)})^2        \notag\]</span></li></ul><p>use <strong>matrix derivative</strong> to minimize <span class="math inline">\(J\)</span></p><ul><li>gradient descent :</li></ul><p><span class="math display">\[\theta_j := \theta_j-\alpha \frac{\partial}{\partial\theta_j}J(\theta)\notag\]</span></p><p><a id="more"></a></p><ul><li>Newton's method:<br /><span class="math display">\[\theta:=\theta-H^{-1}\nabla_\theta l(\theta)\notag\]</span> where <span class="math inline">\(H\)</span> is the Hessian: <span class="math display">\[\displaystyle H_{ij}=\frac{\partial^2l(\theta)}{\partial\theta_i\partial\theta_j}\]</span></li></ul><p>​</p><h3 id="locally-weighted-linear-regression">Locally Weighted Linear Regression</h3><p>cost function: <span class="math display">\[\displaystyle J(\theta)=\sum\limits_i w^{(i)}(y^{(i)}-\theta^T x^{(i)})^2\]</span></p><p>weight <span class="math inline">\(w\)</span> : <span class="math display">\[w^{(i)}=exp(-(x^{(i)}-x)^2/2\tau^2)\]</span></p><h2 id="generalized-linear-models-glm">2. Generalized Linear Models (GLM)</h2><ul><li><h3 id="the-exponential-family">The exponential family</h3></li></ul><p><span class="math display">\[p(y;\eta)=b(y)\exp(\eta^T T(y)-a(\eta))\]</span></p><p>where <span class="math inline">\(\eta\)</span> is the canonical parameter</p><ul><li><h4 id="bernoulli-distribution">Bernoulli distribution</h4></li><li><h4 id="gaussian-distribution">Gaussian distribution</h4></li><li><h4 id="possion-distribution">Possion distribution</h4></li><li><h4 id="logistic-regression">Logistic Regression</h4><span class="math display">\[h(x)=g(\theta^T x)=1/(1+e^{-\theta^T x})\]</span></li></ul><p>To get the parameters, assume :</p><p><span class="math display">\[P(y=1| x;\theta)=h(x)\]</span></p><p><span class="math display">\[P(y=0|x;\theta)=1-h(x)\]</span></p><p>then:</p><p><span class="math display">\[L(\theta)=p(\vec{y}|X;\theta)\]</span></p><p><span class="math display">\[ =\prod\limits_{i=1}^m p(y^{(i)}|x^{(i)};\theta)\]</span> <span class="math display">\[=\prod\limits_{i=1}^m (h(x^{(i)})^{y^{(i)}})(1-h(x^{(i)}))^{1-y^{(i)}}\]</span></p><p>to maximize the likelihood, we can use gradient descent again.</p><ul><li><h4 id="softmax-regression">Softmax Regression</h4><p>Multi-output <span class="math inline">\(\vec{y}\)</span></p><p><span class="math inline">\(p(y=i|x;\theta)=\frac{e^\eta_i}{\sum_{j=1}^k e^{\eta_j}}\)</span></p><h3 id="common-method">✨Common method</h3><p><strong>Step 1</strong> : Assume a distribution</p><p><strong>Step 2</strong> : Fit the GLM and get <span class="math inline">\(\eta\)</span> as well as mean <span class="math inline">\(E(y;\eta)\)</span></p><p>in GLM, <span class="math inline">\(\eta\)</span> is assumed as <span class="math inline">\(\theta^T x\)</span></p><p><span class="math inline">\(h(x)=E(y;\eta)=E(y|x;\theta)\)</span></p><p><strong>Step 3</strong> : Estimate the parameter</p><p>Maximize the likelihood function <span class="math inline">\(L(\theta)=p(y|x)\)</span> and get <span class="math inline">\(\theta\)</span></p></li></ul><h2 id="generative-learning-algorithms">3. Generative Learning algorithms</h2><ul><li><h4 id="gaussian-discriminant-analysis-多元高斯分布">Gaussian discriminant analysis <a href="https://zhuanlan.zhihu.com/p/58987388" target="_blank" rel="noopener">多元高斯分布</a></h4></li><li><h4 id="naive-bayes-朴素贝叶斯">Naive Bayes <a href="https://zhuanlan.zhihu.com/p/25493221" target="_blank" rel="noopener">朴素贝叶斯</a></h4></li></ul>]]></content>
      
      
      <categories>
          
          <category> Computer Science </category>
          
          <category> Machine Learning </category>
          
      </categories>
      
      
        <tags>
            
            <tag> notes </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Computer-Sciencs/HTML学习</title>
      <link href="/2020/01/18/Computer-Sciencs/HTML%E5%AD%A6%E4%B9%A0/"/>
      <url>/2020/01/18/Computer-Sciencs/HTML%E5%AD%A6%E4%B9%A0/</url>
      
        <content type="html"><![CDATA[<h1 id="html-hyper-text-markup-language">HTML: Hyper Text Markup Language</h1><p>速查：https://www.w3school.com.cn/tags/att_standard_id.asp</p>]]></content>
      
      
      <categories>
          
          <category> Computer Science </category>
          
          <category> Web </category>
          
          <category> html </category>
          
      </categories>
      
      
    </entry>
    
    
  
  
</search>
