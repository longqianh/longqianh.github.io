<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>Laser Holography</title>
      <link href="/2020/05/03/Projects/Laser-holography/"/>
      <url>/2020/05/03/Projects/Laser-holography/</url>
      
        <content type="html"><![CDATA[<p>This is the my final report for Semiconductor Laser Holography experiement in physics experiment course.</p><p>waiting for upload~</p><!--<div class="row">    <embed src="/pdf_files/半导体激光全息实验总结.pdf" width="100%" height="550" type="application/pdf"></div>-->]]></content>
      
      
      <categories>
          
          <category> Projects </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>Optomechanical Structural Design</title>
      <link href="/2020/05/03/Projects/Optomechanical-Structural-Design/"/>
      <url>/2020/05/03/Projects/Optomechanical-Structural-Design/</url>
      
        <content type="html"><![CDATA[<p>This is the major assignment for our optomechanical structural design course. Thanks a lot for Xiaowen Wang, Longxun Cao and Hanmo Mei. That  week we all had little time for sleep and we finally made a really big guy! Although that period was very hard , I really cherish it.</p><p>I will make it more detailed when I have time.</p><h3 id="工程图汇总"><a href="#工程图汇总" class="headerlink" title="工程图汇总"></a>工程图汇总</h3><div class="row">    <embed src="/pdf_files/钢铁侠手臂台灯-工程图汇总.pdf" width="100%" height="550" type="application/pdf"></div><h3 id="设计文件"><a href="#设计文件" class="headerlink" title="设计文件"></a>设计文件</h3><div class="row">    <embed src="/pdf_files/钢铁侠手臂台灯项目设计文件.pdf" width="100%" height="550" type="application/pdf"></div><h3 id="展示PPT"><a href="#展示PPT" class="headerlink" title="展示PPT"></a>展示PPT</h3><p>waiting~</p>]]></content>
      
      
      <categories>
          
          <category> Projects </category>
          
          <category> Optics </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>Optomechanical Structural Design</title>
      <link href="/2020/05/03/Optomechanical-Structural-Design/"/>
      <url>/2020/05/03/Optomechanical-Structural-Design/</url>
      
        <content type="html"><![CDATA[<p>This is the major assignment for our optomechanical structural design course. Thanks a lot for Xiaowen Wang, Longxun Cao and Hanmo Mei. That week we all had little time for sleep and we finally made a really big guy! Although that period was very hard , I really cherish it.</p><p>I will make it more detailed when I have time.</p><h3 id="工程图汇总">工程图汇总</h3><div class="row">    <embed src="/pdf_files/钢铁侠手臂台灯-工程图汇总.pdf" width="100%" height="550" type="application/pdf"></div><h3 id="设计文件">设计文件</h3><div class="row">    <embed src="/pdf_files/钢铁侠手臂台灯项目设计文件.pdf" width="100%" height="550" type="application/pdf"></div><h3 id="展示ppt">展示PPT</h3><p>waiting~</p>]]></content>
      
      
      <categories>
          
          <category> Projects </category>
          
          <category> Optics </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>NA-Notes</title>
      <link href="/2020/05/03/Notes-byhand/NA-notes/"/>
      <url>/2020/05/03/Notes-byhand/NA-notes/</url>
      
        <content type="html"><![CDATA[<p>This is my class notes for Numerical Analysis. Hopefully one day I can organize it into an electronic version.</p><p>Waiting for upload~</p><!--<div class="row">    <embed src="/pdf_files/数值分析方法.pdf" width="100%" height="550" type="application/pdf"></div>-->]]></content>
      
      
      <categories>
          
          <category> notes </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>PDE-Notes</title>
      <link href="/2020/05/03/Notes-byhand/pde-notes/"/>
      <url>/2020/05/03/Notes-byhand/pde-notes/</url>
      
        <content type="html"><![CDATA[<p>This is my class notes for PDE (partial differential equations ) course.</p><p>…</p><p>Due to the capacity limit, I cannot upload it (200+MB), will find a solution when I have time~</p>]]></content>
      
      
      <categories>
          
          <category> notes </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>Optical Combination Experiment</title>
      <link href="/2020/05/03/Projects/Optical-combination-experiment/"/>
      <url>/2020/05/03/Projects/Optical-combination-experiment/</url>
      
        <content type="html"><![CDATA[<p>This is the optical combination experiment report I’ve done in the Aplied Optical Experiment course.</p><p>Waiting for upload ~</p><!--<div class="row">    <embed src="/pdf_files/光学组合实验实验报告.pdf" width="100%" height="550" type="application/pdf"></div>-->]]></content>
      
      
      <categories>
          
          <category> Projects </category>
          
          <category> Optics </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>iPhone Focal Length Measurement</title>
      <link href="/2020/05/03/Projects/iPhone-focal-length-measurement/"/>
      <url>/2020/05/03/Projects/iPhone-focal-length-measurement/</url>
      
        <content type="html"><![CDATA[<p>This is the mobile phone focal length measurement experiment report I’ve done in the Aplied Optical Experiment course.</p><p>Waiting for upload~</p><!--<div class="row">    <embed src="/pdf_files/手机焦距测量实验报告.pdf" width="100%" height="550" type="application/pdf"></div>-->]]></content>
      
      
      <categories>
          
          <category> Projects </category>
          
          <category> Optics </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>2020-ICM</title>
      <link href="/2020/05/02/Projects/2020-ICM/"/>
      <url>/2020/05/02/Projects/2020-ICM/</url>
      
        <content type="html"><![CDATA[<p>This work is mainly about the football game team strategy based on big data and is our final paper for the D problem of 2020 Interdisciplinary Contest in Modelling (ICM 2020), contributed collaboratively and equally by R.C. Luo, Y.Z. Zhang and me. </p><p>Thanks cordially to the combined efforts of whole group, we fortunately won an M-prize. Due to privacy and copyright, the control number in our paper is erased.</p><div class="row">    <embed src="/pdf_files/2020_ICM.pdf" width="100%" height="550" type="application/pdf"></div>]]></content>
      
      
      <categories>
          
          <category> Projects </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>Matlab学习</title>
      <link href="/2020/03/03/Computer-Sciencs/Matlab%E5%AD%A6%E4%B9%A0/"/>
      <url>/2020/03/03/Computer-Sciencs/Matlab%E5%AD%A6%E4%B9%A0/</url>
      
        <content type="html"><![CDATA[<h2 id="Matlab-学习笔记"><a href="#Matlab-学习笔记" class="headerlink" title="Matlab 学习笔记"></a>Matlab 学习笔记</h2><ul><li>函数必须以end结尾。将其保存为.m 文件，即可在其他程 序中以文件名（注意不是函数名，文件名和函数名可以不同）调用该函数。</li></ul><ul><li><p>关系运算</p><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs matlab">a~=b<span class="hljs-comment">%不等于</span><br>a&gt;=b<span class="hljs-comment">%大于等于</span><br>a&lt;=b<span class="hljs-comment">%小于等于</span><br></code></pre></td></tr></table></figure></li></ul><ul><li><p>复数</p><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs matlab">a=<span class="hljs-number">1</span>+<span class="hljs-number">2</span><span class="hljs-built_in">i</span><br>z=<span class="hljs-built_in">real</span>(a)<span class="hljs-comment">%实部</span><br>z=<span class="hljs-built_in">imag</span>(a)<span class="hljs-comment">%虚部</span><br>z=<span class="hljs-built_in">angle</span>(a)<span class="hljs-comment">%辐角</span><br>z=<span class="hljs-built_in">abs</span>(a)<span class="hljs-comment">%模</span><br>z=<span class="hljs-built_in">conj</span>(a)<span class="hljs-comment">%共轭</span><br></code></pre></td></tr></table></figure></li></ul><ul><li><p>向量操作</p><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs matlab">a=<span class="hljs-built_in">rand</span>(<span class="hljs-number">1</span>,<span class="hljs-number">3</span>)<br>b=<span class="hljs-built_in">rand</span>(<span class="hljs-number">1</span>,<span class="hljs-number">3</span>)<br>c=<span class="hljs-built_in">dot</span>(a,b)<span class="hljs-comment">%内积</span><br>d=<span class="hljs-built_in">cross</span>(a,b)<span class="hljs-comment">%叉乘</span><br>l=<span class="hljs-built_in">length</span>(a)<span class="hljs-comment">%向量长度</span><br>median(a)<span class="hljs-comment">%中位数</span><br>std(a)<span class="hljs-comment">%标准差</span><br>s=<span class="hljs-built_in">sort</span>(a)<span class="hljs-comment">%排序</span><br><span class="hljs-comment">%还有 min max 等</span><br></code></pre></td></tr></table></figure></li></ul><ul><li>矩阵操作</li></ul><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs matlab">a=<span class="hljs-built_in">rand</span>(<span class="hljs-number">5</span>,<span class="hljs-number">3</span>)<br>b=<span class="hljs-built_in">rand</span>(<span class="hljs-number">5</span>,<span class="hljs-number">3</span>)<br>b=b'<span class="hljs-comment">%转置</span><br>c=a*b<span class="hljs-comment">%矩阵乘法</span><br>d=a.*b<span class="hljs-comment">%逐元素相乘</span><br>m=b^<span class="hljs-number">3</span><span class="hljs-comment">%幂</span><br>m=b.^<span class="hljs-number">3</span><span class="hljs-comment">%点幂</span><br><span class="hljs-built_in">size</span>(b)<span class="hljs-comment">%矩阵大小</span><br>b=<span class="hljs-built_in">reshape</span>(<span class="hljs-number">1</span>,<span class="hljs-number">15</span>)<br>b=<span class="hljs-built_in">flipud</span>(b)<span class="hljs-comment">%上下翻转 up and down</span><br>b=<span class="hljs-built_in">fliplr</span>(b)<span class="hljs-comment">%左右翻转 left and right</span><br>e=<span class="hljs-built_in">diag</span>(b)<span class="hljs-comment">%取出b的对角元素</span><br><br>left_division=a/b<span class="hljs-comment">% b*inv(a)</span><br>right_division=a\b<span class="hljs-comment">% inv(a)*b</span><br><span class="hljs-comment">%X=A\B是方程A*X=B的解，X=A\B是方程X*A=B的解 </span><br><span class="hljs-comment">%记忆：朝向哪 逆在哪</span><br></code></pre></td></tr></table></figure><ul><li><p>绘图</p><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs matlab">x=<span class="hljs-built_in">linspace</span>(<span class="hljs-number">1</span>,<span class="hljs-number">10</span>,<span class="hljs-number">100</span>)<br>y1=<span class="hljs-built_in">sin</span>(x)<br>y2=<span class="hljs-built_in">cos</span>(x)<br>y3=<span class="hljs-built_in">tan</span>(x)<br><span class="hljs-built_in">plot</span>(x,y1,<span class="hljs-string">'blue'</span>,x,y2,<span class="hljs-string">'LineWidth'</span>,<span class="hljs-number">2</span>,<span class="hljs-string">'color'</span>,<span class="hljs-string">'red'</span>)<br><span class="hljs-comment">%要在同一图中画出多条曲线，只需将坐标依次放入plot函数即可</span><br>axis([<span class="hljs-number">0</span> <span class="hljs-number">4</span>*<span class="hljs-built_in">pi</span> <span class="hljs-number">-1.2</span> <span class="hljs-number">1.2</span>])<span class="hljs-comment">%设置坐标轴范围</span><br>xlim([<span class="hljs-number">1</span> <span class="hljs-number">2</span>])<span class="hljs-comment">%单独控制</span><br>xlabel(<span class="hljs-string">'x'</span>); ylabel(<span class="hljs-string">'y'</span>);<br><span class="hljs-built_in">legend</span>(<span class="hljs-string">'sin(x)'</span>,<span class="hljs-string">'cos(x)'</span>);<br>title(<span class="hljs-string">'Sine and Cosine Functions'</span>);<br><span class="hljs-comment">%title里可以使用latex语法</span><br><span class="hljs-comment">%如 ：title('$y_1=\sin(4\pi t+\pi /3)$','interpreter','latex')</span><br><span class="hljs-comment">% 注明解释器为latex即可</span><br><br><span class="hljs-comment">%绘制子图</span><br>subplot(<span class="hljs-number">2</span>,<span class="hljs-number">2</span>,<span class="hljs-number">1</span>); <span class="hljs-built_in">plot</span>(x,y1);<br>subplot(<span class="hljs-number">2</span>,<span class="hljs-number">2</span>,<span class="hljs-number">2</span>); <span class="hljs-built_in">plot</span>(x,y2);<br>subplot(<span class="hljs-number">2</span>,<span class="hljs-number">2</span>,<span class="hljs-number">3</span>); <span class="hljs-built_in">plot</span>(x,y3);<br></code></pre></td></tr></table></figure></li></ul><ul><li><p>信号处理</p><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs matlab"><span class="hljs-comment">%噪声</span><br>snr=<span class="hljs-number">10</span>; <span class="hljs-comment">%Signal‐to‐noise ratio in dB.</span><br>yn=awgn(y,snr,<span class="hljs-string">'measured'</span>); <span class="hljs-comment">% Add white Gaussian noise. 白噪声</span><br><br><span class="hljs-comment">%函数</span><br>k1=<span class="hljs-number">-3</span>; k2=<span class="hljs-number">3</span>; k=k1:k2; n=<span class="hljs-number">0</span>;<br>step=stepfun(t,t0)<span class="hljs-comment">%t是向量形式的变量,t0表示延迟 阶跃函数</span><br>delta=+(k==n) <span class="hljs-comment">% 冲激函数</span><br>stem(k,delta,<span class="hljs-string">'filled'</span>)<span class="hljs-comment">% 离散函数绘制 stem为绘制杆状图</span><br><br><span class="hljs-comment">%rectpuls和tripuls函数产生指定宽度和高度的矩形和三角脉冲。</span><br></code></pre></td></tr></table></figure></li></ul><ul><li><p>其他技巧</p><ul><li>nargin, nargout 的使用 </li></ul></li></ul>]]></content>
      
      
      <categories>
          
          <category> Computer Science </category>
          
          <category> Language Learning </category>
          
          <category> Matlab </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>应用光学</title>
      <link href="/2020/03/02/Physics/%E5%BA%94%E7%94%A8%E5%85%89%E5%AD%A6/"/>
      <url>/2020/03/02/Physics/%E5%BA%94%E7%94%A8%E5%85%89%E5%AD%A6/</url>
      
        <content type="html"><![CDATA[<h1 id="应用光学-整理"><a href="#应用光学-整理" class="headerlink" title="应用光学 整理"></a>应用光学 整理</h1><h2 id="1-几何光学基础"><a href="#1-几何光学基础" class="headerlink" title="1. 几何光学基础"></a>1. 几何光学基础</h2><ul><li><p>全反射</p><script type="math/tex; mode=display">I=\arcsin{\frac{n_2}{n_1}}</script></li><li><p>矢量形式的折射定律</p><script type="math/tex; mode=display">\vec A'=\vec A+P\vec N\\</script><p>其中：</p><script type="math/tex; mode=display">\begin{aligned}P&=(\vec A'-\vec A)\cdot \vec N\\&=n'\cos I'-n\cos I\\&=\sqrt{n'^2-n^2\sin ^2 I}-n\cos I\end{aligned}</script><p>且 $\vec A,\vec A’$ 均为单位向量</p></li><li><p>矢量形式的反射定律</p><script type="math/tex; mode=display">\vec A'=\vec A-2(\vec N\cdot \vec A)\vec N</script></li></ul><ul><li><p>光程</p><p>​    光在介质中所经过的几何路径与该介质折射率的乘积。相当于光在介质中走过路程的时间内，在真空中所走的几何路程。</p><script type="math/tex; mode=display">\notag s=nl=ct</script></li><li><p>完善成像</p><p>​    等光程上完善成像的物理条件。</p></li></ul><h2 id="2-球面与球面系统"><a href="#2-球面与球面系统" class="headerlink" title="2. 球面与球面系统"></a>2. 球面与球面系统</h2><h3 id="单个球面镜成像"><a href="#单个球面镜成像" class="headerlink" title="单个球面镜成像"></a>单个球面镜成像</h3><ul><li><p>基本公式</p><script type="math/tex; mode=display">\begin{aligned}&\frac{n'}{l'}-\frac{n}{l}=\frac{n'-n}{r}\\&n'u'-nu=\frac{n'-n}{r}h\end{aligned}</script></li><li><p>光焦度</p><script type="math/tex; mode=display">\phi=\frac{n'-n}{r}=\frac{n'}{f'}=\frac{n}{f}</script></li><li><p>放大率</p><ul><li>横向<script type="math/tex; mode=display">\beta=\frac{y'}{y}=\frac{l'-r}{l-r}=\frac{nl'}{n'l}</script></li></ul></li></ul><pre><code>$\beta&gt;0$ : 虚实不同；$\beta&lt;0$ : 虚实相同。</code></pre><ul><li>轴向<script type="math/tex; mode=display">\alpha=\frac{dl'}{dl}=\frac{nl'^2}{nl^2}</script>反应像与物的沿轴移动量之比。</li></ul><ul><li>角度<script type="math/tex; mode=display">\gamma=\frac{u'}{u}=\frac{l}{l'}=\frac{n}{n'}\frac{1}{\beta}</script></li></ul><ul><li>关系<script type="math/tex; mode=display">  \alpha\gamma=\beta</script></li></ul><ul><li><p>不变量</p><ul><li>阿贝不变量<script type="math/tex; mode=display">Q=n(\frac{1}{l}-\frac{1}{r})=n'(\frac{1}{l'}-\frac{1}{r'})</script>阿贝不变量表征界面对某物点发出光线的偏折能力.</li></ul></li></ul><ul><li><p>拉赫不变量</p><script type="math/tex; mode=display">J=nyu=n'y'u'</script><p>​          推导：</p><script type="math/tex; mode=display">\notag\beta=\frac{y'}{y}=\frac{nl'}{n'l}=\frac{nu}{n'u'}\implies nyu=n'y'u'</script><p>​        $J$ 大，成像范围大，成像孔径角大，传输光能多。</p><p>​          拉赫不变量表征光学系统的成像能力.</p></li></ul><h3 id="反射球面（球面镜）"><a href="#反射球面（球面镜）" class="headerlink" title="反射球面（球面镜）"></a>反射球面（球面镜）</h3><ul><li>$n’=-n$</li></ul><h2 id="3-平面和平面系统"><a href="#3-平面和平面系统" class="headerlink" title="3. 平面和平面系统"></a>3. 平面和平面系统</h2><h3 id="平面镜"><a href="#平面镜" class="headerlink" title="平面镜"></a>平面镜</h3><ul><li>奇次反射成镜像，偶次反射成一致像</li><li>若反射光线不动，平面镜转 $\alpha$ 角，则反射光线转 $2\alpha$ 角</li></ul><h3 id="双平面镜"><a href="#双平面镜" class="headerlink" title="双平面镜"></a>双平面镜</h3><ul><li>夹角为 $\alpha$ 的双平面镜系统，物与二次反射后所成像的夹角为 $2\alpha$ .</li><li>入射光线与反射光线的夹角为 $2\alpha$ .</li></ul><h3 id="平行平板"><a href="#平行平板" class="headerlink" title="平行平板"></a>平行平板</h3><ul><li>近轴横向位移公式<script type="math/tex; mode=display">\Delta l'=d(1-\frac{1}{n})</script></li></ul><ul><li>近轴纵向位移公式<script type="math/tex; mode=display">\Delta t'=di(1-\frac{1}{n})</script>$i$ 为入射角 . </li></ul><h3 id="反射棱镜"><a href="#反射棱镜" class="headerlink" title="反射棱镜"></a>反射棱镜</h3><ul><li><p>结构常数</p><p>​    光轴在棱镜中的长度与棱镜通光口径之比</p><script type="math/tex; mode=display">K=\frac{d}{D}</script></li></ul><ul><li><p>五角棱镜</p><script type="math/tex; mode=display">K=2+\sqrt{2}\notag</script></li><li><p>达夫棱镜</p><script type="math/tex; mode=display">K=\frac{1}{\sin(45^{\circ}-i)}\notag</script></li></ul><p>  达夫棱镜的重要性质在于当它绕平行于反射面的轴转 $\alpha$ 角时，物体的反射像将转过 $2\alpha$ 角。</p><ul><li><p>屋脊棱镜</p><p>可以增加一次反射，改变像坐标系的左右旋向。</p></li></ul><ul><li>由物坐标求像坐标<ul><li>光轴方向 $z’$ 不变</li><li>垂直于主截面的坐标 $x’$ 视屋脊个数而定：奇数个倒转，偶数个不变。 或者：沿方向画一画确定</li><li>$y’$ 坐标根据总反射次数而定：奇数次变左手系。</li></ul></li></ul><ul><li><p>角锥棱镜</p><ul><li><p>从底面以任意方向入射的光线，经三个反射面顺序反射后，以与入射光线相反的方向从底面射出。</p></li><li><p>当棱镜角以角顶为中心向任意方向偏转时，出射光线方向不变。</p></li><li>用</li><li>矢量形式的反射定律证明</li></ul></li></ul><h3 id="折射棱镜"><a href="#折射棱镜" class="headerlink" title="折射棱镜"></a>折射棱镜</h3><p><img src="https://tva1.sinaimg.cn/large/00831rSTly1gcv1smbisuj30ad06t0sr.jpg" style="zoom: 67%;" /></p><ul><li><p>偏角公式</p><script type="math/tex; mode=display">\sin(\frac{\alpha+\delta_{min}}{2})=n\sin\frac{\alpha}{2}</script><p>此时 $I_1=-I_2’, I’_1=-I_2$ .</p></li><li><p>近轴简化：入射角有一定大小，折射角 $\alpha$ 很小</p><script type="math/tex; mode=display">\delta=\alpha\big(n\frac{\cos I'_1}{\cos I_1}-1\big)</script></li></ul><ul><li>近轴简化：入射角很小，折射角很小<script type="math/tex; mode=display">\delta=(n-1)\alpha</script></li></ul><h2 id="4-理想光学系统"><a href="#4-理想光学系统" class="headerlink" title="4. 理想光学系统"></a>4. 理想光学系统</h2><p><img src="https://tva1.sinaimg.cn/large/00831rSTly1gd5cgjb5nej32720rstdm.jpg" alt="image-20200324211216424"></p><p>​    理想光学系统，就是能对任意宽空间内的点以任意宽的光束成完善像的光学系统。</p><h3 id="（1）基本概念"><a href="#（1）基本概念" class="headerlink" title="（1）基本概念"></a>（1）基本概念</h3><ul><li>主点、主平面</li><li>节点</li><li>基点</li><li>焦物距、焦像距</li><li>光焦度：折合焦距的倒数</li><li>视觉放大率</li><li>物距$\ell$ : 主点到物点到距离，像距$\ell’$ : 主点到像点到距离</li></ul><h3 id="（2）作图技巧"><a href="#（2）作图技巧" class="headerlink" title="（2）作图技巧"></a>（2）作图技巧</h3><ul><li><p>辅助光线：</p><ul><li>平行光轴入射</li><li>过物方焦点入射</li><li>过节点入射</li></ul></li><li><p>依据：</p><ul><li><p>倾斜光轴入射的平行光束过系统后会聚雨像方焦平面</p></li><li><p>物方焦平面上一点发出的光束经系统后相互平行</p></li><li><p>光线与物方、像方主面 的交点，其高度相等</p></li></ul></li></ul><h3 id="（3）公式荟萃"><a href="#（3）公式荟萃" class="headerlink" title="（3）公式荟萃"></a>（3）公式荟萃</h3><h4 id="焦距"><a href="#焦距" class="headerlink" title="焦距"></a>焦距</h4><p>单个光组：</p><script type="math/tex; mode=display">\begin{aligned}(基本)\quad &f'=\frac{h}{u'},\quad f=\frac{h}{u}\\(牛顿公式)\quad & xx'=ff'\\(高斯公式)\quad &\frac{f'}{l'}+\frac{f}{l}=1\\&\beta=-\frac{f}{x}=-\frac{x'}{f'}\\&\frac{f'}{f}=-\frac{n'}{n}\\& \varphi=\frac{n'}{f'}=-\frac{n}{f}\end{aligned}</script><p>两个光组：</p><script type="math/tex; mode=display">\begin{aligned}(牛顿公式)\quad &x_F'=\frac{f_2 f_2'}{\Delta},x_F=\frac{f_1 f_1'}{\Delta} \\(三角形相似)\quad & f'=-\frac{f_1' f_2'}{\Delta},f=\frac{f_1 f_2}{\Delta}\\ &\Delta=d-f_1'-f_2'\end{aligned}</script><p>多个光组（$k$ 个）：</p><script type="math/tex; mode=display">\begin{aligned}&f'=\frac{h_1}{u_k'}\\(截距计算法) \quad &f'=\frac{l_1'l_2'\cdots l_l'}{l_2l_3\cdots l_k}\\\end{aligned}</script><p>​        截距计算法：令 $l_1=-\infty$ , 对每一个光组重复应用高斯公式求得物距像距，最后可推出总焦距。</p><p>望远镜系统：<br>                将第二系统的焦距扩大到 $\Gamma$ 倍。（把远处物体拉近到感觉，张角变大了）</p><h4 id="焦物距-焦像距"><a href="#焦物距-焦像距" class="headerlink" title="焦物距/焦像距"></a>焦物距/焦像距</h4><p>牛顿公式、截距计算法。</p><p>单个光组：</p><script type="math/tex; mode=display">\begin{aligned}&xx'=ff'\\&\beta=-\frac{x'}{f'}=-\frac{f}{x}\\(焦距-焦物距-物距)\quad &x=l-f,x'=l'-f'\end{aligned}</script><p>两个光组：</p><p>​    对第一光组，焦像距 $x’=\Delta$,  对第一光组，焦物距 $x=-\Delta$</p><script type="math/tex; mode=display">x_F'=-\frac{f_2f_2'}{\Delta},x_F=\frac{f_1f_1'}{\Delta}\notag</script><h4 id="放大率"><a href="#放大率" class="headerlink" title="放大率"></a>放大率</h4><script type="math/tex; mode=display">\begin{aligned}&\beta=\frac{y'}{y}=-\frac{x'}{f'}=-\frac{f}{x}\\(轴向放大率)\quad& \alpha=-\frac{x'}{x}\\&\alpha\gamma=\beta\\(两个光组) \quad & \beta=-\frac{f_1f_2/\Delta}{x_1-f_1f_2'/\Delta}=\frac{f_1f_2}{f_1f_1'-x_1\Delta}\\(重要，常用) \quad &\beta=\frac {l'} l=\frac{f'}{l+f'}\end{aligned}</script><h4 id="光焦度"><a href="#光焦度" class="headerlink" title="光焦度"></a>光焦度</h4><script type="math/tex; mode=display">\begin{aligned}(定义)\quad &\phi=\frac{n'}{f'}=-\frac{n}{f}\\(空气中,双光组)\quad &\phi=\phi_1+\phi_2-d\phi_1\phi_2\\(空气中，多光组)\quad &\phi=\frac{1}{h_1}\sum_{i=1}^k h_i\phi_i\end{aligned}</script><h4 id="正切计算法"><a href="#正切计算法" class="headerlink" title="正切计算法"></a>正切计算法</h4><p><img src="https://tva1.sinaimg.cn/large/00831rSTly1gd5bun7wn4j329a0rsjvx.jpg" alt="image-20200324211447349" style="zoom: 25%;" /></p><p><img src="https://tva1.sinaimg.cn/large/00831rSTly1gd5bp3fc1kj31xe0rsn21.jpg" alt="image-20200324210927813" style="zoom:25%;" /></p><p>顺着光路走下去。关键是一步一步地求 $h$ 和 $u$ .</p><script type="math/tex; mode=display">\begin{aligned}&\frac{1}{l'}-\frac{1}{l}=\frac{1}{f'}\implies u_1'-u_1=\frac{h_1}{f_1'},u_2'-u_2=\frac{h_2}{f_2'},\cdots, u'_k-u_{k}=\frac{h_k}{f'_k}\\&u_i=u'_{i-1}\\&l_i=l'_{i-1}-d_i \implies h_i=h_{i-1}-d_{i-1}u'_{i-1}\\\end{aligned}</script><h3 id="（4）透镜"><a href="#（4）透镜" class="headerlink" title="（4）透镜"></a>（4）透镜</h3><h2 id="5-光束限制"><a href="#5-光束限制" class="headerlink" title="5. 光束限制"></a>5. 光束限制</h2><h3 id="孔径光阑"><a href="#孔径光阑" class="headerlink" title="孔径光阑"></a>孔径光阑</h3><h3 id="视场光阑"><a href="#视场光阑" class="headerlink" title="视场光阑"></a>视场光阑</h3><h3 id="渐晕光阑"><a href="#渐晕光阑" class="headerlink" title="渐晕光阑"></a>渐晕光阑</h3><h3 id="景深"><a href="#景深" class="headerlink" title="景深"></a>景深</h3><h2 id="6-光度学基础"><a href="#6-光度学基础" class="headerlink" title="6. 光度学基础"></a>6. 光度学基础</h2><h3 id="基本术语"><a href="#基本术语" class="headerlink" title="基本术语"></a>基本术语</h3><ul><li>以电磁辐射形式发射、传输或接收的能量：辐射能 $Q_e$</li><li><p>单位时间内发射、传输或接收的辐射能：辐射通量 / 辐射功率 $\Phi_e$</p></li><li><p>辐射通量中人眼能感受到的部分：光通量 $\Phi_v$ （单位为流明 lm ）</p></li><li><p>某一方向上单位立体角的光通量：发光强度 $I_v$ （单位为坎德拉 cd ）</p></li><li>（垂直方向）单位面积接受的光通量：光照度 $E_v$  (单位为勒克斯 lx )</li><li>（垂直方向）单位面积发出的光通量：光出射度 $M_v$</li><li>光源发光投影到某一方向上单位面积的发光强度：光亮度 $L_v$  （单位为尼特 nt ）</li></ul><p>理解：光照度表征表面接受的光的性质；光亮度表征光源的发光性质，用立体角度量，而且是单位面积，是一个比光出射度更好的光源发光性质描述。</p><h3 id="辅助量和联系量"><a href="#辅助量和联系量" class="headerlink" title="辅助量和联系量"></a>辅助量和联系量</h3><ul><li>立体角<ul><li>$\Omega=\displaystyle\frac{S}{r^2}$</li><li>$d \Omega=\sin i \cdot di\cdot d\phi$</li><li>$\Omega=\displaystyle\iint<em>S \sin i did\phi=(\phi</em>{\max}-\phi<em>{\min})(\cos i</em>{\min}-\cos i_{\max})$</li><li>平面孔径角 $U$, $\Omega=\displaystyle\int_0^{2\pi}d\phi\int_0^U\sin i di=4\pi \sin^2\left(\frac U 2\right)\approx \pi u^2$</li></ul></li></ul><ul><li><p>光谱光视效率 / 视见函数 $V(\lambda)$</p><p>​        反映人眼的光谱灵敏度，表示人眼对不同波长辐射对敏感度差异。</p><p>​        和辐射通量直接的换算： $1W$（辐射通量）$=683\cdot V(\lambda)$ lm</p></li></ul><ul><li><p>发光效率 $\eta$</p><p>​        辐射体发出的总光通量与该光源的耗电功率之比。</p><p>​        $\eta=\displaystyle\frac{\Phi_v}{P}$</p></li></ul><h3 id="重要关系"><a href="#重要关系" class="headerlink" title="重要关系"></a>重要关系</h3><ul><li><p>光亮度 : $L_v=\displaystyle\frac{I_v}{dA\cos i}=\frac{d\Phi_v}{d\Omega dA\cos i}$</p></li><li><p>朗伯辐射体且面积为 $A$ : $I_N=L_vA$</p></li><li><p>朗伯辐射体已知光出射度或二次辐射源 : </p><script type="math/tex; mode=display">L_v=\frac{M_v}{\pi}=\frac{\rho E_v}{\pi}</script></li></ul><h3 id="基本定律"><a href="#基本定律" class="headerlink" title="基本定律"></a>基本定律</h3><h4 id="朗伯定律"><a href="#朗伯定律" class="headerlink" title="朗伯定律"></a>朗伯定律</h4><p>一个光亮度再各个方向上均相等的发光面源（朗伯辐射体），在某一方向上的发光强度等于该面元法线方向上的发光强度与方向角余弦之积。</p><script type="math/tex; mode=display">I_i=I_N\cos i</script><ul><li>朗伯辐射体在孔径角 $U$ 范围内发出的光通量<script type="math/tex; mode=display">\begin{align}d\Phi_v&=L_v\cos i dAd\Omega\notag \\\implies \Phi_v&=\int_0^{2\pi}d\phi\int_0^UL_v\sin i\cos idA di\notag \\&=\pi L_v\sin^2 U dA\\&=\pi I\sin^2 U(?)\end{align}</script></li></ul><ul><li>孔径角为 $\displaystyle \frac \pi 2$ 时（平面），$L_v=\displaystyle \frac{\Phi_v }{\pi dA}=\frac{M_v}{\pi}$</li></ul><h4 id="距离平方反比定律"><a href="#距离平方反比定律" class="headerlink" title="距离平方反比定律"></a>距离平方反比定律</h4><p>点光源直接照射表面时，受照面光照度为</p><script type="math/tex; mode=display">E_v=\frac{I_v}{r^2}</script><h4 id="照度余弦定则"><a href="#照度余弦定则" class="headerlink" title="照度余弦定则"></a>照度余弦定则</h4><p>光源不垂直于照明面元时的光照度为</p><script type="math/tex; mode=display">E_v=\frac{I_0\cos i}{r^2}=E_v\cos i</script><h3 id="光束光亮度的传递"><a href="#光束光亮度的传递" class="headerlink" title="光束光亮度的传递"></a>光束光亮度的传递</h3><ul><li>面光源照射时受照表面的光照度<script type="math/tex; mode=display">E_v=\frac{L_v d S_1\cos i_1\cos i_2}{r^2}</script>$i_1,i_2$ 分别为两面法线与距离  $\vec r$ 直接的夹角。</li></ul><ul><li><p>光在无损介质中传播时，各截面上的光亮度相等。</p></li><li><p>不同介质分界面上光束的传递 :<br>$$<br>\begin{align}<br>\rho&amp;\approx\left(\frac{n’-n}{n’+n}\right)^2,\tau=1-\rho\<br>L_r&amp;=\rho L_i\<br>L_t&amp;=\left(\frac{n’}{n}\right)^2\tau L_i</p></li></ul><p>  \end{align}</p><script type="math/tex; mode=display">### 光学成像系统的像面照度#### 轴上像点</script><p>\begin{align}<br>E_0’&amp;=\frac{\Phi_v’}{dS’}=\tau \frac{\pi L_v \sin^2 U dS}{dS’}\<br>&amp;=\frac{1}{\beta^2}\tau \pi L_v\sin^2 U &amp;\text{(物空间)}\<br>&amp;=\left(\frac{n’}{n}\right)^2\tau\pi L_v\sin^2 U’ &amp;\text{(像空间)}\<br>\end{align}</p><script type="math/tex; mode=display">其中用到正弦关系：$ny\sin U=n’y’\sin U'$#### 轴外像点设轴外像点 $B’$ 的像方视场角（对出瞳的张角）为 $\omega'$</script><p>\begin{align}<br>\sin U_B’&amp;\approx \sin U’\cos ^2\omega\<br>E_B’&amp;=E_0\cos^4\omega’</p><p>\end{align}</p><p>$$</p><h1 id="应用光学实验"><a href="#应用光学实验" class="headerlink" title="应用光学实验"></a>应用光学实验</h1><h2 id="手机摄像头焦距测量"><a href="#手机摄像头焦距测量" class="headerlink" title="手机摄像头焦距测量"></a>手机摄像头焦距测量</h2><h3 id="通用知识（手机）"><a href="#通用知识（手机）" class="headerlink" title="通用知识（手机）"></a>通用知识（手机）</h3><ul><li><p>手机摄像头近似认为是薄透镜</p></li><li><p>视场光阑：CMOS光敏面最外面一圈</p></li><li><p>一般手机数值孔径：广角～1.8，数值越小难度越大；长焦～2.4，大的到2.8</p></li><li><p>一般手机焦距： 4～6mm</p></li><li><p>等效焦距</p><ul><li><p>同样焦距的镜头，在不同尺寸的感光元件上，成像视角不同，仅以镜头的物理焦距，无法比较不同相机的成像范围（视场角）。</p></li><li><p>为了便于比较，人们习惯将不同尺寸感光元件上成像的视角，转化为 <em>36 x 24 mm 全画幅感光元件上同样成像视角所对应的镜头焦距</em>，这个转化后的焦距就是等效焦距</p></li><li><p>物理焦距 $\times$ 转换系数 $=$ 等效焦距，</p><p>其中 转换系数 $=$ 43.27 ( 全画幅对角线长) $/$ 传感器光面对角线长</p></li><li><p>手机的等效焦距有个坑，1英寸手机厂商这里是 16 mm ，而不是 25.4 mm</p></li></ul></li></ul><h3 id="iPhone-X-实验手机"><a href="#iPhone-X-实验手机" class="headerlink" title="iPhone X (实验手机)"></a>iPhone X (实验手机)</h3><ul><li><p>iPhone X 后置摄像头</p><ul><li>主摄：广角 $F/1.8 $</li><li>副摄：长焦 $F/2.4$</li></ul></li><li><p>CMOS : IMX385 1.22 µm</p></li><li><p>正常拍照模式下一倍变焦用的是广角镜头，二倍变焦用的长焦镜头，人像模式下是两个镜头同时使用，后台计算像场和景深。另外，<strong>长焦镜头使用了更小的光圈，因此需要更多的光线</strong>，苹果让 iPhone 自己来判定光线是否足够，从而启动长焦镜头。</p></li><li><p>物方视场角 FOV：视场角分物方视场角和像方视场角。一般光学设备的使用者关心的是物方视场角。</p><p>对于大多数光学仪器,视场角的度量都是以成像物的直径作为视场角计算的。</p></li><li><p>光瞳直径 $=$ 焦距 $/$ 光圈数 $F$</p></li></ul><h3 id="实验方法"><a href="#实验方法" class="headerlink" title="实验方法"></a>实验方法</h3><ul><li><p>找一张白纸，用直尺画上一条直线，我画的是 150 mm $\implies l=-150$</p></li><li><p>直线一端直立放一把尺子，另一端放手机</p></li><li><p>一倍正常拍摄一张，用的是主（广角）镜头；二倍数字变焦放大拍摄一张，用的是副（长焦）镜头</p></li><li><p>隔空投送到电脑上，用 PhotoShop 寻找尺子 1cm～2cm 的像素距离。</p><p>具体方法为：Ctrl+R 出现横纵坐标轴，在坐标轴上右键选像素，变成像素坐标。在 1cm～2cm 画一个矩形，记录像素距离</p></li><li><p>查找 CMOS 传感器的 unit cell （比如 IMX363 2.4 µm 一个像素点）, 计算实际像高</p></li><li><p>由 $\displaystyle \beta=\frac{y’}{y}=\frac{l’}{l}$ 得到像距 $l’$ ，有了 $l’$ 其他的都可以算了</p></li><li><p>焦距 $f’=\displaystyle\frac{1}{1/l’-1/l}$ （高斯公式）</p></li><li><p>光瞳直径 $\displaystyle D=\frac{f’}{F}$  ，$F$ 为光圈数</p></li><li><p>物方视场角 $\displaystyle FOV=2\arctan\left(\frac{d/2}{l’}\right)$  其中 $d$ 为传感器对角线长</p></li></ul><h3 id="实验代码"><a href="#实验代码" class="headerlink" title="实验代码"></a>实验代码</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><br><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">get_l1</span><span class="hljs-params">(px, unit, y=<span class="hljs-number">10</span>)</span>:</span><br>        <span class="hljs-comment"># 计算像高y1,像距l1</span><br>    l = <span class="hljs-number">150</span><br>    y1 = px * unit / <span class="hljs-number">1000</span><br>    beta = y1 / y<br>    l1 = beta * l<br>    <span class="hljs-keyword">return</span> y1, l1<br><br><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">get_f</span><span class="hljs-params">(l1, l)</span>:</span><br>        <span class="hljs-comment"># 计算焦距</span><br>    <span class="hljs-keyword">return</span> <span class="hljs-number">1</span> / (<span class="hljs-number">1</span> / l1 + <span class="hljs-number">1</span> / l)<br><br><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">get_diaglen</span><span class="hljs-params">(x, y)</span>:</span><br>        <span class="hljs-comment"># 获得对角线长度</span><br>    <span class="hljs-keyword">return</span> np.sqrt(x**<span class="hljs-number">2</span> + y**<span class="hljs-number">2</span>)<br><br><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">get_FOV</span><span class="hljs-params">(diag, l1)</span>:</span><br>        <span class="hljs-comment"># 计算物方视场角</span><br>    <span class="hljs-keyword">return</span> <span class="hljs-number">2</span> * np.arctan(diag / <span class="hljs-number">2</span> / l1) * <span class="hljs-number">180</span> / np.pi<br><br><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">get_D</span><span class="hljs-params">(f, F)</span>:</span><br>        <span class="hljs-comment"># 获得光瞳直径</span><br>    <span class="hljs-keyword">return</span> f / F<br><br><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">r</span><span class="hljs-params">(x, N=<span class="hljs-number">4</span>)</span>:</span><br>        <span class="hljs-comment"># 保留四位小数</span><br>    <span class="hljs-keyword">return</span> round(x, N)<br><br><br>px1 = <span class="hljs-number">237</span><br>px2 = <span class="hljs-number">432</span><br>F1 = <span class="hljs-number">1.8</span><br>F2 = <span class="hljs-number">2.4</span><br>unit = <span class="hljs-number">1.22</span><br>l = <span class="hljs-number">150</span><br>diag = <span class="hljs-number">6.15</span><br>trans = <span class="hljs-number">43.27</span> / diag<br><br>y1, l1 = get_l1(px1, unit)<br>y2, l2 = get_l1(px2, unit)<br>f1 = get_f(l1, l)<br>f2 = get_f(l2, l)<br>D1 = get_D(f1, F1)<br>D2 = get_D(f2, F2)<br>FOV1 = get_FOV(diag, l1)<br>FOV2 = get_FOV(diag, l2)<br><span class="hljs-comment"># diag = get_diaglen(5.21, 6.29)</span><br><br><span class="hljs-comment"># print('传感器对角线长：', round(diag, 4))</span><br><br>print(<span class="hljs-string">'--广角--'</span>)<br>print(<span class="hljs-string">'焦距：'</span>, r(f1))<br>print(<span class="hljs-string">'等效焦距'</span>, r(trans * f1))<br>print(<span class="hljs-string">'物方视场角：'</span>, r(FOV1))<br>print(<span class="hljs-string">'光瞳直径: '</span>, r(D1))<br>print()<br>print(<span class="hljs-string">'--长焦--'</span>)<br>print(<span class="hljs-string">'焦距：'</span>, r(f2))<br>print(<span class="hljs-string">'等效焦距'</span>, r(trans * f2))<br>print(<span class="hljs-string">'物方视场角：'</span>, r(FOV2))<br>print(<span class="hljs-string">'光瞳直径: '</span>, r(D2))<br><br><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">get_err</span><span class="hljs-params">(y1)</span>:</span><br>    l0 = <span class="hljs-number">1</span> / (<span class="hljs-number">1</span> / <span class="hljs-number">4</span> - <span class="hljs-number">1</span> / <span class="hljs-number">150</span>)<br>    y0 = <span class="hljs-number">10</span> * l0 / <span class="hljs-number">150</span>  <span class="hljs-comment"># 10mm原像,150物距</span><br>    <span class="hljs-keyword">return</span> np.abs(y0 - y1) / y0<br><br><br>print()<br>print(<span class="hljs-string">'--误差计算--'</span>)<br><br>err_y = get_err(y1)<br>print(<span class="hljs-string">'像高误差-主镜头:'</span>, r(err_y) * <span class="hljs-number">100</span>, <span class="hljs-string">'%'</span>)<br>print(<span class="hljs-string">'焦距误差-主镜头'</span>, r(np.abs((f1 - <span class="hljs-number">4.0</span>)) / <span class="hljs-number">4.0</span>) * <span class="hljs-number">100</span>, <span class="hljs-string">'%'</span>)<br>beta1 = l1 / l<br>print()<br>print(<span class="hljs-string">'--放大倍率计算--'</span>)<br>print(<span class="hljs-string">'横向放大倍率'</span>, r(beta1))<br>print(<span class="hljs-string">'显示图像放大倍率'</span>, r(<span class="hljs-number">143.6</span> / (beta1 * <span class="hljs-number">10</span>)))<br></code></pre></td></tr></table></figure><h5 id="结果"><a href="#结果" class="headerlink" title="结果"></a>结果</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs python">--广角--<br>焦距： <span class="hljs-number">4.2152</span><br>等效焦距 <span class="hljs-number">29.6573</span><br>物方视场角： <span class="hljs-number">70.6732</span><br>光瞳直径:  <span class="hljs-number">2.3418</span><br><br>--长焦--<br>焦距： <span class="hljs-number">7.5098</span><br>等效焦距 <span class="hljs-number">52.8373</span><br>物方视场角： <span class="hljs-number">42.5086</span><br>光瞳直径:  <span class="hljs-number">3.1291</span><br><br>--误差计算--<br>像高误差-主镜头: <span class="hljs-number">5.54</span> %<br>焦距误差-主镜头 <span class="hljs-number">5.38</span> %<br><br>--放大倍率计算--<br>横向放大倍率 <span class="hljs-number">0.0289</span><br>显示图像放大倍率 <span class="hljs-number">496.6452</span><br></code></pre></td></tr></table></figure><h2 id="光学组合实验"><a href="#光学组合实验" class="headerlink" title="光学组合实验"></a>光学组合实验</h2><p>200px</p><p>1.22</p>]]></content>
      
      
      <categories>
          
          <category> Physics </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>Leecode</title>
      <link href="/2020/03/02/Computer-Sciencs/Leecode/"/>
      <url>/2020/03/02/Computer-Sciencs/Leecode/</url>
      
        <content type="html"><![CDATA[<h1 id="Leecode-题目整理"><a href="#Leecode-题目整理" class="headerlink" title="Leecode 题目整理"></a>Leecode 题目整理</h1><h3 id="三数之和"><a href="#三数之和" class="headerlink" title="三数之和"></a>三数之和</h3><p>排序+<strong>双指针</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs python">nums.sort()<br><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> range(n):<br>  <span class="hljs-keyword">if</span> i&gt;<span class="hljs-number">0</span> <span class="hljs-keyword">and</span> nums[i] == nums[i - <span class="hljs-number">1</span>]:<span class="hljs-keyword">continue</span><br>  l = i + <span class="hljs-number">1</span><br>  r = n - <span class="hljs-number">1</span><br>  <span class="hljs-keyword">while</span>(l &lt; r):<br>    <span class="hljs-keyword">if</span> nums[i] + nums[l] + nums[r] == <span class="hljs-number">0</span>:<br>      ans.append([nums[i], nums[l], nums[r]])<br>      <span class="hljs-keyword">while</span> l&lt;r <span class="hljs-keyword">and</span> nums[r]==nums[r<span class="hljs-number">-1</span>]:r=r<span class="hljs-number">-1</span><br>      <span class="hljs-keyword">while</span> l&lt;r <span class="hljs-keyword">and</span> nums[l]==nums[l+<span class="hljs-number">1</span>]:l=l+<span class="hljs-number">1</span><br>      r=r<span class="hljs-number">-1</span><br>      l=l+<span class="hljs-number">1</span><br>    <span class="hljs-keyword">elif</span> nums[i] + nums[l] + nums[r] &gt; <span class="hljs-number">0</span>:r = r - <span class="hljs-number">1</span><br>    <span class="hljs-keyword">else</span>: l = l + <span class="hljs-number">1</span><br></code></pre></td></tr></table></figure><h3 id="两数之和"><a href="#两数之和" class="headerlink" title="两数之和"></a>两数之和</h3><p><strong>carry</strong> 用得很妙, 模拟进位</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">addTwoNumbers</span><span class="hljs-params">(self, l1: ListNode, l2: ListNode)</span> -&gt; ListNode:</span><br>  ans=ListNode(<span class="hljs-number">0</span>)<br>  head=ans<br>  carry=<span class="hljs-number">0</span><br>  <span class="hljs-keyword">while</span> l1 <span class="hljs-keyword">or</span> l2:<br>  x=l1.val <span class="hljs-keyword">if</span> l1 <span class="hljs-keyword">else</span> <span class="hljs-number">0</span><br>  y=l2.val <span class="hljs-keyword">if</span> l2 <span class="hljs-keyword">else</span> <span class="hljs-number">0</span><br>  s=x+y+carry<br>  carry=s//<span class="hljs-number">10</span><br>  ans.next=ListNode(s%<span class="hljs-number">10</span>)<br>  ans=ans.next<br>  <span class="hljs-keyword">if</span> l1:<br>  l1=l1.next<br>  <span class="hljs-keyword">if</span> l2:<br>  l2=l2.next<br>  <span class="hljs-keyword">if</span> carry:<br>  ans.next=ListNode(carry)<br>  <span class="hljs-keyword">return</span> head.next<br></code></pre></td></tr></table></figure><h2 id="队列"><a href="#队列" class="headerlink" title="队列"></a>队列</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment">#简易版本</span><br>queue=[]<br>queue.append(data) <span class="hljs-comment">#入队</span><br>queue.pop(<span class="hljs-number">0</span>)<span class="hljs-comment">#出队</span><br><br><span class="hljs-comment">#双向队列</span><br><span class="hljs-keyword">import</span> collections<br>que=collectione.deque()<br>que.append() <br>que.appendleft()<br>que.insert(i,x)<span class="hljs-comment">#在第i个位置插入x</span><br>que.popleft()<br>que.pop()<br>que.remove(val)<span class="hljs-comment">#移除查找到的第一个val</span><br>que.count(x)<span class="hljs-comment">#计算que中元素等于x的个数</span><br>que.rotate(n)<span class="hljs-comment">#向右循环移动n步 </span><br>que.clear()<br></code></pre></td></tr></table></figure><h3 id="墙与门"><a href="#墙与门" class="headerlink" title="墙与门"></a>墙与门</h3><p>BFS</p><p>满足条件=&gt;处理=&gt;放入队列</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">used=[]<span class="hljs-comment">#走过的标记不再走</span><br>rooms[tmpk][tmpt] = rooms[i][j] + <span class="hljs-number">1</span> <span class="hljs-comment">#step是上一个的加1</span><br></code></pre></td></tr></table></figure><h3 id="岛屿数量"><a href="#岛屿数量" class="headerlink" title="岛屿数量"></a>岛屿数量</h3><p>BFS ：</p><p>写个bfs函数，注意每到一个点要mark。</p><p>对所有可遍历点bfs（同步更新可遍历点）, 每使用一次就找到了一个模块, cnt++。</p><p><strong>并查集（未）</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">bfs</span><span class="hljs-params">(i, j)</span>:</span><br> queue = deque()<br> queue.appendleft((i, j))<br> grid[i][j] = <span class="hljs-string">"0"</span><br> <span class="hljs-keyword">while</span> queue:<br>   i, j = queue.pop()<br>   <span class="hljs-keyword">for</span> x, y <span class="hljs-keyword">in</span> [[<span class="hljs-number">-1</span>, <span class="hljs-number">0</span>], [<span class="hljs-number">1</span>, <span class="hljs-number">0</span>], [<span class="hljs-number">0</span>, <span class="hljs-number">-1</span>], [<span class="hljs-number">0</span>, <span class="hljs-number">1</span>]]:<br>    tmp_i = i + x<br>    tmp_j = j + y<br>   <span class="hljs-keyword">if</span> <span class="hljs-number">0</span> &lt;= tmp_i &lt; row <span class="hljs-keyword">and</span> <span class="hljs-number">0</span> &lt;= tmp_j &lt; col <span class="hljs-keyword">and</span> grid[tmp_i][tmp_j] == <span class="hljs-string">"1"</span>:<br>   grid[tmp_i][tmp_j] = <span class="hljs-string">"0"</span><br>    queue.appendleft((tmp_i, tmp_j))<br><br> <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> range(row):<br>   <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> range(col):<br>     <span class="hljs-keyword">if</span> grid[i][j] == <span class="hljs-string">"1"</span>:<br>       bfs(i, j)<br>       cnt += <span class="hljs-number">1</span><br></code></pre></td></tr></table></figure><h3 id="打开转盘锁"><a href="#打开转盘锁" class="headerlink" title="打开转盘锁"></a>打开转盘锁</h3><p>yield 的使用</p><h2 id="栈"><a href="#栈" class="headerlink" title="栈"></a>栈</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python">stack=[]<br>stack.append()<br>stack.pop()<br>stack[<span class="hljs-number">-1</span>]<span class="hljs-comment">#取出栈顶元素</span><br></code></pre></td></tr></table></figure><h3 id="最小栈"><a href="#最小栈" class="headerlink" title="最小栈"></a>最小栈</h3><p>使用两个栈，一个作为<strong>辅助栈</strong>。</p>]]></content>
      
      
      <categories>
          
          <category> Computer Science </category>
          
          <category> Practice </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>Linear Algebra</title>
      <link href="/2020/02/28/Mathematics/Linear-Algebra/"/>
      <url>/2020/02/28/Mathematics/Linear-Algebra/</url>
      
        <content type="html"><![CDATA[<h1 id="线性代数学习笔记"><a href="#线性代数学习笔记" class="headerlink" title="线性代数学习笔记"></a>线性代数学习笔记</h1><p>不加入例题</p><p>主要是例题中用到的基本性质和定理的证明</p><p>推荐网站：<a href="https://ccjou.wordpress.com/" target="_blank" rel="noopener">线代启示录</a></p><h2 id="1-线性空间"><a href="#1-线性空间" class="headerlink" title="1. 线性空间"></a>1. 线性空间</h2><h3 id="基的可扩充性"><a href="#基的可扩充性" class="headerlink" title="基的可扩充性"></a>基的可扩充性</h3><p>$V^n$ 的任意一组线性无关的向量都可扩充为一组基。</p><p>证明：</p><p>​        对于一个有 $m$ 个向量的线性无关组，若 $m&lt;n$ ，则 $V$ 中肯定<strong>存在向量 $x$ 不能被他们表示</strong>。</p><p>​        可以证明 $x$ 与他们线性无关，把 $x$ 添进去，构成新的线性无关组。</p><p>​        这样一直添，最后可以扩充为一组基。</p><h3 id="维数公式"><a href="#维数公式" class="headerlink" title="维数公式"></a>维数公式</h3><script type="math/tex; mode=display">dim\ W_1+dim\ W_2=dim(W_1+W_2)+dim(W_1\cap W_2)\notag</script><p>证明：</p><p>​        取 $W_1\cap W_2$ 的一组基，分别扩充为 $W_1$ 和 $W_2$ 的基，</p><p>​        则它们组合起来组成的向量组可以张成 $W_1+W_2$ 。</p><p>​        接下来只需证明它们线性无关。</p><script type="math/tex; mode=display">\begin{aligned}W_1\cap W_2&=\mathcal{L}(\alpha_1,\cdots,\alpha_r)\\W_1&=\mathcal{L}(\alpha_1,\cdots,\alpha_r,\beta_1,\cdots,\beta_s)\\W_2&=\mathcal{L}(\alpha_1,\cdots,\alpha_r,\gamma_1,\cdots,\gamma_t)\\\implies W_1+W_2&=\mathcal{L}(\alpha_1,\cdots,\alpha_r,\beta_1,\cdots,\beta_s,\gamma_1,\cdots,\gamma_t)\end{aligned}</script><p>​        按线性无关定义写出式子，把 $\gamma$ 项移到等式右边，</p><p>​        利用 $W_1\cap W_2$ 可以把两边都表示成 $\alpha$ 项的线性组合，</p><p>​        依次利用移项后是 $W_2$ 和 $ W_1 $ 的基，最后得到全是 $0$。</p><h3 id="直和"><a href="#直和" class="headerlink" title="直和"></a>直和</h3><p>设 $U_1,\cdots,U_m$ 都是 $V$ 的子空间，则:</p><ul><li>（定义）$U_1+\cdots+U_m$ 是直和，如果 $U_1+\cdots+U_m$ 中的每个元素都可以唯一的表示成 $u_1+\cdots+u_m$ ，其中每个 $u_j\in U_j$。</li><li><p>$\iff$ $0$ 唯一分解成 $0+\cdots+0$</p></li><li><p>对于两个子空间的直和，$U+W=U\oplus W\iff U\cap W={0}$</p></li></ul><h5 id="常用结论："><a href="#常用结论：" class="headerlink" title="常用结论："></a>常用结论：</h5><ul><li>$\dim V&lt;\infty$ ，若 $T\in \mathcal{L}[V]$ 是幂等变换，则 $V=N(T)\oplus R(T)$ .</li><li>$T\in\mathcal{L}[V],\dim V=n\implies V=R(T^n)\oplus N(T^n)$</li></ul><h2 id="2-线性映射"><a href="#2-线性映射" class="headerlink" title="2. 线性映射"></a>2. 线性映射</h2><h3 id="线性映射的维数定理"><a href="#线性映射的维数定理" class="headerlink" title="线性映射的维数定理"></a>线性映射的维数定理</h3><p>$T:V\to W’$,  $dim\ N(T)+dim\ R(T)=dim\ V$</p><p>即：$dim\ Ker(T)+dim\ Im(T)=dim\ V$</p><p>证明1：</p><p>​        去证 <strong>$\overline T:\overline V\to W$, $\overline v\mapsto T(v)$ 是线性映射且为双射</strong>, $\overline T$ 是由 $T$ 诱导出来的线性映射。</p><p>​        其中 $W=Im(T)$, $\overline V=V/ker(T)$。 从而 $V/ker(T)\cong Im(T)$。</p><ol><li><p>$\overline T$ 的<strong>定义是合理的</strong>：$\overline T(\overline v)=T(v), \forall k\in Ker(T),\overline v=v+k$</p><p>这需要证明对 $\overline v=v+k_1$ 和  $\overline {v+k_2}=\overline v=v+k_2$, $\overline T(\overline {v+k_1})=\overline T(\overline {v+k_2})=T(v)$. </p><p>即 $\overline T(\overline v)=T(v)$ 的成立不依赖于 $v’\in \overline v=v+Ker(T) $ 的选取</p><p>这是由于 $\forall k\in Ker(T),\overline T(\overline {v+k})=T(v+k)=T(v)+T(k)=T(v)$</p></li><li><p>$\overline T$ <strong>是线性映射</strong>：</p><ul><li><p>加法：</p><p>$\overline T(\overline {v_1+v_2})=T(v_1+v_2)=T(v_1)+T(v_2)=\overline T(\overline v_1)+\overline T(\overline v_2)$</p></li><li><p>数乘：</p><p>$\overline T(\lambda \overline {v})=\overline T(\overline {\lambda v})=T(\lambda v)=\lambda T(v)=\lambda\overline T(\overline v)$</p></li></ul></li></ol><ol><li><p>$\overline T$ <strong>是双射</strong>：</p><ul><li><p>单射：</p><p>$\overline T(\overline v)=0=&gt;T(v)=0=&gt;v\in Ker(T)=&gt;\overline v=0\ =&gt;Ker(\overline T)=0$</p></li><li><p>满射：</p><p>$\forall w\in W=Im(T),\exist v\in V,s.t.\quad T(v)=w\ =&gt;\exist\overline v, \overline T(\overline v)=T(v)=w$</p></li></ul></li></ol><p>证明2:</p><p>​        取 $ N(T)$ 的一组基 $(v<em>1,\cdots,v_s)$ ，将其扩充为 $V$ 的一组基 $(v_1,\cdots,v_s,v</em>{s+1},\cdots,v_n)$</p><p>​        则 $R(T)=\mathcal{L}\big[T(v<em>1),\cdots,T(v_n)\big]=\mathcal{L}\big[T(v</em>{s+1}),\cdots,T(v_n)\big]$</p><p>​        因此 $T(v<em>{s+1}),\cdots,T(v</em>{n})$ 可张成 $R(T)$ ，只需证明它们线性无关。</p><p>​        如果 $a<em>1 T(v</em>{s+1})+\cdots +a<em>{n-s}T(v</em>{n})=0$</p><p>​        则 $T(a<em>1v</em>{s+1}+\cdots+a_{n-s}v_n)=0$</p><p>​        $=&gt; a<em>1v</em>{s+1}+\cdots+a_{n-s}v_n\in N(T)$</p><p>​        故 $\exist v<em>1,\cdots,v_s, \quad a_1v</em>{s+1}+\cdots+a_{n-s}v_n=b_1v_1+\cdots b_sv_s$</p><p>​        全部移到左边，由于 $v_1,\cdots,v_n$ 是 $V$ 的基，全部系数为 $0$.</p><h3 id="线性映射的一些定理"><a href="#线性映射的一些定理" class="headerlink" title="线性映射的一些定理"></a>线性映射的一些定理</h3><ul><li><p>到更大维数向量空间的线性映射不是满的 </p><p>一定有东西会表示不出来</p></li><li><p>到更小维数向量空间的线性映射不是单的</p></li></ul><h3 id="线性映射的矩阵表示"><a href="#线性映射的矩阵表示" class="headerlink" title="线性映射的矩阵表示"></a>线性映射的矩阵表示</h3><p>(搞晕了很久 现在终于弄明白了)</p><h4 id="（1）对基"><a href="#（1）对基" class="headerlink" title="（1）对基"></a>（1）对基</h4><script type="math/tex; mode=display">T(e_1,\cdots,e_n)=(f_1,\cdots,f_m)M(T)\\Te_k=M(T)第k列\notag</script><p>​    其中，$e$ 是原空间的基， $f$ 是像空间的基。</p><h4 id="（2）对向量"><a href="#（2）对向量" class="headerlink" title="（2）对向量"></a>（2）对向量</h4><p>​    设 $X=(x_1,\cdots,x_n)^T$ 为向量 $\xi$ 在基 $e=(e_1,\cdots,e_n)$ 下的坐标。 </p><script type="math/tex; mode=display">\xi=(e_1,\cdots,e_n)X\notag</script><p>​    $T$ 作用后的向量为：</p><script type="math/tex; mode=display">\begin{aligned}T(\xi)&=T(e_1,\cdots,e_n)X\\&=(f_1,\cdots,f_m)M(T)X\end{aligned}</script><p>​    $T$ 作用后得到的向量的坐标是 $M(T)X$.  </p><p>(美妙的证明)</p><h4 id="（3）线性映射在不同基下表示表示矩阵的关系"><a href="#（3）线性映射在不同基下表示表示矩阵的关系" class="headerlink" title="（3）线性映射在不同基下表示表示矩阵的关系"></a>（3）线性映射在不同基下表示表示矩阵的关系</h4><p>相似。</p><script type="math/tex; mode=display">\begin{aligned}T[(e_1,\cdots,e_n)]&=T[(f_1,\cdots,f_m)A]\\&=T[(f_1,\cdots,f_m)]A\\&=(f_1,\cdots,f_m)M_fA\\&=(e_1,\cdots,e_n)A^{-1}M_fA\end{aligned}</script><p>所以，$M_e=A^{-1}M_fA$, $A$ 为基的过渡矩阵，$M_e,M_f$ 为线性映射在不同基下的矩阵表示。</p><h4 id="（4）同一个向量在不同基下的坐标关系"><a href="#（4）同一个向量在不同基下的坐标关系" class="headerlink" title="（4）同一个向量在不同基下的坐标关系"></a>（4）同一个向量在不同基下的坐标关系</h4><p>$T:V\to W$</p><p>$\xi=(v_1,\cdots,v_n)A=(w_1,\cdots,w_m)B$</p><p>其中 $A=(a_1,\cdots,a_n)^T$, $B=(b_1,\cdots,b_m)^T$ (注意有转置，<strong>基是行向量，坐标是列向量</strong>)</p><p>是 $\xi$ 在不同基下的坐标</p><p>则 ：</p><script type="math/tex; mode=display">B=M(T)^{-1}A\notag</script><h4 id="（5）总结"><a href="#（5）总结" class="headerlink" title="（5）总结"></a>（5）总结</h4><p>由此可见，线性映射对应的矩阵：</p><ul><li>对基的变换是右乘作用，对基的 $k$ 分量变换后的结果为矩阵的第 $k$ 列</li><li>对向量的坐标的变换为左乘</li><li>在不同基下的表示矩阵相似</li></ul><h3 id="线性方程组"><a href="#线性方程组" class="headerlink" title="线性方程组"></a>线性方程组</h3><p>设矩阵 $A\in M_{m\times n}(\mathbf{F})$, 若 $r(A)=r$, 则齐次线性方程组 $AX=0$ 的解空间 $N(A)$ 是一个 $n-r$ 维子空间。</p><p>证明：</p><p>​    $A$ 与一个线性映射 $\sigma\in L(V_1,V_2)$ 对应, $\dim V_1=n, \dim V_2=m$ .</p><p>​    $AX=0$  解空间中的基是 $\sigma$ 核空间的基关于 $V_1$ 的坐标, 解空间的基和 $N(\sigma)$ 的基一一对应 .</p><p>简单证明：</p><p>​    把 $A$ 看作线性变换， $rank(A)=Range(A)$ , $A$ 的核 $N(A)$ 就是方程组的解空间。</p><p><strong>注</strong>：矩阵的秩：矩阵列向量中极大线性无关组的元素个数，等于矩阵作为线性变换对应矩阵的像空间维数。</p><h3 id="幂等变换的性质"><a href="#幂等变换的性质" class="headerlink" title="幂等变换的性质"></a>幂等变换的性质</h3><p>幂等变换: $T:V\to W,\quad T^2=T$  </p><ul><li><p>$N(T)={v-T(v)\mid v\in V }$</p></li><li><p>$N(T)\cap R(T)=0$</p></li><li>$V=N(T)\oplus R(T)$</li></ul><p>证明：</p><p>​        对第二条，只需证明核空间与像空间的交是 $0$</p><p>​        如果 $w\in N(T)\cap R(T)$, 则：</p><p>​                由于 $w\in N(T)$, $T(w)=0$</p><p>​                由于 $w\in R(T)$, $\exist v\in V,w=T(v)$, <strong>两边再作用一下 $T$</strong>, 得到：$0=T(w)=T^2(v)=T(v)=w$ </p><p>​        </p><p>​        对第一条，</p><p>​        这是由于 $\forall v\in V,T^2(v)=T(v)=&gt;T[T(v)-v]=0=&gt;T(v)-v\in N(T)=&gt;{v-T(v)}\subseteq N(T)\ \forall v\in N(T),v=v-T(v)=&gt;{v-T(v)}\supseteq N(T) $</p><h3 id="算子"><a href="#算子" class="headerlink" title="算子"></a>算子</h3><p>算子：向量空间到自身的线性映射</p><p>对有限为空间的算子 $T$：$T$ 可逆$\iff$ $T$ 单 $\iff T$ 满</p><h3 id="对偶"><a href="#对偶" class="headerlink" title="对偶"></a>对偶</h3><h2 id="3-内积空间"><a href="#3-内积空间" class="headerlink" title="3. 内积空间"></a>3. 内积空间</h2><p>带有内积的向量空间。</p><p>内积：对第一个分量成线性，对第二个分量成共轭线性，有共轭对称性。</p><h3 id="线性映射的内积表示"><a href="#线性映射的内积表示" class="headerlink" title="线性映射的内积表示"></a>线性映射的内积表示</h3><script type="math/tex; mode=display">\begin{align}T((v_1,\dots,v_n)&=(v_1,\dots,v_n)A\notag \\T(v_i)&=\sum_{j=1}^n v_j a_{ji}\notag \\\therefore \quad a_{ij}&=\langle Tv_j,v_i\rangle\end{align}</script><h3 id="柯西-施瓦茨不等式"><a href="#柯西-施瓦茨不等式" class="headerlink" title="柯西-施瓦茨不等式"></a>柯西-施瓦茨不等式</h3><script type="math/tex; mode=display">|\langle u,v \rangle|\leq\|u\|\|v\|</script><p>证明：</p><p>将 $u$ 正交分解:</p><script type="math/tex; mode=display">u=\frac{\langle u,v\rangle}{\|v^2\|}v + w</script><p>则 </p><script type="math/tex; mode=display">\begin{aligned}\|u\|^2&=\bigg\|\frac{\langle u,v\rangle}{\|v^2\|}v\bigg\|^2+\|w\|^2\\&\geq \bigg\|\frac{\langle u,v\rangle}{\|v^2\|}v\bigg\|^2=\frac{|\langle u,v\rangle|^2}{\|v\|^2}\end{aligned}</script><p>乘过去即得。</p><h3 id="Shcmidt-正交化"><a href="#Shcmidt-正交化" class="headerlink" title="Shcmidt 正交化"></a>Shcmidt 正交化</h3><p>设 $v_1,\dots,v_m$ 是 $V$ 中的线性无关向量组，设 $e_1=v_1/|v_1|$.</p><script type="math/tex; mode=display">e_j=\frac{v_j-\langle v_j,e_1\rangle e_1-\cdots-\langle v_j,e_{j-1}\rangle e_{j-1}}{\|v_j-\langle v_j,e_1\rangle e_1-\cdots-\langle v_j,e_{j-1}\rangle e_{j-1}\|}</script><p>${e_1,\dots,e_m}$ 是 $V$ 中的规范正交组。</p><h3 id="舒尔定理"><a href="#舒尔定理" class="headerlink" title="舒尔定理"></a>舒尔定理</h3><p>设 $V$ 是有限维的复向量空间且 $T\in \mathcal{L}(V,\mathbf{F})$ ，则 $T$ 关于 $V$ 的某个规范正交基具有上三角矩阵。</p><p>证明：</p><p>​        设 $V=span{v_1,\dots,v_n}$ , ${e_1,\dots,e_n}$ 为其规范正交基。</p><p>​        则 $span{e_1,\dots,e_n}=span{v_1,\dots,v_n}$</p><p>​        由于存在 $T$ ,其关于 ${v_1,\dots,v_n}$ 具有上三角矩阵，则对于每个 $j=1,\dots,n$     </p><p>​        $ span{v_1,\dots,v_j}$在 $T$ 作用下不变</p><p>​        故 $span{e_1,\dots,e_j}=span{v_1,\dots,v_j}$ 在 $T$ 作用下不变</p><p>​        所以 $T$ 关于 ${e_1,\dots,e_n}$ 具有上三角矩阵。</p><h5 id="关于上三角矩阵"><a href="#关于上三角矩阵" class="headerlink" title="关于上三角矩阵"></a>关于上三角矩阵</h5><p>设 $T\in\mathcal{L}[V]$，$(v_1,\dots,v_n)$ 是 $V$ 的基。</p><p>TFAE：</p><ul><li>$T$ 关于 $v_1,\dots,v_n$ 的矩阵是上三角的</li><li>$Tv_j\in span{v_1,\dots,v_j}$</li><li>$span{v_1,\dots,v_j}$ 在 $T$ 作用下不变</li></ul><h3 id="对偶空间"><a href="#对偶空间" class="headerlink" title="对偶空间"></a>对偶空间</h3><h4 id="符号说明"><a href="#符号说明" class="headerlink" title="符号说明"></a>符号说明</h4><ul><li>$\mathcal{L}(V,W)$ 表示从 $V$ 到 $W$ 的全部线性映射</li><li>$\mathbf{F}^{m,n}\triangleq \mathbf{F}^m\times\mathbf{F}^n$ 可看作所有 $m\times n$ 矩阵</li><li>线性泛函：从 $V$ 到 $\mathbf{F}$ 的线性映射，即为 $\mathcal{L}(V,\mathbf{F})$ 中的元素</li><li><p>对偶空间 $V’$：$V$ 上所有线性泛函构成的向量空间</p></li><li><p>对偶基 ${\varphi<em>1,\dots,\varphi_n}$： $\varphi_j(e_k)=\delta</em>{jk}$</p></li><li>对偶映射 $T’$：$T’(\varphi)=\varphi\circ T ,\quad T’\in\mathcal{L}(V’,W’), \varphi\in W’,T’\in V’$</li><li>零化子 $U^0$：$U^0={\varphi\in V’:\varphi(u)=0,\forall u\in U},U\subset V$</li></ul><h4 id="重要结论"><a href="#重要结论" class="headerlink" title="重要结论"></a>重要结论</h4><ul><li><p>$\mathcal{M}(T)$ 为 $T\in\mathcal{L}(V,W)$ 的矩阵表示 , 其实是一个从 $\mathcal{L}(V,W)\to\mathbf{F}^{m,n}$ 的同构。</p></li><li><p>对偶映射的代数性质：$(aS+bT)’=aS’+bT’$, $(ST)’=T’S’$</p></li><li>$T’$ 的矩阵是 $T$ 的矩阵的转置</li><li>$\dim V’=\dim V$</li><li>$\dim U+\dim U^0=\dim V$</li><li>$T 满\iff T’单, N(T’)=R(T)^0$</li><li><p>$ T单\iff T’满,R(T’)=N(T)^0$</p></li><li><p>$\dim R(T)=\dim R(T’)$</p></li></ul><h3 id="里斯表示定理"><a href="#里斯表示定理" class="headerlink" title="里斯表示定理"></a>里斯表示定理</h3><p>设 $V$ 是有限维的且 $\varphi$ 是 $V$ 上的线性泛函，则存在唯一的向量 $u\in V$ 使得对每个 $v\in V$ 均有 $\varphi(v)=\langle v,u\rangle$. </p><h2 id="4-多项式"><a href="#4-多项式" class="headerlink" title="4. 多项式"></a>4. 多项式</h2><h3 id="带余除法"><a href="#带余除法" class="headerlink" title="带余除法"></a>带余除法</h3><p>设 $p,s\in \mathcal{P}(\mathbb{F})$ 且 $s\neq 0$, 则存在唯一多项式 $q,r\in\mathcal{P}(\mathbb{F})$ 使得</p><script type="math/tex; mode=display">p=sq+r\notag</script><p>且 $\deg\ r&lt;\deg\ s$ .</p><p>证明： </p><p>​        记 $n=\deg p,m =\deg s$ </p><p>​        $n&gt;m$ 时：</p><script type="math/tex; mode=display">\begin{aligned}&\because T:\mathcal{P_{n-m}}\times\mathcal{P_{m-1}}\to\mathcal{P_{n}},\quad (q,r)\mapsto sq+r \quad 是线性双射\\&\therefore\{(q,r)\mid q\in \mathcal{P_{n-m}},r\in\mathcal{P_{m-1}}\}\cong\{sq+r\mid q\in \mathcal{P_{n-m}},r\in\mathcal{P_{m-1}}\}\\&\because \dim \mathcal{P_{n-m}}\times\mathcal{P_{m-1}}=(n-m+1)+(m-1+1)=n+1\\&\therefore \dim R(T)=n+1=\dim \mathcal{P_n}\\&\therefore \{sq+r\mid q\in \mathcal{P_{n-m}},r\in\mathcal{P_{m-1}}\}\cong \mathcal{P_n(\mathbb{F})}\end{aligned}</script><h3 id="代数基本定理"><a href="#代数基本定理" class="headerlink" title="代数基本定理"></a>代数基本定理</h3><p>任何一个次数大于 $0$ 的复多项式都至少有一个复数根。</p><p>证明：</p><p>​        若 $p\in \mathbf{C}[x]$  没有根，则 $\displaystyle\frac 1 p$ 为全平面有界的解析函数。由刘维尔定理知其必为常数。</p><h3 id="拉格朗日多项式"><a href="#拉格朗日多项式" class="headerlink" title="拉格朗日多项式"></a>拉格朗日多项式</h3><script type="math/tex; mode=display">f_i (x)=\prod_{\substack{s=1\\s\neq i}}^n \frac{x-c_s}{c_i-c_s}</script><p>${f<em>0,f_1,\dots,f_n}$ 构成了 $\mathbf{F}[x]</em>{\leq n} $ 的一组代入意义下的单位正交基（ $f<em>i(c_j)=\delta</em>{ij}$）</p><p>拉格朗日插值公式： $g(x)=\sum b_i f_i $ 满足： $g(c_i)=b_i$ .</p><h2 id="5-矩阵"><a href="#5-矩阵" class="headerlink" title="5. 矩阵"></a>5. 矩阵</h2><h3 id="秩"><a href="#秩" class="headerlink" title="秩"></a>秩</h3><ul><li>定义与意义</li></ul><p>矩阵的列向量的极大线性无关组的元素个数。</p><p>$A:m\times n\iff \sigma:\mathbb{R}^n\to\mathbb{R}^m$</p><p>由于：</p><script type="math/tex; mode=display">R(A)=\left(\begin{matrix}a_{11}x_1+a_{12}x_2+\cdots+a_{1n}x_n\\a_{21}x_1+a_{22}x_2+\cdots+a_{2n}x_n\\\vdots\\a_{m1}x_1+a_{m2}x_2+\cdots+a_{mn}x_n\end{matrix}\right)=\mathscr{L}\left\{ \left(\begin{aligned}a_{11}\\a_{21}\\ \vdots \\ a_{m1}\end{aligned}\right),\left(\begin{aligned}a_{12}\\a_{22}\\ \vdots \\ a_{m2}\end{aligned}\right),\cdots,\left(\begin{aligned}a_{1n}\\a_{2n}\\ \vdots \\ a_{mn}\end{aligned}\right)\right\}</script><p>$A$ 的列秩等于 $A$ 的列空间维数，也是对应线性映射的像空间维数 $\dim R(A)$。</p><ul><li>行秩 $=$ 列秩</li></ul><h3 id="行列式"><a href="#行列式" class="headerlink" title="行列式"></a>行列式</h3><ul><li>$\det (A)=\det(A^T)$     证：初等矩阵转置行列式不变，将矩阵 $A$ 进行初等矩阵分解</li></ul><h2 id="6-特征值理论"><a href="#6-特征值理论" class="headerlink" title="6. 特征值理论"></a>6. 特征值理论</h2><h3 id="特征向量线性无关"><a href="#特征向量线性无关" class="headerlink" title="特征向量线性无关"></a>特征向量线性无关</h3><p>相应于不同特征值的特征向量线性无关。</p><p>证明：</p><p>​        设 $T\in \mathcal{L}(V)$ ，设 $\lambda_1,\dots,\lambda_m$ 是 $T$ 对互不相同的特征值， $v_1,\dots,v_m$ 是相应的特征向量，则 $v_1,\dots,v_m$ 是线性无关的。</p><p>​        设 $k$ 是使得 $v<em>k=span{v_1,\dots,v</em>{k-1}}$ 成立的<strong>最小</strong>正整数。</p><script type="math/tex; mode=display">\begin{aligned}v_k&=a_1v_1+\cdots+a_{k-1}v_{k-1}\\T(v_k)=\lambda_k v_k&=a_1\lambda_1v_1+\cdots+a_{k-1}\lambda_{k-1}v_{k-1}\\\lambda_k v_k&=a_1\lambda_k v_1+\cdots+a_{k-1}\lambda_{k}v_{k-1}\\\\\implies &a_1(\lambda_1-\lambda_k)v_1+\cdots+a_{k-1}(\lambda_{k-1}-\lambda_{k})v_{k-1}=0\\\implies &a_1=\cdots=a_{k-1}=0\end{aligned}</script><p>​        矛盾，故不存在这样的 $k$ ， 特征向量线性无关。</p><h3 id="特征子空间"><a href="#特征子空间" class="headerlink" title="特征子空间"></a>特征子空间</h3><p>特征子空间是不变子空间。</p><p>特征子空间的和是直和。</p><p>$i.e.$ </p><script type="math/tex; mode=display">W=E_{\lambda_1}+\cdots + E_{\lambda_m}=E_{\lambda_1}\oplus \cdots \oplus E_{\lambda_m}\notag</script><p>证明：</p><p>设$\lambda<em>j$ 和 $E</em>{\lambda_j}$ 是 $n$ 维线性空间 $V$ 的线性变换 $T$ 的 $m$ 个互不相同的特征值及相应的特征子空间，则只需证明<strong>零向量</strong>在 $W$ 中的<strong>分解唯一</strong>。</p><p>即证： $\xi<em>1+\cdots \xi_m=0\implies \xi_i=0,\quad \xi_i\in E</em>{\lambda_i}$ </p><p>注意 $\xi<em>i$ 是特征子空间 $E</em>{\lambda_i}$ 中的向量，由属于 $\lambda_i$ 的特征向量线性组合而成，仍有 $T(\xi_i)=\lambda_i\xi_i$</p><p><strong>归纳</strong>证明：</p><script type="math/tex; mode=display">\begin{aligned}m=2: \quad \xi_1+\xi_2=0 &\implies T(\xi_1+\xi_2)=\lambda_1\xi_1+\lambda_2\xi_2=0\\&\implies (\lambda_1-\lambda_2)\xi_2=0\\&\implies \xi_1=\xi_2=0\\\end{aligned}</script><p>设对 $m-1$ 结论成立，考虑 $m$ :</p><script type="math/tex; mode=display">\begin{aligned}& \xi_1+\cdots+\xi_m=0\\&T(\xi_1+\cdots+\xi_m)=\lambda_1\xi_1+\cdots+\lambda_m\xi_m=0\\&(\lambda_1-\lambda_m)\xi_1+\cdots+(\lambda_{m-1}-\lambda_m)\xi_{m-1}=0\\\implies& \xi_1=\cdots=\xi_{m-1}=0\implies \xi_m=0\end{aligned}</script><p>由此也可以得到属于不同特征值的特征向量线性无关，因为 $E<em>{\lambda_i}\cap E</em>{\lambda_j}={\vec 0}$</p><h3 id="可对角化的条件"><a href="#可对角化的条件" class="headerlink" title="可对角化的条件"></a>可对角化的条件</h3><p>$n$ 维线性空间 $V$ 上的线性变换 $T$ 的表示矩阵 $M(T)$ 可对角化：</p><p>$ \iff$  $T$ 有 $n$ 个(线性无关的)特征向量  or  $V$ 有由 $T$ 的特征向量构成的基</p><p>$\iff$ $V=E<em>{\lambda_1}\oplus \cdots \oplus E</em>{\lambda_m} $  (已经知道和是直和，接下来只需证明和就是 $V$ ,由有由特征向量构成的基即得)</p><p>$\iff$ $T$ 的每个特征值的重数等于其特征子空间的维数 ( 代数重数 $=$ 几何重数 ）, 且不同特征值的重数之和等                   于 $n$ </p><p>注：一般情况下，代数重数大于等于几何重数，证明先放一放。</p><h3 id="矩阵的秩、维数与特征值"><a href="#矩阵的秩、维数与特征值" class="headerlink" title="矩阵的秩、维数与特征值"></a>矩阵的秩、维数与特征值</h3><p>特征值个数等于矩阵的维数。其中，不等于 $0$ 且<strong>不同</strong>的特征值个数为矩阵的秩。</p><p>也就是说，矩阵的秩是特征子空间的种类数，如何理解和证明？</p><h3 id="广义特征向量"><a href="#广义特征向量" class="headerlink" title="广义特征向量"></a>广义特征向量</h3><h4 id="零空间的停止增长"><a href="#零空间的停止增长" class="headerlink" title="零空间的停止增长"></a>零空间的停止增长</h4><h4 id="广义特征向量线性无关性"><a href="#广义特征向量线性无关性" class="headerlink" title="广义特征向量线性无关性"></a>广义特征向量线性无关性</h4><h4 id="广义特征空间"><a href="#广义特征空间" class="headerlink" title="广义特征空间"></a>广义特征空间</h4><h5 id="刻画"><a href="#刻画" class="headerlink" title="刻画"></a>刻画</h5><h2 id="7-算子理论"><a href="#7-算子理论" class="headerlink" title="7. 算子理论"></a>7. 算子理论</h2><h3 id="不变子空间"><a href="#不变子空间" class="headerlink" title="不变子空间"></a>不变子空间</h3><p>待整理</p><h3 id="正交投影"><a href="#正交投影" class="headerlink" title="正交投影"></a>正交投影</h3><p>待整理</p><h3 id="自伴算子"><a href="#自伴算子" class="headerlink" title="自伴算子"></a>自伴算子</h3><p>$T=T^*$.</p><p>类比：$z$ 是实数</p><h4 id="性质"><a href="#性质" class="headerlink" title="性质"></a>性质</h4><ul><li><p>$\langle Tv,w\rangle=\langle v,Tw\rangle$</p></li><li><p>特征值都是实数 </p><p>证：$\lambda|v|^2=\langle \lambda v,v\rangle=\langle Tv,v\rangle=\langle v,Tv\rangle=\langle v,\lambda v\rangle=\overline\lambda |v|^2$</p></li><li><p>在 $\mathbf{C}$, 只有零算子才能使 $Tv$ 总正交于 $v$ : $\forall v\in V ,\langle Tv,v\rangle=0\implies T\equiv 0$</p><p>证：</p><script type="math/tex; mode=display">\begin{aligned}\forall u,w\in V\\\langle Tu,w \rangle=&\frac{\left\langle T(u+w),u+w\right\rangle-\left\langle T(u-w),u-w\right\rangle}{4}\\&+\frac{\left\langle T(u+iw),u+iw\right\rangle-\left\langle T(u-iw),u-iw\right\rangle}{4}\end{aligned}</script></li><li><p>在 $\mathbf{C}$, $\forall v\in V,\langle Tv,v\rangle\in \mathbf{R} $  (充要) </p><p>证： $\langle Tv,v\rangle-\overline{\langle Tv,v\rangle}=0$</p></li><li><p>相应于不同特征值的特征向量正交</p></li></ul><h3 id="正规算子"><a href="#正规算子" class="headerlink" title="正规算子"></a>正规算子</h3><p>和伴随可交换：$TT^<em>=T^</em>T$</p><p>类比：复数 $z$ : 显然 $zz^<em>=z^</em>z$</p><h4 id="性质-1"><a href="#性质-1" class="headerlink" title="性质"></a>性质</h4><ul><li><p>$|Tv|=|T^* v|$  (充要)</p><p>证： $TT^<em>-T^</em>T=0\iff \forall v\in V, \langle (TT^<em>-T^</em>T)v,v\rangle=0\iff |T^*v|^2=|Tv|^2$</p></li><li><p>$T$ 和 $T^*$ 有相同的特征向量 （是充分的吗？）</p><p>具体：$v$ 是 $T$ 的相应于特征值 $\lambda$ 的特征向量，则 $v$ 也是 $T^*$ 的相应于 $\overline\lambda$ 的特征向量</p><p>证：$0=|(T-\lambda I)v|=|(T-\lambda I)^<em>v|=|(T^</em>-\overline\lambda I)v|$</p></li><li><p>相应于不同特征值的特征向量正交</p><p>证：$(\lambda-\mu)\langle v,w\rangle=\langle \lambda v,w\rangle-\langle v,\overline\mu w\rangle=\langle Tv,w\rangle-\langle v,T^*w\rangle=0$</p><p>注：$\lambda$ 是 $T$ 的特征值当且仅当 $\overline\lambda$ 是 $T^<em>$ 的特征值。 （ $\det (T-\lambda I)=0\iff \det (T^</em>-\overline \lambda I)=0$ ）</p></li></ul><h3 id="幂零算子"><a href="#幂零算子" class="headerlink" title="幂零算子"></a>幂零算子</h3><h3 id="谱分解"><a href="#谱分解" class="headerlink" title="谱分解"></a>谱分解</h3><h4 id="复谱定理"><a href="#复谱定理" class="headerlink" title="复谱定理"></a>复谱定理</h4><h4 id="实谱定理"><a href="#实谱定理" class="headerlink" title="实谱定理"></a>实谱定理</h4><h4 id="谱分解定理"><a href="#谱分解定理" class="headerlink" title="谱分解定理"></a>谱分解定理</h4><h3 id="奇异值分解"><a href="#奇异值分解" class="headerlink" title="奇异值分解"></a>奇异值分解</h3><h4 id="正算子"><a href="#正算子" class="headerlink" title="正算子"></a>正算子</h4><h5 id="刻画-1"><a href="#刻画-1" class="headerlink" title="刻画"></a>刻画</h5><h4 id="等距同构"><a href="#等距同构" class="headerlink" title="等距同构"></a>等距同构</h4><h5 id="刻画-2"><a href="#刻画-2" class="headerlink" title="刻画"></a>刻画</h5><h4 id="极分解"><a href="#极分解" class="headerlink" title="极分解"></a>极分解</h4><h4 id="奇异值分解-1"><a href="#奇异值分解-1" class="headerlink" title="奇异值分解"></a>奇异值分解</h4><h5 id="奇异值"><a href="#奇异值" class="headerlink" title="奇异值"></a>奇异值</h5><h5 id="线性变换奇异值定理"><a href="#线性变换奇异值定理" class="headerlink" title="线性变换奇异值定理"></a>线性变换奇异值定理</h5><h5 id="矩阵的奇异值分解"><a href="#矩阵的奇异值分解" class="headerlink" title="矩阵的奇异值分解"></a>矩阵的奇异值分解</h5>]]></content>
      
      
      <categories>
          
          <category> Mathematics </category>
          
          <category> Algebra </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>L2-Net</title>
      <link href="/2020/02/23/Computer-Sciencs/Deep%20learning/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-L2-Net/"/>
      <url>/2020/02/23/Computer-Sciencs/Deep%20learning/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-L2-Net/</url>
      
        <content type="html"><![CDATA[<p>论文链接：<a href="http://www.nlpr.ia.ac.cn/fanbin/pub/L2-Net_CVPR17.pdf" target="_blank" rel="noopener">http://www.nlpr.ia.ac.cn/fanbin/pub/L2-Net_CVPR17.pdf</a></p><p>代码链接：<a href="https://github.com/yuruntian/L2-Net" target="_blank" rel="noopener">https://github.com/yuruntian/L2-Net</a></p><p>研读次数：1</p><h2 id="提出的好方法"><a href="#提出的好方法" class="headerlink" title="提出的好方法"></a>提出的好方法</h2><ul><li><p>a progressive sampling strategy 渐进采样策略，可使网络在有限次数内获得大量样本</p></li><li><p>Discriminative Intermediate Feature map (DIF)  在中间的特征层施加了额外的监督</p></li><li><p>Loss function that takes three important error aspects into account:</p><ul><li>descriptor similarity 未完全理解</li><li>descriptor compactness :  ‘An interesting finding is that the degree of overfitting is directly related to the degree of correlation among descriptor dimensions’ </li><li>intermediate feature maps 未完全理解</li></ul></li></ul><h3 id="须了解的相关知识"><a href="#须了解的相关知识" class="headerlink" title="须了解的相关知识"></a>须了解的相关知识</h3><ul><li>SIFT descriptor</li><li>NNS (nearest neighbor search)</li><li>MatchNet (a typical Siamese network)</li></ul><h3 id="应用"><a href="#应用" class="headerlink" title="应用"></a>应用</h3><ul><li>实现 <em>特征匹配</em> 的神经网络的训练</li></ul>]]></content>
      
      
      <categories>
          
          <category> Computer Science </category>
          
          <category> Deep Learning </category>
          
          <category> Paper Notes </category>
          
      </categories>
      
      
        <tags>
            
            <tag> notes </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>SOS-Net</title>
      <link href="/2020/02/23/Computer-Sciencs/Deep%20learning/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-SOS-Net/"/>
      <url>/2020/02/23/Computer-Sciencs/Deep%20learning/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-SOS-Net/</url>
      
        <content type="html"><![CDATA[<p>代码链接：<a href="https://github.com/scape-research/SOSNet" target="_blank" rel="noopener">https://github.com/scape-research/SOSNet</a></p><p>研读次数：1</p><p>对 L2-Net 和超越L2的 Hard-Net 的超越。</p><h2 id="待学的东西"><a href="#待学的东西" class="headerlink" title="待学的东西"></a>待学的东西</h2><ul><li>Von Mises-Fisher distribution</li><li>BOLD</li><li>Hard-Net</li><li>First Order Similarity (FOS)</li><li>$K$ Nearest Neighbors (KNN)</li></ul>]]></content>
      
      
      <categories>
          
          <category> Computer Science </category>
          
          <category> Deep Learning </category>
          
          <category> Paper Notes </category>
          
      </categories>
      
      
        <tags>
            
            <tag> notes </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>数理方法</title>
      <link href="/2020/02/19/Physics/%E6%95%B0%E7%90%86%E6%96%B9%E6%B3%95/"/>
      <url>/2020/02/19/Physics/%E6%95%B0%E7%90%86%E6%96%B9%E6%B3%95/</url>
      
        <content type="html"><![CDATA[<h1 id="数理方法整理"><a href="#数理方法整理" class="headerlink" title="数理方法整理"></a>数理方法整理</h1><center> 作者：黄隆钤 混合1801 </center><h2 id="一-数学物理定解问题"><a href="#一-数学物理定解问题" class="headerlink" title="一 数学物理定解问题"></a>一 数学物理定解问题</h2><h3 id="1-1-定解问题的导出"><a href="#1-1-定解问题的导出" class="headerlink" title="1.1 定解问题的导出"></a>1.1 定解问题的导出</h3><h4 id="（1）振动方程"><a href="#（1）振动方程" class="headerlink" title="（1）振动方程"></a>（1）振动方程</h4><script type="math/tex; mode=display">u_{tt}-a^2u_{xx}=f(x,t)\\u_{tt}-a^2\Delta u =f(\mathbf{x},t) \qquad (high\ dim)</script><ul><li>弦的横振动</li></ul><p>  <img src="https://tva1.sinaimg.cn/large/0082zybply1gc1rytn6i6j313l0lcabz.jpg" style="zoom:50%;" /></p><p>$ \ $ <a id="more"></a></p><ul><li>杆的纵振动</li></ul><p><img src="https://tva1.sinaimg.cn/large/0082zybply1gc1t5r8oilj30u30jaq4k.jpg" style="zoom: 50%;" /></p><ul><li>均匀薄膜的微小横振动</li></ul><p>  <img src="https://tva1.sinaimg.cn/large/0082zybply1gc1sn6p2ppj30xk0u0am9.jpg" style="zoom: 50%;" /></p><ul><li>电磁波方程</li></ul><script type="math/tex; mode=display">\begin{array}\vec E_{tt}-a^2 \Delta _3 \vec E=0\\\vec H_{tt}-a^2\Delta_3 H=0,&\qquad a^2=1/\mu_o\varepsilon_0 = c^2\end{array}\notag</script><h4 id="（2）输运方程"><a href="#（2）输运方程" class="headerlink" title="（2）输运方程"></a>（2）输运方程</h4><script type="math/tex; mode=display">u_t-a^2 u_{xx}=f(x,t)\\u_t-a^2\Delta u=f(\mathbf{x},t)\qquad(high \ dim)</script><ul><li><p>扩散方程</p><p><img src="https://tva1.sinaimg.cn/large/0082zybply1gc2n18scxhj317s0rujvs.jpg" style="zoom: 50%;" /></p></li></ul><ul><li><p>热传导方程</p><script type="math/tex; mode=display">(\Gamma|_x-\Gamma|_{x+dx})dSdt=c(\rho dSdx)du\\=>u_t-a^2u_{xx}=0,\quad a^2=k/c\rho\notag</script></li><li><p>传输线方程</p></li></ul><p><img src="https://tva1.sinaimg.cn/large/0082zybply1gc2nchm8ifj30u00w2424.jpg" style="zoom: 50%;" /></p><h4 id="（3）泊松方程"><a href="#（3）泊松方程" class="headerlink" title="（3）泊松方程"></a>（3）泊松方程</h4><script type="math/tex; mode=display">\Delta u=f</script><ul><li><p>稳定温度分布</p><script type="math/tex; mode=display">c\rho u_t-k\Delta u=F(x,y,z,t),\quad u_t=0\\\implies k\Delta u=-F\notag</script></li><li><p>静电场方程</p><script type="math/tex; mode=display">\oiint \vec E \ dS=\int_V\nabla\cdot \vec E \ dV=\frac{1}{\varepsilon_0}\int_V \rho \ dV\\\implies\nabla\cdot\vec E=\rho/\varepsilon_0,\qquad \vec E=-\nabla V\\\implies \nabla\cdot\nabla V=-\rho / \varepsilon_0\\ i.e.\quad \Delta V=-\rho / \varepsilon_0\notag</script></li><li><p>不可压缩流体的无旋定常流动</p></li></ul><p><img src="https://tva1.sinaimg.cn/large/0082zybply1gc2owe4xd5j30u00xu777.jpg" style="zoom: 50%;" /></p><h4 id="（4）其他知识"><a href="#（4）其他知识" class="headerlink" title="（4）其他知识"></a>（4）其他知识</h4><ul><li>冲击函数的物理意义</li></ul><h3 id="1-2-定解条件的确定"><a href="#1-2-定解条件的确定" class="headerlink" title="1.2 定解条件的确定"></a>1.2 定解条件的确定</h3><h4 id="（1）初始条件"><a href="#（1）初始条件" class="headerlink" title="（1）初始条件"></a>（1）初始条件</h4><p>整个系统的初始状态 :  $u|_{t=0}$</p><h4 id="（2）边界条件"><a href="#（2）边界条件" class="headerlink" title="（2）边界条件"></a>（2）边界条件</h4><ul><li><p>固定：$u|_{x=x_0}=0$</p></li><li><p>自由: 不受外力。以杆为例：$YS\ u<em>x|</em>{x=x<em>0}=0=&gt;u_x|</em>{x=x_0}=0$</p></li><li><p>第三类边界条件：</p><ul><li>自由冷却：遵循牛顿冷却定律。单位时间单位面积散失的热量与温度差成正比。<script type="math/tex; mode=display">\Gamma |_{x=x_0}=h(u|_{x=x_0}-u_0),\quad \Gamma =-k u_x \\i.e. \quad (u_x+\frac{h}{k}u)|_{x=x_0}=\frac{u_0}{k}\notag</script></li></ul></li></ul><ul><li>弹性连接：杆中的弹性力 $=$ 弹性连接物中的弹性恢复力<script type="math/tex; mode=display">YS\ u_x|_{x=x_0}=-ku|_{x=x_0}\\ i.e. \quad (u_x+\frac{k}{YS}u)|_{x=x_0}=0\notag</script></li></ul><ul><li>其他：e.g. 杆连接在屋顶的墙上，下端悬挂重物。（方程列出的是弹性力把重物的重力平衡后的式子）<script type="math/tex; mode=display">-YS\ u_x|_{x=l}=mu_{tt}|_{x=l}\\i.e.\quad (u_x+\frac{m}{YS}u_{tt})=0\notag</script></li></ul><h4 id="（3）衔接条件"><a href="#（3）衔接条件" class="headerlink" title="（3）衔接条件"></a>（3）衔接条件</h4><p><img src="https://tva1.sinaimg.cn/large/0082zybply1gc2pmm9gyoj30a00a2q2x.jpg" style="zoom: 50%;" /></p><script type="math/tex; mode=display">\notag\begin{cases}  u_{I}|_{X=x_0}=u_{II}|_{x=x_0}\\T(-u_{Ix}|_{x=x_0})+Tu_{IIx}|_{x=x_0}=F(t)\end{cases}</script><h3 id="1-3-定解问题的求解"><a href="#1-3-定解问题的求解" class="headerlink" title="1.3 定解问题的求解"></a>1.3 定解问题的求解</h3><ul><li>行波法</li><li>分离变量法</li><li>级数解法</li></ul><h2 id="二-行波法和分离变量法"><a href="#二-行波法和分离变量法" class="headerlink" title="二 行波法和分离变量法"></a>二 行波法和分离变量法</h2><h3 id="2-1-行波法"><a href="#2-1-行波法" class="headerlink" title="2.1 行波法"></a>2.1 行波法</h3><h4 id="（1）达朗贝尔公式"><a href="#（1）达朗贝尔公式" class="headerlink" title="（1）达朗贝尔公式"></a>（1）达朗贝尔公式</h4><script type="math/tex; mode=display">\begin{cases}u_{tt}-a^2 u_{xx}=0, \qquad -\infty<x<\infty,t>0  \\u|_{t=0}=\varphi(x),\ u_t|_{t=0}=\psi (x)\end{cases}\notag</script><script type="math/tex; mode=display">\implies u(x,t)=\frac{1}{2}[\varphi(x+at)+\varphi(x-at)]+\frac{1}{2a}\int_{x-at}^{x+at} \psi(\alpha)d\alpha</script><h4 id="（2）半无界-边界条件不齐次"><a href="#（2）半无界-边界条件不齐次" class="headerlink" title="（2）半无界+边界条件不齐次"></a>（2）半无界+边界条件不齐次</h4><p>$x&gt;at$ ：可认为端点的影响不能传到，直接按原达朗贝尔公式求出</p><p>$x\leq at$ ：待定系数延拓：令</p><script type="math/tex; mode=display">\Psi(x)= \begin{cases}\psi(x),\quad x\geq0\\\psi_1(x),\quad x<0\end{cases}\qquad \Phi(x)=\begin{cases}\varphi(x),\quad x\geq0\\\varphi_1(x),\quad x<0\end{cases}\notag</script><p>带入边界条件，取合适的 $\psi_1(x)$ 和 $\varphi_1(x)$ 使之成立</p><h3 id="2-2-分离变量法"><a href="#2-2-分离变量法" class="headerlink" title="2.2 分离变量法"></a>2.2 分离变量法</h3><h4 id="（1）齐次方程-齐次边界"><a href="#（1）齐次方程-齐次边界" class="headerlink" title="（1）齐次方程-齐次边界"></a>（1）齐次方程-齐次边界</h4><script type="math/tex; mode=display">\begin{cases}u_{tt}-a^2 u_{xx}=0,\quad 0\leq x \leq l,\  t\geq 0& \qquad (I) \\u|_{x=0}=0,\ u|_{x=l}=0 ,\quad t\geq 0&\qquad (II)\\u|_{t=0}=\varphi(x),\ u_t|_{t=0}=\psi(x), \quad 0\leq x \leq l& \qquad (III)\end{cases}\notag</script><script type="math/tex; mode=display">Let\quad u(x,t)=X(x)T(t)\implies \frac{X''}{X}=\frac{T''}{a^2 T}\triangleq -\lambda\\Put \ into \ (I) \ and \ (II) \implies\begin{cases}X''+\lambda X=0\\ X(0)=X(l)=0\end{cases},\quad T''+a^2\lambda \ T=0 \\\implies\cdots=>\lambda>0\\\implies\lambda_n=\frac{n^2\pi^2}{l^2},\quad X_n=c_n \sin(\frac{n\pi}{l}x),\\T_n=a_n\cos(\frac{n\pi}{l}t)+b_n\sin(\frac{n\pi}{l}t)\notag</script><script type="math/tex; mode=display">u(x,t)=\sum\limits_{n=0}^{\infty}X_nT_n=\sum\limits_{n=0}^\infty [A_n \cos(\frac{n\pi}{l}t)+B_n\sin(\frac{n\pi}{l}t)]\sin(\frac{n\pi}{l}x)\\put \ into \ (III)\implies A_n\sin(\frac{n\pi}{l}x)=\varphi(x)\\=>A_n=\frac{\int_0^l\varphi(x)\sin(\frac{n\pi}{l}x)dx}{\int_0^l \sin(\frac{n\pi}{l}x)dx}=\frac{2}{l}\int_0^l\varphi(x)\sin(\frac{n\pi}{l}x)dx\\B_n=\frac{2}{n\pi}\int_0^l\psi(x)\sin(\frac{n\pi}{l}x)dx\notag</script><script type="math/tex; mode=display">=>u(x,t)=\sum\limits_{n=0}^\infty [A_n \cos(\frac{n\pi}{l}t)+B_n\sin(\frac{n\pi}{l}t)]\sin(\frac{n\pi}{l}x),\qquad A_n,B_n \ are \ as \ above.</script><h4 id="（2）非齐次边界"><a href="#（2）非齐次边界" class="headerlink" title="（2）非齐次边界"></a>（2）非齐次边界</h4><p>首先将边界条件齐次化。再回到2.1。</p><h4 id="（3）非齐次方程"><a href="#（3）非齐次方程" class="headerlink" title="（3）非齐次方程"></a>（3）非齐次方程</h4><p>边界条件齐次化之后，可能会转化为齐次化边界的非齐次方程:</p><script type="math/tex; mode=display">\begin{cases}u_{tt}-a^2 u_{xx}=f(x,t),\quad 0\leq x \leq l,\  t\geq 0& \qquad (I) \\u|_{x=0}=0,\ u|_{x=l}=0 ,\quad t\geq 0&\qquad (II)\\u|_{t=0}=\varphi(x),\ u_t|_{t=0}=\psi(x), \quad 0\leq x \leq l& \qquad (III)\end{cases}\notag</script><h5 id="解法一"><a href="#解法一" class="headerlink" title="解法一"></a>解法一</h5><p>设 $u=X(x)\cdot T(t)$ 为 <em>齐次方程</em> 的解</p><p>可得 $\displaystyle X_n=c_n \sin(\frac{n\pi}{l}x)$</p><p>以 $\displaystyle \sin(\frac{n\pi}{l}x)$ 为基，对 $u$ 作傅立叶展开:</p><p><strong>设</strong> </p><script type="math/tex; mode=display">u=\sum\limits_{n=1}^\infty T_n(t)\cdot \sin\frac{n\pi}{l}x</script><p>带入 $I$ :</p><script type="math/tex; mode=display">\sum\limits_{n=1}^\infty (T_n''+\frac{a^2 n^2\pi^2}{l^2}T_n)\sin\frac{n\pi}{l}x=f(x,t)\\\implies\quad  T_n''+\frac{a^2 n^2\pi^2}{l^2}T_n=\frac{2}{l}\int_0^\pi f(x,t)\sin\frac{n\pi}{l}xdx\notag</script><p>解$ODE$：</p><script type="math/tex; mode=display">T_n=Y_n+Y_n^*\\=>u=\sum\limits_{n=1}^\infty[Y_n+Y_n^*]\cdot\sin\frac{n\pi}{l}x\notag</script><h5 id="解法二"><a href="#解法二" class="headerlink" title="解法二"></a>解法二</h5><p>原式 $\iff$ </p><script type="math/tex; mode=display">(I)\begin{cases}u_{tt}-a^2 u_{xx}=0,\\u|_{x=0}=0,\ u|_{x=l}=0 ,\qquad \\u|_{t=0}=\varphi(x),\ u_t|_{t=0}=\psi(x),\end{cases}and \qquad (II)\begin{cases}u_{tt}-a^2 u_{xx}=f(x,t),\\u|_{x=0}=0,\ u|_{x=l}=0 ,\qquad \\u|_{t=0}=0,\ u_t|_{t=0}=0,\end{cases}</script><p>解 （$I$）可得 $u_I$</p><p>解（$II$）：</p><script type="math/tex; mode=display">u_{II}=\int_0^tw(x,\tau)d\tau,\quad w\ satisfy:\\(III)\quad\begin{cases}w_{tt}-a^2w_{xx}=0\\w|_{x=0}=w|_{x=l}=0\\w|_{t=\tau}=0,\ w|_{t=\tau}=f(x,\tau)\end{cases}\notag</script><p>令 $t’=t-\tau$, 同 $I$ 方法解 $(III)$ 即可.</p><script type="math/tex; mode=display">=>u=u_I+u_{II}\notag</script><h2 id="三-球坐标系与柱坐标系"><a href="#三-球坐标系与柱坐标系" class="headerlink" title="三 球坐标系与柱坐标系"></a>三 球坐标系与柱坐标系</h2><h3 id="3-1-拉普拉斯方程"><a href="#3-1-拉普拉斯方程" class="headerlink" title="3.1 拉普拉斯方程"></a>3.1 拉普拉斯方程</h3><p>注：拉普拉斯算子 $\Delta$ 定义为<strong>梯度的散度</strong> $\quad i.e.\quad \Delta f=\nabla\cdot\nabla f$ </p><h4 id="1-极坐标系"><a href="#1-极坐标系" class="headerlink" title="(1) 极坐标系"></a>(1) 极坐标系</h4><script type="math/tex; mode=display">\Delta u=0\iff u_{rr}+\frac{1}{r}u_r+\frac{1}{r^2}u_{\theta\theta}=0</script><p><strong>推导：</strong></p><ol><li>极坐标系下，梯度算子定义为：（径向变化的单位长+角向变化的单位长）</li></ol><script type="math/tex; mode=display">\nabla\triangleq\vec e_r\frac{\partial}{\partial r}+\vec e_\theta\frac{\partial}{r\partial \theta}</script><ol><li>由此推出拉普拉斯算子的公式：</li></ol><script type="math/tex; mode=display">\begin{aligned}\Delta&=\nabla\cdot \nabla  \\&=(\vec e_r\frac{\partial}{\partial r}+\vec e_\theta\frac{\partial}{r\partial \theta})\cdot (\vec e_r\frac{\partial}{\partial r}+\vec e_\theta\frac{\partial}{r\partial \theta})\\&=\frac{\partial^2}{\partial r^2}+\frac{1}{r}\frac{\partial}{\partial r}+\frac{1}{r^2}\frac{\partial^2}{\partial \theta^2}\end{aligned}\notag</script><ol><li>过程中用到：<script type="math/tex; mode=display">\frac{\partial\vec e_\theta}{\partial\theta}=-\vec e_r,\quad \frac{\partial\vec e_r}{\partial\theta}=\vec e_\theta\\\frac{\partial\vec e_\theta}{\partial r}=0,\quad \frac{\partial\vec e_r}{\partial r}=0\\</script></li></ol><h4 id="2-柱坐标系"><a href="#2-柱坐标系" class="headerlink" title="(2) 柱坐标系"></a>(2) 柱坐标系</h4><script type="math/tex; mode=display">\Delta u=0\iff u_{rr}+\frac{1}{r}u_r+\frac{1}{r^2}u_{\varphi\varphi}+u_{zz}=0</script><ol><li>推导中用到梯度算子在柱坐标系中的定义：</li></ol><script type="math/tex; mode=display">\nabla\triangleq\vec e_r\frac{\partial}{\partial r}+\vec e_\varphi\frac{\partial}{r\partial \varphi}+\vec e_z\frac{\partial }{\partial z}\notag</script><ol><li><p>直接分离变量，令 $u=R(r)\Phi(\varphi)Z(z)$, 代入后可得到 关于 $r$ 的<strong>贝塞尔方程</strong></p><p>过程：</p><p>​        分离出 $\Phi $ ，设出 $\lambda$ </p><p> =&gt;  由周期条件解出 $\Phi$, 得到 $\lambda=m^2$ ,回代</p><p> =&gt;  分离出 $ R,Z$ ,设出 $\mu$ </p><p> =&gt;  讨论 $\mu$: $\mu=0$ 为欧拉型ODE;</p></li></ol><p>   ​                     $\mu&gt;0$ ，令 $x\equiv\sqrt {u}\rho$, 为 $m$ 阶贝塞尔方程：</p><script type="math/tex; mode=display">   x^2\frac{d^2R}{dr^2}+x\frac{dR}{dx}+(x^2-m^2)R=0</script><p>   ​                     $\mu&lt;0$ ，令 $x\equiv\sqrt {-\mu}\rho$,为虚宗量贝赛尔方程：</p><script type="math/tex; mode=display">   x^2\frac{d^2R}{dr^2}+x\frac{dR}{dx}-(x^2+m^2)R=0</script><h4 id="3-球坐标系"><a href="#3-球坐标系" class="headerlink" title="(3) 球坐标系"></a>(3) 球坐标系</h4><script type="math/tex; mode=display">\Delta u=0\iff \frac{1}{r^2}\frac{\partial }{\partial r}(r^2\frac{\partial u}{\partial r})+\frac{1}{r^2 \sin \theta}\frac{\partial }{\partial\theta}(\sin\theta\frac{\partial u}{\partial\theta})+\frac{1}{r^2\sin^2\theta}\frac{\partial^2 u}{\partial\varphi^2}=0</script><ol><li><p>推导中用到：</p><p><img src="https://tva1.sinaimg.cn/large/0082zybply1gc3566n5rrj30aq09jq31.jpg" style="zoom: 67%;" /></p><script type="math/tex; mode=display">\nabla\triangleq\vec e_r\frac{\partial}{\partial r}+\vec e_\theta\frac{\partial}{r\partial \theta}+\vec e_\varphi\frac{\partial }{r\sin\theta\ \partial \varphi}\notag</script></li><li><p>单位向量之间的关系：</p><script type="math/tex; mode=display">\vec e_r\cdot\vec e_\theta=\vec e_r\cdot\vec e_\varphi=\vec e_\theta\cdot\vec e_\varphi=0, \ \vec e_\varphi=\vec e_r\times\vec e_\theta  \notag</script></li><li><p>微分关系：</p></li></ol><script type="math/tex; mode=display">\frac{\partial\vec e_r}{\partial r}=\frac{\partial\vec e_r}{\partial \theta}=\frac{\partial\vec e_\varphi}{\partial r}=0.\\\frac{\partial\vec e_r}{\partial \theta}=\vec e_\theta,\ \frac{\partial\vec e_\theta}{\partial \theta}=-\vec e_r,\ \frac{\partial\vec e_\varphi}{\partial \theta}=0.\\\frac{\partial\vec e_r}{\partial \varphi}=\vec e_\varphi \sin\theta,\ \frac{\partial\vec e_\theta}{\partial \varphi}=\vec e_\varphi \cos\theta(未理解,求解答),\\ \frac{\partial\vec e_\varphi}{\partial \varphi}=\frac{\partial(\vec e_r\times\vec e_\theta)}{\partial \varphi}=-\vec e_r\sin\theta-\vec e_\theta\cos\theta.</script><p><strong>推导拉普拉斯方程在球坐标下的表达式，并分离变量</strong>：</p><ol><li>推导</li></ol><script type="math/tex; mode=display">\begin{aligned}\Delta &=(\vec e_r\frac{\partial}{\partial r}+\vec e_\theta\frac{\partial}{r\partial \theta}+\vec e_\varphi\frac{\partial}{r\sin\theta\ \partial \varphi})\cdot(\vec e_r\frac{\partial}{\partial r}+\vec e_\theta\frac{\partial}{r\partial \theta}+\vec e_\varphi\frac{\partial }{r\sin\theta\ \partial \varphi})\\&=\vec e_r\cdot [0+\vec e_r\frac{\partial^2}{\partial r^2}+0+0+0+0]+\frac{1}{r}\vec e_\theta[\vec e_\theta\frac{\partial}{\partial r}+0+0+\vec e_\theta\frac{\partial^2}{r\partial \theta^2}+0+0]\\&+\frac{1}{r\sin\theta}\vec e_\varphi[\vec e_\varphi\sin\theta\frac{\partial}{\partial r}+0+\vec e_\varphi\cos\theta\frac{\partial}{r\partial\theta}+0+0+\vec e_\varphi\frac{\partial^2}{r\sin\theta\partial\varphi^2}]\\&=\frac{\partial^2}{\partial r^2}+\frac{1}{r}\frac{\partial}{\partial r}+\frac{1}{r^2}\frac{\partial^2}{\partial \theta^2}+\frac{1}{r}\frac{\partial}{\partial r}+\frac{\cos\theta}{r^2\sin\theta}\frac{\partial}{\partial \theta}+\frac{1}{r^2\sin^2\theta}\frac{\partial^2}{\partial \varphi^2}\\&=\frac{1}{r^2}\frac{\partial }{\partial r}(r^2\frac{\partial }{\partial r})+\frac{1}{r^2 \sin \theta}\frac{\partial }{\partial\theta}(\sin\theta\frac{\partial }{\partial\theta})+\frac{1}{r^2\sin^2\theta}\frac{\partial^2 }{\partial\varphi^2}\end{aligned}</script><script type="math/tex; mode=display">\therefore \Delta u=0\iff \frac{1}{r^2}\frac{\partial }{\partial r}(r^2\frac{\partial u}{\partial r})+\frac{1}{r^2 \sin \theta}\frac{\partial }{\partial\theta}(\sin\theta\frac{\partial u}{\partial\theta})+\frac{1}{r^2\sin^2\theta}\frac{\partial^2 u}{\partial\varphi^2}=0\notag</script><ol><li><p><strong>分离变量</strong></p><p>设 $u(r,\theta,\varphi)=R(r)\cdot Y(\theta,\varphi)$ ，带入 Laplace方程，得：</p><script type="math/tex; mode=display">\begin{align}&Y\frac{d}{dr}(r^2\frac{dR}{dr})+R\frac{1}{\sin\theta}\frac{d}{d\theta}(\sin\theta\frac{dY}{d\theta})+R\frac{1}{\sin^2\theta}\frac{d^2 Y}{d\varphi^2}=0\notag \\\implies&\frac{1}{R}\frac{d}{dr}(r^2\frac{dR}{dr})=-\frac{1}{Y}\bigg(\frac{1}{\sin\theta}\frac{d}{d\theta}(\sin\theta\frac{dY}{d\theta})+\frac{1}{\sin^2\theta}\frac{d^2 Y}{d\varphi^2}\bigg)\triangleq l(l+1)\notag \\\implies& \quad r^2 R''+2rR'-l(l+1) R=0, \label{EulerODE}&\\&\quad \frac{1}{\sin\theta}\frac{d}{d\theta}(\sin\theta\frac{dY}{d\theta})+\frac{1}{\sin^2\theta}\frac{d^2 Y}{d\varphi^2}+l(l+1)Y=0\label{ballfunc}\end{align}</script></li></ol><p>   $(\ref{EulerODE})$ 为欧拉型 ODE，解为 $\displaystyle R(r)=Cr^l+D\frac{1}{r^{l+1}}$</p><p>   $ (\ref{ballfunc})$为 <strong>球函数方程</strong>， 现进一步分离变量，设 $Y(\theta,\varphi)=H(\theta)\cdot\Phi(\varphi)$ , 代入得 :</p><script type="math/tex; mode=display">   \begin{aligned}&\Phi\cdot\frac{1}{\sin \theta}\frac{d}{d\theta}(\sin\theta\frac{dH}{d\theta})+H\cdot\frac{1}{\sin^2\theta}\frac{d^2\Phi}{d\varphi^2}+l(l+1)H\cdot\Phi=0\\   \implies  & \quad \frac{\sin\theta}{H}\frac{d}{d\theta}(\sin\theta\frac{dH}{d\theta})+l(l+1)\sin^2\theta=-\frac{1}{\Phi}\frac{d^2\Phi}{d\varphi^2}\triangleq\lambda\\   \implies&\quad \Phi''+\lambda\Phi=0 ,\quad \sin\theta\frac{d}{d\theta}(\sin\theta\frac{dH}{d\theta})+\big[l(l+1)\sin^2\theta-\lambda\big]H=0   \end{aligned}</script><p>   关于 $\Phi$ 的方程再加上<em>自然周期条件</em> $\Phi(\varphi)=\Phi(\varphi+2\pi)$, 可得：</p><script type="math/tex; mode=display">   \lambda=m^2,\quad m=0,1,2,3,\cdots\\   \Phi(\varphi)=A\cos m\varphi+B\sin m\varphi   \notag</script><p>   将 $\lambda=m^2$ 代入关于 $H$ 的方程, 并记 $x\equiv \cos\theta$：</p><script type="math/tex; mode=display">   (1-x^2)\frac{d^2 H}{dx^2}-2x\frac{d H}{dx}+\big[l(l+1)-\frac{m^2}{1-x^2}\big]H=0   \label{l-Legendre}</script><p>   $(\ref{l-Legendre})$ 为 $l$ 阶 <strong>连带勒让德方程</strong> </p><h4 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h4><ul><li><p>直角坐标拉普拉斯算子</p><script type="math/tex; mode=display">\Delta=\frac{\partial^2}{\partial x^2}+\frac{\partial^2}{\partial y^2}+\frac{\partial^2}{\partial z^2}</script></li><li><p>极坐标拉普拉斯算子</p><script type="math/tex; mode=display">\Delta=\frac 1 r\frac{\partial}{\partial r}\left(r\frac{\partial}{\partial r}\right)+\frac{1}{r^2}\frac{\partial^2}{\partial \theta^2}</script></li><li><p>柱坐标拉普拉斯算子</p><script type="math/tex; mode=display">\Delta=\frac 1 r\frac{\partial}{\partial r}\left(r\frac{\partial}{\partial r}\right)+\frac{1}{r^2}\frac{\partial^2}{\partial \varphi^2}+\frac{\partial^2}{\partial z^2}</script></li><li><p>球坐标拉普拉斯算子</p><script type="math/tex; mode=display">\Delta=\frac 1 {r^2}\frac{\partial}{\partial r}\left(r^2\frac{\partial}{\partial r}\right)+\frac{1}{r^2\sin\theta}\frac{\partial}{\partial \theta}\left(\sin\theta\frac{\partial}{\partial \theta}\right)+\frac{1}{r^2\sin^2\theta}\frac{\partial^2}{\partial \varphi^2}</script></li></ul><h3 id="3-2-亥姆霍兹方程"><a href="#3-2-亥姆霍兹方程" class="headerlink" title="3.2 亥姆霍兹方程"></a>3.2 亥姆霍兹方程</h3><script type="math/tex; mode=display">\Delta v+k^2v=0</script><p>波动方程 $u_{tt}-a^2\Delta u=0$ 或者输运方程 $u_t-a^2\Delta u=0$  分离时间和空间变量 (令 $u(\vec r,t)=T(t)R(\vec r)$)后将得到亥姆霍兹方程。</p><h4 id="（1）柱坐标系"><a href="#（1）柱坐标系" class="headerlink" title="（1）柱坐标系"></a>（1）柱坐标系</h4><script type="math/tex; mode=display">\begin{aligned}&\Delta v+k^2 v=0\\&v_{rr}+\frac{1}{r}v_r+\frac{1}{r^2}v_{\varphi\varphi}+v_{zz}+k^2 v=0\\\end{aligned}</script><p>设 $v(r,\varphi,z)\triangleq R(r)\Phi(\varphi)Z(z)$</p><p>先分离 $\Phi$ : </p><script type="math/tex; mode=display">\frac{r^2 R''Z+r R'Z+r^2Z''+k^2r^2 R Z}{RZ}=-\frac{\Phi''}{\Phi}\triangleq\lambda\notag</script><p>$\implies$ $ \lambda=m^2 $ , $\Phi(\varphi)=A\cos m\varphi+\sin m\varphi$</p><p>再分离 $Z$ ：</p><script type="math/tex; mode=display">\frac{r^2 R''+r R'+(k^2r^2-m^2) R}{r^2 R}=-\frac{Z''}{Z}\triangleq\nu^2\notag</script><p>=&gt; </p><script type="math/tex; mode=display">\notag Z’’+\nu^2Z=0,\\R''+\frac{1}{r}R'+(\mu'-\frac{m^2}{r^2})R=0,\qquad \mu'\equiv k^2-\nu^2</script><p>令 $x=\sqrt {\mu’}r$， 得：</p><script type="math/tex; mode=display">\frac{d^2R}{dx^2}+\frac{1}{x}\frac{dR}{dx}+(1-\frac{m^2}{x^2})R=0</script><p>$m$ 阶贝塞尔方程。</p><h4 id="（2）球坐标系"><a href="#（2）球坐标系" class="headerlink" title="（2）球坐标系"></a>（2）球坐标系</h4><script type="math/tex; mode=display">\frac{1}{r^2}\frac{\partial }{\partial r}(r^2\frac{\partial v}{\partial r})+\frac{1}{r^2 \sin \theta}\frac{\partial }{\partial\theta}(\sin\theta\frac{\partial v}{\partial\theta})+\frac{1}{r^2\sin^2\theta}\frac{\partial^2 v}{\partial\varphi^2}+k^2 v=0\notag</script><p>设 $v=R(r)Y(\theta,\varphi) $ =&gt;</p><script type="math/tex; mode=display">\frac{1}{R}\frac{\partial }{\partial r}(r^2\frac{\partial R}{\partial r})+k^2 r^2 =-\bigg[\frac{1}{Y\sin \theta}\frac{\partial }{\partial\theta}(\sin\theta\frac{\partial Y}{\partial\theta})+\frac{1}{Y\sin^2\theta}\frac{\partial^2 Y}{\partial\varphi^2}\bigg]\triangleq l(l+1)\notag</script><p>得到：</p><script type="math/tex; mode=display">\frac{1}{\sin \theta}\frac{d}{d\theta}(\sin\theta\frac{d Y}{d\theta})+\frac{1}{\sin^2\theta}\frac{d^2 Y}{d\varphi^2}+l(l+1)Y=0\\\frac{d}{d r}(r^2\frac{d R}{d r})+\big[k^2 r^2-l(l+1)\big]R=0\notag</script><p>分别是球函数方程（可进一步分离成连带勒让德方程）和 $l$ 阶球贝塞尔方程。</p><h3 id="3-3-矢量波动方程"><a href="#3-3-矢量波动方程" class="headerlink" title="3.3 矢量波动方程"></a>3.3 矢量波动方程</h3><script type="math/tex; mode=display">\Delta \vec E +k^2 \vec E=0</script><p>关键：$\vec E=E<em>r \vec e_r+E</em>\theta\vec e_\theta+E_z\vec e_z$ </p><p>​            $\vec E=E<em>r \vec e_r+E</em>\theta\vec e<em>\theta+E</em>\varphi\vec e_\varphi$</p><p><img src="https://tva1.sinaimg.cn/large/0082zybply1gc3upwrq71j30u0107tdb.jpg" style="zoom: 50%;" /></p><p><img src="https://tva1.sinaimg.cn/large/0082zybply1gc3uqaat5qj30u012mtd1.jpg" style="zoom: 50%;" /></p><p><img src="https://tva1.sinaimg.cn/large/0082zybply1gc3uqk4nxjj30u00xmq6w.jpg" style="zoom: 50%;" /></p><p><img src="https://tva1.sinaimg.cn/large/0082zybply1gc3ur101aij30xx0u0n16.jpg" style="zoom: 50%;" /></p><h2 id="四-级数解法和本征值问题"><a href="#四-级数解法和本征值问题" class="headerlink" title="四 级数解法和本征值问题"></a>四 级数解法和本征值问题</h2><h3 id="4-1-常点邻域的级数解法"><a href="#4-1-常点邻域的级数解法" class="headerlink" title="4.1 常点邻域的级数解法"></a>4.1 常点邻域的级数解法</h3><p>可获得勒让德方程的级数解。</p><p>线性二阶常微分方程：</p><script type="math/tex; mode=display">w''+p(z)w'+q(z)w=0\\w(z_0)=C_0,\ w'(z_0)=C_1</script><p>其中 $p(z),\ q(z)$ 为点 $z_0$ 的邻域 $|z-z_0|&lt;R$ 上的解析函数。</p><p>令 $w(z)=\displaystyle \sum\limits_{k=0}^\infty a_k(z-z_0)^k$， 代入方程合并同幂项，对应系数分别为零。</p><h4 id="求解勒让德方程"><a href="#求解勒让德方程" class="headerlink" title="求解勒让德方程"></a>求解勒让德方程</h4><p>在 $x_0=0$ 的邻域上求解 $l$ 阶勒让德方程</p><script type="math/tex; mode=display">(1-x^2)y''-2xy'+l(l+1)y=0\notag</script><p>设 $y=\sum\limits_{n=0}^\infty a_n x^n$  =&gt;</p><script type="math/tex; mode=display">a_{k+2}=\frac{(k-l)(k+l+1)}{(k+2)(k+1)}a_k\notag</script><p>=&gt;</p><script type="math/tex; mode=display">y=a_0y_0 (x)+a_1 y_1(x)\notag</script><h3 id="4-2-正则奇点邻域的级数解法"><a href="#4-2-正则奇点邻域的级数解法" class="headerlink" title="4.2 正则奇点邻域的级数解法"></a>4.2 正则奇点邻域的级数解法</h3><p>正则奇点：在方程 $(18)$ 的奇点邻域上，两个线性无关解全都有有限个负幂项。</p><p>如：  $p(z)$ 以 $z_0$ 为不高于一阶的极点，且 $q(z)$ 以 $z_0$ 为不高于二阶的极点。</p><script type="math/tex; mode=display">i.e.\qquad p(z)=\sum\limits_{k=-1}^\infty p_k(z-z_0)^k ,\ q(z)=\sum\limits_{k=-2}^\infty q_k(z-z_0)^k \notag</script><h4 id="（1）基本求解步骤"><a href="#（1）基本求解步骤" class="headerlink" title="（1）基本求解步骤"></a>（1）基本求解步骤</h4><ol><li><p>设 $y=\displaystyle\sum_{n=0}^\infty a_n(z-z_0)^{s+n}$</p></li><li><p>求出 $s_1,\ s_2$</p></li><li><p>若 $s_1-s_2\neq 整数$， 则 $y(z)=c_1y_1(z)+c_2y_2(z)$</p></li><li><p>若 $s_1-s_2=整数$， 则两解线性相关，求出一解 $y_1$ ，需另设:</p><script type="math/tex; mode=display">y_2(z)=Ay_1(z)\ln (z-z_0)+\sum_{n=0}^\infty b_n (z-z_0)^{s_2+k}</script><p>$y(z)=c_1y_1(z)+c_2y_2(z)$.</p></li></ol><h4 id="（2）求解-nu-阶贝塞尔方程"><a href="#（2）求解-nu-阶贝塞尔方程" class="headerlink" title="（2）求解 $ \nu$ 阶贝塞尔方程"></a>（2）求解 $ \nu$ 阶贝塞尔方程</h4><script type="math/tex; mode=display">x^2 y''+xy'+(x^2-\nu^2)y=0\notag</script><p>其中 $\nu$ 不为整数或半奇数。</p><p>设 $y=\displaystyle\sum\limits_{n=0}^\infty a_n x^{s+n}, a_0\neq 0$ , 带入：</p><script type="math/tex; mode=display">x^2 y''=\sum_{i=0}^\infty (s+i)(s+i-1)a_i x^{i+s},\quad xy'=\sum_{i=0}^\infty (s+i)a_i x^{i+s}\\x^2 y=\sum_{i=2}^\infty a_{i-2}x^{i+s},\quad -\nu^2y=\nu^2 \sum_{i=0}^\infty a_i x^{i+s}\notag</script><p>合并同幂项：</p><script type="math/tex; mode=display">\begin{aligned}&[s^2-\nu^2]a_0=0 ,\\ &[(s+1)^2-\nu^2]a_1=0\\ &[(s+k)^2-\nu^2]a_k+a_{k-2}=0\end{aligned}</script><script type="math/tex; mode=display">\implies \quad s_1=\nu,\ s_2=-\nu ,\ a_1=0,\\a_k=\frac{-1}{(s+k)^2-\nu^2}a_{k-2}\notag</script><p>取 $s=s_1$ :</p><script type="math/tex; mode=display">y_1=a_0x^\nu\bigg[1-\frac{1}{1!(\nu+1)}\big(\frac{x}{2}\big)^2+\cdots+(-1)^k\frac{1}{k!(\nu+1)(\nu+2)\cdots(\nu+k)}\big(\frac{x}{2}\big)^{2k}+\cdots\bigg]\notag</script><p>收敛半径 :</p><script type="math/tex; mode=display">R^2=\lim_{k\to\infty}\frac{a_{k-2}}{a_k}=\lim_{k\to\infty}k(2\nu+k)=\infty.\notag</script><p>通常取</p><script type="math/tex; mode=display">a_0=\frac{1}{2}\Gamma(\nu+1)\notag</script><p>代入得到 $\nu$ 阶 <strong>贝塞尔函数</strong> ：</p><script type="math/tex; mode=display">J_\nu(x)=\sum_{k=0}^\infty (-1)^k\frac{1}{k!\Gamma(\nu+k+1)}\big(\frac{x}{2}\big)^{\nu+2k}</script><p>取 $s=s_2$ :</p><p>得到 $-\nu$ 阶 贝塞尔函数：</p><script type="math/tex; mode=display">J_{-\nu}(x)=\sum_{k=0}^\infty (-1)^k\frac{1}{k!\Gamma(-\nu+k+1)}\big(\frac{x}{2}\big)^{-\nu+2k}</script><p>$\nu$ 阶贝塞尔方程的通解为：</p><script type="math/tex; mode=display">y(x)=C_1J_\nu(x)+C_2J_{-\nu}(x)</script><p>取 $C_1=\cot \nu\pi,\ C_2=-\csc\nu\pi$ 代入得到一个特解 $\nu$ 阶<strong>诺伊曼函数</strong>，以此作为 $\nu$ 阶贝塞尔方程的第二个线性独立的解：</p><script type="math/tex; mode=display">N_\nu(x)=\frac{J_v(x)\cos\nu\pi-J_{-\nu}(x)}{\sin\nu\pi}</script><h4 id="（3）求解半奇数阶贝塞尔方程"><a href="#（3）求解半奇数阶贝塞尔方程" class="headerlink" title="（3）求解半奇数阶贝塞尔方程"></a>（3）求解半奇数阶贝塞尔方程</h4><script type="math/tex; mode=display">x^2 y''+xy'+[x^2-(l+\frac{1}{2})^2]y=0\notag</script><p>$x_0=0$ 为方程的正则奇点。</p><p>$l=0$ 时：</p><script type="math/tex; mode=display">\begin{aligned}y_1(x)=J_{\frac{1}{2}}(x)&=\sum_{k=0}^\infty(-1)^k \frac{1}{k!\Gamma(k+\frac{3}{2})}\big(\frac{x}{2}\big)^{2k+\frac{1}{2}}\\&=\sum_{k=0}^\infty\frac{(-1)^k}{k!(k+\frac{1}{2})\cdots \frac{1}{2}\Gamma(\frac{1}{2})}\big(\frac{x}{2}\big)^{2k+\frac{1}{2}}\\&=\sum_{k=0}^\infty\frac{(-1)^k}{k!(k+\frac{1}{2})\cdots \frac{1}{2}\sqrt \pi\cdot 2^{k+1}\cdot2^k}x^{2k+\frac{1}{2}}\cdot(\frac{1}{2})^{-\frac{1}{2}}\\&=\sqrt{\frac{2x}{\pi}}\sum_{k=0}^\infty(-1)^k\frac{x^{2k}}{(2k+1)!}\\&=\sqrt{\frac{2}{\pi x}}\sin x.\end{aligned}</script><p>（同理可得：$\displaystyle J_{-\frac{1}{2}}=\sqrt{\frac{2}{\pi x}}\cos x$ )</p><p>由于 $s_1-s_2=整数$，设：</p><script type="math/tex; mode=display">y_2(x)=AJ_{\frac{1}{2}}(x)\ln x+\sum_{k=-1/2}^\infty b_k x^k\notag</script><p>仔细代入贝塞尔方程，得到：</p><script type="math/tex; mode=display">\begin{aligned}&A\bigg[x^2J_{\frac{1}{2}}''(x)+xJ_{\frac{1}{2}}'(x)+\big(x^2-\frac{1}{4}\big)J_{\frac{1}{2}}(x)\bigg]\ln x+\\&2AxJ_{\frac{1}{2}}'(x)+\sum_{k=1/2}^\infty k(k-1)b_k x^k+\sum_{k=1/2}^\infty k b_k x^k+\sum_{k=1/2}^\infty b_k x^{k+2}-\sum_{k=1/2}^\infty \frac{1}{4}b_k x^k=0\end{aligned}</script><p>由于 $J_{\frac{1}{2}}(x)$ 是 $1/2$ 阶贝塞尔方程的解，$[\quad \cdot\quad ]$ 里的东西为 $0$ .</p><p>对剩下的合并同幂次项，最后可得：$A=0$.</p><p>进而可以解得：</p><script type="math/tex; mode=display">y(x)=C_1J_{\frac{1}{2}}(x)+C_2J_{-\frac{1}{2}}(x)\notag</script><p>同样的过程可求得 $\displaystyle l+\frac{1}{2}$ 阶贝塞尔函数的解：</p><script type="math/tex; mode=display">y(x)=C_1J_{l+\frac{1}{2}}(x)+C_2J_{-l+\frac{1}{2}}(x)</script><h4 id="（4）整数-m-阶贝塞尔方程"><a href="#（4）整数-m-阶贝塞尔方程" class="headerlink" title="（4）整数 $m$ 阶贝塞尔方程"></a>（4）整数 $m$ 阶贝塞尔方程</h4><p>通解为：</p><script type="math/tex; mode=display">y(x)=C_1 J_m(x)+C_2 N_m (x)</script><p>诺伊曼函数的边界性质：</p><script type="math/tex; mode=display">\lim_{x\to 0}N_\nu (x)=\pm \infty,\ \lim_{x\to 0}N_m(x)=-\infty</script><h4 id="（5）-nu-阶虚宗量贝塞尔方程"><a href="#（5）-nu-阶虚宗量贝塞尔方程" class="headerlink" title="（5）$\nu$ 阶虚宗量贝塞尔方程"></a>（5）$\nu$ 阶虚宗量贝塞尔方程</h4><p>可作变换 $\xi=ix$, 进而求解.</p><p>记 </p><script type="math/tex; mode=display">\begin{aligned}&I_v(x)=i^{-\nu}J_\nu (ix)=\sum_{k=0}^\infty\frac{1}{k!\Gamma(\nu+k+1)}\big(\frac{x}{2}\big)^{\nu+2k}\\&I_{-v}(x)=i^{\nu}J_{-\nu} (ix)=\sum_{k=0}^\infty\frac{1}{k!\Gamma(-\nu+k+1)}\big(\frac{x}{2}\big)^{-\nu+2k}\end{aligned}</script><p>$\nu$ 阶虚宗量贝塞尔方程的一般解为：</p><script type="math/tex; mode=display">y(x)=C_1I_{\nu}(x)+C_2I_{-\nu}(x).</script><h5 id="整数-m-阶虚宗量贝塞尔方程"><a href="#整数-m-阶虚宗量贝塞尔方程" class="headerlink" title="整数 $m$ 阶虚宗量贝塞尔方程"></a>整数 $m$ 阶虚宗量贝塞尔方程</h5><p>整数 $m$ 阶虚宗量贝塞尔方程的一般解：将来学完整理。</p><h3 id="4-3-S-L本征值问题"><a href="#4-3-S-L本征值问题" class="headerlink" title="4.3  S-L本征值问题"></a>4.3  S-L本征值问题</h3><h4 id="（1）S-L-型方程"><a href="#（1）S-L-型方程" class="headerlink" title="（1）S-L 型方程"></a>（1）S-L 型方程</h4><script type="math/tex; mode=display">\frac{d}{dx}\bigg[k(x)\frac{dy}{dx}\bigg]-q(x)y+\lambda\rho (x)y=0,\quad a\leq x\leq b</script><h4 id="（2）一般二阶-ODE-转化为-S-L-型方程"><a href="#（2）一般二阶-ODE-转化为-S-L-型方程" class="headerlink" title="（2）一般二阶 ODE 转化为 S-L 型方程"></a>（2）一般二阶 ODE 转化为 S-L 型方程</h4><script type="math/tex; mode=display">y''+a(x)y'+b(x)y+\lambda c(x)y=0\notag</script><p>两边同时乘 $e^{\int a(x)dx}$ :</p><script type="math/tex; mode=display">\frac{d}{dx}\bigg[e^{\int a(x)dx}\frac{dy}{dx} \bigg]+b(x)e^{\int a(x)dx}y+\lambda c(x)e^{\int a(x)dx}y=0</script><script type="math/tex; mode=display">\therefore k(x)=e^{\int a(x)dx},\ q(x)=-b(x)e^{\int a(x)dx},\ \rho(x)=c(x)e^{\int a(x)dx}</script><h4 id="（3）S-L​本征值问题的共同性质"><a href="#（3）S-L​本征值问题的共同性质" class="headerlink" title="（3）S-L​本征值问题的共同性质"></a>（3）S-L​本征值问题的共同性质</h4><ul><li><p>若 $k(x),k’(x)$ 连续，$q(x)$ 连续或最多以 $x=a$ 或 $x=b$ 为一阶极点，则存在无限多个本征值，相应地有无限多个本征函数。本征函数族是完备的。</p></li><li><p>所有本征值 $\lambda_n\geq 0$</p><p>证明：</p><p>本征值和相应地本征函数满足：</p><script type="math/tex; mode=display">-\frac{d}{dx}\bigg[k(x)\frac{dy_n}{dx}\bigg]+q(x)y_n=\lambda_n\rho (x)y_n\notag</script><p><strong>用 $y_n$ 遍乘各项</strong>，并<strong>逐项从 $a$ 到 $b$ 积分</strong>，得：</p><script type="math/tex; mode=display">\begin{aligned}\lambda_n \int_a^b \rho(x)y_n^2&=-\int_a^by_n (x)\frac{d}{dx}\bigg[k(x)\frac{dy_n}{dx}\bigg]dx+\int_a^b q(x)y_n^2(x)dx\\&=(ky_ny_n')\bigg|_{x=a}-(ky_ny_n')\bigg|_{x=b}+\int_a^bqy_n^2dx\\\end{aligned}</script><p>在前三类边界条件</p><script type="math/tex; mode=display">y_n(a)=y_n(b)=0,\quad or \quad y'_n(a)=y'_n(b)=0\\or\quad (y_n-hy'_n)\bigg|_{x=a}=(y_n+hy'_n)\bigg|_{x=b}=0\notag</script><p>的情况下，右边 $\geq0$, 故 $\lambda_n\geq0$.</p></li></ul><ul><li>相应于不同本征值 $\lambda_n$ 和 $\lambda_m$ 的本征函数 $y_n(x)$ 和 $y_m(x)$ 在区间 $[a,b]$ 带权重 $\rho(x)$ 正交。</li></ul><script type="math/tex; mode=display">i.e\quad \int_a^b y_m(x)y_n(x)\rho(x)dx=0\quad (n\neq m)</script><p>​    证明：</p><p>​             $y_n,y_m$ 分别满足：</p><script type="math/tex; mode=display">\begin{aligned}&\frac{d}{dx}\big(ky'_n\big)-qy_n+\lambda_n\rho y_n=0& (*)\\&\frac{d}{dx}\big(ky'_m\big)-qy_m+\lambda_m\rho y_m=0& (**)\\\end{aligned}</script><p>​                    $\implies\displaystyle \int_a^b\big[(<em>)\cdot y_m-(*</em>)\cdot y_n\big]dx$ :</p><script type="math/tex; mode=display">\begin{aligned}\quad \quad 0&=\int_a^b\bigg[y_m d(ky_n')-y_nd(ky_m')\bigg]+(\lambda_n-\lambda_m)\int_a^b y_ny_m\rho dx\\&=(ky_my_n')\bigg|_a^b-(ky_ny_m')\bigg|_a^b+\int_a^b \big[(ky_n'y_m')-(ky_n'y_m')\big]dx+(\lambda_n-\lambda_m)\int_a^b y_ny_m\rho dx\\&=(\lambda_n-\lambda_m)\int_a^b y_ny_m\rho dx\end{aligned}</script><p>​            故 :</p><script type="math/tex; mode=display">\int_a^b y_ny_m\rho dx=0\qquad (n\neq m)\notag</script><h2 id="五-球函数"><a href="#五-球函数" class="headerlink" title="五 球函数"></a>五 球函数</h2><p>球坐标拉普拉斯方程 :</p><script type="math/tex; mode=display">\frac{1}{r^2}\frac{\partial }{\partial r}(r^2\frac{\partial u}{\partial r})+\frac{1}{r^2 \sin \theta}\frac{\partial }{\partial\theta}(\sin\theta\frac{\partial u}{\partial\theta})+\frac{1}{r^2\sin^2\theta}\frac{\partial^2 u}{\partial\varphi^2}=0\notag</script><p>分离变量可得：</p><script type="math/tex; mode=display">R=Cr^l+\frac{D}{r^{l+1}}\\\frac{1}{\sin\theta}\frac{d}{d\theta}(\sin\theta\frac{dY}{d\theta})+\frac{1}{\sin^2\theta}\frac{d^2 Y}{d\varphi^2}+l(l+1)Y=0\notag</script><p>第二个方程为球函数方程，再次分离变量：</p><script type="math/tex; mode=display">\begin{align}&\Phi_m(\varphi)=A_m\cos m\varphi+B_m\sin m\varphi \notag \\&(1-x^2)\frac{d^2 H}{dx^2}-2x\frac{d H}{dx}+\big[l(l+1)-\frac{m^2}{1-x^2}\big]H=0\qquad \label{associated-Legendre}\end{align}</script><p>就得到了连带勒让德方程 $(\ref{associated-Legendre})$.</p><h3 id="5-1-轴对称球函数"><a href="#5-1-轴对称球函数" class="headerlink" title="5.1 轴对称球函数"></a>5.1 轴对称球函数</h3><p>$m=0$ 时的情况。</p><h4 id="（1）勒让德多项式的表达式"><a href="#（1）勒让德多项式的表达式" class="headerlink" title="（1）勒让德多项式的表达式"></a>（1）勒让德多项式的表达式</h4><p>勒让德方程若和边界条件构成定解问题，一般有自然边界条件（边界处有界），则方程须退化为多项式，此时   $l$ 为整数。将退化的多项式乘以适当的常数，得到 $l$ 阶勒让德多项式。因为 $m=0$ 时 $\Phi(\varphi)$ 为常数，轴对称球函数 $Y$ 简化为勒让德多项式 $P_l(x)$ 。</p><script type="math/tex; mode=display">a_l=\frac{(2l)!}{2^l (l!)^2}\\a_{k+2}=\frac{k(k+1)-l(l+1)}{(k+2)(k+1)}a_k=\frac{(k-l)(k+1-l)}{(k+2)(k+1)}a_k\notag</script><p>勒让德多项式：</p><script type="math/tex; mode=display">P_l(x)=\sum_{k=0}^{[l/2]}(-1)^k\frac{(2l-2k)!}{2^l k! (l-k)!(l-2k)!}x^{l-2k}</script><p>常用：</p><script type="math/tex; mode=display">\begin{aligned}& P_0(x)=1\\&P_1(x)=x\\&P_2(x)=\frac{1}{2}(3x^2-1)\\&P_3(x)=\frac{1}{2}(5x^3-3x)\\&P_4(x)=\frac{1}{8}(35x^4-30x^2+3)\\&------------\\&P_1^1(x)\\&------------\\&P_l(1)=1\\&P_l(-1)=(-1)^l\\& P_{2n}(0)=(-1)^{n}\frac{(2l-1)!!}{(2l)!!}\\& P_{2n+1}(0)=0\end{aligned}</script><h4 id="（2）勒让德函数的相关性质"><a href="#（2）勒让德函数的相关性质" class="headerlink" title="（2）勒让德函数的相关性质"></a>（2）勒让德函数的相关性质</h4><ul><li><p>微分表示—罗德里格斯公式</p><script type="math/tex; mode=display">P_l(x)=\frac{1}{2^l l!}\frac{d^l}{dx^{l}}(x^2-1)^l</script></li><li><p>环路积分表示—施列夫利积分</p><script type="math/tex; mode=display">P_l(x)=\frac{1}{2\pi i}\frac{1}{2^l}\oint\frac{(z^2-1)^l}{(z-x)^{l+1}}dz</script></li><li><p>定积分表示—拉普拉斯积分</p><script type="math/tex; mode=display">\begin{aligned}take\quad z&=x+\sqrt {x^2-1}e^{i\psi}\\\implies P_l(x)&=\frac{1}{\pi}\int_{0}^{\pi}\big[x+i\sqrt{1-x^2}\cos \psi\big]^l d\psi\\&=\frac{1}{\pi}\int_0^{\pi}\big[\cos \theta+i\sin \theta\cos \psi]^l d\psi\end{aligned}</script></li><li><p>模</p><script type="math/tex; mode=display">N_l=\sqrt{\frac{2}{2l+1}}</script><p>推导过程中用到不断地分部积分。</p></li></ul><ul><li><p>正交关系和广义傅里叶级数</p><script type="math/tex; mode=display">\begin{aligned}&f(x)=\sum_{l=0}^\infty f_lP_l(x)\\&f_l=\frac{2l+1}{2}\int_{-1}^{1}f(x)P_l(x)dx\\or: &f_l=\frac{2l+1}{2}\int_{-\pi}^{\pi}f(\theta)P_l(\cos\theta)\sin\theta d\theta\end{aligned}</script></li><li><p>生成函数（母函数）</p><script type="math/tex; mode=display">\frac{1}{\sqrt{1-2r\cos\theta+r^2}}=\begin{cases}\sum\limits_{l=0}^\infty r^l P_l(\cos\theta)\quad(r<1)\\\sum\limits_{l=0}^\infty \frac{1}{r^{l+1}}P_l(\cos\theta)\quad(r>1)\end{cases}\notag</script><p>一般情况：</p><script type="math/tex; mode=display">\frac{1}{\sqrt{R^2-2Rr\cos\theta+r^2}}=\begin{cases}\sum\limits_{l=0}^\infty \frac{r^l}{R^{l+1}} P_l(\cos\theta)\quad (r<R)\\\sum\limits_{l=0}^\infty \frac{R^l}{r^{l+1}}P_l(\cos\theta)\quad(r>R)\end{cases}</script><p>或：</p><script type="math/tex; mode=display">\frac{1}{\sqrt{R^2-2Rrx+r^2}}=\begin{cases}\sum\limits_{l=0}^\infty \frac{r^l}{R^{l+1}} P_l(x)\quad (r<R)\\\sum\limits_{l=0}^\infty \frac{R^l}{r^{l+1}}P_l(x)\quad(r>R)\end{cases}</script></li><li><p>递推关系</p><p>生成函数两边对 $r$ 求导，比较 $r^k$ 系数，可得：</p><script type="math/tex; mode=display">(k+1)P_{k+1}(x)=(2k+1)xP_k(x)-kP_{k-1}(x)</script></li></ul><p>​       生成函数两边对 $x$ 求导，比较 $r^k$ 系数，可得：</p><script type="math/tex; mode=display">P_k(x)=P'_{k+1}(x)-2xP'_k(x)+P'_{k-1}(x)\notag</script><h4 id="（3）勒让德方程的一般解"><a href="#（3）勒让德方程的一般解" class="headerlink" title="（3）勒让德方程的一般解"></a>（3）勒让德方程的一般解</h4><ul><li><p>第二类勒让德函数</p></li><li><p>勒让德方程的一般解</p></li></ul><h4 id="（4）拉普拉斯方程的轴对称定解问题"><a href="#（4）拉普拉斯方程的轴对称定解问题" class="headerlink" title="（4）拉普拉斯方程的轴对称定解问题"></a>（4）拉普拉斯方程的轴对称定解问题</h4><ul><li>半球的稳定温度分布</li><li>均匀介质球的静电场分布</li></ul><h3 id="5-2-连带勒让德函数"><a href="#5-2-连带勒让德函数" class="headerlink" title="5.2 连带勒让德函数"></a>5.2 连带勒让德函数</h3><ul><li><p>来源：连带勒让德方程</p><script type="math/tex; mode=display">(1-x^2)y''-2xy'+\left[l(l+1)-\frac {m^2} {1-x^2}\right]y=0\notag</script></li><li><p>表达式</p></li></ul><script type="math/tex; mode=display">P_l^m(x)=(1-x^2)^{\frac{m}{2}}P_l^{[m]}(x)</script><ul><li>常见<script type="math/tex; mode=display">\begin{aligned}&P_1^1(\cos\theta)=\sin\theta\\&P_2^2(\cos\theta)=3\sin^2\theta\end{aligned}</script></li></ul><ul><li><p>微分表示—罗德里格斯公式</p><script type="math/tex; mode=display">P_l^m (x)=\frac{(1-x^2)^{\frac{m}{2}}}{2^l l!}\frac{d^{l+m}}{dx^{l+m}}(x^2-1)^l</script></li><li></li></ul><script type="math/tex; mode=display">P_l^{m}(x)=(-1)^m\frac{(l+m)!}{(l-m)!}P_l^{-m}(x)</script><ul><li><p>环路积分表示—施列夫利积分</p></li><li><p>定积分表示—拉普拉斯积分</p></li><li><p>模</p><script type="math/tex; mode=display">N_l^m=\sqrt{\frac{(l+m)!}{(l-m)!}\frac{2}{2l+1}}</script></li><li><p>递推关系</p></li><li><p>正交关系和广义傅里叶级数</p><script type="math/tex; mode=display">\begin{aligned}&f(x)=\sum_{l=m}^\infty  f_l P_l^m (x)\\&f_l=\frac{(l-m)!}{(l+m)!}\frac {2l+1}{2}\int_{-1}^1 f(x)P_l^m (x)dx\end{aligned}</script></li></ul><h3 id="5-3-一般的球函数"><a href="#5-3-一般的球函数" class="headerlink" title="5.3 一般的球函数"></a>5.3 一般的球函数</h3><h4 id="（1）球函数方程"><a href="#（1）球函数方程" class="headerlink" title="（1）球函数方程"></a>（1）球函数方程</h4><p>​    拉普拉斯方程的角度部分。</p><script type="math/tex; mode=display">\frac{1}{\sin\theta}\frac{\partial}{\partial\theta}\left(\sin\theta\frac{\partial Y}{\partial\theta}\right)+\frac{1}{\sin^2\theta}\frac{\partial^2 Y}{\partial \varphi^2}+l(l+1)Y=0</script><h4 id="（2）球函数基本性质"><a href="#（2）球函数基本性质" class="headerlink" title="（2）球函数基本性质"></a>（2）球函数基本性质</h4><ul><li>球函数表达式<script type="math/tex; mode=display">Y(\theta,\varphi)=P_l^m(\cos \theta)\left\{\begin{aligned}\cos m\varphi\\\sin m\varphi\end{aligned}\right\}</script>其中大括号表示任选其一， $m=0,\dots,l;\quad l=0,1,2,\dots$</li></ul><p>  复数形式</p><script type="math/tex; mode=display">  Y(\theta,\varphi)=P_l^{|m|}(\cos \theta)e^{im\varphi}  \notag</script><p>其中 $m=-l,\dots,l;\quad l=0,1,2,\dots 。$</p><ul><li><p>球函数的模</p><script type="math/tex; mode=display">N_l^m=\sqrt{\frac{2\pi\delta_m }{2l+1}\frac{(l+m)!}{(l-m)!}}</script><p>其中，$\delta_m=\begin{cases}2,m=0\1,m\neq0\end{cases}$ .</p><p>复数形式的模：</p><script type="math/tex; mode=display">N_l^m=\sqrt{\frac{4\pi }{2l+1}\frac{(l+|m|)!}{(l-|m|)!}}\notag</script></li><li><p>球函数正交关系与球面上函数的广义傅里叶级数</p><script type="math/tex; mode=display">\begin{aligned}& f(\theta,\varphi)=\sum_{l=m}^\infty\sum_{m=0}^\infty \left[A_l^m\cos m\varphi+B_l^m\sin m\varphi\right]P_l^m(\cos \theta)\\& A_l^m = \frac{2l+1}{2\pi\delta_m}\frac{(l-m)!}{(l+m)!}\int_0^{\pi}\int_0 ^{2\pi} f(\theta,\varphi)P_l^m(\cos \theta)\cos m\varphi \sin\theta \ d\theta d\varphi\\& B_l^m = \frac{2l+1}{2\pi}\frac{(l-m)!}{(l+m)!}\int_0^{\pi}\int_0 ^{2\pi} f(\theta,\varphi)P_l^m(\cos \theta)\sin m\varphi \sin\theta \ d\theta d\varphi\end{aligned}</script><p>对简单函数的展开方法：</p><p>​        首先按照 $m$ 分类对 $\varphi$ 展开，然后对每一项前面的系数 $f(\theta)$ 用 $P_l^m$ （这时 $m$ 已经是确定的数）展开。</p></li></ul><ul><li><p>正交归一化的球函数</p><p>​    物理常用，这个以及球函数的复数形式、加法公式等考完试再用到时专门整理。</p></li></ul><h4 id="（3）球函数的应用"><a href="#（3）球函数的应用" class="headerlink" title="（3）球函数的应用"></a>（3）球函数的应用</h4><p><strong>拉普拉斯方程的非轴对称定解问题</strong></p><p>​    拉普拉斯方程在非轴对称情况下的一般解为:</p><script type="math/tex; mode=display">\begin{align}u(r,\theta,\varphi)=\sum_{l=m}^\infty &\sum_{m=0}^\infty  r^l \left[A_l^m\cos m\varphi+B_l^m\sin m\varphi\right]P_l^m(\cos \theta)+\notag\\ &\sum_{l=m}^\infty\sum_{m=0}^\infty\frac 1 {r^{l+1}} \left[C_l^m\cos m\varphi+D_l^m\sin m\varphi\right]P_l^m(\cos \theta)\end{align}</script><h2 id="六-柱函数"><a href="#六-柱函数" class="headerlink" title="六 柱函数"></a>六 柱函数</h2><h3 id="6-1-柱函数的导出"><a href="#6-1-柱函数的导出" class="headerlink" title="6.1 柱函数的导出"></a>6.1 柱函数的导出</h3><h4 id="柱坐标拉普拉斯方程"><a href="#柱坐标拉普拉斯方程" class="headerlink" title="柱坐标拉普拉斯方程"></a>柱坐标拉普拉斯方程</h4><script type="math/tex; mode=display">\begin{aligned}&\Delta u=0\\\\\implies& \begin{cases}\Phi''+m^2\Phi=0,\\Z''-\mu Z=0,\\\rho^2 R''+\rho R+(\mu\rho^2-m^2)R=0\end{cases}\end{aligned}\\</script><script type="math/tex; mode=display">\begin{aligned}&\mu=0:u=\left\{\begin{aligned}1\\z\end{aligned}\right\}\left\{\begin{aligned}&1\\ &\ln\rho\end{aligned}\right\}+\left\{\begin{aligned}1\\z\end{aligned}\right\}\left\{\begin{aligned}\cos m\varphi\\ \sin m\varphi \end{aligned}\right\}\left\{\begin{aligned}&\rho^m\\ &1/\rho^{m}\end{aligned}\right\}\\\\&\mu>0:u=\left\{\begin{aligned}e^{\sqrt\mu z}\\e^{-\sqrt\mu z}\end{aligned}\right\}\left\{\begin{aligned}\cos m\varphi\\ \sin m\varphi \end{aligned}\right\}\left\{\begin{aligned}J_m(\sqrt\mu \rho)\\N_m(\sqrt\mu \rho)\\\end{aligned}\right\}\\\\&\mu<0: 虚宗量 \quad待完善\\&u=\left\{\begin{aligned}\cos\sqrt{-\mu} z\\\sin\sqrt{-\mu} z\end{aligned}\right\}\left\{\begin{aligned}\cos m\varphi\\ \sin m\varphi \end{aligned}\right\}\left\{\begin{aligned}J_m(\sqrt{-\mu} \rho)\\N_m(\sqrt{-\mu} \rho)\\\end{aligned}\right\}\\\end{aligned}</script><h4 id="球坐标亥姆霍兹方程"><a href="#球坐标亥姆霍兹方程" class="headerlink" title="球坐标亥姆霍兹方程"></a>球坐标亥姆霍兹方程</h4><p>球贝塞尔方程。</p><h4 id="柱坐标亥姆霍兹方程"><a href="#柱坐标亥姆霍兹方程" class="headerlink" title="柱坐标亥姆霍兹方程"></a>柱坐标亥姆霍兹方程</h4><script type="math/tex; mode=display">\begin{aligned}&\Delta v+k^2v=0\\\\\implies& \begin{cases}\Phi''+m^2\Phi=0,\\Z''+\nu^2 Z=0,\\\displaystyle R''+\frac{1}{\rho} R+(k^2-\nu^2-\frac{m^2}{\rho^2})R=0\end{cases}\end{aligned}\\</script><p>注意， $z$ 轴的齐次边界条件保证了 $\nu^2$  一定是大于 $0$ 的，否则 $Z$ 为 $e$ 指数形式，不可能为 $0$ .</p><p>令 $\mu’\equiv k^2-\nu^2$, 则 $\rho$ 方向的齐次边界条件保证了 $\mu’$ 是大于等于 $0$ 的（贝塞尔函数的正零点）.</p><p>另外，$\mu’$ 作为贝塞尔函数的零点可以得到具体值， $\nu$  作为 $Z$ 的本征值可以由边界条件确定。</p><p>而 $k^2$ 是最先设的本征值，可由 $k^2=\mu’+\nu^2$ 得到。</p><script type="math/tex; mode=display">\begin{aligned}&\mu'=0 : u=\left\{\begin{aligned}\cos\nu z\\ \sin\nu z\end{aligned}\right\}\left\{\begin{aligned}1\\ \ln\rho\end{aligned}\right\}+\left\{\begin{aligned}\cos\nu z\\ \sin\nu z\end{aligned}\right\}\left\{\begin{aligned}\cos m\varphi\\ \sin m\varphi\end{aligned}\right\}\left\{\begin{aligned}\rho^m \\ \rho^{-m}\end{aligned}\right\}\\\\&\mu'\neq 0:u=\left\{\begin{aligned}\cos\nu z\\ \sin\nu z\end{aligned}\right\}\left\{\begin{aligned}\cos m\varphi\\ \sin m\varphi\end{aligned}\right\}\left\{\begin{aligned}J_m(\sqrt{\mu'}\rho)\\N_m(\sqrt{\mu'}\rho) \end{aligned}\right\}\\&(if\quad \nu=0,\quad then\quad Z=\left\{\begin{aligned}1\\ z\end{aligned}\right\})\end{aligned}</script><h3 id="6-2-柱函数的性质"><a href="#6-2-柱函数的性质" class="headerlink" title="6.2 柱函数的性质"></a>6.2 柱函数的性质</h3><h4 id="1-贝塞尔函数"><a href="#1-贝塞尔函数" class="headerlink" title="(1) 贝塞尔函数"></a>(1) 贝塞尔函数</h4><ul><li><p>公式</p><script type="math/tex; mode=display">J_\nu(x)=\sum_{k=0}^\infty \frac{(-1)^k}{k!\Gamma(\nu+k+1)}\left(\frac x 2 \right)^{2k+\nu}</script></li><li><p>递推关系</p><script type="math/tex; mode=display">\begin{aligned}&\frac{d}{dx}\left[x^\nu Z_\nu(x)\right]=x^{\nu}Z_{\nu-1}(x)\\&\frac{d}{dx}\left[\frac{Z_\nu(x)}{x^\nu} \right]=-\frac{Z_{\nu}(x)}{x^{\nu+1}}\\&-------------\\(展开)\quad & Z_\nu'(x) +\frac{\nu}{x}Z_\nu(x)=Z_{\nu-1}(x)\\&Z_\nu'(x) -\frac{\nu}{x}Z_\nu(x)=-Z_{\nu+1}(x)\\&-------------\\&Z'_\nu(x)=\frac{1}{2}\left[Z_{\nu+1}(x)-Z_{\nu-1}(x)\right]\\& Z_{\nu+1}(x)-2\frac{\nu}{x}Z_\nu(x)+Z_{\nu-1}(x)=0\end{aligned}</script></li><li><p>生成函数</p><script type="math/tex; mode=display">\begin{aligned}& e^{\frac 1 2 x(z-\frac 1 z)}=\sum_{m=-\infty}^\infty J_m(x)z^m\\take \ z=e^{i\theta}:\quad &e^{ix\sin\theta}=\sum_{m=-\infty}^\infty J_m(x) e^{im\theta}\end{aligned}</script></li></ul><p>​        求 $m$ 次导数，然后令 $z=0$ :</p><script type="math/tex; mode=display">J_m(x)=\frac{1}{2\pi i}\oint \frac{e^{\frac x 2 (z-\frac 1 z )}}{z^{m+1}}dz\notag</script><ul><li><p>渐近表示</p><script type="math/tex; mode=display">\lim_{x\to \infty}J_\nu(x)\approx\sqrt{\frac{2}{\pi x}}\cos(x-\frac{\pi}{4}-\frac{\nu}{2}\pi)</script></li><li><p>常用</p><script type="math/tex; mode=display">\begin{aligned}& J'_0(x)=-J_1(x)\\& J_0(0)=1\\& J_\nu(0)=0\quad (\nu\neq0)\end{aligned}</script></li><li><p>物理意义</p><script type="math/tex; mode=display">J_m(\sqrt{\mu'}\rho)e^{-ikat}\notag</script><p>在 $\rho$ 很大时对应驻波。</p></li></ul><ul><li>模</li></ul><ul><li>正交性</li></ul><h4 id="2-诺伊曼函数"><a href="#2-诺伊曼函数" class="headerlink" title="(2) 诺伊曼函数"></a>(2) 诺伊曼函数</h4><ul><li><p>公式</p><script type="math/tex; mode=display">N_\nu(x)=\frac{J_\nu (x)\cos \nu\pi-J_{-\nu}(x)}{\sin \nu\pi}</script></li><li><p>渐近表示</p><script type="math/tex; mode=display">\begin{aligned}&\lim_{x\to 0}N_\nu (x)\to \pm\infty \\&\lim_{x\to \infty}N_\nu(x)\approx\sqrt{\frac{2}{\pi x}}\sin(x-\frac{\pi}{4}-\frac{\nu}{2}\pi)\end{aligned}</script></li><li><p>物理意义</p><script type="math/tex; mode=display">  N_m(\sqrt{\mu'}\rho)e^{-ikat}\notag</script><p>在 $\rho$ 很大时对应驻波。</p></li></ul><h4 id="3-汉克尔函数"><a href="#3-汉克尔函数" class="headerlink" title="(3) 汉克尔函数"></a>(3) 汉克尔函数</h4><ul><li><p>公式</p><script type="math/tex; mode=display">\begin{aligned}&H^{(1)}_{\nu} (x)=J_\nu (x)+iN_{\nu}(x)\\&H^{(2)}_{\nu}(x)=J_\nu(x)-iN_\nu(x)\end{aligned}</script></li><li><p>渐近表示</p></li></ul><script type="math/tex; mode=display">H^{(1,2)}_\nu (x)\approx \sqrt{\frac{2}{\pi x}}e^{\pm i (x-\frac{\pi}{4}-\frac{\nu}{2}\pi)}\notag</script><ul><li><p>重要物理意义</p><script type="math/tex; mode=display">\begin{aligned}&H_m^{(1)}(\sqrt{\mu'}\rho)e^{-ikat}\approx \sqrt{\frac{2}{\pi\sqrt{\mu'\rho}}}e^{i(\sqrt{\mu'}\rho-kat-m\pi/2-\pi/4)}\\&H_m^{2}(\sqrt{\mu'}\rho)e^{-ikat}\approx \sqrt{\frac{2}{\pi\sqrt{\mu'\rho}}}e^{-i(\sqrt{\mu'}\rho+kat-m\pi/2-\pi/4)}\end{aligned}</script><p>分别表示发散波（$t$ 增大，若要收敛则 $\rho$ 也增大）和会聚波。</p></li></ul><ul><li>做题常用渐进表示（待研究）<script type="math/tex; mode=display">1+i\frac 2 \pi \ln \frac{\omega\rho}{2a}+iC</script></li></ul><h4 id="4-虚宗量贝塞尔函数"><a href="#4-虚宗量贝塞尔函数" class="headerlink" title="(4) 虚宗量贝塞尔函数"></a>(4) 虚宗量贝塞尔函数</h4><h4 id="5-球贝塞尔函数"><a href="#5-球贝塞尔函数" class="headerlink" title="(5) 球贝塞尔函数"></a>(5) 球贝塞尔函数</h4><h3 id="6-3-柱函数的应用"><a href="#6-3-柱函数的应用" class="headerlink" title="6.3 柱函数的应用"></a>6.3 柱函数的应用</h3><h2 id="七-格林函数法"><a href="#七-格林函数法" class="headerlink" title="七 格林函数法"></a>七 格林函数法</h2><h2 id="八-积分变换法"><a href="#八-积分变换法" class="headerlink" title="八 积分变换法"></a>八 积分变换法</h2><h3 id="8-1-傅立叶变换"><a href="#8-1-傅立叶变换" class="headerlink" title="8.1 傅立叶变换"></a>8.1 傅立叶变换</h3><h4 id="（1）定义"><a href="#（1）定义" class="headerlink" title="（1）定义"></a>（1）定义</h4><script type="math/tex; mode=display">\begin{align}F(\omega)&=\int_{-\infty}^\infty f(x)e^{-i\omega x} dx\\f(x)&=\frac 1 {2\pi}\int_{-\infty}^\infty F(\omega)e^{i\omega x}d\omega\end{align}</script><p>条件：有限个间断点+绝对可积</p><p>表示：为了方便，通常用大写表示变换后的，有时也用冒尖表示，$\omega$ 有时换成 $k$ 或 $\lambda$ , 即 $u(\vec r)\to U(\vec k),F(\omega),\hat f(k),\hat f(\lambda)$ 等等</p><h4 id="（2）重要性质"><a href="#（2）重要性质" class="headerlink" title="（2）重要性质"></a>（2）重要性质</h4><ul><li><p>伸缩 </p><script type="math/tex; mode=display">\mathcal{F}\left[f(ax)\right]=\frac 1 {|a|} F\left (\frac \omega a\right)</script></li><li><p>时移</p><script type="math/tex; mode=display">\mathcal{F}\left[f(x-x_0)\right]=e^{-i\omega x_0}F\left (\omega\right)</script></li><li><p>频移</p><script type="math/tex; mode=display">\mathcal{F}\left[f(x)e^{i\omega x_0}\right]=F\left (\omega-\omega_0\right)</script></li><li><p>求导</p><script type="math/tex; mode=display">\mathcal{F}\left[f'(x)\right]=i\omega F\left (\omega \right)</script></li><li><p>积分</p></li></ul><script type="math/tex; mode=display">\mathcal{F}\left[\int^{x}_{x_0}  f(\xi) d\xi \right]=\frac 1 {i\omega} F\left (\omega \right)</script><ul><li><p>乘多项式</p><script type="math/tex; mode=display">\mathcal{F}\left[x^k\cdot f(x)\right]=i^k\frac{d^k}{d\omega^k}F(\omega)</script></li><li><p>卷积</p><script type="math/tex; mode=display">\mathcal{F}\left[f_1(x)*f_2(x)\right]=F_1(\omega)\cdot F_2(\omega)</script></li><li><p>对称性</p><script type="math/tex; mode=display">\mathcal{F^{-1}}\left[f(x)\right](\omega)=\frac 1 {2\pi}\mathcal{F}\left[f(x)\right](-\omega)</script><p>例如：</p><script type="math/tex; mode=display">\begin{aligned}&\mathcal{F}\left[e^{-|x|}\right]=\frac 2 {1+\omega^2}\\\implies& \mathcal{F^{-1}}\left[\frac 2 {1+\omega^2}\right](x)=e^{-|x|}\\\implies &\mathcal{F}\left[\frac 2 {1+\omega^2}\right](x)=2\pi\cdot  e^{-|-x|}\\&i.e.\quad \mathcal{F}\left[\frac 1 {1+x^2}\right](\omega)=\pi e^{-|x|}\end{aligned}</script></li></ul><h4 id="（3）多重傅立叶积分"><a href="#（3）多重傅立叶积分" class="headerlink" title="（3）多重傅立叶积分"></a>（3）多重傅立叶积分</h4><p>对每个参数逐个进行变换。</p><script type="math/tex; mode=display">\begin{align}F(k_1,k_2,k_3)&=\iiint_{-\infty}^\infty f(x,y,z)e^{-i(k_1x+k_2y+k_3z)}dxdydz\\&=\int f(\vec r)e^{-i\vec k\cdot \vec r} d\vec k\\f(x,y,z)&=\frac 1 {(2\pi)^3}\iiint_{-\infty}^\infty F(k_1,k_2,k_3)e^{i(k_1x+k_2y+k_3z)}dk_1dk_2dk_3\\&=\frac 1 {(2\pi)^3}\int F(\vec k)e^{i\vec k\cdot \vec r}d\vec r\end{align}</script><h4 id="（4）常用变换"><a href="#（4）常用变换" class="headerlink" title="（4）常用变换"></a>（4）常用变换</h4><script type="math/tex; mode=display">\begin{align}\mathcal{F}\left[e^{-x^2}\right]&=\sqrt{\pi}e^{-\frac{\omega^2}{4}}\\\mathcal{F}\left[e^{-a|x|}\right]&=\frac{2a}{a^2+\omega^2}\\\mathcal{F}\left[\frac{a}{a^2+\omega^2}\right]&=\pi e^{-a|x|}\end{align}</script><h4 id="（5）应用"><a href="#（5）应用" class="headerlink" title="（5）应用"></a>（5）应用</h4><ul><li><p>证明 Helmholtz 定理</p></li><li><p>求解无界空间定解问题</p></li><li><p>求解半无界定解问题</p><p>​    作延拓，求解延拓到无界的方程，限制在半空间得到解。</p></li></ul><h3 id="8-2-拉普拉斯变换"><a href="#8-2-拉普拉斯变换" class="headerlink" title="8.2 拉普拉斯变换"></a>8.2 拉普拉斯变换</h3><h4 id="（1）定义-1"><a href="#（1）定义-1" class="headerlink" title="（1）定义"></a>（1）定义</h4><script type="math/tex; mode=display">\begin{align}\bar f(p)\equiv\mathcal{L}\left[f(x)\right]&=\int_0^\infty f(t)e^{-pt}dt\\f(t)=\mathcal{L}^{-1}\left[\bar f(p)\right]&=\frac{1}{2\pi i}\int_{\sigma-i\infty}^{\sigma+i\infty} \bar f(p)e^{pt}dp\end{align}</script><h4 id="（2）性质"><a href="#（2）性质" class="headerlink" title="（2）性质"></a>（2）性质</h4><h4 id="（3）常用变换"><a href="#（3）常用变换" class="headerlink" title="（3）常用变换"></a>（3）常用变换</h4><h4 id="（4）黎曼-梅林反演公式"><a href="#（4）黎曼-梅林反演公式" class="headerlink" title="（4）黎曼-梅林反演公式"></a>（4）黎曼-梅林反演公式</h4><h4 id="（5）求定解问题"><a href="#（5）求定解问题" class="headerlink" title="（5）求定解问题"></a>（5）求定解问题</h4><h2 id="九-保角变换法"><a href="#九-保角变换法" class="headerlink" title="九 保角变换法"></a>九 保角变换法</h2><h3 id="9-1-分式线型变换"><a href="#9-1-分式线型变换" class="headerlink" title="9.1 分式线型变换"></a>9.1 分式线型变换</h3><script type="math/tex; mode=display">\zeta(z)=k\frac{z-\alpha}{z-\beta}</script><p>为了方便分析可以选取 $k=1$ 或 $k=-1$ 。</p><p>重要性质：</p><ul><li>广义圆 $\mapsto$ 广义圆</li><li>保持对称性</li></ul><h3 id="9-2-儒可夫斯基变换"><a href="#9-2-儒可夫斯基变换" class="headerlink" title="9.2 儒可夫斯基变换"></a>9.2 儒可夫斯基变换</h3><script type="math/tex; mode=display">\zeta(z)=\frac{C}{2}\left(z+\frac{1}{z}\right)</script><p>令 $z=\rho_0 e^{i\varphi}$ 可以发现：</p><p> $\zeta$ 可以将 $z$ 平面上的圆 $\displaystyle x^2 +y^2 =\rho_0^2$ 变为 $\zeta$  平面上的椭圆 $\displaystyle\frac{x^2}{a^2}+\frac{y^2}{b^2}=1$, </p><p>其中 $a=\displaystyle\frac C 2 \left(\rho_0+\frac{1}{\rho_0}\right)$, $b=\displaystyle\frac C 2 \left(\rho_0-\frac{1}{\rho_0}\right)$</p><p>通常是将椭圆变为圆：</p><script type="math/tex; mode=display">z=\frac{C}{2}\left(\zeta+\frac{1}{\zeta}\right)</script><p>反解出来  $\zeta$ 可以将 $z$ 平面的椭圆 $\displaystyle\frac{x^2}{a^2}+\frac{y^2}{b^2}=1$ 变为 $\zeta$ 平面的圆 $\displaystyle x^2 +y^2 =\rho_0^2$ 。</p><p>确定参数：已知 $a,b$ ，求解 $C,\rho_0$ 即可：</p><script type="math/tex; mode=display">\begin{align}C&=\sqrt{a^2-b^2}\\\rho&=\frac{a+b}{C}=\frac{a+b}{\sqrt{a^2-b^2}}\end{align}</script><h3 id="9-3-常见构型"><a href="#9-3-常见构型" class="headerlink" title="9.3 常见构型"></a>9.3 常见构型</h3><h4 id="（1）角形域"><a href="#（1）角形域" class="headerlink" title="（1）角形域"></a>（1）角形域</h4><ul><li><p>利用  $\zeta=e^{i\varphi}\cdot z$ 可将其旋转，使一条边和实轴正半轴重合</p></li><li><p>再利用 $\zeta =z^\alpha$ 将其展平为半平面</p></li></ul><h4 id="（2）上半平面"><a href="#（2）上半平面" class="headerlink" title="（2）上半平面"></a>（2）上半平面</h4><script type="math/tex; mode=display">\zeta(z)=\frac{z-i}{z+i}\notag</script><p>$i\mapsto 0,-i\mapsto \infty$</p><p>原来的两点关于界面对称，新的两点只能关于圆对称，边界必须变成圆。</p><p>将上半平面变换为实心圆柱，代入 $z=0$ 确定半径为 $1$ 。</p><h4 id="（3）平行圆柱或圆柱-直线"><a href="#（3）平行圆柱或圆柱-直线" class="headerlink" title="（3）平行圆柱或圆柱-直线"></a>（3）平行圆柱或圆柱-直线</h4><p>直线是广义圆。</p><p>不妨把两点放到 $x$ 轴上, 以左边的圆的圆心为原点, 两圆相距 $d$ 。</p><p>寻找两圆的公共对称点 $z=a$ 和 $z=b$ :</p><script type="math/tex; mode=display">\begin{aligned}ab&=R_1^2\\(d-a)(d-b)&=R_2^2\end{aligned}</script><p>可以解出 $a,b$ 。</p><p>$a\mapsto 0,b\mapsto \infty$ :</p><script type="math/tex; mode=display">\zeta(z)=\frac{z-a}{z-b}</script><p>可将平行圆变为同心圆。代入 $z$ 平面平行圆的边界点可以确定同心圆的内外径。</p><h4 id="（4）弓形或两圆相交区域"><a href="#（4）弓形或两圆相交区域" class="headerlink" title="（4）弓形或两圆相交区域"></a>（4）弓形或两圆相交区域</h4><ul><li><p>先找到广义圆的两个交点，用分式线型变换把一个变到 $0$ ，另一个变到 $\infty$ </p></li><li><p>由于保角性，交角不变，弓形或者两圆相交区域变为一个角形区域（这是由于 $z$ 平面上的两段广义圆弧变成了 $\zeta$ 平面上的过 $0$ 和 $\infty$ 的广义圆弧，半径为 $\infty$ 只能是两条过原点的射线）</p></li><li><p>再进行（1）和（2）即可</p></li></ul><h3 id="9-4-常用电势电容结论"><a href="#9-4-常用电势电容结论" class="headerlink" title="9.4 常用电势电容结论"></a>9.4 常用电势电容结论</h3><h4 id="（1）同轴圆柱单位电容"><a href="#（1）同轴圆柱单位电容" class="headerlink" title="（1）同轴圆柱单位电容"></a>（1）同轴圆柱单位电容</h4><script type="math/tex; mode=display">C=\frac{2\pi \varepsilon_0}{\ln (R_1/R_2)}</script><p>证明：</p><p>​        利用 $\zeta(z)=\ln z=\ln|z|+i Argz$ 将同轴圆柱变为平行板电容器</p><p>​        $\displaystyle C\cdot l=\frac{\varepsilon_0A}{d}=\frac{\varepsilon\cdot 2\pi\cdot l}{\ln(R_1/R_2)}\implies C=\frac{2\pi\varepsilon_0}{\ln(R_1/R_2)}$</p><h4 id="（2）接地金属圆柱壳-中心细导线电势分布"><a href="#（2）接地金属圆柱壳-中心细导线电势分布" class="headerlink" title="（2）接地金属圆柱壳+中心细导线电势分布"></a>（2）接地金属圆柱壳+中心细导线电势分布</h4><p>设金属圆柱壳的半径为 $a$ 。</p><script type="math/tex; mode=display">u=\frac{\lambda}{2\pi\varepsilon_0}\ln\left(\frac{a}{|\zeta|} \right)</script><p>证明：</p><p>​        由高斯定律 $\displaystyle E\cdot 2\pi rl=\lambda l/\varepsilon_0\implies E=\frac{\lambda}{2\pi\varepsilon_0}\frac 1 r$</p><p>​        $\therefore u(\zeta(z))=\displaystyle\int^\mathcal{O}_{|\zeta|}\vec E\cdot d\vec \ell=\frac{\lambda}{2\pi\varepsilon_0}\ln\left(\frac{a}{|\zeta|} \right)$</p><h4 id="（3）导体圆柱周围电势分布"><a href="#（3）导体圆柱周围电势分布" class="headerlink" title="（3）导体圆柱周围电势分布"></a>（3）导体圆柱周围电势分布</h4><script type="math/tex; mode=display">u=c_1\ln|\zeta|+c_2</script><p>证明：</p><p>​        由柱坐标拉普拉斯方程 $\displaystyle\Delta u=0\implies\frac {1}{r}\frac{\partial}{\partial r}\left(r\frac{\partial u}{\partial r}\right)=0$ </p><p>​        得到通解为 $u=c_1\ln|\zeta|+c_2$</p><p>​        $c_2$ 和零电势点的选取有关，可以令其为0 </p><p>​        $c_1$ 的确定见书 $Page -{308}$  </p><p>​         $|\zeta|\to0,|\zeta|\to \infty$ 时导致的发散是由于点电荷和无穷长导线都是理想的物理模型。</p>]]></content>
      
      
      <categories>
          
          <category> Physics </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>Theoretical Mechanics</title>
      <link href="/2020/02/18/Physics/Theoretical-mechanics/"/>
      <url>/2020/02/18/Physics/Theoretical-mechanics/</url>
      
        <content type="html"><![CDATA[<h1 id="理论力学笔记"><a href="#理论力学笔记" class="headerlink" title="理论力学笔记"></a>理论力学笔记</h1><p>ing～</p>]]></content>
      
      
      <categories>
          
          <category> Physics </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>Electromagnetism</title>
      <link href="/2020/02/18/Physics/Electromagnetism/"/>
      <url>/2020/02/18/Physics/Electromagnetism/</url>
      
        <content type="html"><![CDATA[<h1 id="电动力学笔记"><a href="#电动力学笔记" class="headerlink" title="电动力学笔记"></a>电动力学笔记</h1><h2 id="0-麦克斯韦方程和规范理论概述起源（杨振宁）"><a href="#0-麦克斯韦方程和规范理论概述起源（杨振宁）" class="headerlink" title="0 麦克斯韦方程和规范理论概述起源（杨振宁）"></a>0 麦克斯韦方程和规范理论概述起源（杨振宁）</h2><ul><li><p>Electrotonic state, Faraday    </p><script type="math/tex; mode=display">H=\nabla \times A</script></li><li><p>Maxwell</p><script type="math/tex; mode=display">Light=EM\ waves</script></li><li><p>Maxwell : A Dynamical Theory of the Electromagnetic Field</p><script type="math/tex; mode=display">energy\;\ density=\frac{1}{8\pi ^2}(E^2+H^2)</script></li><li><p>Dirac‘s sea</p></li><li><p>Renormalization</p><script type="math/tex; mode=display">\alpha=(g-2)/2</script></li><li><p>gauge theory 规范理论, non-Abelian gauge theory, 重整化群</p></li><li>Symmetry breaking, Standard Mode </li></ul><p><strong>“妙的地方”</strong></p><p>$ \ $ <a id="more"></a></p><h2 id="1-矢量分析整理"><a href="#1-矢量分析整理" class="headerlink" title="1 矢量分析整理"></a>1 矢量分析整理</h2><h3 id="符号约定"><a href="#符号约定" class="headerlink" title="符号约定"></a>符号约定</h3><ul><li><p>Kronecker</p><script type="math/tex; mode=display">\delta_{ij}=\begin{cases}1\quad i=j,\\0 \quad i\neq j.\end{cases}\notag</script></li><li><p>Levi-Civita</p></li></ul><script type="math/tex; mode=display">\varepsilon_{ijk}=\begin{cases}1\quad (ijk)偶排列,\\ -1 \quad (ijk)奇排列, \\0 \quad 下标中有两个相等.\end{cases}\notag</script><ul><li><script type="math/tex; mode=display">\begin{aligned}&\varepsilon_{ijk}\varepsilon_{lmn}=\left|\begin{array}{cccc}     \delta_{il} & \delta_{im} &  \delta_{in}\\      \delta_{jl}& \delta_{jm}& \delta_{jn}\\     \delta_{kl}& \delta_{km}& \delta_{kn}\end{array}\right|\\&\varepsilon_{ijk}\varepsilon_{lmk}=\delta_{il}-\delta_{jm}\end{aligned}</script></li></ul><ul><li>Einstein 求和约定<script type="math/tex; mode=display">A_i\vec e_i\equiv \sum_{i=1}^n A_i\vec e_i=\vec A\notag</script></li></ul><h3 id="点乘和叉乘"><a href="#点乘和叉乘" class="headerlink" title="点乘和叉乘"></a>点乘和叉乘</h3><script type="math/tex; mode=display">\begin{aligned}&\vec A\times \vec B=A_iB_j\varepsilon_{ijk}\vec e_k=\left|\begin{array}{cccc}     \vec e_x & \vec e_y & \vec e_z \\     B_x & B_y & B_z\\     C_x & C_y & C_z \end{array}\right|\\&\vec A\cdot (\vec B\times\vec C)=\vec B\cdot (\vec C\times \vec A)=\vec C\cdot (\vec A\times \vec B)=\left|\begin{array}{cccc}     A_x & A_y & A_z \\     B_x & B_y & B_z\\     C_x & C_y & C_z \end{array}\right| \\& \vec A\times (\vec B\times\vec C)=(\vec A\cdot \vec C)\vec B-(\vec A\cdot \vec B)\vec C\\& (\vec A\times \vec B)\times \vec C=(\vec A\cdot \vec C)\vec B-(\vec B\cdot\vec C)\vec A\end{aligned}</script><h3 id="多元微分"><a href="#多元微分" class="headerlink" title="多元微分"></a>多元微分</h3><h4 id="1-理解"><a href="#1-理解" class="headerlink" title="1. 理解"></a>1. 理解</h4><p>（1）多元标量函数求导：梯度</p><p>（2）矢量函数求导可以看成有两种：散度、旋度</p><p>（3）标量函数可以求梯度，但无法求散度和旋度</p><p>（4）矢量函数可以求散度和旋度，但无法求梯度</p><h4 id="2-积规则"><a href="#2-积规则" class="headerlink" title="2. 积规则"></a>2. 积规则</h4><h4 id="（1）梯度"><a href="#（1）梯度" class="headerlink" title="（1）梯度"></a>（1）梯度</h4><ul><li><p>乘积</p><script type="math/tex; mode=display">\nabla(fg)=f\nabla g+g\nabla f\notag</script></li><li></li></ul><script type="math/tex; mode=display">\nabla(\frac{f}{g})=\frac{g\nabla f-f\nabla g}{g^2}\notag</script><ul><li>复合</li></ul><script type="math/tex; mode=display">\nabla [f(g)]=\nabla f\odot \nabla g\notag</script><ul><li>点乘</li></ul><script type="math/tex; mode=display">\nabla(\vec A\cdot \vec B)=\vec A\times(\nabla \times\vec B)+\vec B\times(\nabla\times\vec A)+(\vec A \cdot \nabla)\vec B+(\vec B\cdot \nabla )\vec A\notag</script><p>​    </p><p>注意梯度算符同时具有矢量性和微分性。</p><h4 id="（2）散度"><a href="#（2）散度" class="headerlink" title="（2）散度"></a>（2）散度</h4><ul><li><script type="math/tex; mode=display">\nabla \cdot (f\vec A)=(\nabla f)\cdot\vec A+f (\nabla \cdot \vec A)\notag</script></li></ul><ul><li><script type="math/tex; mode=display">\nabla\cdot(\frac{\vec A}{g})=\frac{(\nabla\cdot \vec A)g-(\nabla g)\cdot \vec A}{g^2}\notag</script></li></ul><ul><li><script type="math/tex; mode=display">\nabla \cdot (\vec A\times \vec B)=\vec B\cdot (\nabla \times\vec A)-\vec A\cdot (\nabla\times \vec B)\notag</script></li></ul><h4 id="（3）旋度"><a href="#（3）旋度" class="headerlink" title="（3）旋度"></a>（3）旋度</h4><ul><li><script type="math/tex; mode=display">\nabla\times(f\vec A)=(\nabla f)\times \vec A+f(\nabla\times \vec A)\notag</script></li></ul><ul><li><script type="math/tex; mode=display">\nabla\times(\frac{\vec A}{g})=\frac{(\nabla\times\vec A)g-(\nabla g)\times\vec A}{g^2}\notag</script></li></ul><ul><li><script type="math/tex; mode=display">\nabla\times(\vec A\times \vec B)=(\nabla\cdot \vec B)\vec A-(\nabla\cdot \vec A)\vec B+(\vec B\cdot \nabla)\vec A-(\vec A\cdot \nabla)\vec B\notag</script></li></ul><h4 id="（4）二阶微分"><a href="#（4）二阶微分" class="headerlink" title="（4）二阶微分"></a>（4）二阶微分</h4><ul><li><p>Laplace</p><script type="math/tex; mode=display">\Delta T\triangleq\nabla\cdot \nabla T\notag</script></li><li><p>梯度的旋度为零</p><script type="math/tex; mode=display">\nabla\times(\nabla T)=0\notag</script></li><li><p>旋度的旋度</p><script type="math/tex; mode=display">\nabla\times(\nabla\times\vec A)=\nabla(\nabla\cdot \vec A)-\nabla^2 \vec A\notag</script></li></ul><h4 id="3-波常用"><a href="#3-波常用" class="headerlink" title="3. 波常用"></a>3. 波常用</h4><ul><li><script type="math/tex; mode=display">\begin{align}\nabla e^{i\vec k\cdot \vec r}&=i\vec k e^{i\vec k\cdot \vec r}\\\nabla^2e^{i\vec k\cdot \vec r}&=\nabla\cdot(\nabla e^{i\vec k\cdot \vec r})\notag\\&=i(\nabla\cdot\vec k)e^{i\vec k\cdot \vec r}+i(\nabla e^{i\vec k\cdot\vec r})\cdot\vec k\notag\\&=-k^2 e^{i\vec k\cdot \vec r}\end{align}</script></li><li><p>平面波 $ \vec E=\vec E_0 e^{i\vec k\cdot\vec r}$</p><script type="math/tex; mode=display">\begin{align}\nabla\cdot\vec E&=i\vec k \cdot \vec E\\\nabla\times\vec E&=i\vec k\times\vec E\\\end{align}</script></li></ul><h3 id="多元积分"><a href="#多元积分" class="headerlink" title="多元积分"></a>多元积分</h3><h4 id="1-总：广义Stokes​定理"><a href="#1-总：广义Stokes​定理" class="headerlink" title="1. 总：广义Stokes​定理"></a>1. 总：广义Stokes​定理</h4><script type="math/tex; mode=display">\int_V dw=\int_{\partial V}w</script><h4 id="2-理解"><a href="#2-理解" class="headerlink" title="2. 理解"></a>2. 理解</h4><p>（1）两边的矢量性/标量性要一致</p><p>（2）分两类，一类是两边都是标量，一类是两边都是矢量</p><h4 id="3-积分公式"><a href="#3-积分公式" class="headerlink" title="3. 积分公式"></a>3. 积分公式</h4><p>可以通过同时点乘或叉乘常矢量 $\vec c$ ，然后使用积规则（类似分布积分）证明出。</p><h4 id="（1）梯度-1"><a href="#（1）梯度-1" class="headerlink" title="（1）梯度"></a>（1）梯度</h4><ul><li>梯度的线积分不依赖于路径</li></ul><script type="math/tex; mode=display">\int _a^b (\nabla T)\cdot d\vec \ell=T(b)-T(a)\notag</script><ul><li><script type="math/tex; mode=display">\int_V (\nabla T)d\tau=\int_{\partial V}Td\vec\sigma\notag</script></li></ul><h4 id="（2）散度-1"><a href="#（2）散度-1" class="headerlink" title="（2）散度"></a>（2）散度</h4><ul><li><script type="math/tex; mode=display">(Gauss)\qquad \int_V(\nabla\cdot \vec A) d\tau=\int_{\partial V}\vec A\cdot d\vec \sigma\notag</script></li></ul><ul><li><script type="math/tex; mode=display">\int_S (\nabla\cdot \vec A)d\vec\sigma=\int_{\partial S}\vec A\times d\vec \ell\notag</script></li></ul><h4 id="（3）旋度-1"><a href="#（3）旋度-1" class="headerlink" title="（3）旋度"></a>（3）旋度</h4><ul><li><script type="math/tex; mode=display">\int _V(\nabla \times \vec A)d\tau=\int_{\partial V} d\vec \sigma\times\vec A=-\int_{\partial V}\vec A\times d\vec \sigma\notag</script></li></ul><p>​    注意 $\vec A$ 始终要在叉乘符号的右边</p><ul><li><script type="math/tex; mode=display">(Stokes)\qquad \int_S(\nabla\times\vec A)\cdot d\vec\sigma=\int_{\partial S}\vec A\cdot d\vec \ell\notag</script></li></ul><ul><li><script type="math/tex; mode=display">\int_S (\nabla T)\times d\vec \sigma=-\int_{\partial S}Td\vec \ell\notag</script></li></ul><p>​    注意左边是旋度积分而且两边都是矢量性的，如果右边积分变量写正常，多个负号</p><h3 id="狄拉克函数"><a href="#狄拉克函数" class="headerlink" title="狄拉克函数"></a>狄拉克函数</h3><ul><li>考虑一个正交的曲线坐标系，它由三个参数 $u,v,w$ 来确定（$u=const,v=const,w=const$ 的面互相垂直）。沿着三个相互垂直的方向的无穷小线元的长度分别是 $du/U,dv/V,dw/W$ 。则：</li></ul><script type="math/tex; mode=display">\delta^{(3)}(\vec x-\vec x')=\delta(u-u')\delta(v-v')\delta(w-w')UVW</script><ul><li><script type="math/tex; mode=display">-\nabla^2\frac{1}{|\vec r-\vec r'|^2}=\nabla \cdot (\frac{\vec r - \vec r'}{|\vec r-\vec r'|^3})=4\pi\delta^3(\vec r-\vec r')\notag</script></li></ul><h3 id="位置矢量-vec-r-相关"><a href="#位置矢量-vec-r-相关" class="headerlink" title="位置矢量 $\vec r$ 相关"></a>位置矢量 $\vec r$ 相关</h3><ul><li>定义</li></ul><script type="math/tex; mode=display">\vec r=x\vec e_x+y\vec e_y+z\vec e_z\\r=\sqrt{x^2+y^2+z^2}\notag</script><ul><li><p>$r$</p><script type="math/tex; mode=display">\begin{aligned}\nabla r=\frac{\vec r}{|r|}=\vec e_r\end{aligned}</script></li><li><p>$\vec r$</p></li></ul><script type="math/tex; mode=display">\begin{aligned}\nabla\cdot \vec r=3\\\nabla\times \vec r=0\end{aligned}</script><ul><li>$\displaystyle\frac{1}{r}$</li></ul><script type="math/tex; mode=display">\nabla(\frac{1}{r})=-\frac{\nabla r}{r^2}=-\frac{\vec e_r}{r^2}=-\frac{\vec r}{r^3}\notag</script><script type="math/tex; mode=display">\nabla^2 \frac{1}{r}=-4\pi\delta(r)\notag</script><ul><li>$\vec e_r$<script type="math/tex; mode=display">\nabla \cdot \vec e_r=\frac{2}{r}\notag</script></li></ul><ul><li>$\displaystyle \frac{\vec e_r}{r^2}$<script type="math/tex; mode=display">\notag\nabla\cdot \frac{\vec e_r}{r^2}=0\\\nabla\frac{\vec e_r}{r^2}=\frac{\nabla \vec r r^3-(\nabla r^3)\vec r}{r^6}=\frac{\overleftrightarrow I-3\vec e_r\vec e_r}{r^3}</script></li></ul><p>以上对 $\vec r-\vec r’$ 同样适用。</p><h3 id="张量相关"><a href="#张量相关" class="headerlink" title="张量相关"></a>张量相关</h3><script type="math/tex; mode=display">\begin{aligned}&\iint \vec e_r d\Omega =0\\&\iint \vec e_r\vec e_r d\Omega=\frac {4\pi}{3}\overleftrightarrow I\end{aligned}</script><h2 id="2-电磁学公式"><a href="#2-电磁学公式" class="headerlink" title="2 电磁学公式"></a>2 电磁学公式</h2><h3 id="高斯定律"><a href="#高斯定律" class="headerlink" title="高斯定律"></a>高斯定律</h3><script type="math/tex; mode=display">\nabla\cdot \vec E(\vec r)=\frac{\rho(r)}{\varepsilon_0}</script><h3 id="电流密度"><a href="#电流密度" class="headerlink" title="电流密度"></a>电流密度</h3><script type="math/tex; mode=display">\vec j=\rho_{+}\vec v_++\rho_-\vec v_-</script><h3 id="电荷的连续性方程"><a href="#电荷的连续性方程" class="headerlink" title="电荷的连续性方程"></a>电荷的连续性方程</h3><script type="math/tex; mode=display">\frac{\partial\rho}{\partial t}+\nabla\cdot \vec j=0</script><h3 id="毕奥—萨伐尔定律"><a href="#毕奥—萨伐尔定律" class="headerlink" title="毕奥—萨伐尔定律"></a>毕奥—萨伐尔定律</h3><script type="math/tex; mode=display">\begin{aligned}&d\vec B(\vec r)=\frac{\mu_0}{4\pi}\frac{\vec j(\vec r')\times \vec e(\vec r-\vec r')}{|\vec r-\vec r'|^2}d\tau'\\&\vec B(\vec r)=\frac{\mu_0}{4\pi}\int_V\frac{\vec j(\vec r')\times \vec e(\vec r-\vec r')}{|\vec r-\vec r'|^2}d\tau'=\nabla\times\vec A\\&\vec A=\frac{\mu_0}{4\pi}\int_V\frac{j(\vec r')}{|\vec r -\vec r'|}d\tau'\end{aligned}</script><h3 id="安培定律"><a href="#安培定律" class="headerlink" title="安培定律"></a>安培定律</h3><script type="math/tex; mode=display">\oint \vec B\cdot d\vec \ell=\mu_0\sum I</script><h3 id="磁场对电流的力密度"><a href="#磁场对电流的力密度" class="headerlink" title="磁场对电流的力密度"></a>磁场对电流的力密度</h3><p>施加在单位体积内在流体上的力。</p><script type="math/tex; mode=display">f=j\times B</script><h3 id="法拉第电磁感应定律"><a href="#法拉第电磁感应定律" class="headerlink" title="法拉第电磁感应定律"></a>法拉第电磁感应定律</h3><script type="math/tex; mode=display">\mathcal{E}=-\frac{d\Phi}{dt}=\oint \vec E\cdot d\vec \ell ,\quad \Phi=\int_S\vec B\cdot d\vec \sigma</script><h2 id="3-麦克斯韦方程组"><a href="#3-麦克斯韦方程组" class="headerlink" title="3 麦克斯韦方程组"></a>3 麦克斯韦方程组</h2><h3 id="原始形式"><a href="#原始形式" class="headerlink" title="原始形式"></a>原始形式</h3><script type="math/tex; mode=display">\begin{aligned}\nabla\cdot \vec E&=\frac{\rho}{\varepsilon_0}\\\nabla\times \vec E&=-\frac{d\vec  B}{dt}\\\nabla \cdot\vec  B&=0\\\nabla\times\vec  B&=\mu_0 \vec j+\varepsilon_0\mu_0\frac{\partial \vec E}{\partial t}\end{aligned}</script><h3 id="介质形式"><a href="#介质形式" class="headerlink" title="介质形式"></a>介质形式</h3><script type="math/tex; mode=display">\begin{aligned}\nabla\cdot \vec D&=\rho\\\nabla\times \vec E&=-\frac{d \vec B}{dt}\\\nabla \cdot \vec B&=0\\\nabla\times \vec H&=\vec  j+\frac{\partial\vec  D}{\partial t}\end{aligned}</script><p>其中：</p><script type="math/tex; mode=display">\begin{aligned}\vec D&=\varepsilon_0\vec E+\vec P\\\vec H&=\frac{1}{\mu_0}\vec B-\vec M\end{aligned}</script><p>其中：</p><p>$\vec P=\rho_p\vec \ell$ 为极化强度，是单位体积内分子的总偶极矩。</p><p>$\vec M$ 为单位体积内的磁矩。</p><p>这一部分需要再细细整理。</p><h3 id="边界条件"><a href="#边界条件" class="headerlink" title="边界条件"></a>边界条件</h3><script type="math/tex; mode=display">\begin{aligned}\vec D^{\perp }_1-\vec D_2^\perp&=\sigma_f\\\vec E_1^{\parallel}-\vec E^{\parallel}_2&=0  \\ \vec H_1^{\parallel}-\vec H_2^{\parallel}&=\vec K_f\times\vec n\\\vec B_1^\perp-\vec B_2^\perp&=0 \end{aligned}</script><h2 id="4-电磁场能动量"><a href="#4-电磁场能动量" class="headerlink" title="4 电磁场能动量"></a>4 电磁场能动量</h2><h3 id="能量"><a href="#能量" class="headerlink" title="能量"></a>能量</h3><p>能流密度：</p><script type="math/tex; mode=display">\vec S=\frac{1}{\mu_0}\vec E\times \vec B\\</script><p>电磁场能量密度：</p><script type="math/tex; mode=display">w=\frac{1}{2}(\varepsilon_0 E^2+\frac{1}{\mu_0}B^2                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             )</script><h3 id="麦克斯韦应力张量"><a href="#麦克斯韦应力张量" class="headerlink" title="麦克斯韦应力张量"></a>麦克斯韦应力张量</h3><script type="math/tex; mode=display">\begin{aligned}\vec f&=\rho \vec E+\rho \vec v\times\vec B=\rho\vec E+\vec j\times \vec B\\&=\nabla\cdot \overleftrightarrow{\mathcal{T}}-\varepsilon_0\mu_0\frac{\partial \vec S}{\partial t}\end{aligned}</script><p>其中，麦克斯韦应力张量：</p><script type="math/tex; mode=display">\overleftrightarrow{\mathcal{T}}=\varepsilon_0\vec E\vec E+\frac{1}{\mu_0}\vec B\vec B-\frac{1}{2}\big(\varepsilon_0\vec E^2+\frac{1}{\mu_0}\vec B^2\big)\overleftrightarrow I</script><p>分量形式为：</p><script type="math/tex; mode=display">T_{ij}=\varepsilon_0(E_iE_j-\frac 1 2 \delta_{ij}E^2)+\frac 1 \mu_0 (B_iB_j-\frac 1 2 \delta_{ij}B^2)</script><p>空间 $V$ 内电荷所受合力为：</p><script type="math/tex; mode=display">\vec F=\int_V\vec f d\tau=\int_S\overleftrightarrow{\mathcal{T}}\cdot d\vec \sigma-\varepsilon_0\mu_o\frac{d}{dt}\int_V \vec S d\tau</script><h3 id="动量"><a href="#动量" class="headerlink" title="动量"></a>动量</h3><script type="math/tex; mode=display">\begin{aligned}&\vec f=\frac{d\vec p_{mech}}{dt}=-\frac{d}{dt}(\varepsilon_0\mu_0\vec S)+\nabla\cdot\overleftrightarrow {\mathcal{T}}\\\iff &\frac{d}{dt}\bigg(\vec p_{mech}+\vec g\bigg)=-\nabla\cdot\overleftrightarrow{\Tau}\end{aligned}</script><p>其中 $\vec p<em>{mech}$ 为机械动量密度， $\vec g\equiv\vec p</em>{em}$ 为电磁动量密度，$\overleftrightarrow \Tau=-\overleftrightarrow{\mathcal{T}}$ 为动量流密度。</p><p>电磁场动量密度</p><script type="math/tex; mode=display">\vec g=\varepsilon_0\mu_0\vec S=\frac{1}{c^2}\vec S</script><p>动量流密度</p><script type="math/tex; mode=display">\overleftrightarrow\Tau=\frac{1}{2}\big(\varepsilon_0\vec E^2+\frac{1}{\mu_0}\vec B^2\big)\overleftrightarrow I-\varepsilon_0\vec E\vec E-\frac{1}{\mu_0}\vec B\vec B</script><h3 id="角动量"><a href="#角动量" class="headerlink" title="角动量"></a>角动量</h3><p>电磁场角动量密度</p><script type="math/tex; mode=display">\vec \ell_{em}=\vec r\times\vec g=\varepsilon_0\big[\vec r\times\vec E\times \vec B\big]</script><h3 id="电磁辐射压强"><a href="#电磁辐射压强" class="headerlink" title="电磁辐射压强"></a>电磁辐射压强</h3><script type="math/tex; mode=display">\mathcal{P}=\frac{\Delta F}{\Delta A}=\frac{g\Delta V}{\Delta t\Delta A}=\frac{g\Delta \ell}{\Delta t}=cg</script><p>这是完全吸收时的辐射压强，其中 $c$ 为光速。</p><p>不完全吸收时, $\mathcal{P}=cg(1+r)$ , 其中 $r$ 为反射系数。</p><h2 id="6-静电问题"><a href="#6-静电问题" class="headerlink" title="6 静电问题"></a>6 静电问题</h2><h3 id="电势"><a href="#电势" class="headerlink" title="电势"></a>电势</h3><script type="math/tex; mode=display">\begin{aligned}V(\vec r)&\equiv -\int _{\mathcal{O}}^ r\vec E\cdot d\vec \ell\\&=\int_r^\infty \vec E\cdot d\vec \ell\end{aligned}</script><h3 id="多极展开"><a href="#多极展开" class="headerlink" title="多极展开"></a>多极展开</h3><h4 id="原理"><a href="#原理" class="headerlink" title="原理"></a>原理</h4><ul><li><p>泰勒定理</p><p>若函数 $f$ 在点 $P_0(x_0,y_0)$ 点邻域 $U(P_0)$ 上有直到 $n+1$ 阶的连续偏导数，则对 $U({_0})$ 内任一点 $(x_0+h,y_0+k)$ ，存在相应的 $\theta\in(0,1)$ ，使得</p><script type="math/tex; mode=display">\begin{aligned}f(x_0+h,y_0+k)=&f(x_0,y_0)+\bigg(h\frac{\partial}{\partial x}+k\frac{\partial}{\partial y}\bigg)f(x_0,y_0)\\&+\frac{1}{2!}\bigg(h\frac{\partial}{\partial x}+k\frac{\partial}{\partial y}\bigg)^2f(x_0,y_0)+\cdots\\&+\frac{1}{n!}\bigg(h\frac{\partial}{\partial x}+k\frac{\partial}{\partial y}\bigg)^n f(x_0,y_0)\\&+\frac{1}{(n+1)!}\bigg(h\frac{\partial}{\partial x}+k\frac{\partial}{\partial y}\bigg)^{n+1}f(x_0+\theta h,y_0+\theta k)\end{aligned}</script></li><li><p>场量的泰勒展开：对 $f(\vec x-\vec x’)$ 在 $\vec x’=0$ 附近展开</p></li></ul><script type="math/tex; mode=display">\begin{aligned}f(\vec x-\vec x')&=f(\vec x)-\sum_{i=1}^3 x_i\frac{\partial f}{\partial x_i}+\frac{1}{2!}\sum_{i,j}x_i x_j \frac{\partial^2 f}{\partial x_i\partial x_j}+\cdots\\&=f(\vec x)-\vec x'\cdot \nabla f(\vec x)+\frac{1}{2}\vec x'\vec x'\colon \nabla\nabla f(\vec x)+\cdots\end{aligned}</script><script type="math/tex; mode=display">\begin{aligned}&\nabla(\frac{1}{|\vec r-\vec r_0|})=-\frac{\vec e_r}{|\vec r-\vec r_0|^2}=-\frac{\vec r}{r^3} \\&\nabla\nabla(\frac{1}{|\vec r-\vec r_0|})=-\frac{\overleftrightarrow I r^3- r^2 \vec e_r\vec r}{r^6}=\frac{3\vec e_r\vec e_r-\overleftrightarrow I}{|\vec r-\vec r_0|^3}\end{aligned}</script><ul><li><p>常用展开：把 $\displaystyle \frac{1}{|\vec r- \vec r|}$ 在 $\vec r’=0$ 附近作泰勒展开 </p><script type="math/tex; mode=display">\frac{1}{|\vec r-\vec r'|}=\frac{1}{r}+\frac{\vec r'\cdot\vec e_r}{r^2}+\frac{(3\vec r'\vec r'-r'^2\overleftrightarrow I):\vec e_r\vec e_r}{2r^3}+\cdots\notag</script></li><li><p>更方便地展开：把 $\displaystyle \frac{1}{|\vec r- \vec r|}$ 展开成勒让德多项式 ( $r$ 很大时)</p><script type="math/tex; mode=display">\begin{aligned}\frac{1}{|\vec r-\vec r'|}&=\frac{1}{\sqrt{r^2+r'^2-2rr'\cos\theta'}}\\&=\sum_{n=0}^\infty \frac{(r')^n}{r^{n+1}}P_n(\cos\theta')\\&=\frac{1}{r}+\frac{r'}{r^2}\cos\theta'+\frac{r'^2}{r^3}[\frac{1}{2}(3\cos^2\theta'-1)]+\cdots\\&=\frac{1}{r}+\frac{\vec r'\cdot\vec e_r}{r^2}+\frac{(r')^2(3\cos^2\theta'-1)}{2r^3}+\cdots\end{aligned}</script></li></ul><h4 id="静电场的多极展开"><a href="#静电场的多极展开" class="headerlink" title="静电场的多极展开"></a>静电场的多极展开</h4><h4 id="单极"><a href="#单极" class="headerlink" title="单极"></a>单极</h4><script type="math/tex; mode=display">\varphi_1=\frac{1}{4\pi\epsilon_0}\frac{Q}{r}\notag</script><h4 id="偶极"><a href="#偶极" class="headerlink" title="偶极"></a>偶极</h4><script type="math/tex; mode=display">\varphi_2=\frac{1}{4\pi\epsilon_0}\frac{\vec p\cdot \vec e_r}{r^2}\notag</script><ul><li>电偶极矩 <script type="math/tex; mode=display">\vec p=\int_V\vec r\cdot\rho(\vec r) d\tau\notag</script>$\vec r$ 为每个电荷的位置矢量</li></ul><h4 id="四极"><a href="#四极" class="headerlink" title="四极"></a>四极</h4><script type="math/tex; mode=display">\varphi_3=\frac{1}{4\pi\epsilon_0}\frac{\overleftrightarrow{\mathcal{D}}\colon(3\vec e_r\vec e_r-\overleftrightarrow I)}{2r^3}=\frac{1}{4\pi\epsilon_0}\frac{\overleftrightarrow {D}\colon \vec e_r\vec e_r}{2r^3}</script><ul><li>二级矩<script type="math/tex; mode=display">\overleftrightarrow{\mathcal{D}}=\sum_n q_n\vec r_n\vec r_n\\\overleftrightarrow{\mathcal{D}}=\int_V \rho(\vec r)\cdot \vec r\vec r d\tau\\\notag</script></li></ul><ul><li>四极矩</li></ul><script type="math/tex; mode=display">\overleftrightarrow D=3\overleftrightarrow{\mathcal{D}}-tr(\overleftrightarrow{\mathcal{D}})\overleftrightarrow{I}\notag</script><ul><li><p>四极矩的性质</p><ul><li>对称性：$D<em>{ij}=D</em>{ji}$</li><li>无迹性： $tr(\overleftrightarrow D)=0$</li></ul></li></ul><h3 id="电偶极子在电场中的受力"><a href="#电偶极子在电场中的受力" class="headerlink" title="电偶极子在电场中的受力"></a>电偶极子在电场中的受力</h3><h4 id="位能与受力"><a href="#位能与受力" class="headerlink" title="位能与受力"></a>位能与受力</h4><script type="math/tex; mode=display">\begin{aligned}U&=-\vec p\cdot\vec E\\\vec F&=-\nabla U=\nabla(\vec p\cdot \vec E)\end{aligned}</script><h4 id="力矩"><a href="#力矩" class="headerlink" title="力矩"></a>力矩</h4><script type="math/tex; mode=display">\vec \tau=\vec p\times \vec E\notag</script><h3 id="唯一性定理"><a href="#唯一性定理" class="headerlink" title="唯一性定理"></a>唯一性定理</h3><ul><li>若边界上的电势或者电势的法向变化率已知</li><li>除导体外， $V$ 内电荷分布一致，表面有已知的第一类或第二类边界条件。若导体表面电势已知</li><li>若导体所带的总电量已知</li></ul><p>满足一点，则区域 $V$ 内的电势分布有唯一解。</p><h3 id="电像法"><a href="#电像法" class="headerlink" title="电像法"></a>电像法</h3><p>对球类电场，可以添加镜像电荷使球面电势为 $0$, 若导体球带电荷 $Q$ ，再于球心放置一个电荷量为 $Q$ 的等效电荷。</p><p>球半径为 $R$ , 原电荷在距球心 $a$ 处，电荷量为 $q$ , 则镜像电荷放置到距球心 $\displaystyle\frac{R^2}{a}$ 处，电荷量为 $\displaystyle-\frac{R}{a} q$ .</p><h3 id="格林函数法"><a href="#格林函数法" class="headerlink" title="格林函数法"></a>格林函数法</h3><ul><li>格林函数 $G$ ：</li></ul><script type="math/tex; mode=display">\Delta G=\delta^{(3)}(\vec x-\vec x')\notag</script><ul><li>各种解：</li></ul><ul><li>应用：</li></ul><h2 id="7-静磁问题"><a href="#7-静磁问题" class="headerlink" title="7 静磁问题"></a>7 静磁问题</h2><h3 id="电流"><a href="#电流" class="headerlink" title="电流"></a>电流</h3><p>电流由库仑每秒来量度， $1A=1C/s$</p><ul><li><p>线电流 : $\vec I=\lambda \vec v=I d\vec \ell $  </p></li><li><p>面电流密度 : $\displaystyle\vec K\equiv\frac{d\vec I}{dl<em>{\perp}}=\sigma\vec v$ （电流带带上的电流除以带宽度） $I=\displaystyle\int</em>\ell \vec K\cdot d\vec \ell$</p></li><li>体电流密度 : $\displaystyle\vec J\equiv\frac{d\vec I}{da_{\perp}}=\rho \vec v$ （垂直于电流方向上单位面积流过的电流） $I=\displaystyle\int_S \vec J\cdot d\vec \sigma$</li></ul><p>注：</p><script type="math/tex; mode=display">\begin{aligned}\vec jd\tau&=C\delta(r-a)\delta(\theta-\frac\pi 2)d\varphi \vec e_\varphi\\Id\vec \ell&=Iad\varphi\vec e_\varphi\\&=\int_{d\ell}\vec j(\vec r)d\tau=\vec e_\varphi\int _{d\varphi}C\delta(r-a)\delta(\theta-\frac\pi 2)r^2\sin\theta \, dr d\theta d \varphi\\&=Ca^2d\varphi\vec e_\varphi\\\implies C&=\frac{I}{a}\\\therefore\int \vec j(\vec r)d\tau&=\int\vec e_\varphi \frac I a\delta(r-a)\delta(\theta-\frac\pi 2)r^2\sin\theta\, drd\theta d\varphi \\&=I\int\vec e_\varphi a\,d\varphi=I\int d\vec \ell\end{aligned}</script><p><strong>相关公式</strong></p><ul><li>表面电流密度 $\vec K=\vec M\cdot \hat n$</li><li><p>内部体电流密度 $\vec J=\nabla\times \vec M$</p></li><li><p>磁感应强度 $\vec B=\mu_0 \vec K$</p></li></ul><h3 id="受力"><a href="#受力" class="headerlink" title="受力"></a>受力</h3><h4 id="一段载流导线"><a href="#一段载流导线" class="headerlink" title="一段载流导线"></a>一段载流导线</h4><script type="math/tex; mode=display">\begin{aligned}\vec F&=\int (\vec v\times \vec B)dq=\int (\vec v\times\vec B)\lambda d l=\int (\vec I\times \vec B)dl\\&=I\int \vec d\ell\times\vec B\end{aligned}</script><h4 id="磁偶极子"><a href="#磁偶极子" class="headerlink" title="磁偶极子"></a>磁偶极子</h4><script type="math/tex; mode=display">\begin{aligned}U&=-\vec m\cdot \vec B\\\vec F&=\nabla(\vec m\cdot \vec B)\\\vec \tau&=\vec m\times\vec B\end{aligned}</script><h3 id="源起"><a href="#源起" class="headerlink" title="源起"></a>源起</h3><p>静磁场满足的微分方程：</p><script type="math/tex; mode=display">\begin{aligned}&\nabla\cdot \vec B=0\\& \nabla\times \vec B=\mu_0\vec j\\&\nabla\cdot \vec j=0\end{aligned}</script><h3 id="磁矢势"><a href="#磁矢势" class="headerlink" title="磁矢势"></a>磁矢势</h3><p>$\nabla\times\vec A=0$ 在库仑规范 $\nabla\cdot \vec A=0$ 下得到矢量泊松方程 $\nabla^2\vec A=-\mu_0\vec j$</p><p>磁库仑解为：</p><script type="math/tex; mode=display">\vec A=\frac{\mu_0}{4\pi}\int_全 \frac{\vec j(\vec r')}{|\vec r-\vec r'|}d\tau'\notag</script><p>具体：</p><script type="math/tex; mode=display">\begin{aligned}\vec A&=\frac{\mu_0}{4\pi}\int_V \frac{\vec J(\vec r')}{|\vec r-\vec r'|}d\tau'（体电流产生的磁矢势）\\&=\frac{\mu_0}{4\pi}\int_S \frac{\vec K(\vec r')}{|\vec r-\vec r'|}da'（面电流产生的磁矢势）\\&=\frac{\mu_0}{4\pi}\int_l \frac{\vec I(\vec r')}{|\vec r-\vec r'|}dl'=\frac{\mu_0 I}{4\pi}\int_l \frac{1}{|\vec r-\vec r'|}d\vec \ell（线电流产生的磁矢势）\end{aligned}</script><p>由此可得到毕奥-萨伐尔定律：</p><script type="math/tex; mode=display">\begin{aligned}\vec B&=\nabla\times \vec A=\frac{\mu_0}{4\pi}\int_全 \nabla\times\bigg(\frac{\vec j(\vec r')}{|\vec r-\vec r'|}\bigg)d\tau'\\&=\frac{\mu_0}{4\pi}\vec e_k\int_全 \varepsilon_{ijk}\partial_i \bigg(\frac{\vec j_j(\vec r')}{|\vec r-\vec r'|}\bigg)d\tau' \\&=\frac{\mu_0}{4\pi}\vec e_k\int_全\varepsilon_{ijk}\frac{-(x_i-x_i')}{|\vec r-\vec r'|^3}j_j(\vec r')d\tau'\\&=\frac{\mu_0}{4\pi}\int _全 \vec j(\vec r')\times\frac{\vec r-\vec r'}{|\vec r-\vec r'|^3}d\tau'\\&=\frac{\mu_0}{4\pi}\int_全 \frac{\vec j(\vec r')\times e(\vec r-\vec r')}{|\vec r-\vec r'|^2 }d\tau'\\&=\frac{\mu_0}{4\pi}I\int_l \frac{\vec d\ell'\times e(\vec r-\vec r')}{|\vec r-\vec r'|^2}（线电流）\\&=\frac{\mu_0}{4\pi}\int_S \frac{\vec K(\vec r')\times e(\vec r-\vec r')}{|\vec r-\vec r'|^2}da' （面电流）\\&=\frac{\mu_0}{4\pi}\int_V \frac{\vec J(\vec r')\times e(\vec r-\vec r')}{|\vec r-\vec r'|^2 }d\tau'（体电流）\end{aligned}</script><p>一般地，磁矢势的方向和电流方向一致。</p><p>对称性好的情况下，已知磁感应强度利用磁通量求磁矢势（类似安培定理）：</p><script type="math/tex; mode=display">\begin{aligned}\oint\vec A\cdot d\vec \ell=\int_S(\nabla\times\vec A) \cdot da=\int_S \vec B\cdot d\vec a=\Phi\end{aligned}</script><h3 id="磁矢势多极展开"><a href="#磁矢势多极展开" class="headerlink" title="磁矢势多极展开"></a>磁矢势多极展开</h3><script type="math/tex; mode=display">\begin{aligned}\vec A&=\frac{\mu_0}{4\pi}\int\frac{\vec j(\vec r')}{|\vec r-\vec r'|}d\tau'\\&=\frac{\mu_0}{4\pi}\sum_{n=0}^\infty \frac{1}{r^{n+1}}\int\vec j(\vec r')\big[(r')^n P_n(\cos\theta')\big]d\tau'\\&=\frac{\mu_0}{4\pi}\int\vec j(\vec r')\big[\frac 1 r+\frac {r'\cos\theta'}{r^2}+\frac{r'^2(3\cos^2\theta'-1)}{2r^3}+\cdots\big]d\tau'\\\\\vec A_{偶极}&=\frac{\mu_0}{4\pi}\int\vec j(\vec r')\frac{\vec r'\cdot \vec e_r}{r^2}d\tau'\\&\equiv\frac{\mu_0}{4\pi}\frac{\vec m \times\vec e_r}{r^2}\\\\\vec B_{偶极}&=\frac {\mu_0}{4\pi}\frac{1}{r^3}\left[3(\vec m\cdot\vec e_r)\vec e_r-\vec m\right]\end{aligned}</script><ul><li>磁偶极矩 $\vec m$ :</li></ul><script type="math/tex; mode=display">\begin{aligned}\vec m&\equiv\frac 1 2\int\vec r'\times\vec j(\vec r')d\tau'\end{aligned}</script><p>​       其中$\vec j$ 为电流密度。</p><ul><li><p>环形电流圈（半径为 $a$ ）：</p><script type="math/tex; mode=display">\begin{aligned}\vec m&=\frac1 2 I\oint \vec r'\times d\vec \ell=\frac 1 2 Ia\cdot2\pi a\vec e_k=I\vec S\\m&=\frac {dq}{dt}S=\frac{q_e}{2\pi a/v}\pi a^2=\frac 1 2q_e v r\\\vec A_{偶}&=\frac{\mu_0 I}{4\pi}\frac{\vec S\times \vec e_r}{r^2}\\\vec B_{偶}&=\nabla\times\vec A_{偶}=\frac{\mu_0}{4\pi}\frac{\vec m}{r^3}\cdot (3\vec e_r\vec e_r-\overleftrightarrow I)\\&=\frac{\mu_0}{4\pi}\frac{1}{r^3}[3(\vec m\cdot \vec e_r)\vec e_r-\vec m]\end{aligned}</script><p>对指向 $z$ 轴的 $\vec m $ : </p><script type="math/tex; mode=display">\vec B_{偶}=\frac{\mu_0}{4\pi}\frac{m}{r^3}\left(2\cos\theta\vec e_r+\sin\theta\vec e_\theta\right)</script></li></ul><h3 id="常用磁场"><a href="#常用磁场" class="headerlink" title="常用磁场"></a>常用磁场</h3><p>长直导线</p><script type="math/tex; mode=display">\vec B=\frac{\mu_0 I}{4\pi d}\left(\sin\theta_1-\sin\theta_2\right)</script><h3 id="磁标势"><a href="#磁标势" class="headerlink" title="磁标势"></a>磁标势</h3><p>已知磁化强度 $\vec M$, 以及静磁方程：</p><script type="math/tex; mode=display">\begin{aligned}&\nabla\cdot\vec B=0\\&\nabla\times\vec H=\vec j\\&\vec B=\mu_0(\vec H+\vec M)\end{aligned}</script><p>对于没有传导电流的<em>单连通区域</em> $V$ :    $\nabla\times \vec H=0$</p><p>所以存在磁标势 $\varphi_m$ : $\vec H=-\nabla\varphi_m$</p><p>由静磁方程推出：$\nabla^2\varphi_m=\nabla\cdot \vec M$</p><h2 id="8-电磁波的传播"><a href="#8-电磁波的传播" class="headerlink" title="8 电磁波的传播"></a>8 电磁波的传播</h2><h3 id="能量-1"><a href="#能量-1" class="headerlink" title="能量"></a>能量</h3><script type="math/tex; mode=display">\begin{aligned}&u=\frac 1 2 \varepsilon E^2+\frac{1}{2\mu}B^2=\varepsilon E^2=\frac{1}{\mu}B^2\\&\vec S=\frac{1}{\mu}\vec E\times\vec B=cu\hat k\\&\vec g=\frac 1 {c^2}\vec S=\frac 1 c u\hat k\end{aligned}</script><p>周期平均值：</p><script type="math/tex; mode=display">\begin{aligned}\langle fg\rangle&=\frac 1 2 Re(\widetilde f\widetilde g ^*)\\\langle u\rangle&=\frac 1 2 \varepsilon E^2\\\langle S\rangle&=c\langle u\rangle\\\end{aligned}</script><p>强度与辐射压强：</p><script type="math/tex; mode=display">\begin{aligned}I&\triangleq \langle S\rangle\\P&=c\bar g=\frac{\langle S \rangle}{c}=\frac{I}{c}\end{aligned}</script><h3 id="偏振"><a href="#偏振" class="headerlink" title="偏振"></a>偏振</h3><h3 id="在线性介质中的传播"><a href="#在线性介质中的传播" class="headerlink" title="在线性介质中的传播"></a>在线性介质中的传播</h3><p>由相位在边界上相等可以得到折射定律和反射定律，利用边界条件进一步分析可得到菲涅尔定律等。</p><h4 id="折射定律和反射定律的导出"><a href="#折射定律和反射定律的导出" class="headerlink" title="折射定律和反射定律的导出"></a>折射定律和反射定律的导出</h4><script type="math/tex; mode=display">Ae^{i(\vec k_i\cdot \vec r-\omega t)}+Be^{i(\vec k_r\cdot \vec r-\omega t)}=Ce^{i(\vec k_t\cdot \vec r-\omega t)}\\\implies\begin{cases}\omega_i=\omega_r=\omega_t\equiv \omega=kc\\\vec k_i\cdot \vec r=\vec k_r\cdot \vec r=\vec k_t\cdot \vec r\biggm |_{z=0}\end{cases}\\\begin{aligned}&\implies k_{i_x}=k_{r_x}=k_{t_x}\\&\implies k_i\sin\theta_i=k_r\sin\theta_r=k_t\sin\theta_t\end{aligned}</script><p>进而可以推出折射定律和反射定律。</p><h4 id="菲涅尔定律"><a href="#菲涅尔定律" class="headerlink" title="菲涅尔定律"></a>菲涅尔定律</h4><p>不抄了，利用边界条件推导即可，没必要记。</p><h4 id="布儒斯特角"><a href="#布儒斯特角" class="headerlink" title="布儒斯特角"></a>布儒斯特角</h4><p>偏振方向平行界面入射的波以这角入射时反射波完全消失。</p><script type="math/tex; mode=display">\theta_B=\arctan \frac{n'}{n}</script><h3 id="在导电介质中的传播"><a href="#在导电介质中的传播" class="headerlink" title="在导电介质中的传播"></a>在导电介质中的传播</h3><h4 id="麦克斯韦方程"><a href="#麦克斯韦方程" class="headerlink" title="麦克斯韦方程"></a>麦克斯韦方程</h4><script type="math/tex; mode=display">\begin{aligned}\nabla\cdot \vec E&=0\\\nabla\cdot \vec B&=0\\\nabla\times\vec E&=-\frac{\partial\vec B}{\partial t}\\\nabla\times\vec B&=\mu\varepsilon \frac{\partial \vec E}{\partial t}+\mu\sigma\vec E\end{aligned}</script><p>良导体。差别在磁场的旋度中多了一项。</p><h4 id="平面波解"><a href="#平面波解" class="headerlink" title="平面波解"></a>平面波解</h4><script type="math/tex; mode=display">\widetilde E(z,t)=\widetilde E_0e^{-\kappa z}e^{i(kz-\omega t)}\\\widetilde B(z,t)=\widetilde B_0e^{-\kappa z}e^{i(kz-\omega t)}\\\notag</script><p>注意电场与磁场不再同相，振幅的倍数也不再是 $c$ :</p><script type="math/tex; mode=display">\begin{aligned}&\widetilde B_0=\frac{\widetilde k}{\omega}\widetilde  E_0=\frac{Ke^{i\phi}}{\omega}\widetilde  E_0 \\&\frac{B_0}{E_0}=\frac{K}{\omega}=\sqrt{\varepsilon\mu\sqrt{1+\left(\frac{\sigma}{\varepsilon\omega}\right)^2}}\end{aligned}</script><h4 id="折射定律和反射定律"><a href="#折射定律和反射定律" class="headerlink" title="折射定律和反射定律"></a>折射定律和反射定律</h4><p>仍然成立。</p><h3 id="波导"><a href="#波导" class="headerlink" title="波导"></a>波导</h3><h4 id="边界条件-1"><a href="#边界条件-1" class="headerlink" title="边界条件"></a>边界条件</h4><script type="math/tex; mode=display">\begin{cases}\vec E^{\parallel}=0\\\vec B^\perp=0\end{cases}\notag</script><p>磁场和电场不同的边界条件导致 $TE$ 和 $TM$ 波的不同。</p><h4 id="重要方程"><a href="#重要方程" class="headerlink" title="重要方程"></a>重要方程</h4><p>由于导体的影响，波导内的波一般不再是横波。推导中引入了纵向分量:</p><script type="math/tex; mode=display">\widetilde E_0=E_x\hat x+E_y \hat y +E_z\hat z\\\widetilde B_0=B_x\hat x+B_y \hat y +B_z\hat z\notag</script><p>代入麦克斯韦方程组可以写出各分量方程。</p><p>最后得到独立的 $E_z$ 和 $B_z$ 的方程：</p><script type="math/tex; mode=display">\left[\frac{\partial^2}{\partial x^2}+\frac{\partial^2}{\partial y^2}+\left(\frac{\omega}{c}\right)^2-k^2\right]E_z=0\\\left[\frac{\partial^2}{\partial x^2}+\frac{\partial^2}{\partial y^2}+\left(\frac{\omega}{c}\right)^2-k^2\right]B_z=0</script><h4 id="重要结论"><a href="#重要结论" class="headerlink" title="重要结论"></a>重要结论</h4><p>中空波导中 $TEM$ 波不能发生。 </p><h4 id="矩形波导"><a href="#矩形波导" class="headerlink" title="矩形波导"></a>矩形波导</h4><h5 id="TE-波"><a href="#TE-波" class="headerlink" title="$TE$ 波"></a>$TE$ 波</h5><p>$E_z=0$, 分离变量求解得：</p><script type="math/tex; mode=display">B_z=B_0\cos(\frac{m\pi}{a}x)\cos(\frac{n\pi}{b}y)\notag</script><h5 id="TM-波"><a href="#TM-波" class="headerlink" title="$TM$ 波"></a>$TM$ 波</h5><p>$B_z=0$.</p><script type="math/tex; mode=display">E_z=E_0\sin(\frac{m\pi}{a}x)\sin(\frac{n\pi}{b}y)\notag</script><h5 id="相关物理量"><a href="#相关物理量" class="headerlink" title="相关物理量"></a>相关物理量</h5><script type="math/tex; mode=display">\begin{aligned}&k_x=\frac{m\pi}{a},k_y=\frac{n\pi}{b}\\&\omega_{mn}\equiv c\sqrt{k_x^2+k_y^2}=c\pi\sqrt{\left(\frac{m}{a}\right)^2+\left(\frac{n}{b}\right)^2}(\text{截断频率})\\&k=\sqrt{\left(\frac{\omega}{c}\right)^2-k_x^2-k_y^2}=\frac{1}{c}\sqrt{\omega^2-\omega_{mn}^2}\end{aligned}</script><h5 id="波速与群速度"><a href="#波速与群速度" class="headerlink" title="波速与群速度"></a>波速与群速度</h5><script type="math/tex; mode=display">\begin{aligned}&v=\frac \omega k=\frac{c}{\sqrt{1-(\omega/\omega_{mn})^2}}\\&v_g=\frac{1}{dk/d\omega}=c \sqrt{1-(\omega/\omega_{mn})^2}\end{aligned}</script><h2 id="9-电磁波的激发"><a href="#9-电磁波的激发" class="headerlink" title="9 电磁波的激发"></a>9 电磁波的激发</h2><h3 id="麦克斯韦方程组的探讨"><a href="#麦克斯韦方程组的探讨" class="headerlink" title="麦克斯韦方程组的探讨"></a>麦克斯韦方程组的探讨</h3><script type="math/tex; mode=display">\begin{align}\nabla\cdot \vec E&=-\frac {\rho(\vec r,t)}{\varepsilon}\label{E-divergence}\\\nabla\times\vec E&=-\frac{\partial \vec B}{\partial t}\label{E-curl}\\\nabla\cdot\vec B&=0\label{B-divergence}\\\nabla \times\vec B&=\mu\vec J+\varepsilon\mu\frac{\partial\vec E}{\partial t}\label{B-curl}\end{align}</script><p>$\vec J$ 是电流密度。</p><p>由标势和矢势可以确定电场和磁场：</p><p>由 $(\ref{B-divergence})$ 可得</p><script type="math/tex; mode=display">\vec B=\nabla\times\vec A\label{B}</script><p>这将确定磁场。</p><p>由 $(\ref{E-curl})$ 可得</p><script type="math/tex; mode=display">\begin{align}&\nabla\times\left (\vec E+\frac{\partial \vec A}{\partial t}\right)=0\notag \\\implies &\vec E=-\nabla \varphi-\frac{\partial \vec A}{\partial t}\label{E}\end{align}</script><p>这将确定电场。</p><p>由 $(\ref{E-divergence})$ 和 $(\ref{B-curl})$ 可以确定电荷分布和电流分布：</p><script type="math/tex; mode=display">\begin{align}-\frac{\rho} \varepsilon&=\nabla^2\varphi+\frac{\partial}{\partial t}(\nabla\cdot \vec A)\\-\mu \vec J&=\nabla^2\vec A-\varepsilon\mu\frac{\partial^2 }{\partial t^2}\vec A-\nabla\left(\nabla\cdot \vec A+\varepsilon\mu \frac{\partial}{\partial t }\varphi \right)\end{align}</script><p>麦克斯韦方程组本来有六个变量 $E_x,E_y,E_z,B_x,B_y,B_z$ ，利用矢势和标势将其浓缩为四个变量 $A_x,A_y,A_z,V$ ，留下两个自由度可以用来做规范变换。</p><h3 id="规范变换"><a href="#规范变换" class="headerlink" title="规范变换"></a>规范变换</h3><h4 id="一般规范"><a href="#一般规范" class="headerlink" title="一般规范"></a>一般规范</h4><script type="math/tex; mode=display">\begin{aligned}&\varphi\mapsto  \varphi'=\varphi+\alpha(\vec r,t)\\&\vec A\mapsto  \vec A'=\vec A+\vec \beta(\vec r,t)\end{aligned}</script><p>代入 $(\ref{B})$ $\vec B$ 应保持不变，得到 $\nabla\times\vec \beta=0$</p><p>再代入 $(\ref{E})$ $\vec E$ 也应保持不变，得到 $\nabla \alpha+\displaystyle\frac{\partial\vec \beta}{\partial t}=0$</p><p>$\implies$</p><script type="math/tex; mode=display">\begin{align}&\varphi\mapsto  \varphi'=\varphi-\frac{\partial}{\partial t}\lambda \\&\vec A\mapsto  \vec A'=\vec A+\nabla\lambda\end{align}</script><h4 id="库仑规范"><a href="#库仑规范" class="headerlink" title="库仑规范"></a>库仑规范</h4><p>选取 $\lambda$ 使</p><script type="math/tex; mode=display">\nabla\cdot \vec A=0\notag</script><h4 id="洛伦兹规范"><a href="#洛伦兹规范" class="headerlink" title="洛伦兹规范"></a>洛伦兹规范</h4><p>选取 $\lambda$ 使</p><script type="math/tex; mode=display">\nabla\cdot \vec A+\epsilon\mu\frac{\partial}{\partial t}\varphi=0</script><h3 id="推迟势"><a href="#推迟势" class="headerlink" title="推迟势"></a>推迟势</h3><script type="math/tex; mode=display">\begin{align}\varphi&=\frac{1}{4\pi\varepsilon_0}\int \frac{\rho(\vec r',t_r)}{|\vec r-\vec r'| }d\tau'\\\vec A&=\frac {\mu_0}{4\pi}\int \frac{\vec J(\vec r',t_r)}{|\vec r-\vec r'|}d\tau'\\t_r&=t-\frac{|\vec r-\vec r'|}{c}\end{align}</script><p>非静止状态下，信息不是源现在的状态，而是较早时间 $t_r$ 时信息离开当时的源时的状态。</p><p><strong>证明</strong>：</p><p>洛伦兹规范下，得到（真空中）</p><script type="math/tex; mode=display">\begin{cases}\displaystyle\nabla^2 \vec A-\frac 1 {c^2}\frac {\partial^2}{\partial t^2}\vec A=-\mu_0\vec J\\\displaystyle\nabla^2 \varphi-\frac 1 {c^2}\frac{\partial^2}{\partial t^2}\varphi=-\frac{\rho}{\varepsilon_0}\end{cases}\notag</script><p>考虑</p><script type="math/tex; mode=display">\nabla^2 \psi-\frac 1 {c^2}\frac{\partial^2}{\partial t^2}\psi=-4\pi f(\vec r,t)\notag</script><p>将 $f$ 写成点源形式 </p><script type="math/tex; mode=display">f(\vec r,t)=\int f(\vec r',t)\delta(\vec r-\vec r')d\tau'\notag</script><p>将 $\psi$ 也写成如此形式</p><script type="math/tex; mode=display">\psi=\int G(\vec r-\vec r',t)d\tau'\notag</script><p>可以得到</p><script type="math/tex; mode=display">\nabla^2 G-\frac 1 {c^2}\frac{\partial^2}{\partial t^2}G=-4\pi f(\vec r',t)\delta(\vec r-\vec r')\notag</script><p>可以固定这时的 $\vec r’$ 为源点，利用球坐标拉普拉斯算子得到</p><script type="math/tex; mode=display">\frac 1{r^2}\frac{\partial}{\partial r}\left(r^2\frac{\partial}{\partial r}G\right)-\frac 1 {c^2}\frac{\partial^2}{\partial t^2}G=0\qquad(\vec r\neq \vec 0)\notag</script><p>令 $R(\vec r,t)=r G(\vec r,t)$, 得到</p><script type="math/tex; mode=display">\left(\frac{\partial}{\partial r}-\frac 1 c \frac{\partial}{\partial t}\right)\left(\frac{\partial}{\partial r}+\frac 1 c \frac{\partial}{\partial t}\right)R=0\notag</script><p>引入光锥坐标 </p><script type="math/tex; mode=display">\begin{align}u=r-ct\\v=r+ct\end{align}</script><p>可得 </p><script type="math/tex; mode=display">\begin{aligned}&4\frac{\partial^2}{\partial u \partial v}R=0\\\implies\quad &R(u,v)=g_1(k_1u)+g_2(k_2 v)\end{aligned}</script><p>取 $\displaystyle k_1=-\frac{1}{c},k_2=\frac 1 c$ ，并舍去超前时间，最终得到</p><script type="math/tex; mode=display">G=\frac 1 r g_1(t-\frac r c)\notag</script><p>$\vec r\to \vec 0$ 时，对时间的偏导相对梯度都可以略去，有</p><script type="math/tex; mode=display">\begin{aligned}\nabla^2 G(\vec r,t)&=-4\pi f(\vec 0,t)\delta(\vec r)\\\implies \lim_{\vec r\to\vec 0} G&=\frac{f(\vec 0,t) }r\end{aligned}</script><p>对比非零处可以得到</p><script type="math/tex; mode=display">g_1(t-\frac r c)=f(\vec 0,t-\frac r c)\notag</script><script type="math/tex; mode=display">\begin{aligned}\therefore G(\vec r,t)&=\frac{f(0,t-\displaystyle \frac r c)}{r}& \vec r'=\vec 0\\\implies  G(\vec r-\vec r',t)&=\frac{f(0,t-\displaystyle \frac {|\vec r -\vec r'|} c)}{r}& \vec r'\neq\vec 0\\\psi(\vec r,t)&=\int G(\vec r-\vec r',t)d\tau'\end{aligned}</script><h3 id="李纳-维谢尔势"><a href="#李纳-维谢尔势" class="headerlink" title="李纳-维谢尔势"></a>李纳-维谢尔势</h3><p>特定轨迹 $\vec w(t)$ 的运动点电荷产生的势（推迟势）。</p><script type="math/tex; mode=display">\begin{align}\phi(\vec r,t)&=\frac{1}{4\pi\varepsilon_0}\frac{q}{|\vec r-\vec w(t_r)|}\cdot \frac{1}{\displaystyle 1-\frac{\vec v(t_r)}{c}\cdot\frac{\vec r-\vec w(t_r)}{|\vec r-\vec w(t_r)|}}\\&=\frac{1}{4\pi\varepsilon_0}\frac{q}{|\vec R|}\cdot \frac{1}{\displaystyle1-\frac{\vec v(t_r)}{c}\cdot \hat R}\\\vec A(\vec r,t)&=\frac{\vec v(t_r)}{c^2}\varphi(\vec r,t)\end{align}</script><p>注意这里面最终的时间都是推迟时间。</p><p>其中，有一些重要的量和关系经常用到：</p><script type="math/tex; mode=display">\begin{align}\vec R&=\vec r-\vec w(t_r)\\t_r&=t-\frac{|\vec r-\vec w(t_r)|}{c}=t-\frac{|\vec R|}{c}\\\vec v(t)&=\vec w'(t)=\frac{d}{dt}\vec w(t)\\\vec v(t_r)&=\vec w '(t_r)=\frac{d}{d t_r}\vec w(t_r)\\(&=\frac {d}{dt}\vec w(t)\biggm|_{t=t_r}=\frac {d}{d t_r}\vec w(t)\cdot\frac{d t_r}{dt})\notag\\\end{align}</script><p>比较神奇的是，因子 $\displaystyle\frac{1}{\displaystyle 1-\frac{\vec v(t_r)}{c}\cdot \hat R}$  恰好是 推迟时间对时间的导数：</p><script type="math/tex; mode=display">\begin{align}&c(t-t_r)= |\vec R|\\\implies &c(1-\partial_t t_r)=\partial_t R=\partial_{t_r}R\cdot \partial_t t_r\notag\\\implies &\partial_t t_r=\frac{1}{1-\displaystyle\frac 1 c\partial_{t_r}R}\notag\\\notag \\\because\quad \partial_{t_r}R&\overset{技巧}{=}\frac{\partial\sqrt{\vec R\cdot \vec R}}{\partial t_r}\notag \\&=\frac{\vec R}{R}\frac{\partial\vec R}{\partial t_r}\notag \\&=\vec w'(t_r)\cdot \hat {R}=\vec v\cdot \hat{R}\notag\\\therefore\quad \partial_t t_r&=\displaystyle\frac{1}{\displaystyle 1-\frac{\vec v(t_r)}{c}\cdot \hat R}\end{align}</script><h3 id="运动电荷的场"><a href="#运动电荷的场" class="headerlink" title="运动电荷的场"></a>运动电荷的场</h3><h4 id="一般运动电荷的场"><a href="#一般运动电荷的场" class="headerlink" title="一般运动电荷的场"></a>一般运动电荷的场</h4><p>艰难链式法则求导。</p><script type="math/tex; mode=display">\begin{align}\vec E&=\frac q {4\pi\varepsilon_0}\frac{R}{(\vec R\cdot\vec u)^3}\left[(c^2-v^2)\vec u+\vec R\times (\vec u\times \vec a)\right]\\\vec B&=\frac 1 c \hat R\times\vec E\\ \notag \\t_r&=t-\frac{R}{c}\quad (or: c(t-t_r)=R)\label{t_r}\\\vec R&=\vec r-\vec w(t_r),\label{r-w(t_r)}\\ \vec u&=c\hat R-\vec v,\\\vec v&=\vec v(t_r)=\partial_{t_r}w(t_r),=w'(t_r)\notag\\ \vec a&=w''(t_r)\notag\end{align}</script><p>其中 ，$\vec E$ 的第一项为广义库仑场, 第二项为辐射场。由 $(\ref{t_r})$ 和 $(\ref{r-w(t_r)})$ 可以解出 $t_r$ 。</p><h4 id="匀速运动电荷的场"><a href="#匀速运动电荷的场" class="headerlink" title="匀速运动电荷的场"></a>匀速运动电荷的场</h4><p>$\vec a=0,\vec w(t)=\vec v t$。</p><script type="math/tex; mode=display">\begin{align}\vec E(\vec r,t)&=\frac{q}{4\pi\varepsilon_0}\frac{1-v^2/c^2}{\left(1-v^2\sin^2\theta/c^2\right)^{\frac 3 2}}\frac{\vec r-\vec v t}{|\vec r -\vec v t|^3}\\\vec B&=\frac 1 c \hat R\times \vec E=\frac 1 {c^2}(\vec v\times \vec E)\end{align}</script><p><img src="https://tva1.sinaimg.cn/large/007S8ZIlly1gebpwaba5qj30wa0rsjsw.jpg" style="zoom:25%;" /></p><p>运动垂直方向上：</p><script type="math/tex; mode=display">\vec E=\frac{q}{4\pi\varepsilon_0}\frac{1}{\rho^2}\frac{1}{\sqrt{1-v^2/c^2}}\vec e_\rho</script><p>运动水平方向上：</p><script type="math/tex; mode=display">\vec E=\frac{1}{4\pi\varepsilon_0}\frac 1 {\rho^2}\cdot(1-v^2/c^2)\vec e_\rho</script><h2 id="习题"><a href="#习题" class="headerlink" title="习题"></a>习题</h2><h3 id="高斯定律-1"><a href="#高斯定律-1" class="headerlink" title="高斯定律"></a>高斯定律</h3><p>Three isolated infinite metal (i.e. conducting) slabs have their normals along the <em>z</em> axis, so the slabs are parallel to each other. The top slab has total charge <em>Q</em>, while the bottom slab has total charge <em>q</em>. Find the charge on the top surfaces of each slab and on the bottom surfaces of each slab. (<a href="chrome-extension://ohfgljdgelakfkefopgklcohadegdpjf/https://web.pa.msu.edu/people/duxbury/courses/phy481/Fall2009/MidtermIBSolutions-2009.pdf">Solusion</a>)</p>]]></content>
      
      
      <categories>
          
          <category> Physics </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>2020</title>
      <link href="/2020/02/11/Other%20Things/2020/"/>
      <url>/2020/02/11/Other%20Things/2020/</url>
      
        <content type="html"><![CDATA[<h2 id="2020"><a href="#2020" class="headerlink" title="2020"></a>2020</h2><ul><li><p>大二冬学期期末 1.1～1.17</p></li><li><p>搞博客，研究hexo 1.17～1.20</p></li><li><p><a href="[https://github.com/Pratitya/wuhan2020-timeline/blob/master/%E6%97%B6%E9%97%B4%E7%BA%BFTIMELINE.md](https://github.com/Pratitya/wuhan2020-timeline/blob/master/时间线TIMELINE.md">新冠病毒</a>) </p><p>$ \ $ <a id="more"></a></p><ul><li>2019.12.1 第一位武汉市民有不明原因症状</li><li>2019.12.8 第一例武汉不明原因肺炎病人发病</li><li>2019.12.31 武汉卫健委公开通报出现“不明原因肺炎”   27人</li><li>1.3 武汉市卫健委通，称未发现“人传人”证据。44人</li><li>1.5 56人疑似。</li><li>1.8 中国国家卫健委称，“新型冠状病毒”为<em>疫情病原</em>，多名医护人员陆续感染</li><li>1.9 第一例死亡病例。</li><li>1.16 日本出现。湖北“两会“闭幕。</li><li>1.18 通报新增4例，武汉百步亭“万家宴”</li><li>1.20 通报确诊136例，北京和深圳出现首次疫情报告，钟南山确认“人传人”</li><li>美国、台湾出现。湖北省委书记、省长等出席春节团拜、观看演出。</li><li>香港、澳门出现。</li><li>1.23 武汉、黄冈等封城。 湖北省确诊444人，8人死亡。浙江、广东、湖南启动一级应急响应。</li><li>1.24 除夕，前线医护人员求助物资不足。湖北、北京、上海、安徽、重庆、天津、四川、云南、贵州、山东、福建启动一级响应。“火神山医院” 七日紧急搭建开始。红十字会医院很多遗体处理不过来。国际上英国专家警告，至少4000人，武汉最坏情况为，近万人染病。</li><li>1.25 春晚。白岩松：“我们在这过年，你们在帮我们过关。”武汉准备半个月内再建一所“雷神山医院”。</li><li>1.26 美国关闭武汉领事馆并撤侨。</li><li>1.27 中国大陆确诊4515人。</li><li>1.29 3554人。寿光向武汉捐350吨蔬菜。被低价出售。</li><li>1.30 7771人。WHO宣布疫情构成“国际突发公共卫生事件”。西藏确诊首例病例，疫情已蔓延至中国所有省份。黑十字会。</li><li>2.1 突破10000人。澳大利亚政府拒绝所有来自或途径中国对非澳大利亚公民入境。抢双黄连风波。德国种族歧视袭击。</li><li>2.2 湖北对所有疑似病例进行集中隔离，开始搭建方舱医院。火神山医院交付。</li><li>2.3 上证综指暴跌7%。中国多家媒体收到关于疫情的报道禁令。</li><li>2.4 晋江毒王。</li><li>2.6/7 李文亮医生去世。</li><li>2.8 元宵节。36000人。超过800人死亡。</li><li>武软的强盗行为。</li><li>2.11 42744人。</li><li>2.12 48206人。</li><li>2.14 51986人。</li><li>2.15 66492人。</li><li>2.19 74185人。</li><li>“钻石公主”号 移动的病毒库</li><li>2.21  济宁任城监狱 200+人</li><li>2.26  韩国疫情日益严重</li><li>3.7 福建泉州欣佳快捷酒店坍塌 是医学观察点</li><li>3.7 下午 方舱医院患者清零 东西湖方舱明日起休舱</li><li>3.10 美股熔断 </li><li>3.11 美股高开，大V反弹。意大利疫情加重，监狱暴动；在过去的24小时，塔利班在阿富汗15省发动了32次袭击。俄罗斯通过宪法修正案草案。洛杉矶万人马拉松开跑。（“说起马拉松，想必不少网友会想起那场将意大利拖入绝境的马拉松。正是因为有一名超级传染者夹杂在了比赛中，这才使得近5万人成为了疑似病例。眼下意大利确诊人数已经突破了6000人，总理宣布将北方地区封锁。”）</li><li>3.13 英国准备拖延疫情，“等百分之六十人感染”，“获得群体免疫”。根据流行病学的研究，不知道会如何。</li><li>3.15 塞尔维亚宣布进入紧急状态，塞尔维亚总统几度哽咽请求中国援助。“我们请求中国提供一切帮助”。加油，都加油，努力，再努力。</li><li>3.23 意大利新增新冠肺炎5560例，累计确诊59138例；美国共报告新冠肺炎确诊32717例。</li><li>3.24 过去24小时，西班牙新增新冠肺炎确诊病例6584例，累计确诊39673例。新增死亡病例514例，累计死亡2696例。</li><li>美国新冠肺炎确诊病例达53268例，新增确诊病例达10054例。</li><li>3.27  英国首相鲍里斯·约翰逊确诊肺炎。这两天每天美国单日增13000+。德国累计确诊新冠肺炎49039例，单日新增近6000例。</li><li>3.28 美国单日新增超两万。法国向中国订购10亿只口罩，通过56次来回完成交运工作。特朗普签署台北法案。</li><li>4.2 一百万。 全球新冠肺炎确诊病例达1002159例，死亡病例为51485例。美国新冠肺炎确诊病例升至236339例，是目前确诊病例最多的国家，其死亡病例为5648例；意大利死亡病例达13915例，是目前死亡病例最多的国，其确诊病例为115242例；西班牙确诊病例达110238例，死亡病例为10096例。</li><li>4.4 全国默哀，全网黑白。纳入疗养院数据后，法国确诊病例跳跃性增至83029例。西班牙在过去24小时新增7026例，累计确诊124736例。</li><li>2020.4.7 山东援鄂护师张静静因抢救无效离世。英国首相约翰逊被转进重症监护室。法国单日死亡833人居欧洲首位，医院累计确诊74390例，养老院累计23620例。美国新增确诊病例27235例，新增死亡1127例，累计确诊362759例。</li><li>4.15 加油，意大利。意大利新增确诊2972例，新增死亡602例，为3月14日以来最低增幅。</li><li>4.16 两百万。全球确诊病例已超过200万例，达2000984例。累计死亡病例达128011例。哈尔滨聚集性疫情，传染链出现“跨省”传播，1传43。</li><li>4.18 非洲。过去一周非洲病例增加51%。</li><li>4.20 印度新冠肺炎确诊病例已升至16116例。其中死亡519例，治愈出院2302例。在过去24小时内，印度共新增1324例确诊病例。 美国累计确诊755533例，死亡40461例。新增确诊病例28888例，新增死亡2523例。</li><li>4.26 美国共有新冠病毒感染病例9333050例，新增感染病例42526例，新增死亡病例2374例。</li></ul></li></ul><ul><li><p>日本：山川异域，风月同天。</p></li><li><p>科比遇难 1.27 凌晨四点</p></li><li><p>2.14—2.18 美赛 with l,z.</p></li><li><p>2.24 浙大线上开学</p></li><li><p>2.27 巴基斯坦蝗灾</p></li><li><p>3.30 西昌突发山火。</p></li><li><p>3.31 2020年全国高考延期一个月举行，考试时间为7月7日至8日。</p></li><li><p>4.16 电动力学期中测试，打击与反转</p></li><li><p>4.24  罗志祥、肖战、柯洁</p></li></ul><p>多度paper多度经典文献建立整个学科面貌的认识，培养自己独立的科研兴趣和观点。</p>]]></content>
      
      
      <categories>
          
          <category> Life </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>Movies</title>
      <link href="/2020/02/07/Other%20Things/Movies/"/>
      <url>/2020/02/07/Other%20Things/Movies/</url>
      
        <content type="html"><![CDATA[<h1 id="电影们"><a href="#电影们" class="headerlink" title="电影们"></a>电影们</h1><ul><li>小丑</li><li>爱尔兰杀手</li></ul>]]></content>
      
      
      <categories>
          
          <category> life </category>
          
          <category> movie </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>Mathematic Modeling</title>
      <link href="/2020/02/07/Mathematics/Mathematical-Modeling/"/>
      <url>/2020/02/07/Mathematics/Mathematical-Modeling/</url>
      
        <content type="html"><![CDATA[<h1 id="美赛历年题目学习"><a href="#美赛历年题目学习" class="headerlink" title="美赛历年题目学习"></a>美赛历年题目学习</h1><h2 id="English"><a href="#English" class="headerlink" title="English"></a>English</h2><ul><li>a schematic diagram</li><li>Attributes 属性</li></ul><h2 id="2016-ICM-D"><a href="#2016-ICM-D" class="headerlink" title="2016 ICM D"></a>2016 ICM D</h2><h3 id="1-关键词"><a href="#1-关键词" class="headerlink" title="1. 关键词"></a>1. 关键词</h3><p>信息.</p><h3 id="2-有用的理论"><a href="#2-有用的理论" class="headerlink" title="2. 有用的理论"></a>2. 有用的理论</h3><ul><li>图论<ul><li>Nodes <ul><li>Type : media / person node</li><li>Degree </li><li>State : unknown, known, tired</li></ul></li><li>Edges<ul><li>Start node</li><li>End node</li><li>Time ( ～ communication tools )</li></ul></li></ul></li></ul><ul><li>Pareto Principle<ul><li>帕雷托法则指出，约仅有20%的变因操纵着80%的局面。也就是说：所有变量中，最重要的仅有20%，虽然剩余的80%占了多数，控制的范围却远低于“关键的少数”。</li><li>应用： If the news value meets the Pareto principle, then 20% of the news contains 80% of the total value of all the news in real world.</li></ul></li></ul><p>$ \ $ <a id="more"></a></p><ul><li><p>Indifference Curve 无差异曲线</p><ul><li><p>一条表示当消费者获得同样的效用时的消费组合曲线，其斜率一般为负值，这在经济学中表明在收入与价格既定的条件下，消费者为了获得同样的效用，增加一种商品的消费就必须减少或放弃另一种商品的消费，两种商品在消费者偏好不变的条件下，不能同时减少或增加。</p></li><li><p>应用：构造方程。“This function meets all the typical properties of an Indifference Curve. Thus it can be used to measure information’s inherent value based on its attributes.” </p></li></ul></li></ul><ul><li>Product life-cycle theory ( 产品生命周期理论， PLC )<ul><li>产品生命是指市上的营销生命，产品和人的生命一样，要经历形成，成长，成熟，衰退这样的周期。就产品而言，也就是要经历一个开发，转移，成长，成熟，衰退的阶段。而这个周期在不同的技术水平的国家里，发生的时间和过程是不一样的，期间存在一个相互矛盾的差异和时差，正是这一时差，表现为不同国家在技术上的差距，它反映了同一产品在不同国家市场上的竞争层次的差异，从而决定了国际贸易和国际投资的变化。</li><li>应用：利用产品生命周期理论模拟新通讯网络的诞生和旧通讯网络的衰落</li></ul></li></ul><h3 id="3-O奖论文结构"><a href="#3-O奖论文结构" class="headerlink" title="3. O奖论文结构"></a>3. O奖论文结构</h3><ul><li><p>引言、问题重述、假设、符号规定</p></li><li><p>利用图论建立通讯网络的拓扑图，微观（个人-个人）/ 宏观（媒体-个人）</p></li><li>建立信息价值模型 ，定义了信息的三个属性/类别 （极端、娱乐、新闻），利用无差异曲线和二八定律（帕雷托法则）构造出信息价值的方程，给出了评判信息是否为新闻的标准</li><li>建立信息流动的动态模型 ，主要给出了信息流动的过程（绘制了简易流程图）</li><li>利用BBC新闻的信息流动来作为模型检验和应用的例子，进行了信息的流动模拟仿真</li><li>利用产品生命周期理论建立信息网络更新换代的模型，用以预测2050年的信息网络变化。给网络容量下了公式定义，并给出了不同的网络性能量化指标。提出未来的三十年将出现三种新的信息网络，并给出了网络的强度（人们使用的频繁程度），然后用线性函数简化模型，给出了新的信息网络生命周期的线性函数表达式。</li><li>模型进一步扩展，加入了人的选择因素，引入“门槛效应”建立新的信息流动机制</li><li>灵敏性分析（不知道图是怎么做出来的）、模型优缺点分析</li></ul><h3 id="4-总结"><a href="#4-总结" class="headerlink" title="4. 总结"></a>4. 总结</h3><ul><li>他们的论文解释的很多很详细，但是就是不知道图是怎么出来的，数据怎么得到的。有的地方给出了公式或者文字说了好多就过去了，似乎不用计算。</li><li>灵活地应用了各种经济学的模型</li><li>查阅了详尽资料论文，信息网络有前人的论文可借鉴</li><li>我们的想法：可以引入香农的信息论内容进行分析</li></ul><h2 id="2017-ICM-E"><a href="#2017-ICM-E" class="headerlink" title="2017 ICM E"></a>2017 ICM E</h2><h3 id="1-关键词-1"><a href="#1-关键词-1" class="headerlink" title="1. 关键词"></a>1. 关键词</h3><p>smart growth</p><p>模糊综合评价、层次分析法</p><h3 id="2-我们的想法"><a href="#2-我们的想法" class="headerlink" title="2. 我们的想法"></a>2. 我们的想法</h3><h4 id="2-1-smart-growth-的10个原则（一级指标）"><a href="#2-1-smart-growth-的10个原则（一级指标）" class="headerlink" title="2.1 smart growth 的10个原则（一级指标）"></a>2.1 smart growth 的10个原则（一级指标）</h4><p>$U={U_i\mid i=1,\cdots,10}$</p><p>给出一级指标集对应的权重向量 $A=[a<em>1,\cdots,a</em>{10}]$</p><h4 id="2-2-衡量一座城市的10大指标"><a href="#2-2-衡量一座城市的10大指标" class="headerlink" title="2.2 衡量一座城市的10大指标"></a>2.2 衡量一座城市的10大指标</h4><p>$V={v_i\mid i=1,\cdots10}$</p><p>对每个 $U_i$ , 取其中不同的 $s$ 个指标作为评判不同 $U_i$ 的二级指标。</p><p>可以给出 $U<em>i$ 的指标集对应的权重向量 $A_i=[a_1,\cdots,a</em>{s}]$</p><h4 id="2-3-定义评语集：成功度"><a href="#2-3-定义评语集：成功度" class="headerlink" title="2.3 定义评语集：成功度"></a>2.3 定义评语集：成功度</h4><p>$S={s_i\mid i=1,\cdots,m}$</p><h4 id="2-4-综合评价"><a href="#2-4-综合评价" class="headerlink" title="2.4 综合评价"></a>2.4 综合评价</h4><ul><li><p>根据成功度对不同的二级指标作出评判，得到 10 个二级指标的 $s\times m$ 评判向量 $R_i$ ,  $ i=1,\cdots,10$ </p></li><li><p>第 $i$ 个一级指标的评判结果：$B<em>i=A_i\cdot R_i$， 组成综合评判矩阵 $R=[B_1;\cdots;B</em>{10}]$</p></li><li><p>最终综合评判结果 $B=A\cdot R$ , 根据最大隶属度原则，取 $B$ 中最大值对应的成功度作为城市 smart growth 的成功度</p></li></ul><h2 id="3-O奖论文学习"><a href="#3-O奖论文学习" class="headerlink" title="3 O奖论文学习"></a>3 O奖论文学习</h2><h3 id="3-1-English"><a href="#3-1-English" class="headerlink" title="3.1 English"></a>3.1 English</h3><p>propose feasible plan</p><p>To ameliorate this situation</p><p>According to the optimization model aforementioned</p><h3 id="3-2-有用的东西-可学习的东西"><a href="#3-2-有用的东西-可学习的东西" class="headerlink" title="3.2 有用的东西/可学习的东西"></a>3.2 有用的东西/可学习的东西</h3><ul><li><p>flow chart</p></li><li><p>表格里添加不同浅色背景</p></li><li><p>数据归一化处理方法</p></li><li><p>AHP：层次分析法</p></li><li><p>友好的Latex注记方式：<a href="https://www.latexstudio.net/archives/51620.html" target="_blank" rel="noopener">添加脚注</a></p></li><li><p>Entropy Weight Method 熵权法：确定综合评价的权重</p><p>客观赋权法，仅依赖于数据本身的离散性</p></li><li><p>K-means clustering Algorithm ：K-均值聚类</p><ul><li>把 n 个点（可以是样本的一次观察或一个实例）划分到 k 个聚类中，使得每个点都属于离他最近的均值（此即聚类中心）对应的聚类，以之作为聚类的标准。</li><li>应用：（甚妙）文中利用K均值聚类方法，通过求解非线性规划问题，得到衡量城市“smart growth”不同方面程度的量化值（类似“成功度”）</li></ul></li></ul><ul><li><p><a href="https://zhuanlan.zhihu.com/p/33692660" target="_blank" rel="noopener">SVM 和 SVR</a> </p></li><li><p>“ grid search algorithm ” 调整模型参数的算法（其实就是穷举）</p></li><li><p>Time Series Forecasting</p><p>时间序列预测,机器学习的一个重要领域</p></li><li><p>创新地结合SVM和时间序列预测方法（加权移动平均法），提出对未来的预测模型</p></li><li><p>radar diagram 雷达图</p></li></ul><h3 id="3-3-O奖论文结构"><a href="#3-3-O奖论文结构" class="headerlink" title="3.3 O奖论文结构"></a>3.3 O奖论文结构</h3><ul><li>引言、模型假设、符号说明</li><li>二级模糊综合评价，完成任务一。权重矩阵由层次分析法、“专家”评估法、熵权法获得；使用K-均值聚类方法获得城市“成功度”的量化值</li><li>使用雷达图、条形图介绍和对比两城市的现有发展规划，完成任务二</li><li>提出基于smart growth的城市发展规划，使用时间序列分析方法和支持向量机给出预测模型，完成任务三</li><li>根据不同城市的水平，提出不同的人口增长模型，在此基础上通过雷达图表现预测结果</li><li><p>用Matlab画了个三维图（参数1，参数2，误差）作为灵敏度分析</p></li><li><p>优缺点分析</p></li></ul><h2 id="2018-ICM-D"><a href="#2018-ICM-D" class="headerlink" title="2018 ICM D"></a>2018 ICM D</h2><h3 id="关键词"><a href="#关键词" class="headerlink" title="关键词"></a>关键词</h3><p>充电汽车，充电网络</p><h3 id="建模解题"><a href="#建模解题" class="headerlink" title="建模解题"></a>建模解题</h3><h3 id="Task-1"><a href="#Task-1" class="headerlink" title="Task 1"></a>Task 1</h3><p>Is Tesla on track to allow a complete switch to all-electric in the US? If everyone switched to all-electric personal passenger vehicles in the US, how many charging stations would be needed, and how should they be distributed between urban, suburban, and rural areas?</p><h4 id="符号说明"><a href="#符号说明" class="headerlink" title="符号说明"></a>符号说明</h4><ul><li><p>充电桩数量：$N_c$</p></li><li><p>汽车拥有量: $N$</p></li><li><p>充电汽车占有率：$\alpha$</p></li><li><p>在用电动汽车总数 ：$N_{EV}=\alpha\cdot N $</p></li><li><p>每天汽车总加油量 : $G$</p></li><li><p>每天内汽车总里程 $S=S(G)$</p></li><li><p>$N_c=f(P,s,\cdots)$</p></li></ul><h4 id="确定充电桩数量"><a href="#确定充电桩数量" class="headerlink" title="确定充电桩数量"></a>确定充电桩数量</h4><ol><li>一段时间内总的充电电动汽车数量：</li></ol><ul><li><p>电动汽车蓄电池的充电时间是一个受使用者偏好等随机因素影响的随机变量，根据中心极限定理，可认为电动汽车的平均充电时间服从正态分布 $N(\mu,\sigma)$，即不同的充电时间 $t$ 发生的概率为 $\phi(t)$.</p></li><li><p>$\mu,\sigma$ 和电动汽车的普及程度 、电动汽车各类型比例、不同类型电动汽车的充电时间有关，可以按两种类型的充电桩分别讨论</p></li><li><p>时间段 $T$ 内，在充电汽车数量：</p><script type="math/tex; mode=display">N_{charging}=N_{EV}\int_{T_0}^{T_0+T} \phi(t)dt</script></li></ul><ol><li><p>设置充电桩以不改变客户的出行方式为目的，就是假设确保不改变总里程 $S$, 每天充电总需求时间 $T_R=T_R(S)$</p></li><li><p>设每天每辆汽车平均充电 $m$ 次，每天充电总供给时间 $T<em>S=N</em>{charing}\cdot \Delta t \cdot m $</p></li><li><p>确定 $\mu$: 推荐加油时常</p></li><li><p>确定 $\sigma$</p></li></ol><ol><li><p>想法二：获得美国充电站数量的历年数据，使用预测方法推出需要的充电站数量。这也可以对上面的模型进行检验。</p></li><li><p>想法三：根据加油站数量等的历史数据，拟合出加油站数量在成长阶段的增长曲线。然后进行常数变异，拟合充电站的增长曲线。同样可以对上面的模型进行检验。</p></li></ol><h4 id="设置充电桩位置"><a href="#设置充电桩位置" class="headerlink" title="设置充电桩位置"></a>设置充电桩位置</h4><ol><li><p>要求：距离每个充电桩最近的充电桩在充电后可跑历程范围内 ；同时使用的充电桩消耗的功率不会使电网崩溃</p></li><li><p>具体化：白天任意时段内确保 $k$ km附近有空闲的目的地充电桩；乡镇需要：乡镇内每天有空闲的目的地充电桩；公路需要：沿途在一次充电里程的后半段内有空闲的加压充电桩</p></li><li><p>考虑因素：</p><ul><li>地域<ul><li>城市</li><li>乡村</li><li>城市—乡村过渡带</li></ul></li><li>电动汽车分布</li></ul></li><li><p>想法：</p><ul><li><p>利用层次分析法获得每个州的交通运输度综合评价得分，根据得分（看作权重）分配充电站数量。$N_i=N\times w_i$</p></li><li><p>根据各州的电动汽车保有量和交通运输量，在每个充电站里细分提供的充电桩种类和数量</p></li><li><p>先广覆盖，满足基本需求，再有针对性地根据地域和需求逐步增加数量</p></li><li><p>借鉴加油站的分布</p></li><li><p>由于智能充电引导系统的应用，可以假设驾驶员都可以选择最优的充电桩</p></li><li><p>若有美国电动汽车充电桩的数据，可使用K-means聚类方法确定充电站的位置：“如果我们定位了50个公共充电站，则将应用K-means方法将充电时间窗的位置划分为50个簇，然后将充电站定位在每个集群的质心处。”</p></li><li><p>电动汽车拥有率～所需充电里程数</p></li></ul></li></ol><ol><li><p>The electrification rate, defined as the ratio of miles PHEVs travel in all electric mode over the total driving miles, is adopted to evaluate different location plans。</p></li><li><p>Time series Simulation Model</p></li></ol><h3 id="电动汽车拥有量预测"><a href="#电动汽车拥有量预测" class="headerlink" title="电动汽车拥有量预测"></a>电动汽车拥有量预测</h3><ul><li>Bass 扩散模型</li></ul><h3 id="O奖论文学习"><a href="#O奖论文学习" class="headerlink" title="O奖论文学习"></a>O奖论文学习</h3><h4 id="D82504"><a href="#D82504" class="headerlink" title="D82504"></a>D82504</h4><h3 id="1-English"><a href="#1-English" class="headerlink" title="1. English"></a>1. English</h3><p>quantify the key factors’ influences</p><p>Redefine the concept of urban, suburban and rural areas</p><p>establish a functional relationship between the charger density and out chosen factors</p><p>in practice</p><p>Empirically 以经验为依据地</p><p>visualized simulation results</p><p>conduct further discussions</p><h3 id="2-有用的东西"><a href="#2-有用的东西" class="headerlink" title="2. 有用的东西"></a>2. 有用的东西</h3><ul><li><p>Markov method</p></li><li><p>Gini coefficient 基尼系数</p><p>判断年收入分配公平程度的指标。在0～1之间。基尼系数越小，年收入分配越平均；基尼系数越大，年收入分配越不平均。</p></li></ul><h3 id="3-Learn"><a href="#3-Learn" class="headerlink" title="3. Learn"></a>3. Learn</h3><ul><li>‘Related Work’ Section</li><li><p>写得好：“3.1 Tesla’s Objective”</p></li><li><p>use the completed charging network in Manhattan to estimate $c_u$</p></li><li><p>divide the urban area to several squares, and consider the distribution of stations in each square.</p></li><li><p>考虑实际情况，在用K-means聚类方法时使用曼哈顿距离（$L_1$）代替传统的欧式距离</p></li><li>在对电动汽车市场占有份额建模时，采用逻辑回归模型 Logistic Model</li></ul><h4 id="D82794"><a href="#D82794" class="headerlink" title="D82794"></a>D82794</h4><h3 id="English-1"><a href="#English-1" class="headerlink" title="English"></a>English</h3><p>from a macro perspective</p><p>Here we list the symbols and notations used in this paper, as shown in Table 1. </p><p>folk customs 民俗</p><h3 id="D81402"><a href="#D81402" class="headerlink" title="D81402"></a>D81402</h3><h4 id="1-English-1"><a href="#1-English-1" class="headerlink" title="1. English"></a>1. English</h4><h4 id="2-有用的东西-1"><a href="#2-有用的东西-1" class="headerlink" title="2. 有用的东西"></a>2. 有用的东西</h4><ul><li><p>决策策略：Nash Equilibrium</p></li><li><p>经济学概念：帕累托最优</p></li><li><p>传播理论：Bass diffusion model</p><p>适用于耐用消费品的分析预测。</p></li></ul><h2 id="论文写作"><a href="#论文写作" class="headerlink" title="论文写作"></a>论文写作</h2><h3 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h3><p>优秀的内容提要：对建模方法良好组织的精确的描述、获得的基本结果、你的建议。</p><h3 id="数学模型"><a href="#数学模型" class="headerlink" title="数学模型"></a>数学模型</h3><ul><li>明确了关键假设，说明详实合理，在建模过程中起到了作用</li><li>从数学和文字方面对建模动机和理由进行阐述</li><li>估算和解释模型中的参数值</li><li>重点分析了题目关键点</li><li>用到的结果和数据的调查，以及对用到的相关科学术语很好的解释</li><li>是否利用真是数据验证模型，是否测试了模型的精度和鲁棒性</li><li>如何利用模型来告知决策者并指导他未来的决策</li><li>你是否真正了解你的模型。应讨论模型的优缺点：局限性、假设条件的约束及所用方法的局限性。改善模型的方法。</li></ul><h3 id="信息、视觉、图表"><a href="#信息、视觉、图表" class="headerlink" title="信息、视觉、图表"></a>信息、视觉、图表</h3><p>写作规范、明了、适当使用图表。</p><h3 id="灵敏性分析"><a href="#灵敏性分析" class="headerlink" title="灵敏性分析"></a>灵敏性分析</h3><ul><li><p>对参数添加呈正态分布的随机变量干扰</p></li><li><p>添加高斯噪声</p></li><li><p>交叉验证</p></li></ul>]]></content>
      
      
      <categories>
          
          <category> Mathematics </category>
          
          <category> Mathematics Modeling </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>学习规划</title>
      <link href="/2020/02/06/Other%20Things/%E5%AD%A6%E4%B9%A0%E8%A7%84%E5%88%92/"/>
      <url>/2020/02/06/Other%20Things/%E5%AD%A6%E4%B9%A0%E8%A7%84%E5%88%92/</url>
      
        <content type="html"><![CDATA[<h2 id="大二下"><a href="#大二下" class="headerlink" title="大二下"></a>大二下</h2><p>$ \ $ <a id="more"></a></p><p>6.24, 6.26, (6.27) ,6.29, 6.30, 7.2, 7.3</p><ul><li><p>物理的学习</p><ul><li><p>电动力学 6.24 8:00-10:00</p><ul><li><p>课前预习</p></li><li><p>上课认真做笔记</p></li><li>上课后Markdown整理</li><li>教材未知</li></ul></li></ul></li></ul><ul><li><p>理论力学7.2 10:30—12:30</p><ul><li>课前预习</li><li>上课认真做笔记</li></ul></li></ul><ul><li><p>应用光学 7.3 8:00—10:00</p><ul><li>当天必须解决不明白的</li><li>每周整理</li></ul></li></ul><ul><li>数理方法II 4.23 10:30—12:30</li></ul><ul><li><p>专业课的学习</p><ul><li><p>数电 6.29 8:00-10:00</p><ul><li>上课认真听</li><li>每周整理笔记</li></ul></li></ul></li></ul><ul><li>信号与系统 6.26 14:00-16:00</li></ul><ul><li><p>数学的学习</p><ul><li>线性代数 6.30—8:00—10:00</li><li>矩阵论十讲</li><li>随机过程 6.27 10:30—12:30 周五345，西1-106</li><li>凸优化</li></ul></li></ul><ul><li><p>计算机的学习</p><ul><li>数字图像处理 自学完成</li><li>机器学习：<strong>CS229</strong></li><li>数据结构</li><li>爬虫</li></ul></li></ul><ul><li><p>硬件软件配置</p><ul><li>配置好 Texpad</li><li>Sublime 的代码自动补全配置</li><li>IPython或jupyter notebook的配置</li></ul></li></ul><ul><li><p>科研与竞赛</p><ul><li>导师的那篇论文 CNN实现<ul><li>可能要去看 <a href="http://cs231n.stanford.edu/syllabus.html" target="_blank" rel="noopener">CS231</a></li></ul></li><li><p>中控杯（须尽快完成）</p></li><li><p>SRTP</p></li><li>物理创新竞赛<ul><li>可能要学习 <a href="https://morvanzhou.github.io/tutorials/python-basic/tkinter/" target="_blank" rel="noopener">Tkinter窗口库</a></li></ul></li></ul></li><li><p>课余时间（少）</p><ul><li><p>每天跑步和早起早睡</p></li><li><p>围棋</p></li><li>台球</li><li>npy？</li></ul></li><li><p>GRE（重要） 5.9</p></li><li><p>待完成</p><ul><li>数值分析的整理</li></ul></li></ul><h2 id="大三"><a href="#大三" class="headerlink" title="大三"></a>大三</h2><ul><li>微分几何</li><li>大数据分析</li><li>概率论</li><li>数理统计</li><li>数据库</li><li>数据结构</li></ul>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>Mathematics Models</title>
      <link href="/2020/02/01/Mathematics/Mathematic-Models/"/>
      <url>/2020/02/01/Mathematics/Mathematic-Models/</url>
      
        <content type="html"><![CDATA[<h1 id="数学建模-模型学习"><a href="#数学建模-模型学习" class="headerlink" title="数学建模 模型学习"></a>数学建模 模型学习</h1><h2 id="1-确定性连续模型"><a href="#1-确定性连续模型" class="headerlink" title="1 确定性连续模型"></a>1 确定性连续模型</h2><h2 id="1-1-静态优化模型-微分法建模"><a href="#1-1-静态优化模型-微分法建模" class="headerlink" title="1.1 静态优化模型/微分法建模"></a>1.1 静态优化模型/微分法建模</h2><h3 id="1-1-1-不允许缺货的存贮模型"><a href="#1-1-1-不允许缺货的存贮模型" class="headerlink" title="1.1.1 不允许缺货的存贮模型"></a>1.1.1 不允许缺货的存贮模型</h3><ol><li><p>模型假设：</p><ul><li>每天存货费用：$c_1$  元/吨</li><li>每次订货费用：$c_2$  元</li><li>每天货物需求量：$r$ 吨/天</li><li>任意时刻 $t$ 的货物贮存量：$q(t)$</li><li>订货周期：$T$  天</li><li>每次订货数量：$Q$  吨</li></ul></li><li><p>模型假设：</p><p>每次订货后库存量均匀下降：</p><script type="math/tex; mode=display">\frac{dq}{dt}=-r,\qquad q(0)=Q \\q(t)=-r\cdot t+Q</script></li><li><p>模型建立：</p><ul><li>订货数量、订货周期、每日货物需求的关系：</li></ul><script type="math/tex; mode=display">Q=r\cdot T</script></li></ol><ul><li><p>每日平均花费：</p><script type="math/tex; mode=display">Cost(T)=\frac{1}{T}\cdot(c_2+c_1\int_0^Tq(t)dt)=\frac{c_2}{T}+\frac{1}{2}c_1 rT</script></li></ul><ul><li><p>目标：$min[Cost]$</p><script type="math/tex; mode=display">\frac{dCost}{dT}=0\\=> T=\sqrt{\frac{2c_2}{c_1r}},\quad Q=\sqrt{\frac{2c_2r}{c_1}}</script></li></ul><p>$ \ $ <a id="more"></a></p><h3 id="1-1-2-允许缺货的存贮模型"><a href="#1-1-2-允许缺货的存贮模型" class="headerlink" title="1.1.2 允许缺货的存贮模型"></a>1.1.2 允许缺货的存贮模型</h3><h2 id="2-遗传算法-GA"><a href="#2-遗传算法-GA" class="headerlink" title="2 遗传算法 GA"></a>2 遗传算法 GA</h2><h3 id="2-1-算法流程"><a href="#2-1-算法流程" class="headerlink" title="2.1 算法流程"></a>2.1 算法流程</h3><ul><li><p>适应度函数</p><p>目标函数，函数的最优值便是适应度最高（最适合生存）的种群的适应度</p></li><li><p>变异</p><p>产生跳出局部最优解的可能</p></li></ul><h3 id="2-2-单目标优化"><a href="#2-2-单目标优化" class="headerlink" title="2.2 单目标优化"></a>2.2 单目标优化</h3><p>pass</p><h2 id="3-综合评价方法"><a href="#3-综合评价方法" class="headerlink" title="3 综合评价方法"></a>3 综合评价方法</h2><h3 id="3-1-层次分析法-AHP"><a href="#3-1-层次分析法-AHP" class="headerlink" title="3.1 层次分析法 AHP"></a>3.1 层次分析法 AHP</h3><p>Analytic Hierarchy Process.</p><p><a href="https://zhuanlan.zhihu.com/p/38207837" target="_blank" rel="noopener">算法流程</a>：</p><ul><li><p>建模，确定各层次因素</p></li><li><p>进行单层次排序（从上往下）</p><ul><li>对于每一个上一层对元素，挨个分析每一层因素的相对重要性，构建成对比较矩阵（使用<strong>1-9标度法</strong>）</li><li>进行一致性检验（传递性），不通过则需要调整相对重要性</li><li>获得归一化的最大特征向量，最为当前层对上一层对权重向量 </li></ul></li><li><p>进行层次总排序，获得最下层每个元素对最终目标的归一化权重向量（从下往上）</p></li><li><p>得到决策结果</p></li></ul><p>为什么特征向量可以作为权重？</p><p>可证充分性。$AX$的列向量的第 $i$ 个元素可以作为第 $i$ 个指标的综合评价（=$\sum_j$第 $i$ 个元素对第 $j$ 个元素的重要程度$\times$ 第 $j$ 个元素的最终权重），正比于第 $i$ 个元素的最终权重（$AX=\lambda X $）</p><h3 id="3-2-主成分分析-PCA"><a href="#3-2-主成分分析-PCA" class="headerlink" title="3.2 主成分分析 PCA"></a>3.2 主成分分析 PCA</h3><p>Principle Component Analysis.</p><p>应用：</p><ul><li><p>变量较多，需要从数据中挖掘出主要成分。通过正交变换，消除变量之间的相关影响。</p></li><li><p>对多变量的截面数据表进行最佳综合简化。</p></li><li><p>对指标进行客观赋权。（从相关系数矩阵的特征值引出的信息贡献率可作为”新变量“的权重）</p></li></ul><p>算法流程：</p><ul><li>设指标变量为 $\mathbf{x}=[x_1,\cdots,x_n]$</li><li>将变量标准化、去除量纲：$\mathbf{\widetilde x}=\displaystyle\frac{\mathbf{x}-\mu}{\sigma}$</li><li>获得 $\mathbf{\widetilde x}$ 的相关系数矩阵 $R=(r<em>{ij})</em>{n\times n }$</li><li>计算 $R$ 的特征值 $\lambda_1\geq\cdots \geq\lambda_n$ 和对应的特征(列)向量 $\mathbf{\mu_1,\cdots\mu_n}$</li><li>设 $\mathbf{\mu<em>i}=[\mu</em>{1i},\cdots,\mu<em>{ni}]^T$, 得到新的变量：$\mathbf{y_i}=\sum_j \mu</em>{ji}\cdot\widetilde x_i$</li><li>特征值 $\lambda<em>i$ 的信息贡献率 $b_i=\lambda_i\big/(\sum_i \lambda_i)$, 累计贡献率 $\alpha_p=(\sum</em>{j=1}^p \lambda_j)\big/(\sum_i\lambda_i)$</li><li>根据累计贡献率挑选出主成分</li><li>根据信息贡献率得到基于主成分的综合评价得分：$Z=\sum_{j=1}^p b_j y_j$</li></ul><h3 id="3-3-模糊综合评价"><a href="#3-3-模糊综合评价" class="headerlink" title="3.3 模糊综合评价"></a>3.3 模糊综合评价</h3><p>Fuzzy Comprehension Evaluation.</p><p>应用：评价的人多的时候比较好，比如人事考核，军训打分。</p><h4 id="（1）一级模糊综合评判"><a href="#（1）一级模糊综合评判" class="headerlink" title="（1）一级模糊综合评判"></a>（1）一级模糊综合评判</h4><ul><li><p>确定因素集 $U={u_1,\cdots,u_n}$</p></li><li><p>确定各因素权重  $A=[a_1,\cdots,a_n]$</p><ul><li>主成分分析</li><li><a href="https://zhuanlan.zhihu.com/p/28067337" target="_blank" rel="noopener">熵权法</a>（基于多个样本在指标下的离散程度赋权）</li><li>专家评估</li><li>众人打分</li></ul></li><li><p>确定评语集 $V={v_1,\cdots,v_m}$</p></li><li><p>对每个因素 $u<em>i$ 获得一个对应评语集的评价向量 $R_i=[r</em>{i1},\cdots,r<em>{im}]$, 得到模糊综合判断矩阵 $R=(r</em>{ij})<em>{n\times m}$ （$r</em>{ij}\%$ 的人认为第 $i$ 个因素可以达到评语 $v_j$ ）</p></li><li><p>综合评判 $B=A\cdot R=[b_1,\cdots, b_m]$, 可取数值最大的评语作为最终结果（最大隶属度原则）</p></li></ul><h4 id="（2）多级模糊综合评判"><a href="#（2）多级模糊综合评判" class="headerlink" title="（2）多级模糊综合评判"></a>（2）多级模糊综合评判</h4><p><a href="http://html.rhhz.net/ZGJCYJ/html/2007-03-30.htm" target="_blank" rel="noopener">例子</a></p><h3 id="3-4-灰色关联评估"><a href="#3-4-灰色关联评估" class="headerlink" title="3.4 灰色关联评估"></a>3.4 灰色关联评估</h3><p>灰色系统理论的一个分支，应用于受多种相互关联因素影响的事物和现象的综合评价问题。</p><h3 id="3-5-可作为综合题练习"><a href="#3-5-可作为综合题练习" class="headerlink" title="3.5 可作为综合题练习"></a>3.5 可作为综合题练习</h3><p>第1辑第3章医疗保健系统评估问题。</p><h2 id="模拟-仿真方法"><a href="#模拟-仿真方法" class="headerlink" title="模拟/仿真方法"></a>模拟/仿真方法</h2><h3 id="元胞自动机"><a href="#元胞自动机" class="headerlink" title="元胞自动机"></a>元胞自动机</h3><p>制定规则，模拟。</p><ul><li><a href="https://blog.csdn.net/Harrytsz/article/details/85094334" target="_blank" rel="noopener">模拟交通流</a></li><li><a href="https://blog.csdn.net/weixin_39590507/article/details/86760958" target="_blank" rel="noopener">模拟游客疏散</a> </li><li><a href="https://github.com/chen622/Louvre" target="_blank" rel="noopener">比较全面地模拟游客疏散</a></li><li><a href="https://blog.csdn.net/your_answer/article/details/79287367" target="_blank" rel="noopener">模拟流言传播</a></li></ul><h2 id="模型"><a href="#模型" class="headerlink" title="模型"></a>模型</h2><ul><li><p>贝叶斯信念网络 （概率图）</p></li><li><p>小世界模型</p></li><li><p>Lotka–Volterra方程（捕食者-被捕食者方程） 可发挥创造性推广至多捕食者多被捕食者的动态网络。</p></li><li><p>扩散模型</p><ul><li>扩散方程</li><li>高斯烟流模式：大气污染预测</li><li>技术扩散模型：Bass Diffusion Model</li><li>创新扩散模型：Diffusion of Innovations Theory</li></ul></li><li><p>拓扑网络</p><ul><li>局部中心</li><li>影响度</li><li>Pagerank 佩奇排名算法度量网络节中心性</li></ul></li><li><p>普林斯顿海洋模型（POM） 47、48</p></li><li><p>Forrester 世界模型 51</p></li></ul>]]></content>
      
      
      <categories>
          
          <category> Mathematics </category>
          
          <category> Mathematics Modeling </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>神经网络学习</title>
      <link href="/2020/01/30/Computer-Sciencs/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%AD%A6%E4%B9%A0/"/>
      <url>/2020/01/30/Computer-Sciencs/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%AD%A6%E4%B9%A0/</url>
      
        <content type="html"><![CDATA[<h1 id="神经网络-学习笔记"><a href="#神经网络-学习笔记" class="headerlink" title="神经网络 学习笔记"></a>神经网络 学习笔记</h1><p>学习资源: <a href="">neuralnetworksanddeeplearning.com</a></p><h2 id="Chapter-1、2"><a href="#Chapter-1、2" class="headerlink" title="Chapter 1、2"></a>Chapter 1、2</h2><h3 id="1-1-基本概念"><a href="#1-1-基本概念" class="headerlink" title="1.1 基本概念"></a>1.1 基本概念</h3><ul><li><p>activation function 激活函数/传递函数   定义了该节点在给定的输入或输入的集合下的输出，比如 sigmoid function</p></li><li><p>perceptron model 感知器：输入 $0,1$ 二值函数，输出 $0,1$ 二值函数</p></li><li><p>sigmoid neurons  S 神经元  </p><p>​    中间部分更精细，$\displaystyle\sigma(z)=\frac{1}{1+e^{-z}}$ 输入二值，输出为 $[0,1]$ 之间的数，极限性质和感知器一样</p></li><li><p>feedforward neural networks 前馈神经网络</p><p>​    没有反馈的神经网络，由输入层(input layer)、隐藏层(hidden layer)、输出层(output layer)构成</p></li></ul><p>$ \ $ <a id="more"></a></p><h3 id="1-2-stochastic-gradient-descent-随机梯度下降"><a href="#1-2-stochastic-gradient-descent-随机梯度下降" class="headerlink" title="1.2 stochastic gradient descent 随机梯度下降"></a>1.2 stochastic gradient descent 随机梯度下降</h3><h4 id="1-2-1-参数"><a href="#1-2-1-参数" class="headerlink" title="1.2.1 参数"></a>1.2.1 参数</h4><ul><li>$x$ ：输入的训练集（一个矩阵，每一列是一次单独的输入）,  $y$ ：最终输出，$y=w\cdot x+b$</li><li>$w$：weights，由矩阵组成的向量。$w_j$ 是一个 $m\times n$ 型矩阵，连接 $j-1$ 层和 $j$ 层，其中 $j-1$ 层有 $n$ 个神经元，$ j $ 层有 $m$ 个神经元</li><li>$b$ ：biases，由 $ m\times 1$ 型矩阵组成的向量。 $b_k$ 是一个$m\times 1$ 型矩阵，连接 $j-1$ 层和 $j$ 层，其中第 $j$ 层有 $m$ 个神经元</li><li>Cost function ： $ C(w,b)=\displaystyle\frac{1}{2n}\sum<em>x |y(x)-a |^2=\frac{1}{2n}\sum</em>{i=1}^{n}[y(x^{(i)})-a^{(i)}]^2 $</li></ul><h4 id="1-2-2-方法"><a href="#1-2-2-方法" class="headerlink" title="1.2.2 方法"></a>1.2.2 方法</h4><ul><li>对于整个训练集，用随机梯度下降法使损失函数尽可能小</li><li>先将训练集打乱，再按给定的小批训练集大小等间隔取小批训练集（相当于随机取样），每次选择更优的 $w,b$ 使损失函数一步步减小</li></ul><h4 id="1-2-3-保证每次都获得更优的-w-b-："><a href="#1-2-3-保证每次都获得更优的-w-b-：" class="headerlink" title="1.2.3 保证每次都获得更优的 $w,b$："></a>1.2.3 保证每次都获得更优的 $w,b$：</h4><ol><li><script type="math/tex; mode=display">\displaystyle \nabla C=(\frac{\partial C}{\partial v_1},\frac{\partial C}{\partial v_2})^T , \quad \vec v_1\equiv v_1\equiv w,\vec v_2\equiv v_2\equiv b\\ \displaystyle\Delta C\approx  \frac{\partial C}{\partial w}\Delta v_1+\frac{\partial C}{\partial b}\Delta v_2=\Delta v\cdot \nabla C \\ => take\quad \Delta v=(\Delta v_1,\Delta v_2)=-\eta \nabla C,\quad \eta>0\\\begin{aligned}\therefore C&:=C+\Delta C=C-\eta \|\nabla C \|^2\\v_1& :=v_1-\eta\cdot\frac{\partial C}{\partial v_1}\\v_2&:=v_2-\eta\cdot\frac{\partial C}{\partial v_2s}\end{aligned}</script></li><li><p>分量式：</p></li></ol><script type="math/tex; mode=display">\begin{aligned}w_{jk}&:=w_{jk}-\eta\cdot \frac{\partial C}{\partial w_{jk}}=w_{jk}-\eta\cdot \nabla C_{w_{jk}}\approx w_{jk}-\eta\cdot \frac{1}{m}\sum_{i=1}^m \frac{\partial C}{\partial w_{jk}^{(i)}} \\b_{k}&:=b_{ k}-\eta\cdot \frac{\partial C}{\partial b_{k}}=b_{k}-\eta\cdot \nabla C_{b_{k}}\approx b_{k}-\eta\cdot\frac{1}{m}\sum_{i=1}^m \frac{\partial C}{\partial b_{k}^{(i)}}\end{aligned}</script><h2 id="2-BP算法（反向传播-back-propagate-）"><a href="#2-BP算法（反向传播-back-propagate-）" class="headerlink" title="2 BP算法（反向传播 back propagate ）"></a>2 BP算法（反向传播 back propagate ）</h2><p>目的：快速计算 $\displaystyle \frac{\partial C}{\partial w},\frac{\partial C}{\partial b}$ .</p><h3 id="2-1-原理："><a href="#2-1-原理：" class="headerlink" title="2.1 原理："></a>2.1 原理：</h3><p>最终结果产生的偏差是由于每个神经元产生的误差叠加起来造成的。通过前向反馈得到的结果若与正确结果有偏差，则从此偏差反向推导，可得到各层神经元产生的误差。</p><h3 id="2-2-符号表示"><a href="#2-2-符号表示" class="headerlink" title="2.2 符号表示"></a>2.2 符号表示</h3><ul><li>$w_{jk}^l$ ：连接第 $l-1$层第 $k$ 个神经元和第 $l$ 层第 $j$ 个神经元的权重</li><li>$w^l$ ：连接第 $l-1$ 和第 $l$ 层网络的权重矩阵</li><li>$b_j^l$ ：第 $l$ 层第 $j$ 个神经元的 bias</li><li>$z<em>j^l$ ：第 $l$ 层网络的带权输入  $z_j^l=\displaystyle\sum_k w</em>{jk}^l a_k^{l-1}+b_j^l$，$z^l=w^l a^{l-1}+b^l$</li><li><p>$\delta_j^l$ ：第 $l$ 层第 $j$ 个神经元产生的误差,，定义 $\displaystyle \delta^l_j \equiv \frac{\partial C}{\partial z^l_j}$</p></li><li><p>$a_j^l$ ：第 $l$ 层网络的第 $j$ 个神经元的激活量，$a_j^l=\sigma(z_j^l)$</p></li><li>$C$ ：损失函数，用小批量输入的平均值近似。</li></ul><h3 id="2-3-重要的关系公式"><a href="#2-3-重要的关系公式" class="headerlink" title="2.3 重要的关系公式"></a>2.3 重要的关系公式</h3><ol><li><p>注：推导中的除法 ‘’$\bigg /$ ‘’、乘法 $\odot$ （ Hadamard Product）均为<strong>elementwise</strong> </p></li><li><script type="math/tex; mode=display">C=\displaystyle \frac{1}{2n}\sum_x \|y(x)-a^L(x)\|^2=\frac{1}{n}\sum_x ^n C(x)\approx\frac{1}{m}\sum_x^m C(x)\\ C(x)=\frac{1}{2}\|y-a^L(x)\|^2=\frac{1}{2}\sum_i \big(y_i-a_i^L(x)\big)^2</script></li></ol><ol><li><script type="math/tex; mode=display">a_j^l=\sigma\bigg(\sum_k w_{jk}^l a_k^{l-1}+b_j^l\bigg)\\ a^l=\sigma\bigg(w^l a^{l-1}+b^l\bigg)</script></li></ol><ol><li><script type="math/tex; mode=display">\delta^l=\frac{\partial C}{\partial b^l}\bigg/ \frac{\partial z^l}{\partial b^l}=\frac{\partial C}{\partial b^l},\qquad \frac{\partial C}{\partial b^l}\triangleq(\frac{\partial C}{\partial b_1^l},\cdots,\frac{\partial C}{\partial b_{N(l)}^l})^T \tag{1}</script></li></ol><ol><li><script type="math/tex; mode=display">\delta_j^l=\frac{\partial C}{\partial w_{jk}^l}\bigg /\frac{\partial z^l}{\partial w_{jk}^l}=\frac{\partial C}{\partial w_{jk}^l}\big/ a_k^{l-1}</script></li></ol><script type="math/tex; mode=display">i .e. \qquad \frac{\partial C}{\partial w_{jk}^l}=a_{k}^{l-1}\cdot  \delta_j^l \qquad =>\nabla C_{w^l}=\delta^l\cdot (a^{l-1})^T \tag{2}</script><ol><li><script type="math/tex; mode=display">\delta^L=\frac{\partial C}{\partial a^L}\odot \frac{\partial a^L}{\partial z^L}=\frac{\partial C}{\partial a^L}\odot\sigma'(z^L)=(a^L-y) \odot \sigma'(z^L)\tag{3}</script></li></ol><ol><li><p><strong>Move error backward:</strong></p><script type="math/tex; mode=display">\begin{eqnarray}z^{l+1}_k = \sum_j w^{l+1}_{kj} a^l_j +b^{l+1}_k = \sum_j w^{l+1}_{kj} \sigma(z^l_j) +b^{l+1}_k=>\frac{\partial z^{l+1}_k}{\partial z^l_j} = w^{l+1}_{kj} \sigma'(z^l_j)\end{eqnarray}</script><script type="math/tex; mode=display">\delta_j^l=\sum_k \frac{\partial C}{\partial z_k^{l+1}}\cdot \frac{\partial z_k^{l+1}}{\partial z_j^l}=\sum_{k=1}^{N(l)}\delta_k^{l+1}\cdot w_{kj}^{l+1}\cdot \sigma'(z_j^l)</script></li></ol><script type="math/tex; mode=display">   => \delta^l=\big((w^{l+1})^T\sigma'(z^l)\big)\odot \delta^{l+1}\tag{4}</script><h3 id="2-4-实现步骤"><a href="#2-4-实现步骤" class="headerlink" title="2.4 实现步骤"></a>2.4 实现步骤</h3><ol><li><p>feedforward :  得到 $z^L$ 和相应的 $a^L$</p><script type="math/tex; mode=display">a^{x,l} = \sigma(z^{x,l})</script></li><li><p>output error :</p><script type="math/tex; mode=display">\delta^{x,L} = \nabla_a C_x \odot \sigma'(z^{x,L})</script></li><li><p>error back propagate :  </p><script type="math/tex; mode=display">\delta^{x,l} = ((w^{l+1})^T \delta^{x,l+1})  \odot \sigma'(z^{x,l})</script></li></ol><ol><li>update weights and biases : <script type="math/tex; mode=display">\begin{aligned}w_{jk}&:=w_{jk}-\eta\cdot \nabla C_{w_{jk}}\approx w_{jk}-\eta\cdot \frac{1}{m}\sum_{i=1}^m \frac{\partial C}{\partial w_{jk}^{(x_i)}}=w_{jk}-\eta\cdot\frac{1}{m}\sum_{i=1}^m \big(a_k^{l-1}\delta_j^{l}\big)^{(x_i)}\\b_{k}&:=b_{k}-\eta\cdot \nabla C_{b_{k}}\approx b_{k}-\eta\cdot\frac{1}{m}\sum_{i=1}^m \frac{\partial C}{\partial b_{k}^{(x_i)}}=b_{k}-\eta\cdot\frac{1}{m}\sum_{i=1}^m \big(\delta_k^{l}\big)^{(x_i)}\end{aligned}</script></li></ol><p>   即：</p><script type="math/tex; mode=display">   w^l \rightarrow     w^l-\frac{\eta}{m} \sum_x \delta^{x,l} (a^{x,l-1})^T    \\b^l \rightarrow b^l-\frac{\eta}{m}     \sum_x \delta^{x,l}</script><h3 id="2-5-代码实现"><a href="#2-5-代码实现" class="headerlink" title="2.5 代码实现"></a>2.5 代码实现</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> random<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><br><br><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Network</span><span class="hljs-params">(object)</span>:</span><br><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span><span class="hljs-params">(self, sizes)</span>:</span><br>        <span class="hljs-comment"># 生成神经网络 </span><br>        self.num_layers = len(sizes)<br>        self.sizes = sizes<br>        self.biases = [np.random.randn(y, <span class="hljs-number">1</span>) <span class="hljs-keyword">for</span> y <span class="hljs-keyword">in</span> sizes[<span class="hljs-number">1</span>:]]<br>        self.weights = [np.random.randn(y, x)<br>                        <span class="hljs-keyword">for</span> x, y <span class="hljs-keyword">in</span> zip(sizes[:<span class="hljs-number">-1</span>], sizes[<span class="hljs-number">1</span>:])]<br><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">feedforward</span><span class="hljs-params">(self, a)</span>:</span><br>        <span class="hljs-comment"># 激活神经元，向后面的层产生反馈</span><br>        <span class="hljs-keyword">for</span> b, w <span class="hljs-keyword">in</span> zip(self.biases, self.weights):<br>            a = sigmoid(np.dot(w, a) + b)<br>        <span class="hljs-keyword">return</span> a<br><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">SGD</span><span class="hljs-params">(self, training_data, epochs, mini_batch_size, eta,<br>            test_data=None)</span>:</span><br>        <span class="hljs-comment"># 随机梯度下降 Stochastic Gradient Descent</span><br>        <span class="hljs-comment"># epochs 训练次数, mini_batch_size 每次选取的小训练集大小, eta 学习率 由自己设定</span><br>        <span class="hljs-keyword">if</span> test_data:<br>            test_data = list(test_data)  <br>            n_test = len(test_data)<br>        training_data = list(training_data)<br>        n = len(training_data)<br>        <br>        <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> range(epochs):<br>            random.shuffle(training_data)<br>            mini_batches = [<br>                training_data[k:k + mini_batch_size]<br>                <span class="hljs-keyword">for</span> k <span class="hljs-keyword">in</span> range(<span class="hljs-number">0</span>, n, mini_batch_size)]  <br>            <span class="hljs-keyword">for</span> mini_batch <span class="hljs-keyword">in</span> mini_batches:<br>                self.update_mini_batch(mini_batch, eta)<br>            <span class="hljs-keyword">if</span> test_data:<br>                print(<span class="hljs-string">"Epoch &#123;0&#125;: &#123;1&#125; / &#123;2&#125;"</span>.format(j,<br>                                                    self.evaluate(test_data), n_test))<br><br>            <span class="hljs-keyword">else</span>:<br>                print(<span class="hljs-string">"Epoch &#123;0&#125; complete"</span>.format(j))<br><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">update_mini_batch</span><span class="hljs-params">(self, mini_batch, eta)</span>:</span><br>        <span class="hljs-comment"># 更新 w 和 b</span><br>        nabla_b = [np.zeros(b.shape) <span class="hljs-keyword">for</span> b <span class="hljs-keyword">in</span> self.biases]<br>        nabla_w = [np.zeros(w.shape) <span class="hljs-keyword">for</span> w <span class="hljs-keyword">in</span> self.weights]<br>        <span class="hljs-keyword">for</span> x, y <span class="hljs-keyword">in</span> mini_batch:<br>            delta_nabla_b, delta_nabla_w = self.backprop(x, y)<br>            nabla_b = [nb + dnb <span class="hljs-keyword">for</span> nb, dnb <span class="hljs-keyword">in</span> zip(nabla_b, delta_nabla_b)]<br>            nabla_w = [nw + dnw <span class="hljs-keyword">for</span> nw, dnw <span class="hljs-keyword">in</span> zip(nabla_w, delta_nabla_w)]<br>        self.weights = [w - (eta / len(mini_batch)) * nw<br>                        <span class="hljs-keyword">for</span> w, nw <span class="hljs-keyword">in</span> zip(self.weights, nabla_w)]<br>        self.biases = [b - (eta / len(mini_batch)) * nb<br>                       <span class="hljs-keyword">for</span> b, nb <span class="hljs-keyword">in</span> zip(self.biases, nabla_b)]<br><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">backprop</span><span class="hljs-params">(self, x, y)</span>:</span><br>        <span class="hljs-comment"># 反向传播算法</span><br>        nabla_b = [np.zeros(b.shape) <span class="hljs-keyword">for</span> b <span class="hljs-keyword">in</span> self.biases]<br>        nabla_w = [np.zeros(w.shape) <span class="hljs-keyword">for</span> w <span class="hljs-keyword">in</span> self.weights]<br>        <span class="hljs-comment"># feedforward</span><br>        activation = x<br>        activations = [x]  <span class="hljs-comment"># list to store all the activations, layer by layer</span><br>        zs = []  <span class="hljs-comment"># list to store all the z vectors, layer by layer</span><br>        <span class="hljs-keyword">for</span> b, w <span class="hljs-keyword">in</span> zip(self.biases, self.weights):<br>            z = np.dot(w, activation) + b<br>            zs.append(z)<br>            activation = sigmoid(z)<br>            activations.append(activation)<br>        <span class="hljs-comment"># backward pass</span><br>        delta = self.cost_derivative(activations[<span class="hljs-number">-1</span>], y) * \<br>            sigmoid_prime(zs[<span class="hljs-number">-1</span>])<span class="hljs-comment"># \delta^L</span><br>        nabla_b[<span class="hljs-number">-1</span>] = delta<br>        nabla_w[<span class="hljs-number">-1</span>] = np.dot(delta, activations[<span class="hljs-number">-2</span>].transpose())<br><br>        <span class="hljs-keyword">for</span> l <span class="hljs-keyword">in</span> range(<span class="hljs-number">2</span>, self.num_layers):<br>            z = zs[-l]<br>            sp = sigmoid_prime(z)<br>            delta = np.dot(self.weights[-l + <span class="hljs-number">1</span>].transpose(), delta) * sp<br>            nabla_b[-l] = delta<br>            nabla_w[-l] = np.dot(delta, activations[-l - <span class="hljs-number">1</span>].transpose())<br>        <span class="hljs-keyword">return</span> (nabla_b, nabla_w)<br><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">evaluate</span><span class="hljs-params">(self, test_data)</span>:</span><br>       <span class="hljs-comment"># 返回输出结果和训练数据集的正确结果相同的个数</span><br>        test_results = [(np.argmax(self.feedforward(x)), y)<br>                        <span class="hljs-keyword">for</span> (x, y) <span class="hljs-keyword">in</span> test_data]<br>        <span class="hljs-keyword">return</span> sum(int(x == y) <span class="hljs-keyword">for</span> (x, y) <span class="hljs-keyword">in</span> test_results) <br><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">cost_derivative</span><span class="hljs-params">(self, output_activations, y)</span>:</span><br>        <span class="hljs-string">"""Return the vector of partial derivatives \partial C_x /<br>        \partial a for the output activations."""</span><br>        <span class="hljs-keyword">return</span> (output_activations - y)<br><br><span class="hljs-comment"># Miscellaneous functions</span><br><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">sigmoid</span><span class="hljs-params">(z)</span>:</span><br>    <span class="hljs-comment"># The sigmoid function.</span><br>    <span class="hljs-keyword">return</span> <span class="hljs-number">1.0</span> / (<span class="hljs-number">1.0</span> + np.exp(-z))<br><br><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">sigmoid_prime</span><span class="hljs-params">(z)</span>:</span><br>    <span class="hljs-comment"># Derivative of the sigmoid function.</span><br>    <span class="hljs-keyword">return</span> sigmoid(z) * (<span class="hljs-number">1</span> - sigmoid(z))<br></code></pre></td></tr></table></figure><h2 id="Chapter-3"><a href="#Chapter-3" class="headerlink" title="Chapter 3"></a>Chapter 3</h2><h3 id="3-1-交叉熵"><a href="#3-1-交叉熵" class="headerlink" title="3.1 交叉熵"></a>3.1 交叉熵</h3><p>对错误的乘法力度加大，学习速率更快</p><h3 id="3-2-Softmax"><a href="#3-2-Softmax" class="headerlink" title="3.2 Softmax"></a>3.2 Softmax</h3><p>输出转化为概略分布</p><h3 id="3-3-其他损失函数"><a href="#3-3-其他损失函数" class="headerlink" title="3.3 其他损失函数"></a>3.3 其他损失函数</h3><h3 id="3-4-调整超参数的方法"><a href="#3-4-调整超参数的方法" class="headerlink" title="3.4 调整超参数的方法"></a>3.4 调整超参数的方法</h3><h2 id="Chapter-4"><a href="#Chapter-4" class="headerlink" title="Chapter 4"></a>Chapter 4</h2><p>神经网络可以计算任何函数。</p><h2 id="Chapter-5"><a href="#Chapter-5" class="headerlink" title="Chapter 5"></a>Chapter 5</h2><ul><li><p>vanishing gradient</p></li><li><p>exploding gradient</p></li></ul><h2 id="Chapter-6-CNN"><a href="#Chapter-6-CNN" class="headerlink" title="Chapter 6 CNN"></a>Chapter 6 CNN</h2><h3 id="6-1-架构"><a href="#6-1-架构" class="headerlink" title="6.1 架构"></a>6.1 架构</h3><ul><li>卷积层<ul><li>共享权重</li><li>提取特征</li></ul></li><li>池化层<ul><li>减少参量</li></ul></li><li>全连层<ul><li>二维压缩成一维，方便输出</li></ul></li><li>Softmax层<ul><li>输出概率分布</li></ul></li></ul><h3 id="6-2-代码：-with-pytorch"><a href="#6-2-代码：-with-pytorch" class="headerlink" title="6.2 代码： with pytorch"></a>6.2 代码： with pytorch</h3><h4 id="6-2-1-数据载入"><a href="#6-2-1-数据载入" class="headerlink" title="6.2.1 数据载入"></a>6.2.1 数据载入</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><code class="hljs python">train_data = torchvision.datasets.MNIST(<br>    root=<span class="hljs-string">'./'</span>,    <span class="hljs-comment"># 保存或者提取位置</span><br>    train=<span class="hljs-literal">True</span>, <br>    <span class="hljs-comment"># 转换 PIL.Image or numpy.ndarray</span><br>    transform=torchvision.transforms.ToTensor(),<br>    download=DOWNLOAD_MNIST,<br>)<br><span class="hljs-comment"># print(train_data.data.shape)</span><br><span class="hljs-comment">#train_data.data : (60000,28,28)</span><br><span class="hljs-comment"># train_data.targets : (60000)</span><br>test_data = torchvision.datasets.MNIST(root=<span class="hljs-string">'./'</span>, train=<span class="hljs-literal">False</span>)<br><span class="hljs-comment"># test_data 包括：test_data.data 和 test_data.targets</span><br><span class="hljs-comment">#test_data.data : (10000,28,28)</span><br><span class="hljs-comment">#test_data.targets : (10000)</span><br><br><span class="hljs-comment"># 批训练 50samples, 1 channel, 28x28 (50, 1, 28, 28)</span><br>train_batches = Data.DataLoader(<br>    dataset=train_data, batch_size=BATCH_SIZE, shuffle=<span class="hljs-literal">True</span>)<br><span class="hljs-comment"># print(train_batches.dataset.targets.shape</span><br><br><span class="hljs-comment"># 测试前2000个</span><br>test_x = torch.unsqueeze(test_data.data, dim=<span class="hljs-number">1</span>).type(torch.FloatTensor)[<br>    :<span class="hljs-number">2000</span>] / <span class="hljs-number">255.0</span>  <span class="hljs-comment"># shape from (2000, 28, 28) to (2000, 1, 28, 28), value in range(0,1)</span><br>test_y = test_data.targets[:<span class="hljs-number">2000</span>]<br></code></pre></td></tr></table></figure><h4 id="6-2-2-卷积神经网络构建"><a href="#6-2-2-卷积神经网络构建" class="headerlink" title="6.2.2 卷积神经网络构建"></a>6.2.2 卷积神经网络构建</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">CNN</span><span class="hljs-params">(nn.Module)</span>:</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span><span class="hljs-params">(self)</span>:</span><br>        super(CNN, self).__init__()<br>        self.conv1 = nn.Sequential(  <span class="hljs-comment"># input shape (1, 28, 28)</span><br>            nn.Conv2d(<br>                in_channels=<span class="hljs-number">1</span>,      <span class="hljs-comment"># input height</span><br>                out_channels=<span class="hljs-number">16</span>,    <span class="hljs-comment"># n_filters i.e. number of features</span><br>                kernel_size=<span class="hljs-number">5</span>,      <span class="hljs-comment"># filter size</span><br>                stride=<span class="hljs-number">1</span>,           <span class="hljs-comment"># filter movement/step</span><br>                <span class="hljs-comment"># 如果想要 con2d 出来的图片长宽没有变化, padding=(kernel_size-1)/2 当 stride=1</span><br>                padding=<span class="hljs-number">2</span>,<br>            ),      <span class="hljs-comment"># -&gt; (16, 28, 28)</span><br>            nn.ReLU(),    <span class="hljs-comment"># activation</span><br>            nn.MaxPool2d(kernel_size=<span class="hljs-number">2</span>),    <span class="hljs-comment"># -&gt; (16, 14, 14)</span><br>        )<br>        self.conv2 = nn.Sequential(  <span class="hljs-comment"># input shape (16, 14, 14)</span><br>            nn.Conv2d(<span class="hljs-number">16</span>, <span class="hljs-number">32</span>, <span class="hljs-number">5</span>, <span class="hljs-number">1</span>, <span class="hljs-number">2</span>),  <span class="hljs-comment"># output shape (32, 14, 14)</span><br>            nn.ReLU(),  <span class="hljs-comment"># activation</span><br>            nn.MaxPool2d(<span class="hljs-number">2</span>),  <span class="hljs-comment"># output shape (32, 7, 7)</span><br>        )<br>        <span class="hljs-comment"># fully connected layer, output 10 classes</span><br>        self.fc1 = nn.Linear(<span class="hljs-number">32</span> * <span class="hljs-number">7</span> * <span class="hljs-number">7</span>, <span class="hljs-number">100</span>)<br>        self.fc2 = nn.Linear(<span class="hljs-number">100</span>, <span class="hljs-number">10</span>)<br><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">forward</span><span class="hljs-params">(self, x)</span>:</span><br>        x = self.conv1(x)<br>        x = self.conv2(x)<br>        x = x.view(x.size(<span class="hljs-number">0</span>), <span class="hljs-number">-1</span>)   <span class="hljs-comment"># 展平多维的卷积图成 (batch_size, 32 * 7 * 7)</span><br>        x = torch.sigmoid(self.fc1(x))<br>        x = self.fc2(x)<br>        <span class="hljs-keyword">return</span> x<br></code></pre></td></tr></table></figure><h4 id="6-2-3-反向传播、训练神经网络"><a href="#6-2-3-反向传播、训练神经网络" class="headerlink" title="6.2.3 反向传播、训练神经网络"></a>6.2.3 反向传播、训练神经网络</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><code class="hljs python">cnn = CNN()<br>optimizer = torch.optim.Adam(cnn.parameters(), lr=LR) <span class="hljs-comment">#adam算法</span><br>loss_func = nn.CrossEntropyLoss()  <span class="hljs-comment"># Softmax–Log–NLLLoss，自动输出log-softmax</span><br><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">train</span><span class="hljs-params">()</span>:</span><br>    <span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> range(epochs):<br>        <span class="hljs-comment"># 分配 batch data, normalize x when iterate train_loader</span><br>        <span class="hljs-keyword">for</span> step, (b_x, b_y) <span class="hljs-keyword">in</span> enumerate(train_batches):  <span class="hljs-comment"># enumerate 添加索引可便历</span><br>            <span class="hljs-comment"># print(b_x.shape)--&gt;(50,1,28,28)</span><br>            <span class="hljs-comment"># print(b_y.shape)--&gt;(50)</span><br>            <span class="hljs-comment"># 1200组</span><br>            output = cnn(b_x)               <span class="hljs-comment"># cnn output</span><br>            loss = loss_func(output, b_y)   <span class="hljs-comment"># cross entropy loss</span><br>            optimizer.zero_grad()           <span class="hljs-comment"># clear gradients for this training step</span><br>            loss.backward()                 <span class="hljs-comment"># backpropagation, compute gradients</span><br>            optimizer.step()                <span class="hljs-comment"># apply gradients</span><br>            <span class="hljs-keyword">if</span> step % <span class="hljs-number">100</span> == <span class="hljs-number">0</span>:<br>                test_output = cnn(test_x)<br>                pred_y = torch.max(test_output, <span class="hljs-number">1</span>)[<br>                    <span class="hljs-number">1</span>].data.numpy()  <span class="hljs-comment"># [0]:一行中的最大值,[1]:最大值的索引</span><br>                accuracy = float((pred_y == test_y.data.numpy()).astype(<br>                    int).sum()) / float(test_y.size(<span class="hljs-number">0</span>))<br>                print(<span class="hljs-string">'Epoch: '</span>, epoch, <span class="hljs-string">'| train loss: %.4f'</span> %<br>                      loss.data.numpy(), <span class="hljs-string">'| test accuracy: %.2f'</span> % accuracy)<br>    torch.save(cnn.state_dict(), <span class="hljs-string">"cnn_net_params.pkl"</span>)<br><br>train()<br></code></pre></td></tr></table></figure><h4 id="6-2-4-参数存储与加载"><a href="#6-2-4-参数存储与加载" class="headerlink" title="6.2.4 参数存储与加载"></a>6.2.4 参数存储与加载</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python">torch.save(cnn.state_dict(), <span class="hljs-string">"cnn_net_params.pkl"</span>)<span class="hljs-comment">#保存训练好的参数</span><br><br><br>cnn = CNN()<br>cnn.load_state_dict(torch.load(<span class="hljs-string">'cnn_net_params.pkl'</span>))<span class="hljs-comment">#加载参数</span><br></code></pre></td></tr></table></figure><p>其他：关于深度学习和图像处理卷积的定义问题：深度学习中conv2d卷积层其实是无所谓是否翻转的，因为所有的weights也就是kernel其实是随机初始化的。那么每次的更新迭代都是为了去寻找一个最合适的kernel，所以是否翻转也变的无关紧要了。</p>]]></content>
      
      
      <categories>
          
          <category> Computer Science </category>
          
          <category> Machine Learning </category>
          
          <category> Neural Networks </category>
          
      </categories>
      
      
        <tags>
            
            <tag> notes </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>数值分析 学习笔记</title>
      <link href="/2020/01/28/Computer-Sciencs/%E6%95%B0%E5%80%BC%E5%88%86%E6%9E%90-%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
      <url>/2020/01/28/Computer-Sciencs/%E6%95%B0%E5%80%BC%E5%88%86%E6%9E%90-%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/</url>
      
        <content type="html"><![CDATA[<h1 id="数值分析-学习笔记"><a href="#数值分析-学习笔记" class="headerlink" title="数值分析 学习笔记"></a>数值分析 学习笔记</h1>]]></content>
      
      
      <categories>
          
          <category> Computer Science </category>
          
          <category> Numerical Analysis </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>Python 学习笔记</title>
      <link href="/2020/01/28/Computer-Sciencs/Python-%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
      <url>/2020/01/28/Computer-Sciencs/Python-%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/</url>
      
        <content type="html"><![CDATA[<h1 id="Python-学习笔记"><a href="#Python-学习笔记" class="headerlink" title="Python 学习笔记"></a>Python 学习笔记</h1><h2 id="pandas-library"><a href="#pandas-library" class="headerlink" title="pandas library"></a>pandas library</h2><h3 id="Day-1"><a href="#Day-1" class="headerlink" title="Day #1"></a>Day #1</h3><p>df = pd.read_csv(‘ ‘)</p><p>df.head(n)</p><p>df.tail(n)</p><p>df.nlargest(n,’name’)</p><p>df.nsmallest(n,’name’)</p><p>df [Pd[‘bla bla’]==’labalaba’]</p><h3 id="Day-2"><a href="#Day-2" class="headerlink" title="Day #2"></a>Day #2</h3><p>df.shape</p><p>df.columns.tolist( )</p><p>df[‘name’].unique( )</p><p>df = df.replace(‘Orig’ , ‘New’)</p><p>df.isnull( )     // Checks if each value in the dato frame is missing</p><p>Trick: print(df.isnull().sum())      // return the total amount of missing values for each feature(column)</p><p>NaN stands for ‘not a number’</p><p><strong>creating columns:</strong></p><p>df[‘new column name’] = fomula </p><p>e.g.     df[‘% Female’] = df[‘Female’] / df[‘Total’]</p><p>df.dtypes</p><p>df.select_dtypes([‘object’])</p><p><strong>measures of spread or distribution</strong></p><p>df[‘column name’].mean( )</p><p>df[‘column name’].median( )</p><p>df[‘column name’].mode( )</p><p>df.groupby(by=’column name’).agg(‘mean’) </p><p> // agg stands for ‘aggregate’.  group the data by the ‘column name’</p><p>df[‘column name’].max( ) — df[‘column name’].min( )</p><p>df[‘column name’].std( )    // standard deviation </p><p>df[‘column name’].var( )    // variance</p><p>df.groupby(by=’column name’).agg(‘std’)</p><p><strong>correlation coefficient</strong></p><p>df.corr( )</p><p>df.corr( )[‘x’] [‘y’]</p><h3 id="Day-3"><a href="#Day-3" class="headerlink" title="Day #3"></a>Day #3</h3><h4 id="Bar-Chart-条形图"><a href="#Bar-Chart-条形图" class="headerlink" title="Bar Chart 条形图"></a>Bar Chart 条形图</h4><p>df_top10 = df.nlargest(10,’Total’)</p><p>df_top10.plot.bar(x=’Major Name’, y=’Total’)</p><h4 id="Histograms-直方图"><a href="#Histograms-直方图" class="headerlink" title="Histograms 直方图"></a>Histograms 直方图</h4><p>df.hist(column = ‘% Female’)</p><h4 id="Boxplot-箱形图-超有用"><a href="#Boxplot-箱形图-超有用" class="headerlink" title="Boxplot 箱形图 超有用"></a>Boxplot 箱形图 超有用</h4><p>df.boxplot(column = ‘% Female’, vert=False)</p><h4 id="Scatterplots-散点图"><a href="#Scatterplots-散点图" class="headerlink" title="Scatterplots 散点图"></a>Scatterplots 散点图</h4><p>df.plot.scatter(x=’Male’, y=’Female’)</p><h2 id=""><a href="#" class="headerlink" title=". . ."></a>. . .</h2><h4 id="Simulation"><a href="#Simulation" class="headerlink" title="Simulation"></a>Simulation</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> random<br>random.ranint(<span class="hljs-number">1</span>,<span class="hljs-number">10</span>)<br><br><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> range(<span class="hljs-number">1</span>,<span class="hljs-number">100</span>):<br>  print(random.randint(<span class="hljs-number">1</span>,<span class="hljs-number">10</span>))<br></code></pre></td></tr></table></figure><h3 id="Day-4"><a href="#Day-4" class="headerlink" title="Day #4"></a>Day #4</h3><ul><li>generate a dataset of random numbers</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> random <span class="hljs-keyword">as</span> rd<br>arr=[]<br><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> range(<span class="hljs-number">100</span>):<br>  value=rd.randint(<span class="hljs-number">1</span>,<span class="hljs-number">10</span>)<br>  arr.append(&#123;<span class="hljs-string">'value'</span>:value&#125;)<br></code></pre></td></tr></table></figure><ul><li><p><strong>Monty Hall Game</strong> </p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br><span class="hljs-keyword">import</span> random<br><br>results = []<br><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> range(<span class="hljs-number">1000</span>):<br>  prize = random.randint(<span class="hljs-number">1</span>, <span class="hljs-number">3</span>)<br>  choice = random.randint(<span class="hljs-number">1</span>, <span class="hljs-number">3</span>)<br>  print(<span class="hljs-string">"We picked door "</span> + str(choice))<br><br>  <span class="hljs-comment"># Show a door that is not the winning door:</span><br>  <span class="hljs-keyword">if</span> prize != <span class="hljs-number">1</span> <span class="hljs-keyword">and</span> choice != <span class="hljs-number">1</span>: showdoor = <span class="hljs-number">1</span><br>  <span class="hljs-keyword">elif</span> prize != <span class="hljs-number">2</span> <span class="hljs-keyword">and</span> choice != <span class="hljs-number">2</span>: showdoor = <span class="hljs-number">2</span><br>  <span class="hljs-keyword">else</span>: showdoor = <span class="hljs-number">3</span><br>  print(<span class="hljs-string">"We were shown that door "</span> + str(showdoor) + <span class="hljs-string">" was a goat"</span>)<br><br>  <span class="hljs-comment"># We did NOT swap the door:</span><br>  <span class="hljs-keyword">if</span>   choice == <span class="hljs-number">1</span> <span class="hljs-keyword">and</span> showdoor == <span class="hljs-number">2</span>: choice = <span class="hljs-number">3</span><br>  <span class="hljs-keyword">elif</span> choice == <span class="hljs-number">1</span> <span class="hljs-keyword">and</span> showdoor == <span class="hljs-number">3</span>: choice = <span class="hljs-number">2</span><br><br>  <span class="hljs-keyword">elif</span> choice == <span class="hljs-number">2</span> <span class="hljs-keyword">and</span> showdoor == <span class="hljs-number">1</span>: choice = <span class="hljs-number">3</span><br>  <span class="hljs-keyword">elif</span> choice == <span class="hljs-number">2</span> <span class="hljs-keyword">and</span> showdoor == <span class="hljs-number">3</span>: choice = <span class="hljs-number">1</span><br><br>  <span class="hljs-keyword">elif</span> choice == <span class="hljs-number">3</span> <span class="hljs-keyword">and</span> showdoor == <span class="hljs-number">1</span>: choice = <span class="hljs-number">2</span><br>  <span class="hljs-keyword">elif</span> choice == <span class="hljs-number">3</span> <span class="hljs-keyword">and</span> showdoor == <span class="hljs-number">2</span>: choice = <span class="hljs-number">1</span><br>    <br>  print(<span class="hljs-string">"We DID swap doors."</span>)<br><br>  <span class="hljs-comment"># Check if we won:</span><br>  <span class="hljs-keyword">if</span> prize == choice:<br>    print(<span class="hljs-string">"WE WIN!!!!!!!!!!!!!!!"</span>)<br>    results.append( &#123;<span class="hljs-string">"result"</span>: <span class="hljs-number">1</span>&#125; )<br>  <span class="hljs-keyword">else</span>:<br>    print(<span class="hljs-string">" :( "</span>)<br>    results.append( &#123;<span class="hljs-string">"result"</span>: <span class="hljs-number">0</span>&#125; )<br>    <br>df = pd.DataFrame(results)<br></code></pre></td></tr></table></figure></li></ul><h2 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h2><p>enumerate() 函数用于将一个可遍历的数据对象(如列表、元组或字符串)组合为一个索引序列，同时列出数据和数据下标，一般用在 for 循环当中</p><p>向量范数</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">while</span> sum(i**<span class="hljs-number">2</span> <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> f(x)) &gt;= TOL**<span class="hljs-number">2</span>:<br></code></pre></td></tr></table></figure><p>列表一个溢出error的解决</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python">i = [<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">5</span>, <span class="hljs-number">8</span>, <span class="hljs-number">13</span>]<br>j = [<span class="hljs-literal">None</span>] * len(i)<br><span class="hljs-comment">#j == [None, None, None, None, None, None]</span><br>k = <span class="hljs-number">0</span><br><br><span class="hljs-keyword">for</span> l <span class="hljs-keyword">in</span> i:<br>   j[k] = l<br>   k += <span class="hljs-number">1</span><br></code></pre></td></tr></table></figure><p>Python中初始化一个5 x 3每项为0的数组，最好方法是：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">multilist = [[<span class="hljs-number">0</span> <span class="hljs-keyword">for</span> col <span class="hljs-keyword">in</span> range(<span class="hljs-number">5</span>)] <span class="hljs-keyword">for</span> row <span class="hljs-keyword">in</span> range(<span class="hljs-number">3</span>)]<br></code></pre></td></tr></table></figure><p>np数组索引：</p><p>A[i,j]</p><p>A[i,:i] i的前一个</p><p>A[i,i:] 算上i往后</p><p>函数中的参量似乎不是形参</p><p>if all(abs(x1[i]-x0[i]) &lt; eps for i in range(n))</p><p>[max([abs(m[i][j]) for j in range(n)]) for i in range(n)] </p><p>A.shape[0]和A.shape[1]</p><p>print(…,end=’ ‘)</p><p>新的Python语法，是不支持的代码对齐中，混用TAB和空格的。所以出现上述错误提示了。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">map(func, seq1[, seq2,…])<br></code></pre></td></tr></table></figure><p>第一个参数接受一个函数名，后面的参数接受一个或多个可迭代的序列，返回的是一个集合。<br>Python函数编程中的map()函数是将func作用于seq中的每一个元素，并将所有的调用的结果作为一个list返回。如果func为None，作用同zip()。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">print(“&#123;:<span class="hljs-number">.3</span>f&#125;<span class="hljs-string">".format())</span><br></code></pre></td></tr></table></figure><p>Matrix product of two arrays:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">numpy.matmul(*x1*, *x2*, */*, *out=<span class="hljs-literal">None</span>*, ***, *casting=<span class="hljs-string">'same_kind'</span>*, *order=<span class="hljs-string">'K'</span>*, *dtype=<span class="hljs-literal">None</span>*, *subok=<span class="hljs-literal">True</span>*[, *signature*, *extobj*]) *= *<br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python">D = np.diag(np.diag(A)) <span class="hljs-comment"># A的对角元构成的矩阵</span><br>L = np.tri(*np.shape(A),<span class="hljs-number">-1</span>) * (-A)  <span class="hljs-comment"># A的下三角元的相反数构成的矩阵L</span><br>U = D - L -A <span class="hljs-comment">#A的上三角元的相反数构成的元素</span><br>M = np.linalg.inv(D-L)  <span class="hljs-comment">#求（D-L）的逆</span><br></code></pre></td></tr></table></figure><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python">numpy.tri(N, M=None, k=0, dtype=&lt;class 'float'&gt;)[source]<br>/*An array with ones at and below the given diagonal and zeros elsewhere.*/<br>/*k : int, optional<br>The sub-diagonal at and below which the array is filled. k = 0 is the main diagonal, while k &lt; 0 is below it, and k &gt; 0 is above. The default is 0.*/<br>np.tri(3, 5, 2, dtype=int)<br>array([[1, 1, 1, 0, 0],<br>       [1, 1, 1, 1, 0],<br>       [1, 1, 1, 1, 1]])<br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">list(enumerate(<span class="hljs-string">'abc'</span>, <span class="hljs-number">1</span>)) <br>[(<span class="hljs-number">1</span>, <span class="hljs-string">'a'</span>), (<span class="hljs-number">2</span>, <span class="hljs-string">'b'</span>), (<span class="hljs-number">3</span>, <span class="hljs-string">'c'</span>)]<br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment">#三元运算</span><br>[on_true] <span class="hljs-keyword">if</span> [expression] <span class="hljs-keyword">else</span> [on_false]<br>x, y = <span class="hljs-number">50</span>, <span class="hljs-number">25</span><br>small = x <span class="hljs-keyword">if</span> x &lt; y <span class="hljs-keyword">else</span> y<br></code></pre></td></tr></table></figure><figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs dockerfile">xk = x.<span class="hljs-keyword">copy</span><span class="bash">()</span><br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python">a = [i/<span class="hljs-number">100.0</span> <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> range(<span class="hljs-number">10</span>, <span class="hljs-number">50</span>)]<br><br>numpy.arange(<span class="hljs-number">0.1</span>, <span class="hljs-number">0.5</span>, <span class="hljs-number">0.01</span>)<br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python">x = np.linspace(<span class="hljs-number">-10</span>,<span class="hljs-number">10</span>,<span class="hljs-number">500</span>)<br>y = f(x)<br>plt.plot(x,y,color=<span class="hljs-string">"orange"</span>,label=<span class="hljs-string">"$x^2 + 10 * sin(x) + 1$"</span>,linewidth=<span class="hljs-number">2</span>)<br></code></pre></td></tr></table></figure><p>获取横纵坐标的简洁写法</p><p>plot里面可以用latex！</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">res = minimize_scalar(f, bounds = (<span class="hljs-number">-5</span>, <span class="hljs-number">0</span>), method = <span class="hljs-string">'bounded'</span>)<br><span class="hljs-keyword">print</span> <span class="hljs-string">"(-5, 0)"</span>, res.x<br></code></pre></td></tr></table></figure><p>获取极值以及对应的坐标</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment">#支持中文显示</span><br><span class="hljs-keyword">from</span> pylab <span class="hljs-keyword">import</span> *<br>mpl.rcParams[<span class="hljs-string">'font.sans-serif'</span>] = [<span class="hljs-string">'SimHei'</span>]<br> <br><span class="hljs-comment">#创建数据</span><br>x = np.linspace(<span class="hljs-number">-5</span>, <span class="hljs-number">5</span>, <span class="hljs-number">100</span>)<br>y1 = np.sin(x)<br>y2 = np.cos(x)<br> <br><span class="hljs-comment">#创建figure窗口</span><br>plt.figure(num=<span class="hljs-number">3</span>, figsize=(<span class="hljs-number">8</span>, <span class="hljs-number">5</span>))<br><span class="hljs-comment">#画曲线1</span><br>plt.plot(x, y1)<br><span class="hljs-comment">#画曲线2</span><br>plt.plot(x, y2, color=<span class="hljs-string">'blue'</span>, linewidth=<span class="hljs-number">5.0</span>, linestyle=<span class="hljs-string">'--'</span>)<br><span class="hljs-comment">#设置坐标轴范围</span><br>plt.xlim((<span class="hljs-number">-5</span>, <span class="hljs-number">5</span>))<br>plt.ylim((<span class="hljs-number">-2</span>, <span class="hljs-number">2</span>))<br><span class="hljs-comment">#设置坐标轴名称</span><br>plt.xlabel(<span class="hljs-string">'xxxxxxxxxxx'</span>)<br>plt.ylabel(<span class="hljs-string">'yyyyyyyyyyy'</span>)<br><span class="hljs-comment">#设置坐标轴刻度</span><br>my_x_ticks = np.arange(<span class="hljs-number">-5</span>, <span class="hljs-number">5</span>, <span class="hljs-number">0.5</span>)<br>my_y_ticks = np.arange(<span class="hljs-number">-2</span>, <span class="hljs-number">2</span>, <span class="hljs-number">0.3</span>)<br>plt.xticks(my_x_ticks)<br>plt.yticks(my_y_ticks)<br> <br><span class="hljs-comment">#显示出所有设置</span><br>plt.show()<br></code></pre></td></tr></table></figure><p>python添加元素</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python">p_arr = np.concatenate((p_arr,[p_])) <span class="hljs-comment"># 先将p_变成list形式进行拼接，注意输入为一个tuple</span><br>p_arr = np.append(p_arr,p_) <span class="hljs-comment">#直接向p_arr里添加p_</span><br><span class="hljs-comment">#注意一定不要忘记用赋值覆盖原p_arr不然不会变</span><br></code></pre></td></tr></table></figure><p>Np.cos 自变量是弧度</p><p>卡西欧计算器cos自变量是角度</p><p>当函数要接受元组或者字典参数时，它分别使用<em>和*</em>前缀。</p><p>如果使用**前缀，多余的参数会被认为是字典.</p><h2 id="绘制三维图"><a href="#绘制三维图" class="headerlink" title="绘制三维图"></a>绘制三维图</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python">fig = plt.figure()<br>ax = Axes3D(fig)<br>X = np.meshgrid(X)<br>Y = np.meshgrid(Y)<br>Z = f(X,Y)<br>ax.plot_surface(X,Y,Z,cmap=plt.get_cmap(<span class="hljs-string">'rainbow'</span>))<br></code></pre></td></tr></table></figure><h2 id="聚类分析"><a href="#聚类分析" class="headerlink" title="聚类分析"></a>聚类分析</h2><h3 id="1-K-均值聚类"><a href="#1-K-均值聚类" class="headerlink" title="1. K-均值聚类"></a>1. K-均值聚类</h3><p>划分式聚类方法。</p><p>已知要分点聚类数，随机生成类数个质心，从质心出发逐渐分类</p><ul><li>生成 KMeans 类</li><li>使用 KMeans 中的 fit_predict 函数直接得聚类后各点对应的类标签</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> sklearn.datasets <span class="hljs-keyword">import</span> make_blobs<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br><span class="hljs-keyword">from</span> sklearn.cluster <span class="hljs-keyword">import</span> KMeans<br><br><span class="hljs-comment"># 生成n_samples个点对,data[1]是每个成员的整数标签(类别)</span><br>data = make_blobs(n_samples=<span class="hljs-number">500</span>, n_features=<span class="hljs-number">2</span>, centers=<span class="hljs-number">8</span>,<br>                  cluster_std=<span class="hljs-number">1.6</span>, random_state=<span class="hljs-number">50</span>)<br>points = data[<span class="hljs-number">0</span>]<br>fig1 = plt.figure()  <span class="hljs-comment"># 生成画布</span><br>fig1 = plt.scatter(points[:, <span class="hljs-number">0</span>], points[:, <span class="hljs-number">1</span>], c=data[<span class="hljs-number">1</span>],<br>                   cmap=<span class="hljs-string">'viridis'</span>)<br>plt.title(<span class="hljs-string">'before'</span>)<br>plt.xlim(<span class="hljs-number">-15</span>, <span class="hljs-number">15</span>)<br>plt.ylim(<span class="hljs-number">-15</span>, <span class="hljs-number">15</span>)<br><br><span class="hljs-comment"># create kmeans object</span><br>kmeans = KMeans(n_clusters=<span class="hljs-number">8</span>)<br><br><span class="hljs-comment"># print location of clusters learned by kmeans object</span><br><span class="hljs-comment"># print(kmeans.cluster_centers_)</span><br><br>km_res = kmeans.fit_predict(points)<br><br>fig2 = plt.figure()<br>fig2 = plt.scatter(points[:, <span class="hljs-number">0</span>], points[:, <span class="hljs-number">1</span>], c=km_res,<br>                   cmap=<span class="hljs-string">'viridis'</span>)  <span class="hljs-comment"># c:color 按data[1]给每个点对应的颜色</span><br>plt.title(<span class="hljs-string">'after'</span>)<br>plt.xlim(<span class="hljs-number">-15</span>, <span class="hljs-number">15</span>)<br>plt.ylim(<span class="hljs-number">-15</span>, <span class="hljs-number">15</span>)<br>plt.show()<br></code></pre></td></tr></table></figure><h3 id="2-层次分析聚类"><a href="#2-层次分析聚类" class="headerlink" title="2. 层次分析聚类"></a>2. 层次分析聚类</h3><p>层次化聚类方法。</p><p>从每个点各为一类开始，“归并”。</p><p>步骤：</p><ul><li>生成距离矩阵：pdist函数</li><li>进行层次聚类，使用ward提出的离差平方和方法效果较好： linkage函数。 注：返回的Z的第一列和第二列代表聚集的两类的序列号，第三列代表第一列和第二列序号所代表的集群在聚集时的距离(与层次聚类图的高度相等)，第四列代表聚集时所包含的原始数据的个数</li><li>绘制树状图 dendrogram 函数 </li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br><span class="hljs-keyword">import</span> scipy<br><span class="hljs-keyword">import</span> scipy.cluster.hierarchy <span class="hljs-keyword">as</span> sch<br><br><br><span class="hljs-comment"># 生成待聚类的数据点,这里生成了20个点,每个点4维:</span><br>points = scipy.randn(<span class="hljs-number">20</span>, <span class="hljs-number">4</span>)<br><br><span class="hljs-comment"># 生成点与点之间的距离矩阵,这里用的欧氏距离:</span><br>disMat = sch.distance.pdist(points, <span class="hljs-string">'euclidean'</span>)<br><span class="hljs-comment"># 进行层次聚类:</span><br>Z = sch.linkage(disMat, method=<span class="hljs-string">'ward'</span>)<br><span class="hljs-comment"># 将层级聚类结果以树状图表示出来并保存为plot_dendrogram.png</span><br>P = sch.dendrogram(Z)<br>plt.savefig(<span class="hljs-string">'plot_dendrogram.png'</span>)<br><br><span class="hljs-comment"># 根据linkage matrix Z得到聚类结果:</span><br>cluster = sch.fcluster(Z, t=<span class="hljs-number">4</span>, criterion=<span class="hljs-string">'maxclust'</span>)<span class="hljs-comment">#t表示最大聚类簇数</span><br>print(<span class="hljs-string">"Original cluster by hierarchy clustering:\n"</span>, cluster)<br><br>plt.show()<br></code></pre></td></tr></table></figure><h3 id="3-应用"><a href="#3-应用" class="headerlink" title="3. 应用"></a>3. 应用</h3><p>首先使用变量聚类法找出相关度较低的“主变量”（主要指标），删除主变量之外的次变量，然后根据主变量使用样本聚类分析法进行样本分类。</p><h2 id="主成分分析-PCA"><a href="#主成分分析-PCA" class="headerlink" title="主成分分析 PCA"></a>主成分分析 PCA</h2><p>Principle Component Analysis. 将相关度很高的向量转化为相关度较低的向量。</p><p>Python 实现：</p><p>直接调库：<strong>sklearn.decomposition.PCA</strong> （类）</p><p>参数：</p><ul><li>n_component : 想要将到的维数；或者规定主成分的累计贡献率阀值（percentage）</li><li>whiten: 是否白化，即归一化</li><li>explained<em>variance</em> : 代表降维后的各主成分的方差值。方差值越大，则说明越是重要的主成分。</li><li>explained<em>variance_ratio</em> : 代表降维后的各主成分的方差值占总方差值的比例(累计贡献率)</li><li>Y = fit_transform(X) 利用主成分分析方法对数据降维，返回对X降维后的矩阵: X.shape=(n_samples,n_features); Y.shape=(n_samples,n_components)</li><li>fit(X) 利用主成分分析法对X降维和变换，X已经改变</li><li>transform(X) 返回 n_samples$\times$ n_components 的切掉后面的矩阵</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br><span class="hljs-keyword">from</span> sklearn.decomposition <span class="hljs-keyword">import</span> PCA<br><br>x = np.array([[<span class="hljs-number">1</span>, <span class="hljs-number">2</span>], [<span class="hljs-number">1</span>, <span class="hljs-number">4</span>], [<span class="hljs-number">5</span>, <span class="hljs-number">8</span>]])<br>pca = PCA(n_components=<span class="hljs-number">0.9</span>)<br>y = pca.fit_transform(x)<br>print(<span class="hljs-string">"累计贡献率："</span>, pca.explained_variance_ratio_)<br>print(<span class="hljs-string">"变换后的x"</span>, y)<br><span class="hljs-comment">#or:</span><br><span class="hljs-comment">#pca.fit(x)</span><br><span class="hljs-comment">#y=pca.transform(x)</span><br></code></pre></td></tr></table></figure><p>（numpy练习）</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><br><span class="hljs-comment"># 归一化</span><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">stdData</span><span class="hljs-params">(dataMat)</span>:</span><br>    meanVal = np.mean(dataMat, axis=<span class="hljs-number">0</span>)  <span class="hljs-comment"># 按列求均值，即求各个特征的均值</span><br>    _, n = dataMat.shape<br>    stdval = np.std(dataMat, axis=<span class="hljs-number">0</span>)<br>    newData = (dataMat - meanVal)<br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> range(n):<br>        newData[:, i] /= stdval[i]<br>    <span class="hljs-keyword">return</span> newData<br><br><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">percentage2n</span><span class="hljs-params">(eigVals, percentage)</span>:</span><br>    sortEig = np.sort(eigVals)  <span class="hljs-comment"># 升序</span><br>    sortEig = sortEig[<span class="hljs-number">-1</span>::<span class="hljs-number">-1</span>]  <span class="hljs-comment"># 逆转，即降序</span><br>    arraySum = sum(sortEig)<br>    tmpSum = <span class="hljs-number">0</span><br>    num = <span class="hljs-number">0</span><br>    contribute = []  <span class="hljs-comment"># 信息贡献率</span><br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> sortEig:<br>        contribute.append(i / arraySum)<br>    contribute = np.array(contribute)<br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> sortEig:<br>        tmpSum += i<br>        num += <span class="hljs-number">1</span><br>        <span class="hljs-keyword">if</span> tmpSum &gt;= arraySum * percentage:<br>            <span class="hljs-keyword">return</span> num, contribute<br><br><span class="hljs-comment">#主成分分析</span><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">PCA</span><span class="hljs-params">(dataMat, percentage=<span class="hljs-number">0.9</span>)</span>:</span><br>    newData = stdData(dataMat)<br>    corMat = np.corrcoef(newData, rowvar=<span class="hljs-number">0</span>)<br>    <span class="hljs-comment"># 求特征值和特征向量,特征向量是按列放的，即一列代表一个特征向量</span><br>    eigVals, eigVects = np.linalg.eig(np.mat(corMat))<br>    eigValIndice = np.argsort(eigVals)  <span class="hljs-comment"># 对特征值从小到大排序</span><br>    n, contribute = percentage2n(eigVals, percentage)  <span class="hljs-comment"># 达到累积贡献率百分比的n,默认90%</span><br>    n_eigValIndice = eigValIndice[<span class="hljs-number">-1</span>:-(n + <span class="hljs-number">1</span>):<span class="hljs-number">-1</span>]  <span class="hljs-comment"># 最大的n个特征值的下标</span><br>    n_eigVect = eigVects[:, n_eigValIndice]  <span class="hljs-comment"># 最大的n个特征值对应的特征向量</span><br>    lowDDataMat = newData[:,:n] * n_eigVect  <span class="hljs-comment"># 低维特征空间的数据</span><br>    contribute = contribute[:n]<br>    score = np.float(contribute * lowDDataMat)  <span class="hljs-comment"># 基于主成分分析的综合评价得分</span><br>    <span class="hljs-keyword">return</span> lowDDataMat, score<br><br><br>x = np.array([[<span class="hljs-number">1</span>, <span class="hljs-number">2</span>], [<span class="hljs-number">1</span>, <span class="hljs-number">4</span>], [<span class="hljs-number">5</span>, <span class="hljs-number">8</span>]])<br>print(PCA(x))<br></code></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Computer Science </category>
          
          <category> Language Learning </category>
          
          <category> Python </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>LaTex Tricks</title>
      <link href="/2020/01/25/LaTex/Latex-Tricks/"/>
      <url>/2020/01/25/LaTex/Latex-Tricks/</url>
      
        <content type="html"><![CDATA[<h1 id="LaTex-Tricks"><a href="#LaTex-Tricks" class="headerlink" title="LaTex Tricks"></a>LaTex Tricks</h1><h4 id="字母上面加东西："><a href="#字母上面加东西：" class="headerlink" title="字母上面加东西："></a>字母上面加东西：</h4><ul><li>$ \overline x$ : \overline x,   $ \bar x$  :  \bar x , $\hat x$ : \hat x,  $\widehat x$ : \widehat x</li></ul><ul><li>$\widetilde {x}, \widetilde{ab}$ : <strong>\widetilde</strong> {x}, \widetilde{ab}</li></ul><ul><li>$\dot x$ : \dot x,  $\ddot x$ : \ddot x</li><li><p>$\vec{x}$ : \vec x</p></li><li><p>东西上写东西 $\overset{a}{bcd}$  ： \overset{a}{bcd}</p></li></ul><h4 id="数学常用："><a href="#数学常用：" class="headerlink" title="数学常用："></a>数学常用：</h4><ul><li>$ \sum\limits<em>{1\leq i\leq n}$ : \sum\sum\limits</em>{1\leq i\leq n}{1\leq i\leq n}</li></ul><ul><li>$\because$ — \because,  $\therefore$ — \therefore</li></ul><ul><li>$\forall$ :  \forall,  $ \exists $ : \exists</li></ul><ul><li><p>$\sqrt[n]{abc}$   : \sqrt[n]{abc}</p> <a id="more"></a></li></ul><ul><li><p>$a\biggm| \displaystyle{\frac{n+1}{3}}$  :   a<strong>\biggm|</strong> <strong>\displaystyle</strong>{\frac{n+1}{3}}</p></li><li><p>$\pm$ :  \pm</p></li><li><p>$\mp$ :  \mp</p></li><li><p>多行对齐：\begin{aligned} &amp; \end{aligned}</p></li><li><p>大括号：\begin{equation} \begin{aligned} \left \ {  \right. \end{aligned}\end{equation}</p></li><li><p>同构 $\cong$ ：\cong</p></li><li><p>内积 $\langle \rangle$ :  \langle \rangle</p></li><li><p>等号上写东西 $\xlongequal[abc]{def}$ : \xlongequal[abc]{def} </p></li></ul><h4 id="物理常用："><a href="#物理常用：" class="headerlink" title="物理常用："></a>物理常用：</h4><ul><li>$\nabla$ ：\nabla</li></ul>]]></content>
      
      
      <categories>
          
          <category> LaTex </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>Image Processing 学习笔记</title>
      <link href="/2020/01/24/Computer-Sciencs/Image-Processing%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
      <url>/2020/01/24/Computer-Sciencs/Image-Processing%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/</url>
      
        <content type="html"><![CDATA[<h1 id="图像信息处理"><a href="#图像信息处理" class="headerlink" title="图像信息处理"></a>图像信息处理</h1><h2 id="1-灰度变换与空间滤波"><a href="#1-灰度变换与空间滤波" class="headerlink" title="1  灰度变换与空间滤波"></a>1  灰度变换与空间滤波</h2><h3 id="1-1-灰度变换：-s-T-r"><a href="#1-1-灰度变换：-s-T-r" class="headerlink" title="1.1 灰度变换：$s=T(r)$"></a>1.1 灰度变换：$s=T(r)$</h3><ul><li>图像反转：$s=L-1-r$</li><li>对数变换：$s=c\log(1+r)$</li><li>伽马变换：$s=cr^\gamma$</li><li>分段分式线性变换：对比度拉伸、灰度级分层、比特平面分层</li></ul><p>$ \ $ <a id="more"></a></p><h3 id="1-2-直方图处理"><a href="#1-2-直方图处理" class="headerlink" title="1.2 直方图处理"></a>1.2 直方图处理</h3><p>$ h(r_k)=n_k$ ，$r_k$ 是第 $k$ 级灰度值，$n_k$ 为图像中灰度为 $r_k$ 的像素个数。不妨从 $0$ 开始，令 $r_k=k$</p><p>归一化： $p(r_k)=n_k/MN$</p><h4 id="1-2-1-直方图均衡化"><a href="#1-2-1-直方图均衡化" class="headerlink" title="1.2.1 直方图均衡化"></a>1.2.1 直方图均衡化</h4><ol><li>$p_s(s)=p_r(r)\cdot |\displaystyle\frac{dr}{ds}|=p_r(r) / |T^{‘}(r)|$</li><li>选取变换函数  $s=T(r)=(L-1) \displaystyle\int_0 ^r p_r(w)dw$</li><li>$=&gt; \quad p_s(s)=\displaystyle\frac{1}{L-1}$</li><li>离散形式：$ s<em>k=T(r_k)=(L-1)\displaystyle\sum\limits</em>{j=0}^k p<em>r (r </em> j)=\displaystyle\frac{L-1}{MN}\sum\limits_{j=0}^k n_j $，最后取值四舍五入</li></ol><h4 id="1-2-2-直方图规定化"><a href="#1-2-2-直方图规定化" class="headerlink" title="1.2.2 直方图规定化"></a>1.2.2 直方图规定化</h4><h4 id="1-2-3-局部直方图处理"><a href="#1-2-3-局部直方图处理" class="headerlink" title="1.2.3 局部直方图处理"></a>1.2.3 局部直方图处理</h4><p>略～</p><p>$ \ $</p><h2 id="1-2-空间滤波"><a href="#1-2-空间滤波" class="headerlink" title="1.2 空间滤波"></a>1.2 空间滤波</h2><p>空间滤波器由一个邻域和预定义操作组成。</p><p>$g(x,y)=\displaystyle\sum\limits<em>{s=-a}^b\sum\limits</em>{t=-b}^b w(s,t)f(x+s,y+t)$</p><h3 id="1-2-1-空间相关与卷积"><a href="#1-2-1-空间相关与卷积" class="headerlink" title="1.2.1 空间相关与卷积"></a>1.2.1 空间相关与卷积</h3><p>相关上滤波器模版移过图像并计算每个位置乘积之和的处理，卷积的机理类似，但滤波器首先要旋转$180^o$</p><h4 id="1-2-1-1-平滑空间滤波器"><a href="#1-2-1-1-平滑空间滤波器" class="headerlink" title="1.2.1.1 平滑空间滤波器"></a>1.2.1.1 平滑空间滤波器</h4><ul><li>均值滤波器：$g(x,y)=\displaystyle\frac{\sum\limits<em>{s=-a}^a\sum\limits</em>{s=-b}^b w(s,t)f(x+s,y+t)}{\sum\limits<em>{s=-a}^a\sum\limits</em>{s=-b}^b w(s,t)}$</li><li>统计排序滤波器   $e.g. $ 中值滤波器：去除椒盐噪声</li></ul><p>$ \ $</p><h4 id="1-2-1-2-锐化空间滤波器"><a href="#1-2-1-2-锐化空间滤波器" class="headerlink" title="1.2.1.2 锐化空间滤波器"></a>1.2.1.2 锐化空间滤波器</h4><p>定义: $\displaystyle\frac{\partial f}{\partial x}=f(x+1)-f(x)$ , $\displaystyle\frac{\partial ^2f}{\partial^2 x}=f(x+1)+f(x-1)-2f(x)$</p><p>(1) 使用拉普拉斯算子</p><p>$\nabla^2 f(x,y)=f(x+1,y)+f(x-1,y)+f(x,y+1)+f(x,y-1)-4f(x,y)$</p><p>$g(x,y)=f(x,y)+c[\nabla^2 f(x,y)]$</p><p><a href="https://www.cnblogs.com/polly333/p/7269843.html" target="_blank" rel="noopener">比较清楚的介绍</a></p><p>(2) 非锐化掩蔽</p><ol><li>模糊原图像 $\overline f (x,y)$</li><li>从原图像中减去模糊图像（产生差值图像，即模版）$g_{mask}(x,y)=f(x,y)-\overline f(x,y)$</li><li>将模版加到原图像上 $g(x,y)=f(x,y)+k\cdot g_{mask}(x,y)$</li></ol><p>(3) 使用梯度算子</p><p><a href="https://blog.csdn.net/qq_29540745/article/details/51918004" target="_blank" rel="noopener">Soble算子</a>：$M(x,y)=|(z_7+2z_8+z_9)-(z_1+2z_2+z_3)|+|(z_3+2z_6+z_9)-(z_1+2z_4+z_7)$</p><p>$ \ $</p><h3 id="1-2-2-使用模糊技术进行灰度变换和空间滤波"><a href="#1-2-2-使用模糊技术进行灰度变换和空间滤波" class="headerlink" title="1.2.2 使用模糊技术进行灰度变换和空间滤波"></a>1.2.2 使用模糊技术进行灰度变换和空间滤波</h3><h4 id="1-2-2-1-模糊集合论"><a href="#1-2-2-1-模糊集合论" class="headerlink" title="1.2.2.1 模糊集合论"></a>1.2.2.1 模糊集合论</h4><ul><li><p>模糊集合：${(z,\mu(z))}$  有元素和它的隶属度函数组成的数对组成，$\mu(z)\in[0,1]$</p></li><li><p>模糊逻辑：</p><p> $ A\ AND\ B\iff\min(\mu_A(z),\mu_B(z)),\quad \forall z\in Z $ ,</p><p> $A\ OR\ B\iff \max(\mu_A(z),\mu_B(z)),\quad \forall z\in Z$ ,</p><p> $A=B\iff\mu_A (z)=\mu_B (z),\quad \forall z\in Z $ , </p><p>$A\subseteq B\iff \mu_A(z)\leq\mu_B(z),\quad \forall z\in Z $ ,</p><p>$A\supseteq B\iff \mu_A(z)\geq\mu_B(z),\quad \forall z\in Z $ .</p></li></ul><ul><li><p>应用步骤：</p><ul><li>$IF-THEN$ 形式化</li><li>输入输出模糊化：$\mu_i(z),\mu_o(z)$ </li><li>既满足 $IF$ 又满足 $THEN$ $=&gt; INPUT\&amp;OUTPUT$ $=&gt; \mu_3(z,v)=\min{\mu_i(z),\mu_o(v)}$</li><li>对每一个 $z_0$ ，最终模糊输出 $Q(v)=\mu_3(z_0,v)$  , 对于多个 $Q_i(v)$ ，全部模糊响应应为单个模糊响应的并集，取 $\max\limits_i (Q_i (v))$ </li><li>去模糊：计算集合重心：$v<em>0=\displaystyle\frac{\sum\limits</em>{v=1}^K vQ(v)}{\sum\limits_{v=1}^K Q(v)}$</li></ul></li></ul><h4 id="1-2-2-2-利用模糊集合论进行灰度变换"><a href="#1-2-2-2-利用模糊集合论进行灰度变换" class="headerlink" title="1.2.2.2 利用模糊集合论进行灰度变换"></a>1.2.2.2 利用模糊集合论进行灰度变换</h4><ul><li><p>目的：增强对比度。黑的更黑，白的更白，灰的仍灰</p></li><li><p>$IF-THEN$ 形式化：</p><ul><li><p>$IF\quad dark,\quad THEN \quad darker $</p></li><li><p>$IF\quad gray ,\quad THEN \quad gray$</p></li><li><p>$IF\quad white,\quad THEN \quad whiter$</p></li></ul></li></ul><ul><li><p>输入模糊化：$dark-\mu<em>{id}(z),\quad gray-\mu</em>{ig}(z),\quad white-\mu_{iw}(z)$</p><ul><li><script type="math/tex; mode=display">\mu_{id}(z)=\begin{equation}\left\{\begin{aligned}1 &, &  0\leq z< 80, \\ \displaystyle\frac{1}{47}(127-z)& , & 80\leq z\leq 127,\\ 0&,& 127<z\leq 255\end{aligned}\right.\end{equation}</script></li><li><script type="math/tex; mode=display">\mu_{ig}(z)=\begin{equation}\left\{\begin{aligned}0 &, &  0\leq z< 80, \\ \displaystyle\frac{1}{47}(z-80)& , & 80\leq z\leq 127,\\ \displaystyle\frac{1}{47}(174-z)& , & 127<z\leq 174,\\ 0&,& 174<z\leq 255\end{aligned}\right.\end{equation}</script></li><li><script type="math/tex; mode=display">\mu_{iw}(z)=\begin{equation}\left\{\begin{aligned}0 &, &  0\leq z< 127, \\ \displaystyle\frac{1}{47}(z-127)& , & 127\leq z\leq 174,\\ 1&,& 174<z\leq 255\end{aligned}\right.\end{equation}</script></li></ul></li></ul><ul><li>输出模糊化：$datker-\mu<em>{od}(v),\quad gray-\mu</em>{og}(v),\quad whiter-\mu_{ow}(v)$<ul><li><script type="math/tex; mode=display">\mu_{od}(v)=\begin{equation}\left \{\begin{aligned}\infty,&\quad v=v_d\\ 0,&\quad otherwise \end{aligned}\right.\end{equation}</script></li><li><script type="math/tex; mode=display">\mu_{og}(v)=\begin{equation}\left \{\begin{aligned}\infty,&\quad v=v_g\\ 0,&\quad otherwise \end{aligned}\right.\end{equation}</script></li><li><script type="math/tex; mode=display">\mu_{ow}(v)=\begin{equation}\left \{\begin{aligned}\infty,&\quad v=v_w\\ 0,&\quad otherwise \end{aligned}\right.\end{equation}</script></li></ul></li></ul><ul><li>输出最终模糊响应：$Q(v)=\max{Q<em>d,Q_g,Q_w}=\max{\min\limits</em>{v\in Z}{\mu<em>{ik}(z_0),\mu</em>{ok}(v)}}$</li><li>去模糊：$v<em>0=\displaystyle\frac{\mu</em>{id}(z<em>0)\cdot v_d+\mu</em>{ig}(z<em>0)\cdot v_g+\mu</em>{iw}(z<em>0)\cdot v_w}{\mu</em>{id}(z<em>0)+\mu</em>{ig}(z<em>0)+\mu</em>{iw}(z_0)}$</li></ul><p><strong>Code : </strong> </p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 基于模糊集合论的灰度变换 </span><br><span class="hljs-comment"># 增加对比度</span><br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> cv2<br><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">f_id</span><span class="hljs-params">(z)</span>:</span><br><br>    <span class="hljs-keyword">if</span> z &lt; <span class="hljs-number">80</span>:<br>        <span class="hljs-keyword">return</span> <span class="hljs-number">1</span><br>    <span class="hljs-keyword">elif</span> z &gt;= <span class="hljs-number">80</span> <span class="hljs-keyword">and</span> z &lt;= <span class="hljs-number">127</span>:<br>        <span class="hljs-keyword">return</span> <span class="hljs-number">1</span> / <span class="hljs-number">47</span> * (<span class="hljs-number">127</span> - z)<br>    <span class="hljs-keyword">else</span>:<br>        <span class="hljs-keyword">return</span> <span class="hljs-number">0</span><br><br><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">f_ig</span><span class="hljs-params">(z)</span>:</span><br><br>    <span class="hljs-keyword">if</span> z &gt;= <span class="hljs-number">80</span> <span class="hljs-keyword">and</span> z &lt;= <span class="hljs-number">127</span>:<br>        <span class="hljs-keyword">return</span> <span class="hljs-number">1</span> / <span class="hljs-number">47</span> * (z - <span class="hljs-number">80</span>)<br>    <span class="hljs-keyword">elif</span> z &gt; <span class="hljs-number">127</span> <span class="hljs-keyword">and</span> z &lt;= <span class="hljs-number">174</span>:<br>        <span class="hljs-keyword">return</span> <span class="hljs-number">1</span> / <span class="hljs-number">47</span> * (<span class="hljs-number">174</span> - z)<br>    <span class="hljs-keyword">else</span>:<br>        <span class="hljs-keyword">return</span> <span class="hljs-number">0</span><br><br><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">f_iw</span><span class="hljs-params">(z)</span>:</span><br><br>    <span class="hljs-keyword">if</span> z &gt;= <span class="hljs-number">127</span> <span class="hljs-keyword">and</span> z &lt;= <span class="hljs-number">174</span>:<br>        <span class="hljs-keyword">return</span> <span class="hljs-number">1</span> / <span class="hljs-number">47</span> * (z - <span class="hljs-number">127</span>)<br>    <span class="hljs-keyword">elif</span> z &gt; <span class="hljs-number">174</span> <span class="hljs-keyword">and</span> z &lt;= <span class="hljs-number">255</span>:<br>        <span class="hljs-keyword">return</span> <span class="hljs-number">1</span><br>    <span class="hljs-keyword">else</span>:<br>        <span class="hljs-keyword">return</span> <span class="hljs-number">0</span><br><br><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">gray_trans</span><span class="hljs-params">(img)</span>:</span><br>    vd = <span class="hljs-number">0</span><br>    vg = <span class="hljs-number">127</span><br>    vw = <span class="hljs-number">255</span><br>    output_img = np.copy(img)<br>    m, n = img.shape<br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> range(<span class="hljs-number">1</span>, m):<br>        <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> range(<span class="hljs-number">1</span>, n):<br>            tmp1 = f_id(img[i][j]) * vd + f_ig(img[i][j]) * \<br>                vg + f_iw(img[i][j]) * vw<br>            tmp2 = f_id(img[i][j]) + f_ig(img[i][j]) + f_iw(img[i][j])<br>            output_img[i][j] = tmp1 / tmp2<br>    <span class="hljs-keyword">return</span> output_img<br><br><br>img = cv2.imread(<span class="hljs-string">'test.jpg'</span>, <span class="hljs-number">0</span>)<br>img2 = gray_trans(img)<br>cv2.imshow(<span class="hljs-string">'before'</span>, img)<br>cv2.imshow(<span class="hljs-string">'after'</span>, img2)<br>cv2.waitKey(<span class="hljs-number">0</span>)<br>cv2.destroyAllWindows()<br></code></pre></td></tr></table></figure><p><strong>效果：</strong>(before and after)</p><p><img src="https://tva1.sinaimg.cn/large/006tNbRwly1gbdwm7ycd7j30dm0go0w3.jpg" alt="before"></p><p><img src="https://tva1.sinaimg.cn/large/006tNbRwly1gbdwm89b0zj30dm0goq6v.jpg" alt="after"></p><h4 id="1-2-2-3-利用模糊集合进行空间滤波"><a href="#1-2-2-3-利用模糊集合进行空间滤波" class="headerlink" title="1.2.2.3 利用模糊集合进行空间滤波"></a>1.2.2.3 利用模糊集合进行空间滤波</h4><p>有一种基于模糊集合的边缘提取方法.</p><p>$ \ $ </p><h2 id="2-频率域滤波"><a href="#2-频率域滤波" class="headerlink" title="2 频率域滤波"></a>2 频率域滤波</h2><h3 id="2-1-傅立叶变换基础"><a href="#2-1-傅立叶变换基础" class="headerlink" title="2.1 傅立叶变换基础"></a>2.1 傅立叶变换基础</h3><h4 id="2-1-1-冲激函数相关"><a href="#2-1-1-冲激函数相关" class="headerlink" title="2.1.1 冲激函数相关"></a>2.1.1 冲激函数相关</h4><ol><li><p>冲激函数 对连续函数取样和对离散函数取样定义有所不同</p></li><li><p>冲激串函数：$\displaystyle s<em>{\Delta T}(t)=\sum\limits</em>{n=-\infty}^{\infty}\delta(t-n\Delta T)$ , 以 $\Delta T$ 为间隔取样</p></li></ol><h4 id="2-1-2-傅立叶变换相关"><a href="#2-1-2-傅立叶变换相关" class="headerlink" title="2.1.2 傅立叶变换相关"></a>2.1.2 傅立叶变换相关</h4><ol><li><p>傅立叶级数：$\displaystyle f(t)=\sum\limits<em>{n=-\infty}^\infty c_ne^{j\frac{2\pi n}{T}t},\quad c_n=\frac{1}{T}\int</em>{-\frac{T}{2}}^\frac{T}{2}f(t)e^{-j\frac{2\pi n}{T}t}$, 其中 $f(t)$ 以 $T$ 为周期</p></li><li><p>傅立叶变换：$\displaystyle\mathcal{F}[f(t)]=\int_{-\infty}^\infty f(t)e^{-2\pi\mu t} dt $</p></li><li><p>关于原点对称的宽为 $W$ 、高为 $A$ 的带限函数 $W(t)$ 的傅立叶变换： $\mathcal{F}[W(t)]=AWsinc(m)$, 其中在数字图像处理中，$sinc(x)=\displaystyle\frac{sin(\pi x)}{\pi x}$</p></li><li><p>冲激函数的傅立叶变换：$\mathcal{F}[\delta(t-t_0)]=e^{-j2\pi\mu t_0}=&gt;\mathcal{F}^{-1}[e^{-j2\pi\mu t_0}]=\delta(t-t_0)=&gt;\mathcal{F}[e^{-j2\pi\mu_0 t}]=\delta(-\mu-\mu_0)$</p></li><li><p>冲激串函数的傅立叶变换 ：</p><ul><li>将冲激串函数用傅立叶级数展开（不展开直接变换似乎不一致收敛，就不能交换求和号和积分号）：$\displaystyle s<em>{\Delta T}(t)=\sum\limits</em>{n=-\infty}^\infty c<em>ne^{j\frac{2\pi n}{\Delta T}t},\quad c_n=\frac{1}{\Delta T}\int</em>{-\frac{\Delta T}{2}}^\frac{\Delta T}{2} s<em>{\Delta T}(t)e^{-j\frac{2\pi n}{\Delta T}t}=\frac{1}{\Delta T}e^0=\frac{1}{\Delta T}\=&gt;\displaystyle  s</em>{\Delta T}(t)=\frac{1}{\Delta T}\sum\limits_{n=-\infty}^\infty e^{j\frac{2\pi n}{\Delta T}t}$</li><li>$S(\mu)=\displaystyle\mathcal{F}[ s<em>{\Delta T}(t)]=\frac{1}{\Delta T}\sum\limits</em>{n=-\infty}^\infty \delta(\mu-\frac{n}{\Delta T})$</li></ul></li><li><p>卷积：</p><p>$\begin{aligned} f(t)<em>g(t)&amp;\iff F(\mu)\cdot G(\mu)\F(\mu)</em>G(\mu)&amp;\iff f(t)\cdot g(t)\end{aligned}$</p></li></ol><h4 id="2-1-3-取样"><a href="#2-1-3-取样" class="headerlink" title="2.1.3 取样"></a>2.1.3 取样</h4><ul><li><p>取样后的函数 $\widetilde f(t)=f(t)\cdot s<em>{\Delta T}(t)=\displaystyle \sum\limits</em>{n=-\infty}^{\infty}f(t)\delta(t-n\Delta T)$</p></li><li><p>每个取样值：由加权后的冲激强度给出。 $f<em>k=\displaystyle\int</em>{-\infty}^{\infty}f(t)\delta(t-k\Delta T)=f(k\Delta T)$</p></li><li><p>取样后的函数的傅立叶变换：$\displaystyle \widetilde F(\mu)=F(\mu)*S(\mu)=\frac{1}{\Delta T}\sum\limits<em>{n=-\infty}^{\infty}\int</em>{-\infty}^{\infty}F(\tau)\delta(\mu-\frac{n}{\Delta T}-\tau)d\tau=\frac{1}{\Delta T}\sum\limits_{n=-\infty}^{\infty}F(\mu-\frac{n}{\Delta T})$</p><p>这是取样前函数$F(\mu)$ 的一个拷贝的无限、周期序列，确切的说是周期为 $\displaystyle\frac{1}{\Delta T}$ 的无限延伸的连续函数。</p></li><li><p>另一方面，直接变换得：$\widetilde F(\mu)=\displaystyle \sum<em>{n=-\infty}^{\infty}\int</em>{-\infty}^{\infty}f(t)\delta (t-n\Delta T)e^{-j2\pi \mu t}dt= \sum_{n=-\infty}^{\infty}f(n\Delta T)e^{-j2\pi \mu n\Delta T}$ </p></li><li><p><strong>取样定理</strong>：如果一超过函数最高频率的两倍的取样率来获得样本，连续的带限函数可以完全地从它的样本集来恢复。 $\displaystyle\frac{1}{\Delta T}&gt;2\mu_{max}$</p></li><li>复原：令 $H(\mu)=\begin{equation}\left{\begin{aligned} \Delta T,&amp;\quad -\mu<em>{max}\leqslant\mu\leqslant\mu</em>{max}\ 0.&amp;\quad otherwise\end{aligned}\right.\end{equation}$,  $F(\mu)=H(\mu)\cdot \widetilde F(\mu)$，进而由傅立叶逆变换可复原 $f$</li><li>但是，在实践中我们通常要限制函数的持续时间，相当于要乘一个周期内为 $1$ 其他地方为 $0$ 的函数，而这在频率域内相当于用 $sinc(x)$ 作卷积，这就引入了频率域无限周期分量。这样，在频率域截取时总无法截取全部周期，混淆总会产生。</li></ul><h3 id="2-2-离散傅立叶变换-DFT"><a href="#2-2-离散傅立叶变换-DFT" class="headerlink" title="2.2 离散傅立叶变换 DFT"></a>2.2 离散傅立叶变换 DFT</h3><h4 id="2-2-1-单变量-DFT"><a href="#2-2-1-单变量-DFT" class="headerlink" title="2.2.1 单变量$DFT$"></a>2.2.1 单变量$DFT$</h4><p>对 $\widetilde F(\mu)$ 的一个周期取样是 $DFT$  的基础。</p><p>记 $f(n\Delta T)$ 为 $f<em>n$ ,  $\widetilde F(\mu)=\displaystyle \sum</em>{n=-\infty}^{\infty}f_ne^{-j2\pi \mu n\Delta T}$ </p><p>想在周期 $\mu = 0$ 和 $\mu=\displaystyle\frac{1}{\Delta T}$ 之间得到 $M$ 个等间距的<em>样本</em> ，可令 $\mu=\displaystyle\frac{m}{M\Delta T}$.</p><p>离散傅立叶变换 $DFT$ 为：</p><script type="math/tex; mode=display">F_m=\sum\limits_{n=0}^{M-1}f_ne^{-j2\pi mn/M}</script><p>离散傅立叶逆变换 $IDFT$ 为：</p><script type="math/tex; mode=display">f_n=\frac{1}{M}\sum\limits_{m=0}^{M-1}F_m e^{j2\pi mn/M}</script><p>为了更方便表示，引入 $u$ 和 $x$ 代替 $m$ 和 $n$ ：</p><p>$DFT$：</p><script type="math/tex; mode=display">F(u)=\sum\limits_{x=0}^{M-1}f(x)e^{-j2\pi ux/M}</script><p>$IDFT$：</p><script type="math/tex; mode=display">f(x)=\frac{1}{M}\sum\limits_{u=0}^{M-1}F(u)e^{j2\pi ux/M}</script><p>（PS：有点小疑问：为什么是 $f(x)$ 而不是 $ f(x\Delta T)$ ？）</p><p>傅立叶正变换和逆变换得到的函数都是无限周期的，周期为 $M$。</p><h3 id="2-2-2-二维DFT"><a href="#2-2-2-二维DFT" class="headerlink" title="2.2.2 二维DFT"></a>2.2.2 二维DFT</h3><p>略</p><h3 id="2-2-3-频率域滤波器"><a href="#2-2-3-频率域滤波器" class="headerlink" title="2.2.3 频率域滤波器"></a>2.2.3 频率域滤波器</h3><p>过程：空间域 $=&gt;$ 傅立叶变换转到频率域 $=&gt;$ 在频率域使用模版处理振幅或者相位 $=&gt;$ 傅立叶逆变换回到空间域</p><ul><li>理想低/高通滤波器</li><li>k阶布特沃斯低/高通滤波器</li><li>高斯低/高通滤波器</li><li>频率域拉普拉斯算子（需归一化）</li><li>同态滤波（未完全理解）</li><li>选择性滤波器：带通滤波器、陷波滤波器（未实现）</li></ul><p><strong>代码实现：</strong></p><p>（1）：低通/高通滤波器</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> cv2<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br><br><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">IPF</span><span class="hljs-params">(img, d0, flag)</span>:</span><br>    <span class="hljs-comment">#  理想滤波器 ideal pass filter，d0 为滤波器半径</span><br>    <span class="hljs-comment"># flag == 1 : low pass filter; flag == 0 : high pass filter</span><br>    m, n = img.shape<br>    ans = np.zeros(img.shape)<br><br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> range(m):<br>        <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> range(n):<br>            <span class="hljs-keyword">if</span> (i - m / <span class="hljs-number">2</span>)**<span class="hljs-number">2</span> + (j - n / <span class="hljs-number">2</span>)**<span class="hljs-number">2</span> &lt; d0**<span class="hljs-number">2</span>:<br>                ans[i][j] = <span class="hljs-number">1</span><br>    <span class="hljs-keyword">if</span> flag == <span class="hljs-number">0</span>:<br>        ans = <span class="hljs-number">1</span> - ans<br><br>    <span class="hljs-keyword">return</span> ans<br><br><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">GPF</span><span class="hljs-params">(img, d0, flag)</span>:</span><br>    <span class="hljs-comment"># 高斯滤波器</span><br>    m, n = img.shape<br>    d0 = d0**<span class="hljs-number">2</span><br>    ans = np.zeros(img.shape)<br><br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> range(m):<br>        <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> range(n):<br>            d = (i - m / <span class="hljs-number">2</span>)**<span class="hljs-number">2</span> + (j - n / <span class="hljs-number">2</span>)**<span class="hljs-number">2</span><br>            <span class="hljs-keyword">if</span> d &lt; d0:<br>                ans[i][j] = np.exp(-d / (<span class="hljs-number">2</span> * d0))<br><br>    <span class="hljs-keyword">if</span> flag == <span class="hljs-number">0</span>:<br>        ans = <span class="hljs-number">1</span> - ans<br><br>    <span class="hljs-keyword">return</span> ans<br><br><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">BPF</span><span class="hljs-params">(img, do, flag, k)</span>:</span><br>    <span class="hljs-comment"># k阶布特沃斯高通滤波器</span><br>    m, n = img.shape<br>    d0 = d0**<span class="hljs-number">2</span><br>    ans = np.zeros(img.shape)<br><br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> range(m):<br>        <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> range(n):<br>            d = (i - m / <span class="hljs-number">2</span>)**<span class="hljs-number">2</span> + (j - n / <span class="hljs-number">2</span>)**<span class="hljs-number">2</span><br>            <span class="hljs-keyword">if</span> d &lt; d0:<br>                ans[i][j] = <span class="hljs-number">1</span> / (<span class="hljs-number">1</span> + (d / d0)**k)<br><br>    <span class="hljs-keyword">if</span> flag == <span class="hljs-number">0</span>:<br>        ans = <span class="hljs-number">1</span> - ans<br><br>    <span class="hljs-keyword">return</span> ans<br><br><br><span class="hljs-comment"># 高通滤波--提取轮廓</span><br><span class="hljs-comment"># 低通滤波--模糊化</span><br>img_man = cv2.imread(<span class="hljs-string">'ch03_5.jpg'</span>, <span class="hljs-number">0</span>)  <span class="hljs-comment"># 直接读为灰度图像</span><br>plt.subplot(<span class="hljs-number">131</span>), plt.imshow(img_man, <span class="hljs-string">'gray'</span>), plt.title(<span class="hljs-string">'before'</span>)<br>plt.xticks([]), plt.yticks([])<br><br><br>rows, cols = img_man.shape<br>mask1 = np.ones(img_man.shape, np.uint8)  <span class="hljs-comment"># 高通</span><br>mask1[int(rows / <span class="hljs-number">2</span>) - <span class="hljs-number">30</span>: int(rows / <span class="hljs-number">2</span>) + <span class="hljs-number">30</span>,<br>      int(cols / <span class="hljs-number">2</span>) - <span class="hljs-number">30</span>:int(cols / <span class="hljs-number">2</span>) + <span class="hljs-number">30</span>] = <span class="hljs-number">0</span><br><br>mask2 = np.zeros(img_man.shape, np.uint8)  <span class="hljs-comment"># 低通</span><br>mask2[int(rows / <span class="hljs-number">2</span>) - <span class="hljs-number">30</span>:int(rows / <span class="hljs-number">2</span>) + <span class="hljs-number">30</span>,<br>      int(cols / <span class="hljs-number">2</span>) - <span class="hljs-number">30</span>:int(cols / <span class="hljs-number">2</span>) + <span class="hljs-number">30</span>] = <span class="hljs-number">1</span><br><br><br>mask31 = np.ones(img_man.shape, np.uint8)<br>mask31[int(rows / <span class="hljs-number">2</span>) - <span class="hljs-number">10</span>:int(rows / <span class="hljs-number">2</span>) + <span class="hljs-number">10</span>,<br>       int(cols / <span class="hljs-number">2</span>) - <span class="hljs-number">10</span>:int(cols / <span class="hljs-number">2</span>) + <span class="hljs-number">10</span>] = <span class="hljs-number">0</span><br>mask32 = np.zeros(img_man.shape, np.uint8)<br>mask32[int(rows / <span class="hljs-number">2</span>) - <span class="hljs-number">80</span>:int(rows / <span class="hljs-number">2</span>) + <span class="hljs-number">80</span>,<br>       int(cols / <span class="hljs-number">2</span>) - <span class="hljs-number">80</span>:int(cols / <span class="hljs-number">2</span>) + <span class="hljs-number">80</span>] = <span class="hljs-number">1</span><br>mask3 = mask31 * mask32  <span class="hljs-comment"># 带通</span><br><br>mask = IPF(img_man, <span class="hljs-number">30</span>, <span class="hljs-number">1</span>)<br><br>f1 = np.fft.fft2(img_man)<br>f1shift = np.fft.fftshift(f1)<br>f1shift = f1shift * mask<br>f2shift = np.fft.ifftshift(f1shift)<br>img_new = np.fft.ifft2(f2shift)<br>img_new = np.abs(img_new)<br><span class="hljs-comment"># 调整大小范围便于显示</span><br><span class="hljs-comment"># img_new = (img_new - np.amin(img_new)) / (np.amax(img_new) - np.amin(img_new))</span><br><br>plt.subplot(<span class="hljs-number">132</span>), plt.imshow(mask, <span class="hljs-string">'gray'</span>), plt.title(<span class="hljs-string">'mask'</span>)<br>plt.xticks([]), plt.yticks([])<br>plt.subplot(<span class="hljs-number">133</span>), plt.imshow(img_new, <span class="hljs-string">'gray'</span>), plt.title(<span class="hljs-string">'after'</span>)<br>plt.xticks([]), plt.yticks([])<br>plt.show()<br></code></pre></td></tr></table></figure><p>（2）：频率域拉普拉斯滤波</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">Laplace</span><span class="hljs-params">(shape)</span>:</span><br>    m, n = shape<br>    ans = np.zeros(shape)<br><br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> range(m):<br>        <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> range(n):<br>            d = (i - m / <span class="hljs-number">2</span>)**<span class="hljs-number">2</span> + (j - n / <span class="hljs-number">2</span>)**<span class="hljs-number">2</span><br>            ans[i][j] = <span class="hljs-number">1</span> + <span class="hljs-number">4</span> * (np.pi**<span class="hljs-number">2</span>) * d / (m * n)<br>            <span class="hljs-comment"># 之前失败是由于没有处以mn</span><br>    <span class="hljs-keyword">return</span> ans<br><br><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">stdimg</span><span class="hljs-params">(img)</span>:</span><br>        <span class="hljs-comment"># 灰度值归一化</span><br>    m, n = img.shape<br>    min_img = np.amin(img)<br>    max_img = np.amax(img)<br>    img = np.float64(img)<br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> range(m):<br>        <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> range(n):<br>            img[i][j] = (img[i][j] - min_img) / (max_img - min_img)<br><br>    <span class="hljs-keyword">return</span> img<br><br><br>img = cv2.imread(<span class="hljs-string">'ch03_3.jpg'</span>, <span class="hljs-number">0</span>)<br>img = stdimg(img)<br>f = np.fft.fft2(img)<br>f = np.fft.fftshift(f)<br>mask = Laplace(img.shape)<br>f *= mask<br>img_back = np.fft.ifftshift(f)<br>img_back = np.fft.ifft2(img_back)<br>img_back = np.abs(img_back)<br>plt.subplot(<span class="hljs-number">131</span>), plt.imshow(img, <span class="hljs-string">'gray'</span>), plt.title(<span class="hljs-string">'before'</span>)<br>plt.xticks([]), plt.yticks([])<br>plt.subplot(<span class="hljs-number">132</span>), plt.imshow(mask, <span class="hljs-string">'gray'</span>), plt.title(<span class="hljs-string">'mask'</span>)<br>plt.xticks([]), plt.yticks([])<br>plt.subplot(<span class="hljs-number">133</span>), plt.imshow(img_back, <span class="hljs-string">'gray'</span>), plt.title(<span class="hljs-string">'after'</span>)<br>plt.xticks([]), plt.yticks([])<br><br>plt.show()<br></code></pre></td></tr></table></figure><h2 id="3-图像复原与重建"><a href="#3-图像复原与重建" class="headerlink" title="3 图像复原与重建"></a>3 图像复原与重建</h2><h2 id="4-彩色图像处理"><a href="#4-彩色图像处理" class="headerlink" title="4 彩色图像处理"></a>4 彩色图像处理</h2>]]></content>
      
      
      <categories>
          
          <category> Computer Science </category>
          
          <category> Image Processing </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>Computer-Sciencs/Git学习笔记</title>
      <link href="/2020/01/24/Computer-Sciencs/Git%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
      <url>/2020/01/24/Computer-Sciencs/Git%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/</url>
      
        <content type="html"><![CDATA[<h2 id="Git学习"><a href="#Git学习" class="headerlink" title="Git学习"></a>Git学习</h2><h3 id="创建版本库"><a href="#创建版本库" class="headerlink" title="创建版本库"></a>创建版本库</h3><p>mkdir dirname // make directory 创建目录 dirname 为目录名</p><p>pwd //print working directory 查看当前工作目录的完整路径</p><p>ls -a // 显示所有文件及目录，包括隐藏档</p><p>git init</p><h3 id="修改与提交"><a href="#修改与提交" class="headerlink" title="修改与提交"></a>修改与提交</h3><p>git add filename1.txt filename2.txt // 把要提交的所有<em>修改</em> 放到暂存区</p><p>git commit -m “what I did in this commission” // 一次性把暂存区的所有修改提交到分支 -m表示message</p><p>git log // 查看修改日志</p><p>git log —graph // 查看分支合并图</p><p>git log —pretty=oneline // 每次修改在一行简明显示</p> <a id="more"></a><p>git reflog // 查看命令历史</p><p>git reset —hard versionnumber // 彻底回退到某版本</p><p>git status // 查看版本库状态</p><p>cat filename // 查看文件内容</p><p>git diff HEAD — readme.txt // 查看版本库最新版本和工作区的readme文件的区别</p><p>git restore —staged filename // 撤销提交到暂存区</p><p>rm filename // remove 删除文件</p><p>rmdir dirname // 删除空文件目录</p><p>git rm filename // 从版本库中删除文件</p><p>git checkout — filename // 误删文件的恢复</p><h3 id="远程仓库"><a href="#远程仓库" class="headerlink" title="远程仓库"></a>远程仓库</h3><p>git remote add origin git@github.com:longqianh/learngit.git</p><p>git push -u origin master</p><p>git clone git@github.com:longqianh/learngit.git</p><h3 id="分支管理"><a href="#分支管理" class="headerlink" title="分支管理"></a>分支管理</h3><p>git checkout </p><p>git branch // 查看分支</p><p>git branch -d branchname // 删除分支</p><p>git branch branchname // 创建分支</p><p>git checkout branchname 或 git checkout branchname // 切换分支</p><p>git checkout -b branchname 或 git switch -c branchname // 创建并切换分支</p><p>git merge branchname // 合并branch分支到master上</p><p>git merge —no-ff -m “branchname” // 合并branch分支到master上,并产生一条记录</p><p>建议：使用分支完成某个任务，合并后再删掉分支</p><p>git remote // 查看远程库信息</p><p>git branch —set-upstream branchname origin/branchname // 建立本地分支与远程分支的关联</p><p>git pull // 拉取远程分支新提交并合并</p><p>git push branchname // 向远程仓库推送分支</p><p>git tag tagname  // 给分支打标签</p><p>git tag -a tagname -m “message” // 给标签加说明</p><p>git tag // 查看所有标签</p><p>git push tagname // 推送一个本地标签到远程</p><p>git push —tag // 推送所有本地标签</p><p>git tag -d tagname // 删除标签</p><p>git push origin :refs/tags/tagname // 删除一个远程标签</p><p>git config —global alias.st status // 配置别名 加—global对当前用户起作用，不加则对当前仓库起作用</p>]]></content>
      
      
      <categories>
          
          <category> Computer Science </category>
          
          <category> Git </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>Abstract Algebra</title>
      <link href="/2020/01/20/Mathematics/Abstract-Algebra/"/>
      <url>/2020/01/20/Mathematics/Abstract-Algebra/</url>
      
        <content type="html"><![CDATA[<h1 id="抽象代数内容整理"><a href="#抽象代数内容整理" class="headerlink" title="抽象代数内容整理"></a>抽象代数内容整理</h1><h2 id="1-群论"><a href="#1-群论" class="headerlink" title="1  群论"></a>1  群论</h2><h3 id="1-1-群-Group"><a href="#1-1-群-Group" class="headerlink" title="1.1 群 Group"></a>1.1 群 Group</h3><h4 id="1-1-1-群的定义"><a href="#1-1-1-群的定义" class="headerlink" title="1.1.1 群的定义"></a>1.1.1 群的定义</h4><p>一个<em>群</em> 是带有下列性质的合成法则的集合$G$ :</p><ol><li>合成法则满足结合律</li><li>包含单位元</li><li>每个元素都有逆元</li></ol><p>=&gt; 消去律</p><p>$ \ $ <a id="more"></a></p><h4 id="1-1-2-子群"><a href="#1-1-2-子群" class="headerlink" title="1.1.2 子群"></a>1.1.2 子群</h4><h4 id="1-1-2-1-定义"><a href="#1-1-2-1-定义" class="headerlink" title="1.1.2.1 定义"></a>1.1.2.1 定义</h4><ol><li>对运算具有封闭性</li><li>包含单位元</li><li>每个元素都有逆元</li></ol><p>$ \ $</p><h4 id="1-1-2-2-正规子群"><a href="#1-1-2-2-正规子群" class="headerlink" title="1.1.2.2 正规子群"></a>1.1.2.2 正规子群</h4><p>$ N \trianglelefteq G $</p><p>$ \iff  $ $ \forall a\in N,g\in G \quad gag^{-1}\in G $ $ \ $ </p><p>$ \iff  $ $ gNg^{-1}=N $</p><p>$ \iff $ $ gN=Ng $</p><p>$ \ $</p><h4 id="1-1-3-同态"><a href="#1-1-3-同态" class="headerlink" title="1.1.3 同态"></a>1.1.3 同态</h4><p>两个群中与合成法则相容的映射。</p><p>$\varphi : G\to G’, s.t \ \forall a,b \in G, \quad \varphi(ab)=\varphi(a)\varphi(b)  $</p><p>$\implies$ $\varphi$ 把单位元映射为单位元，把逆元映射为逆元</p><p>$\implies$ $ im \varphi \leqslant G’, \quad \ker \varphi \trianglelefteq G$ </p><p>$\implies$ 群同态基本定理： $G/\ker\varphi \cong im\varphi$</p><p>$ \ $</p><h4 id="1-1-4-同构"><a href="#1-1-4-同构" class="headerlink" title="1.1.4 同构"></a>1.1.4 同构</h4><p>双射群同态。</p><p>$\implies$ 第一同构定理：</p><p> $ \varphi$ 是一个满同态， $\pi $ 是典范态射 $(canonical)$ </p><p>则存在唯一一个同构映射$\overline \varphi : \overline G\to G’ \quad  s.t. \quad \varphi=\overline\varphi \circ \pi$</p><ul><li><p>验证 $\varphi:G\to G’$ 是同构的方法：</p><p>只需验证 $\ker \varphi={1},im\varphi=G’$</p></li></ul><h4 id="1-1-5-陪集"><a href="#1-1-5-陪集" class="headerlink" title="1.1.5 陪集"></a>1.1.5 陪集</h4><p>关于同余关系的等价类。</p><h4 id="1-1-5-1-左陪集"><a href="#1-1-5-1-左陪集" class="headerlink" title="1.1.5.1 左陪集"></a>1.1.5.1 左陪集</h4><p>$ H\leqslant G, a\in G, aH={ah|a\in H  }$ </p><p>$\implies$ $a\in bH \Leftrightarrow aH=bH$</p><p>$\implies$ $ |G|=[G:H]\cdot|H|$</p><p>$ \ $</p><h4 id="1-1-5-2-拉格朗日定理"><a href="#1-1-5-2-拉格朗日定理" class="headerlink" title="1.1.5.2 拉格朗日定理"></a>1.1.5.2 拉格朗日定理</h4><p>子群的阶整除群的阶。 $i.e. |H| \biggm| |G|$</p><p>$\implies$ 素数阶群是循环群</p><p>  $ \ $</p><h4 id="1-1-6-对应定理"><a href="#1-1-6-对应定理" class="headerlink" title="1.1.6 对应定理"></a>1.1.6 对应定理</h4><p>$\varphi : G\to G’ $ 是一个满同态.</p><p>$ K=ker\varphi, H’\leqslant G’, H\supset K$ .</p><p>$\implies$ 若 $H’$ 是正规子群，则 $H$ 也是正规子群。$\varphi$ 是满射，$H$ 是正规子群，则$H’$ 也是正规子群。</p><p>$\implies$ ${G的含有K的子群 }\longleftrightarrow {G’的子群}$</p><p>$ \ $</p><h4 id="1-1-7-积群"><a href="#1-1-7-积群" class="headerlink" title="1.1.7 积群"></a>1.1.7 积群</h4><p>$G\times G’={(g,g’) |g\in G, g’\in G’}$</p><p>$ \ $</p><p>$\implies$ $r$、$s$ 互素，则 $C_{rs}\cong C_r\times C_s$</p><p>$\implies$ 命题 $2.11.4$ :</p><p>$H,K \leqslant G, let \quad f:H\times K \to G$ 是一个映射，</p><p>$def : f(h,k)=hk. \quad imf=HK={hk|h\in H,k\in K } $</p><p>$then$ $f$  是一个同构   i.e  $H\times K \cong HK $ </p><p>$ \iff$ $H\cap K={1},HK=G,\quad H\trianglelefteq G,K\trianglelefteq G.  $</p><p>$ \ $</p><h4 id="1-1-8-商群"><a href="#1-1-8-商群" class="headerlink" title="1.1.8 商群"></a>1.1.8 商群</h4><p>群$G$在正规子群$N$的陪集的集合上定义合成法则，这个运算法则使得正规子群的陪集成为一个群，称为<em>商群</em>。</p><p>$\overline G=G/N\triangleq { \overline g|\overline g=gN,g\in G }$</p><p>$ \ $</p><p>$\implies$ 典范态射：$\pi : G\to \overline G \quad g\mapsto\overline g$      这是一个满同态。</p><p>$ \ $</p><h3 id="1-2-群作用"><a href="#1-2-群作用" class="headerlink" title="1.2 群作用"></a>1.2 群作用</h3><h4 id="1-2-1-轨道、稳定子"><a href="#1-2-1-轨道、稳定子" class="headerlink" title="1.2.1 轨道、稳定子"></a>1.2.1 轨道、稳定子</h4><h4 id="1-2-1-1-定义"><a href="#1-2-1-1-定义" class="headerlink" title="1.2.1.1 定义"></a>1.2.1.1 定义</h4><p>orbit： $O_s={s’\in S | s’=gs,g\in G}$</p><p>stabilizer：$G_s={g\in G|gs=s}$</p><p>$ \ $</p><h4 id="1-2-1-2-计数公式"><a href="#1-2-1-2-计数公式" class="headerlink" title="1.2.1.2 计数公式"></a>1.2.1.2 计数公式</h4><p>$|G|=|G_s|\cdot |O_s|$</p><p>$ \ $</p><p>$\implies$  $|O_s|=[G:G_s]$</p><p>$\implies$ $|S|=|O_1|+|O_2|+\cdots +|O_k|$</p><p>$ \ $</p><h4 id="1-2-2-对陪集的作用"><a href="#1-2-2-对陪集的作用" class="headerlink" title="1.2.2 对陪集的作用"></a>1.2.2 对陪集的作用</h4><h4 id="1-2-2-1-诱导表示"><a href="#1-2-2-1-诱导表示" class="headerlink" title="1.2.2.1 诱导表示"></a>1.2.2.1 诱导表示</h4><h4 id="1-2-3-置换表示"><a href="#1-2-3-置换表示" class="headerlink" title="1.2.3 置换表示"></a>1.2.3 置换表示</h4><p>群$G$的置换表示送从该群到一个对称群的同态.</p><p>$\varphi : G\to S_N$</p><p>$[G在S上的作用]\leftrightarrow[置换表示]$</p><p>$ \ $</p><h4 id="1-2-3-2-凯莱定理"><a href="#1-2-3-2-凯莱定理" class="headerlink" title="1.2.3.2 凯莱定理"></a>1.2.3.2 凯莱定理</h4><p>每一个有限群都同构于某个置换群的子群.</p><p>如果$|G|=n$ , 则 $G\hookrightarrow S_n$</p><p>$ \ $</p><h4 id="1-2-4-共轭作用"><a href="#1-2-4-共轭作用" class="headerlink" title="1.2.4 共轭作用"></a>1.2.4 共轭作用</h4><h4 id="1-2-4-1-中心化子、共轭类"><a href="#1-2-4-1-中心化子、共轭类" class="headerlink" title="1.2.4.1 中心化子、共轭类"></a>1.2.4.1 中心化子、共轭类</h4><p>中心化子：元素$x$关于共轭作用的稳定子。</p><p>$Z(x)={g\in G|gx=xg}$</p><p>共轭类：$x$关于共轭作用的轨道。</p><p>$C(x)={x’\in G|x’=gxg^{-1},g\in G}$</p><p>$ \ $</p><p>$\implies$ $|G|=|Z(x)|\cdot |C(x)|$</p><p>$ \ $</p><h4 id="1-2-4-1-类方程"><a href="#1-2-4-1-类方程" class="headerlink" title="1.2.4.1 类方程"></a>1.2.4.1 类方程</h4><p>共轭类划分群$G$。</p><p>$ |G|=\sum\limits<em>{共轭类C} |C|=|Z|+\sum\limits</em> {x\in g}|C(x)| $</p><p>$ \ $</p><h4 id="1-2-5-Sylow定理"><a href="#1-2-5-Sylow定理" class="headerlink" title="1.2.5 Sylow定理"></a>1.2.5 Sylow定理</h4><p>设 $|G|=n=p^e m$ .</p><h4 id="1-2-5-1-p-群相关命题"><a href="#1-2-5-1-p-群相关命题" class="headerlink" title="1.2.5.1 p-群相关命题"></a>1.2.5.1 p-群相关命题</h4><p>p-群：阶是素数 $p$ 的正幂的群。</p><ul><li><p>p-群 $G$ 的中心是非平凡群。</p></li><li><p>（不动点定理）$G$是p-群，$S$ 是一个有限集合，$G$ 在 $S$ 上面作用。若$p\nmid |S|$ , 则$G$的作用有个不动点$s$， 它的稳定子是整个群。</p></li><li><p>$p^2$ 阶群是 $Abel$ 群。</p><p>$ \ $</p></li></ul><h4 id="1-2-5-4-Sylow-I"><a href="#1-2-5-4-Sylow-I" class="headerlink" title="1.2.5.4 Sylow-I"></a>1.2.5.4 Sylow-I</h4><p>阶被素数 $p$ 整除的有限群包含一个 $Sylow-p$ 子群。</p><p>$ \ $</p><p>$=&gt;$ 阶被素数 $p$ 整除的有限群包含一个 $p$ 阶的元素。</p><p>$ \ $</p><h4 id="1-2-5-5-Sylow-II"><a href="#1-2-5-5-Sylow-II" class="headerlink" title="1.2.5.5 Sylow-II"></a>1.2.5.5 Sylow-II</h4><p>(a) $G$ 的 $Sylow-p$ 子群是共轭子群。</p><p>(b) $G$的每一个p-群的子群都包含在一个 $Sylow-p$ 子群里。 </p><p>$ \ $</p><p>$\implies$ 群 $G$ 只有一个 $Sylow-p$ 子群$\iff$这个子群是正规子群</p><p>$ \ $</p><h4 id="1-2-5-6-Sylow-III"><a href="#1-2-5-6-Sylow-III" class="headerlink" title="1.2.5.6 Sylow-III"></a>1.2.5.6 Sylow-III</h4><p>$G$ 的 $Sylow-p$ 子群的个数整除 $m$ 且模 $p$ 余 $1$.</p><p>$ \ $</p><h3 id="1-2-6-自由群"><a href="#1-2-6-自由群" class="headerlink" title="1.2.6 自由群"></a>1.2.6 <a href="https://zh.wikipedia.org/wiki/%E8%87%AA%E7%94%B1%E7%BE%A4" target="_blank" rel="noopener">自由群</a></h3><p>群的元素的一个集合称为是<em>自由的</em>，如果其元素除了群的公理给出的关系外不满足任何别的关系。</p><p>具有自由的生成元的集合的群称为<em>自由群</em>。</p><p>$ \ $</p><h2 id="2-环论"><a href="#2-环论" class="headerlink" title="2  环论"></a>2  环论</h2><h3 id="2-1-环的定义-Ring"><a href="#2-1-环的定义-Ring" class="headerlink" title="2.1 环的定义 Ring"></a>2.1 环的定义 Ring</h3><p>一个<em>环</em> $R$ 是一个具有两种合成法则$+$和$\times$ 的集合。</p><p>关于加法为阿贝尔群，关于乘法满足结合律。</p><p>关于加法和乘法满足分配律。</p><p>$ \ $</p><p><strong>整环</strong>（Integral Domain）：不含零因子的环。整环满足消去律。</p><p><strong>诺特环</strong>：一个环是诺特环如果它的每个理想都是有限生成的。</p><p>$ \ $</p><h3 id="2-2-环同态"><a href="#2-2-环同态" class="headerlink" title="2.2 环同态"></a>2.2 环同态</h3><p>从一个环到另一个环的映射，与加法和乘法的合成法则相容。</p><p>$\varphi (a+b)=\varphi(a)+\varphi(b),\quad \varphi(ab)=\varphi(a)\cdot \varphi(b)$</p><p>若环有乘法单位元，则 $\varphi(1)=1$</p><p>$ \ $</p><h3 id="2-3-理想-Ideal"><a href="#2-3-理想-Ideal" class="headerlink" title="2.3 理想 Ideal"></a>2.3 理想 Ideal</h3><ul><li>环$R$的左理想$I$是满足下列性质的非空子集：</li></ul><p>（1）关于加法封闭</p><p>（2）$\forall r\in R, s\in I, \quad rs\in I$</p><p>$ \ $</p><ul><li>极大理想：$M&lt; R(M\neq R),$ 若$I\subseteq M,$ 则 $I=M$ 或 $I=R$ 。</li></ul><p>$ \ $</p><p>$\implies$ 整数环 $Z$ 的极大理想是有素数生成的主理想。</p><p>$\implies$ $F$ 是一个域，$F[x]$ 的极大理想是由既约的首一多项式生成的主理想</p><p>$ \ $</p><h3 id="2-4-商环-第一同构定理"><a href="#2-4-商环-第一同构定理" class="headerlink" title="2.4 商环, 第一同构定理"></a>2.4 商环, 第一同构定理</h3><p>类似群论。</p><h3 id="2-5-对应定理"><a href="#2-5-对应定理" class="headerlink" title="2.5 对应定理"></a>2.5 对应定理</h3><p>$\varphi ：R\to R’$ 是满射环同态，则存在一个双射对应：</p><p>${R的含核 理想}\leftrightarrow {R’的理想}$</p><p>$ \ $</p><h3 id="2-6-希尔伯特零点定理"><a href="#2-6-希尔伯特零点定理" class="headerlink" title="2.6 希尔伯特零点定理"></a>2.6 希尔伯特零点定理</h3><p>多项式环 $\mathbf C[x_1,x_2,\cdots,x_n]$的极大理想与复$n$维空间的点一一对应。$\mathbf{C}^n $ 的一个点$a=(a_1,a_2,\cdots,c_n)$对应于映 $x_i \rightsquigarrow a_i$的代入映射 $s_a:\mathbf{C}[x_1,\cdots, x_n]\to\mathbf{C}$的核$M_a$ . 这个映射的核 $M_a$ 是由 $n$ 个线性多项式 $x_i-a_i$ 生成的理想。</p><p>$ \ $</p><h3 id="2-7-因子分解"><a href="#2-7-因子分解" class="headerlink" title="2.7 因子分解"></a>2.7 因子分解</h3><h4 id="2-7-1-基本概念"><a href="#2-7-1-基本概念" class="headerlink" title="2.7.1 基本概念"></a>2.7.1 基本概念</h4><ul><li>单位 unit ：有乘法逆元</li><li>相伴 associate ：$a$ 和 $b$ 相伴$\iff$$(a)=(b)$</li><li>不可约 irreducible :  不是单位且没有真因子，因子为单位或者相伴元</li><li>素元 prime : $p$ 是素元 $\iff$ $p\mid ab=&gt;p\mid a \quad or \quad p\mid b$</li></ul><p>$ \ $</p><h4 id="2-7-2-欧几里得整环-ED"><a href="#2-7-2-欧几里得整环-ED" class="headerlink" title="2.7.2 欧几里得整环 ED"></a>2.7.2 欧几里得整环 ED</h4><ul><li>有尺度函数，可进行带余除法</li><li>常见例子：$\mathbf{Z},F[x],\mathbf{Z}[i]$</li><li>$ED$ is $PID$</li></ul><p>$ \ $</p><h4 id="2-7-3-主理想整环-PID"><a href="#2-7-3-主理想整环-PID" class="headerlink" title="2.7.3 主理想整环 PID"></a>2.7.3 主理想整环 PID</h4><ul><li>所有理想均为主理想</li><li>理想$(a,b)=Ra+Rb$ 的生成元 $d$ 是 $a,b$ 的最大公因子</li><li>$\exists r,s \in R\quad s.t.\quad d=ra+sb$</li><li>$PID$ 中，元素是不可约的当且仅当它是素的</li></ul><p>$ \ $</p><h4 id="2-7-4-唯一分解整环-UFD"><a href="#2-7-4-唯一分解整环-UFD" class="headerlink" title="2.7.4 唯一分解整环 UFD"></a>2.7.4 唯一分解整环 UFD</h4><ul><li>分解终止，且元素的既约分解唯一</li><li>$ED=&gt;PID=&gt;UFD$</li></ul><p>$ \ $</p><h3 id="2-7-高斯引理"><a href="#2-7-高斯引理" class="headerlink" title="2.7 高斯引理"></a>2.7 高斯引理</h3><ul><li>本原多项式：正次数的正系数多项式，且整数系数 $a_1, a_2,\cdots,a_n$的最大公因子是$1$。</li><li>$f$ 是本原的$\iff$$f$ 不能被任何素数  $ p $ 整除 $\iff$ $\forall p: prime,\psi_p(f)\neq 0\quad(\psi_p为系数模素数p的同态)$</li><li>$Gauss’s$ $Lemma$ : 本原多项式的积是本原的</li><li>每个有理系数的正次数多项式 $f(x)$ 可唯一地写成 $f(x)=cf_0(x)$ ，其中 $c\in \mathbb{Q}$，$f_0(x)$ 是本原多项式</li><li>多项式环 $ \mathbf{Z}[x]$ 是唯一分解整环。每个不是 $\pm 1$ 的非零多项式 $f(x)\in\mathbf{Z}[x]$ 可以写成积的形式： $f(x)=\pm p_1\cdots p_m q_1(x)\cdots q_n(x)$ ，$p_i $ 是整素数，$q_i$ 是本原的既约多项式。</li></ul><p>$ \ $</p><h3 id="2-8-爱森斯坦判别法"><a href="#2-8-爱森斯坦判别法" class="headerlink" title="2.8 爱森斯坦判别法"></a>2.8 爱森斯坦判别法</h3><p>设 $f(x)=a_nx^n+\cdots+a_0$ 是一个整多项式，并设 $p$ 是一个素整数。若 $f$ 的系数满足：</p><p>(1) $p\nmid a_n$</p><p>(2) $p\mid a_{n-1},\dots,p\mid a_0$</p><p>(3) $p^2 \nmid a_0$</p><p>则 $f$ 在 $\mathbf{Q}[x]$ 中是既约的。</p><p>$ \ $</p><h3 id="2-9-模论：环上的线性代数"><a href="#2-9-模论：环上的线性代数" class="headerlink" title="2.9 模论：环上的线性代数"></a>2.9 模论：环上的线性代数</h3><h4 id="2-9-1-模-Module"><a href="#2-9-1-模-Module" class="headerlink" title="2.9.1 模 Module"></a>2.9.1 模 Module</h4><p>$R$ 是一个环，$R$-模 $V$ 包含一个加法阿贝尔群与一个标量乘法 $R\times V\to V ,\quad r,v\rightsquigarrow rv $ , 满足一下条件：</p><p>$1v=v,\quad (rs)v=r(sv),\quad (r+s)v=rv+sv,\quad r(v+v’)=rv+rv’.\qquad\forall r,s \in R,\quad v,v’\in V$</p><p>$ \ $</p><p>$=&gt;$ $\mathbf{Z}$-模 与 阿贝尔群 是等价的概念，因为一个合成法则记为加法的阿贝尔群有唯一的 方法构成 $\mathbf{Z}$ 上的一个模。</p><p>$ \ $</p><h4 id="2-9-2-子模"><a href="#2-9-2-子模" class="headerlink" title="2.9.2 子模"></a>2.9.2 子模</h4><p>在加法和标量乘法下封闭的子集。</p><p>$=&gt;$ $R$-模 $R$ 的子模是 $R$ 的理想</p><p>$ \ $</p><h4 id="2-9-3-商模"><a href="#2-9-3-商模" class="headerlink" title="2.9.3 商模"></a>2.9.3 商模</h4><h4 id="2-9-3-1-模同态"><a href="#2-9-3-1-模同态" class="headerlink" title="2.9.3.1 模同态"></a>2.9.3.1 模同态</h4><p>$\varphi : V\to W\quad \varphi(v+v’)=\varphi(v)+\varphi(v’),\quad \varphi(rv)=r\varphi(v)$</p><p>同态的像是子模。</p><p>$ \ $</p><h4 id="2-9-3-2-典范态射"><a href="#2-9-3-2-典范态射" class="headerlink" title="2.9.3.2 典范态射"></a>2.9.3.2 典范态射</h4><p>令 $W $ 是 $R$-模 $V$ 的子模。</p><p>$\pi : V\to \overline V\quad v\rightsquigarrow\overline v=[v+W]$ </p><p>$\pi$ 是一个满同态，$\ker\pi =W$</p><p>$ \ $</p><h4 id="2-9-3-3-第一同构定理"><a href="#2-9-3-3-第一同构定理" class="headerlink" title="2.9.3.3 第一同构定理"></a>2.9.3.3 第一同构定理</h4><p> $f:V\to V’$ 是模满同态，同态核  $K=W$.  则 $\overline f:\overline V=V/W\to V’$ 是一个同构。</p><p>$ \ $</p><h4 id="2-9-3-4-对应定理"><a href="#2-9-3-4-对应定理" class="headerlink" title="2.9.3.4 对应定理"></a>2.9.3.4 对应定理</h4><p>$f:V\to V’$ 是模满同态, 核为 $W$ .  存在一个一一对应：</p><p>${V的包含W的子模}\leftrightarrow {V’ 的子模}$</p><p>$ \ $</p><h4 id="2-9-4-自由模"><a href="#2-9-4-自由模" class="headerlink" title="2.9.4 自由模"></a>2.9.4 自由模</h4><p>一个模是自由的当且仅当它有基。</p><p>设 $R$ 是一个非零交换环。</p><p>（1）一个自由模的基变换矩阵是一个可逆矩阵</p><p>（2）$R$ 上同一个自由模的两个基具有同样的元素个数</p><p>$ \ $</p><h4 id="2-9-5-阿贝尔群结构定理"><a href="#2-9-5-阿贝尔群结构定理" class="headerlink" title="2.9.5 阿贝尔群结构定理"></a>2.9.5 阿贝尔群结构定理</h4><p>有限生成阿贝尔群 $V$ 是循环子群 $C<em>{d_1},\cdots,C</em>{d_n}$ 和一个自由阿贝尔群 $L$ 的直和：</p><script type="math/tex; mode=display">V=C_{d_1}\oplus\cdots C_{d_n}\oplus L,\qquad d_i>1,d_i\mid d_{i+1}</script><p>$ \ $</p><p>进一步分解后：</p><p>$=&gt;$ 每一个有限生成阿贝尔群是素数幂阶循环群的直和</p><p>$ \ $</p><h2 id="3-域论"><a href="#3-域论" class="headerlink" title="3  域论"></a>3  域论</h2><h3 id="3-1-域-Field"><a href="#3-1-域-Field" class="headerlink" title="3.1 域 Field"></a>3.1 域 Field</h3><h3 id="3-1-1-域的定义"><a href="#3-1-1-域的定义" class="headerlink" title="3.1.1 域的定义"></a>3.1.1 域的定义</h3><p>域 $F$ 具有加法和乘法两个合成法则，关于加法称为阿贝尔群 $F^+$ ，非零元关于乘法称为阿贝尔群 $F^{\times}$，关于加法和乘法满足分配律。</p><ul><li>含幺交换环 $+$ 每个元素都有逆元 $=&gt;$ 域</li></ul><p>子域：域的子集，且关于加减乘除封闭</p><p>$ \ $</p><h3 id="3-1-2-代数元和超越元"><a href="#3-1-2-代数元和超越元" class="headerlink" title="3.1.2 代数元和超越元"></a>3.1.2 代数元和超越元</h3><h4 id="3-1-2-1-基本概念"><a href="#3-1-2-1-基本概念" class="headerlink" title="3.1.2.1 基本概念"></a>3.1.2.1 基本概念</h4><p>代数元：是一个系数属于 $F$ 的某个首一多项式的根</p><p>超越元：不是任何一个系数属于 $F$ 的某个首一多项式的根</p><p>代数元 $\alpha$ 在 $F$ 上的既约多项式 $f$ : $F[x]$ 上的首一、次数最低、以 $\alpha$ 为根的多项式</p><p>$=&gt;$ 由 $f$ 生成的 $F[x]$ 的主理想是一个极大理想</p><p>$\alpha$ 在 $F$ 上的次数 : 既约多项式 $f$ 的次数</p><p>扩域 $K/F$ 的次数 $[K:F]$：$K$ 作为 $F$ 向量空间 $_F K$ 的维数</p><p>$ \ $</p><p><strong>次数的乘法性质</strong>：$F\subset K\subset L,\quad [L:F]=[L:K]\cdot [K:F]$</p><p>$ \ $</p><h4 id="3-1-2-2-相关命题"><a href="#3-1-2-2-相关命题" class="headerlink" title="3.1.2.2 相关命题"></a>3.1.2.2 相关命题</h4><ul><li><p>扩域的一个元素 $\alpha$ 是 $F$ 上的代数元 $\iff$ 扩域的次数 $[F(\alpha):F]$ 有限</p></li><li><p>$K/F$ 为 $n$ 次有限扩域，$\alpha \in K$ $=&gt;$ $\alpha$ 在 $F$ 上是代数的，且其在 $F$ 上的次数为 $n$</p></li><li><p>令 $F\subset F’\subset L$ 是域. 如果 $L$ 中元素 $\alpha$ 是 $F$ 上的代数元，则它也是 $F’$ 上的代数元。如果 $\alpha$ 在 $F$ 上的次数为 $d$ , 则它在 $F’$ 上的次数最多为 $d$。</p></li><li><p>由有限多个代数元生成的扩域是有限扩域，一个有限扩域由有限多个代数元生成</p></li><li><p>如果 $K$ 是 $F$ 的扩域，则 $K$ 中所有 $F$ 上的代数元的集合构成 $K$ 的子域 （代数元加减乘除还是代数元）</p></li><li><p>设 $K$ 是 $F$ 上的素数 $p$ 次扩域， $\alpha \in K,\alpha\notin F$, 则 $\alpha$ 在 $F$ 上的次数为 $p$ 且 $K=F(\alpha)$ </p><p>$ \ $</p></li></ul><p>令 $\alpha$ 是扩域 $K/F$ 上的元素，$\alpha$ 是 $F$ 上的代数元，令 $f$ 是 $\alpha$ 在 $F$ 上的既约多项式。</p><ul><li><p>$F[\alpha]\cong F(\alpha)$ , 更一般：$F[\alpha_1,\cdots, \alpha_n]\cong F(\alpha_1,\cdots, \alpha_n)\qquad pf:Bezout $</p></li><li><p>$[F(\alpha):F]=deg$ $f$ </p><p>$ \ $</p></li></ul><h3 id="3-1-3-尺规作图"><a href="#3-1-3-尺规作图" class="headerlink" title="3.1.3 尺规作图"></a>3.1.3 尺规作图</h3><p>令 $a$ 是一个可构造的实数，则 $a$ 是一个代数数，且它在 $\mathbf{Q}$ 上的次数是 $2$ 的幂。 （“平方根塔”）</p><p>$ \ $</p><h3 id="3-1-4-扩域中的带余除法"><a href="#3-1-4-扩域中的带余除法" class="headerlink" title="3.1.4 扩域中的带余除法"></a>3.1.4 扩域中的带余除法</h3><p>设 $f$ 和 $g$ 是系数属于 $F$ 的多项式， $f\neq 0$，设 $K$ 是 $F$ 的扩域。</p><ul><li>在 $F[x]$ 和 $K[x]$ 中，由 $f$ 对 $g$ 作的带余除法得到相同的答案</li><li>在 $K[x]$ 中 $f$ 整除 $g$ $\iff$ 在 $F[x]$ 中 $f$ 整除 $g$  </li><li>如果 $f$ 和 $g$ 在 $K$ 上有公共根，则它们在 $F[x]$ 中不是互素的。如果 $f$ 和 $g$ 在 $K[x]$ 中不是互素的，则存在一个扩域 $L$ ，它们在其中有公共根</li><li>如果 $f$ 在 $F[x]$ 中是既约的且 $f$ 和 $g$ 在 $K$ 中有公共根，则 $f$ 在$F[x]$ 中整除 $g$  </li></ul><p>$ \ $</p><h3 id="3-1-5-重根"><a href="#3-1-5-重根" class="headerlink" title="3.1.5 重根"></a>3.1.5 重根</h3><p>令 $f(x)$ 是一个系数属于 $F$ 的多项式.</p><p>存在 $K/F$ ，在其上 $f(x)$ 有重根$\iff$ $f$ 和 $f’$ 不互素</p><p>$ \ $</p><p>$=&gt;$ 若 $f(x)$ 是既约的，且 $char$$F=0$，则 $f$ 在 $F$ 的任意扩域中没有重根</p><p>$ \ $</p><h3 id="3-1-6-有限域"><a href="#3-1-6-有限域" class="headerlink" title="3.1.6 有限域"></a>3.1.6 有限域</h3><p> $K$ 是有限域 ，则 $char$ $K$ $= p$（素数），$|K|=p^r\triangleq q$</p><h4 id="相关命题"><a href="#相关命题" class="headerlink" title="相关命题"></a>相关命题</h4><ul><li>$ K $ 的元素是多项式 $x^q-x $ 的根</li><li>在素域 $F=\mathbf{F_p}$ 上的多项式 $x^q-x$ 的既约因子是次数整除 $r$ 的 $F[x]$ 上的既约多项式</li><li>所有的 $q$ 阶域是同构的</li><li>$ K$ 的非零元素的乘法群 $K^{\times}$ 是一个 $q-1$ 阶循环群</li><li>$K$ 内含有 $p^k$ 阶子域当且仅当 $k$ 整除 $r$</li><li>多项式 $x^q-x$ 在 $F$ 的任何扩域上没有重根 （导数等于 $-1$ ，与 $x^q-x$ 无公共根）</li><li>在多项式环 $F[x,y]$ 中，$(x+y)^q=x^q+y^q$</li></ul><p>$ \ $</p><h2 id="4-Galois​-理论-（部分）"><a href="#4-Galois​-理论-（部分）" class="headerlink" title="4  Galois​ 理论 （部分）"></a>4  Galois​ 理论 （部分）</h2><h3 id="4-1-基本概念"><a href="#4-1-基本概念" class="headerlink" title="4.1 基本概念"></a>4.1 基本概念</h3><ul><li>分裂域 (splitting field) ： $F$ 上 $f$ 的分裂域是扩域 $K/F$ ，使得 $f$ 在 $K$ 里完全分裂 $f=(x-\alpha_1)\cdots (x-\alpha_n),\quad \alpha_i\in K$, 且 $K=F(\alpha_1,\cdots,\alpha_n)$</li><li>$F$$-$同构：令 $K$ 与 $K’$ 是 $F$ 的域扩张，$\sigma : K\to K’$，为限制在子域 $F$ 上为恒等映射的同构</li><li>$Galois$ 群：有限扩张 $K$ 的 $F-$自同构构成一个群，称为 $K$ 在 $F$ 上的 $Galois$ 群 $Gal(K/F)$</li><li>$Galois$扩张：$|Gal(K/F)|=[K:F]$ 的扩张</li><li>固定域：令 $H$ 是域 $K$ 的自同构群，$H$ 的固定域 $K^H$ 是由 $K$ 的每个群元素固定不动的元素集合：$K^H={\alpha \in K|\sigma(\alpha)=\alpha,\sigma\in H }$</li></ul><h3 id="4-2-相关定理"><a href="#4-2-相关定理" class="headerlink" title="4.2 相关定理"></a>4.2 相关定理</h3><h4 id="4-2-1-Galois​-扩张的特征性质"><a href="#4-2-1-Galois​-扩张的特征性质" class="headerlink" title="4.2.1 Galois​ 扩张的特征性质"></a>4.2.1 Galois​ 扩张的特征性质</h4><p>令 $K/F$ 是有限扩张，设 $G$ 为它的 $Galois$ 群</p><p>$K/F$  is  $Galois$</p><p>$\iff$ $|G|=[K:F]$</p><p>$\iff$ 固定域 $K^G$ 等于 $F$</p><p>$\iff$ $K$ 是 $F$ 的分裂域</p><h4 id="4-2-2-主要定理-The-Main-Theorem"><a href="#4-2-2-主要定理-The-Main-Theorem" class="headerlink" title="4.2.2 主要定理 The Main Theorem"></a>4.2.2 主要定理 The Main Theorem</h4><p>令 $K$ 是域 $F$ 的 $Galois$ 扩张，设 $G$ 为它的 $Galois$ 群，则在 $G$ 的子群与中间域之间存在一一对应，这个对应把子群 $H$ 与它的固定域、中间域 $L$ 与 $K$ 在 $L$ 上的 $Galois$ 群结合起来.</p><p>$\Phi:H\rightsquigarrow K^H$  和 $ \Psi:L\rightsquigarrow G(K/L)$ 是互逆的。</p><p>即： $\Phi \circ \Psi (L)=L$, $\Psi\circ\Phi (H)=H$</p><h4 id="4-2-3-应用"><a href="#4-2-3-应用" class="headerlink" title="4.2.3 应用"></a>4.2.3 应用</h4><p> $K/F=F(\alpha)/F$ 上的最小多项式为:</p><p>$f(x)=\displaystyle\prod\limits_{\sigma\in Gal(K/F)} (x-\sigma(\alpha))$</p><p>$ \ $</p><p><strong>例：</strong></p><p>Let $N\geqslant 3$ ，$\xi_N$ is a primitive $n$ th root of unit.</p><p>Assume $\sigma(\xi_N)=\xi_N ^a$ where $(a,N)=1$</p><p>we have :  $\phi: Gal(\mathbb{Q}(\xi_N)/\mathbb{Q})\to (\mathbb{Z}/N\mathbb Z)^{\times}$  is bijective.</p><p>$ \phi $ is injective since $\ker \phi=1$ （identity mapping)</p><p>$\phi$ is surjective since $\forall p,(p,N)=1 ,\exists \sigma\in Gal(\mathbb{Q}(\xi_N)/\mathbb{Q}),\quad s.t.\quad \sigma(\xi_N)=\xi_N^p$</p><p>$\because \mathbb{Q}(\xi_N)$ is the splitting field of $x^N-1$ </p><p>$\therefore \mathbb{Q}(\xi_N)/\mathbb{Q}$ is $Galois$ </p><p>$\therefore [\mathbb{Q}(\xi_N):\mathbb{Q}]=|Gal(\mathbb{Q}(\xi_N)/\mathbb{Q})|=|(\mathbb{Z}/N\mathbb Z)^{\times}|=\varphi(N)$</p><p>And the unit polynomial is :</p><p> $f(x)=\displaystyle\prod\limits<em>{\sigma\in Gal(\mathbb{Q}(\xi_N)/\mathbb{Q})}(x-\sigma(\xi_N))=\displaystyle\prod\limits</em>{(a,n)=1}(x-\xi_N^a)$ </p>]]></content>
      
      
      <categories>
          
          <category> Mathematics </category>
          
          <category> Algebra </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 代数 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>搭建此博客过程中的心得</title>
      <link href="/2020/01/19/Other%20Things/%E6%90%AD%E5%BB%BA%E6%AD%A4%E5%8D%9A%E5%AE%A2%E8%BF%87%E7%A8%8B%E4%B8%AD%E7%9A%84%E5%BF%83%E5%BE%97/"/>
      <url>/2020/01/19/Other%20Things/%E6%90%AD%E5%BB%BA%E6%AD%A4%E5%8D%9A%E5%AE%A2%E8%BF%87%E7%A8%8B%E4%B8%AD%E7%9A%84%E5%BF%83%E5%BE%97/</url>
      
        <content type="html"><![CDATA[<h1 id="搭建此博客过程中的心得"><a href="#搭建此博客过程中的心得" class="headerlink" title="搭建此博客过程中的心得"></a>搭建此博客过程中的心得</h1><h2 id="1-Hexo框架"><a href="#1-Hexo框架" class="headerlink" title="1. Hexo框架"></a>1. <a href="https://zhuanlan.zhihu.com/p/26625249" target="_blank" rel="noopener">Hexo框架</a></h2><p>看到“绑定域名”之前就可以了。</p><p>理解以下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs php+HTML">hexo clean % 清除当前缓存<br>hexo g -d % generate 生成博客<br>hexo d % deploy 将博客部署到GitHub<br>hexo s % hexo server的简写 之后可以在localhost上访问<br>hexo new &quot;bulabula&quot; %生成名为bulabula的md文件（一篇新文章）<br></code></pre></td></tr></table></figure><h2 id="2-购买域名"><a href="#2-购买域名" class="headerlink" title="2. 购买域名"></a>2. 购买域名</h2><p>选择了阿里云，发现域名买起来也挺方便的。</p> <a id="more"></a><h2 id="3-域名与GitHub-Page-绑定"><a href="#3-域名与GitHub-Page-绑定" class="headerlink" title="3. 域名与GitHub Page 绑定"></a>3. 域名与GitHub Page 绑定</h2><p>这里踩了不少坑。有的文章跟着走下来却没有效果。最后是跟着<a href="https://cloud.tencent.com/developer/article/1037114" target="_blank" rel="noopener">这篇文章</a>的域名解析和GitHub解析部分完成的。还是要用SSH。只需要做一个A类型和一个CNAME类型两个域名解析。</p><p>需要域名和GitHub Page双向绑定。</p><p>（1）输入longqianh.github.io。由于在setting里的设置，GitHub Page会帮我重定向到我购买的longqianh.com，然后DNS服务器解析域名，将 longqianh.com 解析为我GitHub Page 的IP地址，然后得以访问。<a href="https://blog.csdn.net/gui951753/article/details/83070180" target="_blank" rel="noopener">但是可能是一个IP可能对应多个web地址，直接访问IP地址是不行的</a>。</p><p>（2）输入longqianh.com。DNS服务器解析到GitHub Page的IP地址进行访问。</p><p>我似乎还没有理解在域名解析那里设置CNAME所起的作用。</p><h2 id="4-主题设置"><a href="#4-主题设置" class="headerlink" title="4. 主题设置"></a>4. 主题设置</h2><p>我从<a href="https://hexo.io/themes/" target="_blank" rel="noopener">各种hexo的主题</a>里选择了 Ayer 主题， 然后修改.yml文件、一些.ejs文件，然后更换了一些图片。从Google的主题上拿下来了一个钢铁侠的超好看背景图片，然后从一些icon网站下了一些钢铁侠的图标，用PS反相操作一下，把黑色反转成白色以突出，就成了现在的模样。</p><h2 id="5-一些常见问题"><a href="#5-一些常见问题" class="headerlink" title="5. 一些常见问题"></a>5. 一些常见问题</h2><ul><li><p>hexo g 失败：</p><p>‘YAMLException: can not read a block mapping entry; a multiline key may not be an implicit key at line 6, column 1’</p></li></ul><p>解决：</p><p>title: hexo 注意冒号后面要加空格</p><p>categories 下面的’-’ 号，后面也要加空格再写字</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>监督学习</title>
      <link href="/2020/01/19/Computer-Sciencs/Supvised%20Learning/"/>
      <url>/2020/01/19/Computer-Sciencs/Supvised%20Learning/</url>
      
        <content type="html"><![CDATA[<h1 id="Supvised-Learning"><a href="#Supvised-Learning" class="headerlink" title="Supvised Learning"></a>Supvised Learning</h1><h2 id="1-Linear-Regression"><a href="#1-Linear-Regression" class="headerlink" title="1.Linear Regression"></a>1.Linear Regression</h2><p>output hypotheses function:    <script type="math/tex">h(x)= \theta^Tx</script></p><p>$x$  is the input vector: <script type="math/tex">x=(x_1,x_2,\cdots,x_n)^T</script></p><p>$\theta$  is the parameter vector:    <script type="math/tex">\theta=(\theta_1,\theta_2,\cdots,\theta_n)^T</script></p><p>$y$  is the training output </p><p>$X$ is the training input matrix:   <script type="math/tex">X= (x^{(1)},x^{(2)},\cdots,x^{(m)})</script></p><p>$Y$ is the training output matrix:    <script type="math/tex">Y=(y^{(1)},y^{(2)},\cdots,y^{(m)})</script></p><p>$\ $ </p><h3 id="LMS-algorithm"><a href="#LMS-algorithm" class="headerlink" title="LMS algorithm"></a>LMS algorithm</h3><ul><li><p>cost function:    </p><script type="math/tex; mode=display">J(\theta)=\frac{1}{2}\parallel{\theta^T X-Y}\parallel^2\\        or : J(\theta)=\frac{1}{2}\sum\limits_{i=1}^{m}(h(x^{(i)})-y^{(i)})^2        \notag</script><p>use <strong>matrix derivative</strong> to minimize $J$     </p></li><li><p>gradient descent :    </p></li></ul><script type="math/tex; mode=display">\theta_j := \theta_j-\alpha \frac{\partial}{\partial\theta_j}J(\theta)\notag</script> <a id="more"></a><ul><li>Newton’s method:    <script type="math/tex; mode=display">\theta:=\theta-H^{-1}\nabla_\theta l(\theta)\notag</script>where $H$ is the Hessian: <script type="math/tex">\displaystyle H_{ij}=\frac{\partial^2l(\theta)}{\partial\theta_i\partial\theta_j}</script></li></ul><p>​      </p><h3 id="Locally-Weighted-Linear-Regression"><a href="#Locally-Weighted-Linear-Regression" class="headerlink" title="Locally Weighted Linear Regression"></a>Locally Weighted Linear Regression</h3><p>cost function:   <script type="math/tex">\displaystyle J(\theta)=\sum\limits_i w^{(i)}(y^{(i)}-\theta^T x^{(i)})^2</script></p><p>weight $w$ :      <script type="math/tex">w^{(i)}=exp(-(x^{(i)}-x)^2/2\tau^2)</script></p><h2 id="2-Generalized-Linear-Models-GLM"><a href="#2-Generalized-Linear-Models-GLM" class="headerlink" title="2. Generalized Linear Models (GLM)"></a>2. Generalized Linear Models (GLM)</h2><ul><li><h3 id="The-exponential-family"><a href="#The-exponential-family" class="headerlink" title="The exponential family"></a>The exponential family</h3></li></ul><script type="math/tex; mode=display">p(y;\eta)=b(y)\exp(\eta^T T(y)-a(\eta))</script><p>  where $\eta$  is the canonical parameter</p><ul><li><h4 id="Bernoulli-distribution"><a href="#Bernoulli-distribution" class="headerlink" title="Bernoulli distribution"></a>Bernoulli distribution</h4></li><li><h4 id="Gaussian-distribution"><a href="#Gaussian-distribution" class="headerlink" title="Gaussian distribution"></a>Gaussian distribution</h4></li><li><h4 id="Possion-distribution"><a href="#Possion-distribution" class="headerlink" title="Possion distribution"></a>Possion distribution</h4></li><li><h4 id="Logistic-Regression"><a href="#Logistic-Regression" class="headerlink" title="Logistic Regression"></a>Logistic Regression</h4><script type="math/tex; mode=display">h(x)=g(\theta^T x)=1/(1+e^{-\theta^T x})</script></li></ul><p> To get the parameters, assume :</p><script type="math/tex; mode=display">P(y=1| x;\theta)=h(x)</script><script type="math/tex; mode=display">P(y=0|x;\theta)=1-h(x)</script><p>  then:</p><script type="math/tex; mode=display">L(\theta)=p(\vec{y}|X;\theta)</script><script type="math/tex; mode=display">=\prod\limits_{i=1}^m p(y^{(i)}|x^{(i)};\theta)$$   $$=\prod\limits_{i=1}^m (h(x^{(i)})^{y^{(i)}})(1-h(x^{(i)}))^{1-y^{(i)}}</script><p>  to maximize the likelihood, we can use gradient descent again.</p><ul><li><h4 id="Softmax-Regression"><a href="#Softmax-Regression" class="headerlink" title="Softmax Regression"></a>Softmax Regression</h4><p>Multi-output $\vec{y}$</p><p>$p(y=i|x;\theta)=\frac{e^\eta<em>i}{\sum</em>{j=1}^k e^{\eta_j}}$</p></li></ul><h3 id="✨Common-method"><a href="#✨Common-method" class="headerlink" title="✨Common method"></a>✨Common method</h3><p>  <strong>Step 1</strong>  :    Assume a distribution</p><p>  <strong>Step 2</strong> :     Fit the GLM and get  $\eta$  as well as mean $E(y;\eta)$</p><p>  in GLM, $\eta$  is assumed as $\theta^T x$</p><p>  $h(x)=E(y;\eta)=E(y|x;\theta)$</p><p>  <strong>Step 3</strong>    :  Estimate the parameter</p><p>  Maximize  the likelihood function $L(\theta)=p(y|x)$ and get $\theta$</p><h2 id="3-Generative-Learning-algorithms"><a href="#3-Generative-Learning-algorithms" class="headerlink" title="3. Generative Learning algorithms"></a>3. Generative Learning algorithms</h2><ul><li><h4 id="Gaussian-discriminant-analysis-多元高斯分布"><a href="#Gaussian-discriminant-analysis-多元高斯分布" class="headerlink" title="Gaussian discriminant analysis   多元高斯分布"></a>Gaussian discriminant analysis   <a href="https://zhuanlan.zhihu.com/p/58987388" target="_blank" rel="noopener">多元高斯分布</a></h4></li><li><h4 id="Naive-Bayes-朴素贝叶斯"><a href="#Naive-Bayes-朴素贝叶斯" class="headerlink" title="Naive Bayes        朴素贝叶斯"></a>Naive Bayes        <a href="https://zhuanlan.zhihu.com/p/25493221" target="_blank" rel="noopener">朴素贝叶斯</a></h4></li></ul>]]></content>
      
      
      <categories>
          
          <category> Computer Science </category>
          
          <category> Machine Learning </category>
          
      </categories>
      
      
        <tags>
            
            <tag> notes </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Computer-Sciencs/HTML学习</title>
      <link href="/2020/01/18/Computer-Sciencs/HTML%E5%AD%A6%E4%B9%A0/"/>
      <url>/2020/01/18/Computer-Sciencs/HTML%E5%AD%A6%E4%B9%A0/</url>
      
        <content type="html"><![CDATA[<h1 id="HTML-Hyper-Text-Markup-Language"><a href="#HTML-Hyper-Text-Markup-Language" class="headerlink" title="HTML: Hyper Text Markup Language"></a>HTML: Hyper Text Markup Language</h1><p>速查：<a href="https://www.w3school.com.cn/tags/att_standard_id.asp" target="_blank" rel="noopener">https://www.w3school.com.cn/tags/att_standard_id.asp</a></p>]]></content>
      
      
      <categories>
          
          <category> Computer Science </category>
          
          <category> Web </category>
          
          <category> html </category>
          
      </categories>
      
      
    </entry>
    
    
  
  
</search>
